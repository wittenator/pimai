{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wittenator/pimai/blob/master/src/notebook/src/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90gWsaxMXxiK",
        "colab_type": "code",
        "outputId": "6fa14b54-ddbf-4012-ee13-d9393f2b7dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  !pip install torch torchvision skorch\n",
        "  !pip install hypertools\n",
        "  colab = True\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/1e/cc4e1f23cd1faab06672f309e0857294aaa80c5f84670f4d3d19b08ab10b/skorch-0.7.0-py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.6)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.1)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.7.0\n",
            "Collecting hypertools\n",
            "  Downloading https://files.pythonhosted.org/packages/74/85/94f7f6908646fe19fbd36dbcab7e5a5861255f64f4629367dbc52b538a36/hypertools-0.6.2.tar.gz\n",
            "Collecting PPCA>=0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/16/7f/7195bf3742e19076a21a9c3250a4f11c87153bb4ea3dcaf1077678383b76/ppca-0.0.4-py3-none-any.whl\n",
            "Collecting scikit-learn<0.22,>=0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from hypertools) (0.25.3)\n",
            "Requirement already satisfied: seaborn>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from hypertools) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from hypertools) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from hypertools) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from hypertools) (1.17.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hypertools) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from hypertools) (2.21.0)\n",
            "Collecting deepdish\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/39/2a47c852651982bc5eb39212ac110284dd20126bdc7b49bde401a0139f5d/deepdish-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hypertools) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.19.1->hypertools) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->hypertools) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->hypertools) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->hypertools) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->hypertools) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->hypertools) (2.4.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->hypertools) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->hypertools) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->hypertools) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->hypertools) (2019.11.28)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from deepdish->hypertools) (3.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->hypertools) (42.0.2)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->deepdish->hypertools) (2.7.1)\n",
            "Building wheels for collected packages: hypertools\n",
            "  Building wheel for hypertools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hypertools: filename=hypertools-0.6.2-cp36-none-any.whl size=46622 sha256=2ef884028b0400dc0e5906b4320c46a5932698ac932be470fc06fd5e47ef9bd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/31/3a/0a3f26ae77857ae19ee5947fd2ee9bf34249fcd9c6c90636c2\n",
            "Successfully built hypertools\n",
            "Installing collected packages: PPCA, scikit-learn, deepdish, hypertools\n",
            "  Found existing installation: scikit-learn 0.22.1\n",
            "    Uninstalling scikit-learn-0.22.1:\n",
            "      Successfully uninstalled scikit-learn-0.22.1\n",
            "Successfully installed PPCA-0.0.4 deepdish-0.3.6 hypertools-0.6.2 scikit-learn-0.21.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPMgseDXxiZ",
        "colab_type": "code",
        "outputId": "ecb37feb-2897-45a5-e7d2-dddaed6d70bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from datetime import datetime\n",
        "\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "from torch.distributions import *\n",
        "\n",
        "import skorch\n",
        "import numpy as np\n",
        "import hypertools as hyp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "#torch.autograd.set_detect_anomaly(True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/hypertools/plot/__init__.py:10: UserWarning: Could not switch backend to TkAgg.  This may impact performance of the plotting functions.\n",
            "  warnings.warn('Could not switch backend to TkAgg.  This may impact performance of the plotting functions.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaYNKNJqXxip",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koWH_sFdXxit",
        "colab_type": "code",
        "outputId": "fe691188-d3fd-4ecf-d4bd-416d9bf42caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(use_cuda)\n",
        "\n",
        "kwargs = {'num_workers': cpu_count(), 'pin_memory': True} if use_cuda else {}\n",
        "if not colab:\n",
        "  train_loader = DataLoader(Subset(\n",
        "      datasets.MNIST('/data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), indices=range(1000)),\n",
        "      batch_size=64, shuffle=True, **kwargs)\n",
        "  test_loader = DataLoader(Subset(\n",
        "      datasets.MNIST('/data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), indices=range(1000)),\n",
        "      batch_size=1000, shuffle=True, **kwargs)\n",
        "else:\n",
        "  train_loader = DataLoader(\n",
        "      datasets.MNIST('/data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "      batch_size=128, shuffle=True, **kwargs)\n",
        "  test_loader = DataLoader(\n",
        "      datasets.MNIST('/data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        #transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "      batch_size=1000, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8720656.22it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz to /data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 129980.66it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2121290.44it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49262.62it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbmJnimKXxi3",
        "colab_type": "text"
      },
      "source": [
        "## Generic autoencoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vnseljiXxi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        now = datetime.now()\n",
        "        current_time = now.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        self.writer = SummaryWriter(log_dir=\"/data/runs/\"+current_time)\n",
        "        self.embeddings = []\n",
        "        self.embedding_labels =[]\n",
        "    \n",
        "    def trains(self, device, train_loader, optimizer, epoch):\n",
        "        self.train()\n",
        "        loss_sum = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = self.compute_loss_train(data, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()\n",
        "            if batch_idx % 10 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "            self.writer.add_scalar('Loss/train', loss.item(), epoch*len(train_loader)+batch_idx)\n",
        "            \n",
        "    def tests(self, device, test_loader):\n",
        "        self.eval()\n",
        "        test_loss = 0\n",
        "        recon = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                loss, output = self.compute_loss_test(data, target)\n",
        "                test_loss += loss\n",
        "                recon += F.binary_cross_entropy_with_logits(output, data.view(-1, 784), reduction='none').sum(axis=1).mean()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        recon /= len(test_loader.dataset)\n",
        "\n",
        "        print('\\nTest set: Average loss: {:.4f}, Reconstruction error: {}\\n'.format(\n",
        "            test_loss, recon))\n",
        "        \n",
        "    def add_embedding(self, loader):\n",
        "        with torch.no_grad():\n",
        "            labels = []\n",
        "            embs = []\n",
        "            for data, label in loader:\n",
        "                data, label = data.to(device), label.to(device)\n",
        "                labels.append(label)\n",
        "                recon_batch, a, b = self(data)\n",
        "                emb = self.reparameterize(a,b)\n",
        "                embs.append(emb)\n",
        "            self.embeddings.append(torch.cat(tuple(embs), dim=0).cpu().numpy())\n",
        "            self.embedding_labels = torch.cat(tuple(labels), dim=0).cpu().numpy()\n",
        "            \n",
        "    def visualize_embeddings(self, epoch):\n",
        "        hyp.plot(self.embeddings[epoch], '.', hue=self.embedding_labels, reduce='TSNE', ndims=2, save_path=f'/data/visualizations/{self.__class__.__name__}-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.svg' if not colab else None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca_SLALTXxjC",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qKCWvCFXxjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleAutoencoder(Autoencoder):\n",
        "    def __init__(self):\n",
        "        super(SimpleAutoencoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output       \n",
        "    \n",
        "    def compute_loss_train(self, data, target):\n",
        "        output = self(data)\n",
        "        return F.nll_loss(output, target)\n",
        "    \n",
        "    def compute_loss_test(self, data, target):\n",
        "        output = self(data)\n",
        "        return F.nll_loss(output, target, reduction='sum').item(), output  # sum up batch loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTS4EVR9XxjN",
        "colab_type": "code",
        "outputId": "d325c658-d189-4f96-c58a-64a59c7ac3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "model = SimpleAutoencoder().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "# plot model\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# write to tensorboard\n",
        "#writer.add_image('mnist_images', img_grid)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1)\n",
        "for epoch in range(1, 14 + 1):\n",
        "    model.trains(device, train_loader, optimizer, epoch)\n",
        "    model.tests(device, test_loader)\n",
        "    scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2eebc719d3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2b21ab3cdbc4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSimpleAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleAutoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e0740c23bfd9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/runs/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# and recreated later as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m_get_file_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             self.file_writer = FileWriter(self.log_dir, self.max_queue,\n\u001b[0;32m--> 252\u001b[0;31m                                           self.flush_secs, self.filename_suffix)\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpurge_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         self.event_writer = EventFileWriter(\n\u001b[0;32m---> 62\u001b[0;31m             log_dir, max_queue, flush_secs, filename_suffix)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         self._file_name = os.path.join(logdir, \"events.out.tfevents.%010d.%s.%s.%s\" %\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m           \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_import_hooks/_tensorflow.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m\"\"\"Loads Tensorflow normally and emits a notification.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpreviously_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtf_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     if (tf_module.__version__.startswith('1') and\n",
            "\u001b[0;32m/usr/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mC_BUILTIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_package\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# We still need all the names that are toplevel on tensorflow_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# In V1 API we need to print deprecation messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msysconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muser_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/_api/v1/tpu/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbfloat16_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_replica_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWmNtPJBXxjS",
        "colab_type": "text"
      },
      "source": [
        "## Gaussian Variational Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2yfQy7XxjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(Autoencoder):\n",
        "    def __init__(self, k=20):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, k)\n",
        "        self.fc22 = nn.Linear(400, k)\n",
        "        self.fc3 = nn.Linear(k, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        #x = self.conv1(x)\n",
        "        #x = F.relu(x)\n",
        "        #x = self.conv2(x)\n",
        "        #x = F.max_pool2d(x, 2)\n",
        "        #x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "    \n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "\n",
        "        # see Appendix B from VAE paper:\n",
        "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "        # https://arxiv.org/abs/1312.6114\n",
        "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        return BCE #+ KLD\n",
        "    \n",
        "    def compute_loss_train(self, data, target):\n",
        "        recon_batch, mu, logvar = self(data)\n",
        "        return self.loss_function(recon_batch, data, mu, logvar)\n",
        "    \n",
        "    def compute_loss_test(self, data, target):\n",
        "        recon_batch, mu, logvar = self(data)\n",
        "        return self.loss_function(recon_batch, data, mu, logvar).item(), recon_batch  # sum up batch loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLJeo93BXxjf",
        "colab_type": "code",
        "outputId": "97ee7ecd-60f7-485d-87b6-7ac12e33b6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vae = VAE(k=20).to(device)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1)\n",
        "for epoch in range(1, 100 + 1):\n",
        "    vae.trains(device, train_loader, optimizer, epoch)\n",
        "    vae.tests(device, test_loader)\n",
        "    vae.add_embedding(test_loader)\n",
        "    scheduler.step()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 70431.750000\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 35830.601562\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 28170.546875\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 28071.683594\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 26515.425781\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 25353.722656\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 24022.806641\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 24011.886719\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 22916.126953\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 22421.082031\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 19705.632812\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 18799.636719\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 18313.123047\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 18248.246094\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 16741.060547\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 16719.931641\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 16725.234375\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 15850.042969\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 15048.493164\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 14748.677734\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 15398.705078\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 15059.375000\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 14916.373047\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 14929.910156\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 14636.726562\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 14438.498047\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 14689.480469\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 13720.970703\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 12956.796875\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 12542.199219\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 12635.694336\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 13269.309570\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 13086.634766\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 12337.099609\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 12168.070312\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 12317.841797\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 13071.635742\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 12308.214844\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 12325.199219\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 12241.533203\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 11225.359375\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 11409.849609\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 12084.056641\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 11519.503906\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 11449.529297\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 11611.269531\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 10971.021484\n",
            "\n",
            "Test set: Average loss: 87.7450, Reconstruction error: 0.5288227796554565\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 11317.097656\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 10800.674805\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 11677.367188\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 11880.931641\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 11085.065430\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 11419.446289\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 11062.591797\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 10780.152344\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 10890.674805\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 11546.462891\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 11898.244141\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 10905.972656\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 11739.029297\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 11750.955078\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 11117.960938\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 11454.893555\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 10820.933594\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 10629.196289\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 10464.922852\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 11577.924805\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 10527.560547\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 11607.891602\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 11249.503906\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 11379.872070\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 11189.669922\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 11151.138672\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 11239.234375\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 11097.038086\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 10778.253906\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 10541.486328\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 10930.862305\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 11107.229492\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 11225.232422\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 10704.058594\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 10764.519531\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 10900.308594\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 11266.290039\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 10934.540039\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 10771.605469\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 10461.531250\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 10823.364258\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 11256.630859\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 10615.151367\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 10757.000000\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 11325.066406\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 10822.070312\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 11477.373047\n",
            "\n",
            "Test set: Average loss: 84.4520, Reconstruction error: 0.5274091362953186\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 11678.065430\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 10837.577148\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 10646.439453\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 10879.927734\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 10595.834961\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 10437.500000\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 11247.179688\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 11199.793945\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 10563.073242\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 10873.164062\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 11627.853516\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 10424.703125\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 11028.502930\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 10491.230469\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 11062.598633\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 10666.918945\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 11148.622070\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 11075.964844\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 10694.828125\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 10633.522461\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 11038.953125\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 10983.427734\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 10313.453125\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 11086.079102\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 11080.837891\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 11178.082031\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 11063.998047\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 10786.316406\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 10168.805664\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 11131.918945\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 10867.019531\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 11340.259766\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 10450.020508\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 11511.651367\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 11767.669922\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 10668.997070\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 10552.465820\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 11063.671875\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 10709.808594\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 10284.746094\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 10745.027344\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 10744.907227\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 10868.204102\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 10551.093750\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 10840.939453\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 11112.946289\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 10858.558594\n",
            "\n",
            "Test set: Average loss: 84.1121, Reconstruction error: 0.527429461479187\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 11002.240234\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 11560.435547\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 10479.822266\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 10450.555664\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 10964.402344\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 10702.119141\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 11165.556641\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 11607.835938\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 10958.339844\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 10396.508789\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 10935.835938\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 10978.156250\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 10354.087891\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 11567.900391\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 10483.858398\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 11004.149414\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 11328.198242\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 11370.406250\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 11612.509766\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 10388.160156\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 10740.974609\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 11150.694336\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 11545.605469\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 10715.841797\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 10491.230469\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 10839.536133\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 10930.370117\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 10792.181641\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 10607.363281\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 10841.213867\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 10741.302734\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 10810.738281\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 11740.266602\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 10738.365234\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 11021.326172\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 10688.726562\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 10532.032227\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 10713.922852\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 11146.925781\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 11449.071289\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 10903.560547\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 10935.382812\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 11210.083984\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 10796.907227\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 9865.058594\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 11068.347656\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 10982.733398\n",
            "\n",
            "Test set: Average loss: 84.0857, Reconstruction error: 0.527403712272644\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 10232.048828\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 11077.560547\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 10211.283203\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 10962.601562\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 11011.132812\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 11180.060547\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 11451.175781\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 10641.832031\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 10647.908203\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 10987.389648\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 10404.692383\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 10703.897461\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 10416.047852\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 11114.446289\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 11364.216797\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 11393.363281\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 11452.771484\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 10911.045898\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 10782.955078\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 10785.975586\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 10559.355469\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 10671.818359\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 10625.302734\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 10944.709961\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 10801.748047\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 10900.016602\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 10652.657227\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 11104.486328\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 10987.291992\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 10602.671875\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 11542.444336\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 10727.299805\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 10990.787109\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 10983.767578\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 11382.355469\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 10885.895508\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 11246.116211\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 11135.726562\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 11042.167969\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 10767.115234\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 10556.039062\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 10349.430664\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 10645.240234\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 10309.257812\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 10901.059570\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 11168.041992\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 10994.684570\n",
            "\n",
            "Test set: Average loss: 84.0835, Reconstruction error: 0.5274097323417664\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 10658.143555\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 11164.115234\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 11008.861328\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 10687.166016\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 10524.790039\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 10517.679688\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 10421.483398\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 10721.503906\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 11172.353516\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 10403.491211\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 11180.121094\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 11121.970703\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 10386.049805\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 10866.614258\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 10788.651367\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 10694.744141\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 10432.851562\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 10661.262695\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 10976.346680\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 10922.341797\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 10940.129883\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 11469.263672\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 10851.160156\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 10899.064453\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 11211.978516\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 11338.063477\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 11258.060547\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 10638.482422\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 11367.355469\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 10986.915039\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 10893.833984\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 11404.419922\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 10737.791016\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 10786.427734\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 11063.706055\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 10972.470703\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 10688.267578\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 10466.437500\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 10474.660156\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 10926.292969\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 11025.978516\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 11165.112305\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 11183.701172\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 10736.095703\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 11186.085938\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 11673.481445\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 11126.024414\n",
            "\n",
            "Test set: Average loss: 84.0827, Reconstruction error: 0.527410089969635\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 10502.707031\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 10772.876953\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 10819.304688\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 10996.652344\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 10780.676758\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 10796.550781\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 10254.705078\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 10951.419922\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 10746.884766\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 11282.591797\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 10798.405273\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 10583.710938\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 11211.720703\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 11213.097656\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 10725.427734\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 10673.386719\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 10373.630859\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 10932.519531\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 11359.273438\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 11391.792969\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 11048.557617\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 10388.937500\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 10510.109375\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 11223.215820\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 11014.234375\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 11166.670898\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 10650.287109\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 11067.019531\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 10252.145508\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 11118.541016\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 11254.479492\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 11031.824219\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 10563.781250\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 10834.925781\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 10843.663086\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 11108.686523\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 11298.192383\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 10936.520508\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 10636.701172\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 10681.683594\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 11355.012695\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 10912.458984\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 11170.693359\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 10733.292969\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 10420.789062\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 10744.645508\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 11223.929688\n",
            "\n",
            "Test set: Average loss: 84.0827, Reconstruction error: 0.5274097323417664\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 10688.051758\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 10585.593750\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 11217.246094\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 11192.605469\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 10650.931641\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 10980.924805\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 11334.437500\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 11040.170898\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 10874.595703\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 11345.170898\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 10703.857422\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 10611.314453\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 10748.640625\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 10246.837891\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 11037.740234\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 11436.543945\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 10177.160156\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 10792.636719\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 11201.287109\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 11251.350586\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 10921.376953\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 10818.973633\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 11358.754883\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 11190.639648\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 10635.911133\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 10581.819336\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 11488.614258\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 11123.916992\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 10831.800781\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 10694.183594\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 11029.910156\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 10545.617188\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 10720.185547\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 11329.129883\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 10415.756836\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 10758.766602\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 10512.896484\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 10426.904297\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 11032.147461\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 10977.022461\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 10610.867188\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 11010.003906\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 10577.499023\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 10854.666016\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 11297.155273\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 11001.758789\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 11309.861328\n",
            "\n",
            "Test set: Average loss: 84.0819, Reconstruction error: 0.5274091362953186\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 10745.466797\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 10577.584961\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 10233.576172\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 10901.717773\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 11147.721680\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 10677.722656\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 11097.996094\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 10947.881836\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 11763.080078\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 10513.944336\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 11041.468750\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 11244.663086\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 11028.485352\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 11012.935547\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 10810.724609\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 10983.736328\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 11180.240234\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 11220.361328\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 10933.472656\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 10962.201172\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 11077.375000\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 10672.390625\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 10663.739258\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 10951.392578\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 11048.556641\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 11161.710938\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 11456.647461\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 11190.804688\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 10817.708984\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 10783.546875\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 11301.417969\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 10650.351562\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 11217.478516\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 10972.650391\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 11396.839844\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 10818.798828\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 11168.132812\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 10598.945312\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 10968.853516\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 11321.231445\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 10457.594727\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 11125.212891\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 10626.551758\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 10841.337891\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 10826.746094\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 10674.033203\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 10427.681641\n",
            "\n",
            "Test set: Average loss: 84.0827, Reconstruction error: 0.5274090766906738\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 11195.539062\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 10994.812500\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 10230.402344\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 11085.638672\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 11139.412109\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 10907.031250\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 10753.428711\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 11136.708984\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 11206.720703\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 10449.665039\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 11194.353516\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 11381.339844\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 10689.797852\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 11313.208984\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 11142.683594\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 11688.907227\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 10223.266602\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 10444.637695\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 11185.568359\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 11197.253906\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 11023.688477\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 10502.272461\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 10641.066406\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 10932.874023\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 11077.102539\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 10442.437500\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 11353.674805\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 10534.386719\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 11342.868164\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 10832.869141\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 10939.934570\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 10751.291992\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 10415.119141\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 10637.203125\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 10792.669922\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 10766.156250\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 11039.659180\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 10736.445312\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 11212.068359\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 10705.717773\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 11306.108398\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 11090.927734\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 10372.498047\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 11160.523438\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 10774.472656\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 11011.247070\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 11196.011719\n",
            "\n",
            "Test set: Average loss: 84.0825, Reconstruction error: 0.5274097323417664\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 10444.308594\n",
            "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 11129.076172\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 11230.175781\n",
            "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 11298.273438\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 11333.495117\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 10835.880859\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 10512.970703\n",
            "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 11002.660156\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 10869.343750\n",
            "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 10693.842773\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 11150.205078\n",
            "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 11432.765625\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 10904.863281\n",
            "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 11039.583008\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 10902.854492\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 11193.818359\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 10846.106445\n",
            "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 10163.105469\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 10978.000977\n",
            "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 10906.497070\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 11312.978516\n",
            "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 10777.685547\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 11167.908203\n",
            "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 10704.173828\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 10890.658203\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 10486.945312\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 10995.314453\n",
            "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 11118.469727\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 11324.591797\n",
            "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 10768.982422\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 10755.730469\n",
            "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 11105.375000\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 10966.983398\n",
            "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 11308.464844\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 10521.101562\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 10648.154297\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 11324.689453\n",
            "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 11456.829102\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 11508.128906\n",
            "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 11436.613281\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 10569.460938\n",
            "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 11550.611328\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 11674.853516\n",
            "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 11103.539062\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 10235.016602\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 10944.767578\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 11228.986328\n",
            "\n",
            "Test set: Average loss: 84.0840, Reconstruction error: 0.527410626411438\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 11452.066406\n",
            "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 11406.384766\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 11280.669922\n",
            "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 11219.829102\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 10599.446289\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 11311.718750\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 10703.999023\n",
            "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 11170.564453\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 11398.316406\n",
            "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 10753.146484\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 10455.833984\n",
            "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 10734.516602\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 10753.759766\n",
            "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 11365.261719\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 11014.448242\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 10684.246094\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 10614.765625\n",
            "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 11334.976562\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 11018.007812\n",
            "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 10177.536133\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 11230.875000\n",
            "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 11082.669922\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 11203.913086\n",
            "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 11246.584961\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 10641.486328\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 11012.149414\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 10902.567383\n",
            "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 11453.166016\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 11201.309570\n",
            "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 10655.230469\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 10745.571289\n",
            "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 11005.703125\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 10824.838867\n",
            "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 11282.931641\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 11292.761719\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 10876.759766\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 10639.468750\n",
            "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 10660.787109\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 10276.713867\n",
            "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 10864.994141\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 11636.447266\n",
            "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 10549.900391\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 11115.300781\n",
            "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 10793.410156\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 10820.328125\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 11400.957031\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 10968.425781\n",
            "\n",
            "Test set: Average loss: 84.0838, Reconstruction error: 0.5274105668067932\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 10677.286133\n",
            "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 10985.271484\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 10487.947266\n",
            "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 10905.395508\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 10340.775391\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 10518.586914\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 10994.907227\n",
            "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 10446.611328\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 10868.638672\n",
            "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 10693.484375\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 11046.281250\n",
            "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 11134.696289\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 10692.814453\n",
            "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 10987.579102\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 10560.068359\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 10592.982422\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 11316.416016\n",
            "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 11108.386719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-31ca27e368bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d57ded6dc630>\u001b[0m in \u001b[0;36mtrains\u001b[0;34m(self, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmgcTeAXxjn",
        "colab_type": "code",
        "outputId": "3ae9e8ad-b232-408a-964e-e6975192791b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "vae.visualize_embeddings(-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXSIFSiKRSCTrkv8PPgGMLfVDf4kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ5hIOSTIJkZ",
        "colab_type": "code",
        "outputId": "5a7edf2e-85fe-4d42-f325-31038c1fbe78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sample = torch.randn(64, 20).to(device)\n",
        "sample = vae.decode(sample).reshape(64, 28, 28).cpu().detach().numpy()\n",
        "f, axarr = plt.subplots(8,8)\n",
        "for i in range(64):\n",
        "  axarr[i//8,i%8].imshow(sample[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAD8CAYAAABaZT40AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 64 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnhhJ8F5Xxjv",
        "colab_type": "text"
      },
      "source": [
        "## Stick-breaking process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P-mNDsMXxjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stickbreakingprocess(a, b):\n",
        "    eps = 10*torch.finfo(torch.float).eps\n",
        "    batch_size = a.size()[0]\n",
        "    \n",
        "    uniform_samples = Uniform(torch.tensor([eps]), torch.tensor([1.0-eps])).rsample(a.size()).squeeze() if not use_cuda else torch.cuda.FloatTensor(a.size(0), a.size(1)).uniform_().clamp(eps, 1.0-eps)\n",
        "    exp_a = torch.reciprocal(a)\n",
        "    exp_b = torch.reciprocal(b)\n",
        "    km = (1- uniform_samples.pow(exp_b) + eps).pow(exp_a)\n",
        "    \n",
        "    #no Nans are allowed in the matrix\n",
        "    #assert not torch.isnan(km).any().item()\n",
        "    \n",
        "    cumprods = torch.cat((torch.ones([batch_size, 1], device=device), torch.cumprod(1-km, axis=1)), dim=1)\n",
        "    sticks = cumprods[:,:-1]*km\n",
        "    sticks[:, -1] = 1- sticks[:, :-1].sum(axis=1) \n",
        "    return sticks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziPKTj5dXxj4",
        "colab_type": "code",
        "outputId": "96697f23-e8ff-4397-d3aa-b8048b7c6e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "stickbreakingprocess(torch.rand(10,20).to(device), torch.rand(10,20).to(device)).sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QheULZUTXxkB",
        "colab_type": "text"
      },
      "source": [
        "## Stick-breaking Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qp8w_wAXxkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SBVAE(Autoencoder):\n",
        "    def __init__(self, k):\n",
        "        super(SBVAE, self).__init__()\n",
        "        self.k = k\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 400)\n",
        "        self.fc21 = nn.Linear(400, self.k)\n",
        "        self.fc22 = nn.Linear(400, self.k)\n",
        "        \n",
        "        \n",
        "        self.fc3 = nn.Linear(self.k, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return F.softplus(self.fc21(h1)), F.softplus(self.fc22(h1))\n",
        "\n",
        "    def reparameterize(self, a, b):\n",
        "        return stickbreakingprocess(a, b)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return self.fc4(h3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a, b = self.encode(x)\n",
        "        z = self.reparameterize(a, b)\n",
        "        return self.decode(z), a, b\n",
        "    \n",
        "    def Beta(self, a,b):\n",
        "        return torch.exp(torch.lgamma(a) + torch.lgamma(b) - torch.lgamma(a+b))\n",
        "    \n",
        "    def loss_function(self, recon_x, x, a, b, prior_alpha, prior_beta):\n",
        "        BCE = F.binary_cross_entropy_with_logits(recon_x, x.view(-1, 784), reduction='none')\n",
        "        ab = (a*b)\n",
        "        kl = 1/(1+ab) * self.Beta(1/a, b)\n",
        "        kl += 1/(2+ab) * self.Beta(2/a, b)\n",
        "        kl += 1/(3+ab) * self.Beta(3/a, b)\n",
        "        kl += 1/(4+ab) * self.Beta(4/a, b)\n",
        "        kl += 1/(5+ab) * self.Beta(5/a, b)\n",
        "        kl += 1/(6+ab) * self.Beta(6/a, b)\n",
        "        kl += 1/(7+ab) * self.Beta(7/a, b)\n",
        "        kl += 1/(8+ab) * self.Beta(8/a, b)\n",
        "        kl += 1/(9+ab) * self.Beta(9/a, b)\n",
        "        kl += 1/(10+ab) * self.Beta(10/a, b)\n",
        "        kl *= (prior_beta-1)*b\n",
        "                                                                                                                                            \n",
        "        kl += (a-prior_alpha)/a * (-np.euler_gamma - torch.digamma(b) - 1/b) #T.psi(self.posterior_b)                                                                                        \n",
        "\n",
        "        # add normalization constants                                                                                                                                                                \n",
        "        kl += torch.log(ab) + torch.log(self.Beta(prior_alpha, prior_beta))\n",
        "\n",
        "        # final term                                                                                                                                                                                 \n",
        "        kl += -(b-1)/b \n",
        "\n",
        "        return len(train_loader)/a.size(0) * torch.mean(8*kl.sum(axis=1) + BCE.sum(axis=1))\n",
        "    \n",
        "    def compute_loss_train(self, data, target):\n",
        "        recon_batch, a, b = self(data)\n",
        "        return self.loss_function(recon_batch, data, a, b, torch.Tensor([1]).to(device), torch.Tensor([5]).to(device))\n",
        "    \n",
        "    def compute_loss_test(self, data, target):\n",
        "        recon_batch, a, b = self(data)\n",
        "        return self.loss_function(recon_batch, data, a, b, torch.Tensor([1]).to(device), torch.Tensor([5]).to(device)).item(), recon_batch "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmNemMwJXxkI",
        "colab_type": "code",
        "outputId": "58f1f420-d4a6-4680-8163-ee88cd9989df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sbvae = SBVAE(k=50).to(device)\n",
        "optimizer = optim.Adam(sbvae.parameters(), lr=0.0003, betas=(0.95, 0.999))\n",
        "#sbvae.writer.add_graph(sbvae, next(iter(train_loader))[0])\n",
        "\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1)\n",
        "for epoch in range(1, 1000 + 1): \n",
        "    sbvae.trains(device, train_loader, optimizer, epoch)\n",
        "    sbvae.tests(device, test_loader)\n",
        "    scheduler.step()\n",
        "    sbvae.add_embedding(test_loader)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2444.006104\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2011.594482\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1906.826294\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1837.594849\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1771.216797\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1696.575439\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1613.946899\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1532.160278\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1434.976074\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1351.486450\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1276.792725\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1192.051270\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1124.993530\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1070.672607\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1028.968750\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 995.335266\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 969.330933\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 919.764893\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 907.761414\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 893.089783\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 881.517456\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 884.201538\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 862.930542\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 842.223145\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 827.627136\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 821.967041\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 791.989441\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 807.028564\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 784.413574\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 760.454224\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 787.828491\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 804.025574\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 753.459534\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 786.318665\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 770.554626\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 748.649414\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 776.310364\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 779.851807\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 754.598389\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 765.641846\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 746.893127\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 754.721375\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 770.440491\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 765.061035\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 755.000061\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 737.944092\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 732.603882\n",
            "\n",
            "Test set: Average loss: 0.0953, Reconstruction error: 0.2007739394903183\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 745.263550\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 747.938477\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 728.148254\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 748.017029\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 764.174988\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 742.675293\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 723.376465\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 758.970398\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 746.776062\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 739.172607\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 745.849426\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 723.259949\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 749.833374\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 748.064087\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 730.055481\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 764.560303\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 751.350525\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 722.098083\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 721.678711\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 760.574890\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 732.872192\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 750.203003\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 758.985046\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 744.791260\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 752.600159\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 734.312927\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 718.178467\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 730.618286\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 730.088318\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 753.479919\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 737.455811\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 743.012695\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 757.132080\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 734.888611\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 759.641174\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 749.899902\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 745.404419\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 753.421143\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 758.080994\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 739.828430\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 756.959351\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 744.419922\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 745.722046\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 724.854370\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 726.432190\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 721.004150\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 744.418579\n",
            "\n",
            "Test set: Average loss: 0.0942, Reconstruction error: 0.1981199085712433\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 746.448425\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 756.302002\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 716.812439\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 738.332397\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 743.912354\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 735.146240\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 745.676636\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 718.838501\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 739.103760\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 741.728821\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 762.699280\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 738.939697\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 737.865906\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 735.542480\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 735.448364\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 713.381958\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 736.842773\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 738.362854\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 751.382690\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 725.581665\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 728.491150\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 734.574646\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 718.402222\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 751.417175\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 731.854370\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 756.822876\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 717.838562\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 735.502991\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 709.168091\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 742.214050\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 726.423096\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 737.271606\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 739.952576\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 749.749146\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 716.884094\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 726.069641\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 725.801819\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 784.128052\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 736.268494\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 749.359802\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 760.312805\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 745.750305\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 765.287781\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 719.676331\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 744.599182\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 747.618042\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 706.426147\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978311538696289\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 736.698059\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 720.153687\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 717.592529\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 706.700256\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 763.481812\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 744.027222\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 730.461975\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 711.300537\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 729.783997\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 747.477905\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 744.845032\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 729.846619\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 698.661072\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 746.982239\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 740.396606\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 729.150757\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 741.290466\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 712.924927\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 728.753479\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 727.020203\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 742.024536\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 735.206543\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 757.580566\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 709.077271\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 725.595764\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 757.788757\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 723.498840\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 712.936707\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 728.980225\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 748.203369\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 755.466125\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 731.836670\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 712.835266\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 726.278198\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 752.987061\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 753.654846\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 720.949219\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 720.573975\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 731.475281\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 731.065369\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 737.354309\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 742.333374\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 726.589844\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 747.013000\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 739.967773\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 746.712524\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 746.713013\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780880212783813\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 728.746399\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 713.923645\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 737.279724\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 729.381836\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 722.231506\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 731.294373\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 763.652100\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 725.599792\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 746.336365\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 731.939758\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 742.879517\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 711.506775\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 737.482788\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 729.783569\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 720.412720\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 703.118896\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 732.265625\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 741.143555\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 755.411865\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 750.349548\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 753.283020\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 748.417725\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 732.709778\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 725.957397\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 733.814819\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 763.959778\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 736.621704\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 708.718018\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 735.140442\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 736.160339\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 742.042969\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 728.183960\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 722.984985\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 733.053528\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 735.672546\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 726.322205\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 734.570740\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 764.699646\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 712.549744\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 743.919067\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 754.493103\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 735.813965\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 745.046448\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 742.352173\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 737.074707\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 750.668030\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 736.811890\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978316456079483\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 739.013794\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 722.797058\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 736.058533\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 747.161255\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 732.124512\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 739.805115\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 748.240112\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 728.253479\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 735.661194\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 725.165100\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 737.005493\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 753.504395\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 747.903137\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 720.582153\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 740.659546\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 741.438721\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 726.964966\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 755.242065\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 761.646729\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 750.285400\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 746.853821\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 740.076965\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 703.737610\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 716.787354\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 739.971985\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 740.950989\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 722.022949\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 720.454590\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 751.409485\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 733.900818\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 724.045715\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 746.880798\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 758.614807\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 741.831421\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 717.721741\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 765.943726\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 740.786133\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 753.326111\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 729.918091\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 746.923523\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 721.403320\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 722.053223\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 710.520264\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 749.344421\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 737.500061\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 728.317871\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 710.680725\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784769415855408\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 747.885071\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 753.204041\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 745.068054\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 740.642944\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 737.856140\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 744.505310\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 726.132263\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 731.449097\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 737.484436\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 757.304199\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 741.836365\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 779.179443\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 691.630981\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 766.505493\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 730.512024\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 741.336670\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 750.301575\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 740.056763\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 742.132080\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 741.138733\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 729.184021\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 756.163635\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 709.383789\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 731.829956\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 718.237793\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 740.678833\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 735.359375\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 749.868774\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 720.554993\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 738.177551\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 725.103760\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 736.357239\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 709.359497\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 741.762878\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 704.137146\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 751.056335\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 718.639221\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 734.909363\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 737.864868\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 725.377808\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 720.126709\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 720.750122\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 686.539856\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 726.107849\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 724.179382\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 719.851929\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 756.169678\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782043993473053\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 740.667053\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 727.451843\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 724.574402\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 726.653320\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 714.179626\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 728.200195\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 738.751770\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 747.412659\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 731.602112\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 747.729187\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 714.877441\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 731.178162\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 723.911316\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 751.306702\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 735.474304\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 713.745789\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 740.428772\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 726.949463\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 714.306274\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 728.016968\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 712.889099\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 695.664368\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 734.643799\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 743.258179\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 755.293030\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 730.279724\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 739.471924\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 731.646912\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 762.900696\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 733.567932\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 742.165405\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 720.435242\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 733.900513\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 724.331543\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 743.669861\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 721.365967\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 736.095825\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 745.170105\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 733.340027\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 725.338135\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 730.513184\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 723.920837\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 754.483887\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 712.874390\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 744.142822\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 728.123230\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 741.363220\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781595468521118\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 745.034607\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 755.529297\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 711.382507\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 744.398132\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 748.597229\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 752.647400\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 737.397583\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 734.997131\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 728.125183\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 736.651733\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 744.399353\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 733.768982\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 750.175842\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 740.188049\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 745.715820\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 747.399414\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 727.045715\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 718.581665\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 761.234680\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 733.458130\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 722.772705\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 753.887451\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 758.939697\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 739.599060\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 730.071167\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 747.527893\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 731.193359\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 704.992737\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 724.706970\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 747.334351\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 710.764709\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 765.506226\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 746.815186\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 719.250732\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 733.771362\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 739.034851\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 729.846985\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 739.201965\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 734.016418\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 727.340088\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 736.703796\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 734.766846\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 734.577454\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 734.825256\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 739.629639\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 739.538147\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 728.643555\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787517189979553\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 743.108154\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 736.579285\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 717.063660\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 737.751526\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 752.281616\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 703.558472\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 747.478455\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 741.800354\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 760.606384\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 724.736755\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 745.148010\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 723.009949\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 755.196350\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 716.404236\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 752.407104\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 734.411255\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 736.281311\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 715.077332\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 735.448120\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 759.850708\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 749.407654\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 740.624695\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 724.283081\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 733.174744\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 722.835510\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 725.123291\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 717.301697\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 742.549927\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 712.950806\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 727.072632\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 740.137939\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 730.332153\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 723.875732\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 754.240479\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 731.307556\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 724.689331\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 742.245117\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 736.085632\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 761.095154\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 707.082092\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 731.158264\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 751.111755\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 727.692993\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 721.507141\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 751.249573\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 749.330200\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 732.559448\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785059988498688\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 752.793701\n",
            "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 729.548401\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 744.319031\n",
            "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 717.563354\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 713.862366\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 739.368286\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 757.815247\n",
            "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 718.879944\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 709.647095\n",
            "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 749.548584\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 726.639709\n",
            "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 745.440247\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 731.317749\n",
            "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 739.764038\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 765.836914\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 737.386414\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 746.771973\n",
            "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 726.391479\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 750.605896\n",
            "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 717.776489\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 719.453796\n",
            "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 732.111267\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 722.583679\n",
            "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 742.615051\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 733.945496\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 733.055237\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 713.567993\n",
            "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 753.242065\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 733.796387\n",
            "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 721.013550\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 719.898621\n",
            "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 735.328308\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 728.040771\n",
            "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 751.742493\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 733.757690\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 720.942261\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 723.564636\n",
            "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 762.315552\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 734.367676\n",
            "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 731.504272\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 728.431213\n",
            "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 728.535645\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 742.433350\n",
            "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 728.794922\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 734.167480\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 746.779846\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 744.224487\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978418081998825\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 748.952576\n",
            "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 748.684692\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 730.230957\n",
            "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 715.415894\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 745.571533\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 753.572815\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 722.868713\n",
            "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 757.564026\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 723.324585\n",
            "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 731.540771\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 731.072754\n",
            "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 758.318359\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 733.577942\n",
            "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 754.369568\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 746.165833\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 742.126282\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 732.440369\n",
            "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 737.062256\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 750.421997\n",
            "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 726.357544\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 736.299316\n",
            "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 746.079895\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 751.444214\n",
            "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 733.268066\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 729.116150\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 752.109070\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 745.734070\n",
            "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 743.491150\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 729.832458\n",
            "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 725.643738\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 741.420654\n",
            "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 744.136047\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 720.050232\n",
            "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 745.917542\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 736.400391\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 728.990540\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 750.212036\n",
            "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 698.321167\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 751.898315\n",
            "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 724.687805\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 738.063293\n",
            "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 750.168457\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 738.098877\n",
            "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 697.927551\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 737.383606\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 736.739990\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 721.291992\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978212296962738\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 749.495911\n",
            "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 767.891174\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 724.435608\n",
            "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 722.911865\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 738.574524\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 723.875916\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 751.967285\n",
            "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 741.471436\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 742.604614\n",
            "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 736.517151\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 749.895691\n",
            "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 725.255676\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 740.645935\n",
            "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 736.469788\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 733.212708\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 713.589050\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 752.812744\n",
            "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 752.337646\n",
            "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 732.651367\n",
            "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 738.996521\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 743.898315\n",
            "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 745.962280\n",
            "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 729.395020\n",
            "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 759.295654\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 767.804504\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 744.440918\n",
            "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 755.739929\n",
            "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 760.465881\n",
            "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 750.483948\n",
            "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 742.184143\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 741.975403\n",
            "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 715.966858\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 729.599548\n",
            "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 746.639099\n",
            "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 735.590515\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 752.301514\n",
            "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 720.741821\n",
            "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 727.588562\n",
            "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 725.118835\n",
            "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 742.997009\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 728.700867\n",
            "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 763.685425\n",
            "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 760.446167\n",
            "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 699.308594\n",
            "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 739.280945\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 728.845581\n",
            "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 720.410706\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978054791688919\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 744.837097\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 708.425293\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 738.009888\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 746.273071\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 754.386536\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 724.847595\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 734.240906\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 731.166748\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 746.848267\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 768.812622\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 754.407227\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 740.974182\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 727.916504\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 747.964355\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 733.205200\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 710.051086\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 746.764954\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 740.746704\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 726.108337\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 740.390564\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 717.657043\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 728.745056\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 748.682129\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 729.927368\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 748.532227\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 733.424622\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 756.766724\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 732.832397\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 733.669495\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 734.533630\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 725.016907\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 718.019226\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 753.707764\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 746.286499\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 740.707825\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 725.821167\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 747.147278\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 722.305725\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 758.967468\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 753.851074\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 756.776978\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 725.208740\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 744.673096\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 749.515381\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 755.084595\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 715.832336\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 761.138245\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978341042995453\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 717.368286\n",
            "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 738.617432\n",
            "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 719.186218\n",
            "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 743.264709\n",
            "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 724.313049\n",
            "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 742.431885\n",
            "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 743.607117\n",
            "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 760.090393\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 737.163818\n",
            "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 732.791931\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 738.457214\n",
            "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 735.497437\n",
            "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 745.126770\n",
            "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 719.458191\n",
            "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 719.286865\n",
            "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 733.997375\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 715.559387\n",
            "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 728.882080\n",
            "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 728.219116\n",
            "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 714.757080\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 762.980408\n",
            "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 740.529846\n",
            "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 735.640076\n",
            "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 720.145203\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 750.734863\n",
            "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 741.723206\n",
            "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 745.326599\n",
            "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 712.579224\n",
            "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 751.432068\n",
            "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 734.986389\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 725.540405\n",
            "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 728.534912\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 758.756348\n",
            "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 726.755859\n",
            "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 751.641907\n",
            "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 727.147278\n",
            "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 707.807068\n",
            "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 723.982971\n",
            "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 734.777527\n",
            "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 752.525940\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 747.919739\n",
            "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 724.523132\n",
            "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 758.350403\n",
            "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 738.844788\n",
            "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 729.072571\n",
            "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 741.613098\n",
            "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 745.111267\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783686101436615\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 733.268860\n",
            "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 750.959412\n",
            "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 716.133667\n",
            "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 757.912781\n",
            "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 730.349609\n",
            "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 725.803162\n",
            "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 757.373779\n",
            "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 723.202026\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 705.429688\n",
            "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 744.346619\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 716.288208\n",
            "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 730.835632\n",
            "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 733.630737\n",
            "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 739.449768\n",
            "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 724.116089\n",
            "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 736.415833\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 747.313293\n",
            "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 751.910828\n",
            "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 739.459534\n",
            "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 742.580811\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 734.079407\n",
            "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 744.341248\n",
            "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 733.934021\n",
            "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 748.054321\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 746.663086\n",
            "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 744.585876\n",
            "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 745.978088\n",
            "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 729.922546\n",
            "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 726.919312\n",
            "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 733.162476\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 737.757202\n",
            "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 727.662476\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 697.995361\n",
            "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 744.767273\n",
            "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 748.658691\n",
            "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 719.939880\n",
            "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 723.411560\n",
            "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 727.740540\n",
            "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 710.456848\n",
            "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 749.704529\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 740.851440\n",
            "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 720.966309\n",
            "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 753.744446\n",
            "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 735.796936\n",
            "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 738.306458\n",
            "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 721.324402\n",
            "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 731.398621\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783958792686462\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 728.835876\n",
            "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 742.085022\n",
            "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 751.584778\n",
            "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 753.460571\n",
            "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 727.553711\n",
            "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 754.766602\n",
            "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 767.745300\n",
            "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 737.195862\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 735.525330\n",
            "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 725.841797\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 724.792419\n",
            "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 744.018982\n",
            "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 736.196228\n",
            "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 731.411133\n",
            "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 728.269348\n",
            "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 732.471680\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 753.854919\n",
            "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 724.891235\n",
            "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 748.601074\n",
            "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 744.408142\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 721.912598\n",
            "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 729.515076\n",
            "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 724.091248\n",
            "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 722.640930\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 717.539124\n",
            "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 759.045837\n",
            "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 741.293396\n",
            "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 766.057678\n",
            "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 746.244324\n",
            "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 738.768372\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 753.645142\n",
            "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 753.638916\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 726.894043\n",
            "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 732.555969\n",
            "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 726.506836\n",
            "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 732.489685\n",
            "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 740.227051\n",
            "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 748.911011\n",
            "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 732.335388\n",
            "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 764.906677\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 735.546570\n",
            "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 745.677246\n",
            "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 728.116272\n",
            "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 736.850525\n",
            "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 757.212524\n",
            "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 726.698853\n",
            "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 729.007812\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784168899059296\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 734.268066\n",
            "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 739.798584\n",
            "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 742.795288\n",
            "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 734.852905\n",
            "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 745.266724\n",
            "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 752.028809\n",
            "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 743.012146\n",
            "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 728.036987\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 718.736694\n",
            "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 760.386963\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 707.177063\n",
            "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 755.251953\n",
            "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 738.375000\n",
            "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 744.935852\n",
            "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 738.200378\n",
            "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 712.701233\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 740.017273\n",
            "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 709.170532\n",
            "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 728.832336\n",
            "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 724.337402\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 751.349670\n",
            "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 730.040283\n",
            "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 746.282288\n",
            "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 711.211914\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 711.295898\n",
            "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 728.690125\n",
            "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 729.265991\n",
            "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 731.858643\n",
            "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 720.821350\n",
            "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 728.090515\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 747.746460\n",
            "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 737.725647\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 728.910645\n",
            "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 729.166199\n",
            "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 703.828735\n",
            "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 743.346863\n",
            "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 735.830017\n",
            "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 758.294983\n",
            "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 731.300720\n",
            "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 752.434326\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 717.909119\n",
            "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 739.803589\n",
            "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 751.014160\n",
            "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 746.838379\n",
            "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 739.993652\n",
            "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 723.874573\n",
            "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 710.063660\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978519707918167\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 734.684875\n",
            "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 738.643738\n",
            "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 727.341858\n",
            "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 753.488708\n",
            "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 731.343628\n",
            "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 733.175293\n",
            "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 692.133179\n",
            "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 728.763672\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 729.264282\n",
            "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 758.044739\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 754.024048\n",
            "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 721.727966\n",
            "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 737.343811\n",
            "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 726.021057\n",
            "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 733.128235\n",
            "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 713.381165\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 724.733643\n",
            "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 730.480347\n",
            "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 732.766479\n",
            "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 745.708313\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 720.753174\n",
            "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 722.978577\n",
            "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 748.894104\n",
            "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 727.075745\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 725.302795\n",
            "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 739.184998\n",
            "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 710.962952\n",
            "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 741.868896\n",
            "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 729.285278\n",
            "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 756.580811\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 727.668274\n",
            "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 729.379211\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 707.128174\n",
            "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 729.567993\n",
            "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 729.506409\n",
            "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 752.393555\n",
            "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 734.887756\n",
            "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 714.416504\n",
            "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 738.156616\n",
            "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 740.324707\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 729.813843\n",
            "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 747.709473\n",
            "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 730.067627\n",
            "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 757.407837\n",
            "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 706.751892\n",
            "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 726.133118\n",
            "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 740.843689\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780638813972473\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 764.988525\n",
            "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 709.529663\n",
            "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 743.543396\n",
            "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 745.916687\n",
            "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 744.468750\n",
            "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 758.476257\n",
            "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 742.221436\n",
            "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 749.007690\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 756.137329\n",
            "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 737.125305\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 740.823181\n",
            "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 729.031372\n",
            "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 744.506653\n",
            "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 720.857178\n",
            "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 737.316467\n",
            "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 740.661438\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 745.114746\n",
            "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 707.812378\n",
            "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 718.992249\n",
            "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 720.062683\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 747.021240\n",
            "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 745.176758\n",
            "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 742.389832\n",
            "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 720.901794\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 739.375366\n",
            "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 745.244995\n",
            "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 765.323547\n",
            "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 729.523560\n",
            "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 764.201599\n",
            "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 719.469910\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 726.161072\n",
            "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 754.349365\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 722.713379\n",
            "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 713.529663\n",
            "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 742.562317\n",
            "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 742.104492\n",
            "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 733.298401\n",
            "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 714.518738\n",
            "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 761.005798\n",
            "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 747.537231\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 772.417297\n",
            "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 722.374512\n",
            "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 729.021484\n",
            "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 744.956726\n",
            "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 725.212280\n",
            "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 729.301086\n",
            "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 770.874207\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978408694267273\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 721.159485\n",
            "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 731.248169\n",
            "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 707.379395\n",
            "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 718.320679\n",
            "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 720.624756\n",
            "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 754.557373\n",
            "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 718.325073\n",
            "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 747.493774\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 737.519409\n",
            "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 743.623535\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 766.014587\n",
            "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 715.714905\n",
            "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 726.352783\n",
            "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 741.028992\n",
            "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 763.695618\n",
            "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 733.557434\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 746.430786\n",
            "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 727.900757\n",
            "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 760.629456\n",
            "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 713.926514\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 737.621338\n",
            "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 741.226379\n",
            "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 712.427795\n",
            "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 746.897095\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 718.792114\n",
            "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 743.232971\n",
            "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 735.978638\n",
            "Train Epoch: 21 [34560/60000 (58%)]\tLoss: 711.655823\n",
            "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 727.396301\n",
            "Train Epoch: 21 [37120/60000 (62%)]\tLoss: 725.308838\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 743.253174\n",
            "Train Epoch: 21 [39680/60000 (66%)]\tLoss: 720.377014\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 729.506165\n",
            "Train Epoch: 21 [42240/60000 (70%)]\tLoss: 727.714233\n",
            "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 759.597107\n",
            "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 739.536804\n",
            "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 731.152832\n",
            "Train Epoch: 21 [47360/60000 (79%)]\tLoss: 738.016235\n",
            "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 764.234131\n",
            "Train Epoch: 21 [49920/60000 (83%)]\tLoss: 716.975281\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 723.101440\n",
            "Train Epoch: 21 [52480/60000 (87%)]\tLoss: 742.361816\n",
            "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 750.818481\n",
            "Train Epoch: 21 [55040/60000 (92%)]\tLoss: 718.964722\n",
            "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 728.442871\n",
            "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 734.442810\n",
            "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 752.247986\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978454291820526\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 738.098694\n",
            "Train Epoch: 22 [1280/60000 (2%)]\tLoss: 742.578796\n",
            "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 731.370850\n",
            "Train Epoch: 22 [3840/60000 (6%)]\tLoss: 735.616394\n",
            "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 706.620117\n",
            "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 729.800781\n",
            "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 723.466431\n",
            "Train Epoch: 22 [8960/60000 (15%)]\tLoss: 712.559509\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 732.432556\n",
            "Train Epoch: 22 [11520/60000 (19%)]\tLoss: 739.766541\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 750.012939\n",
            "Train Epoch: 22 [14080/60000 (23%)]\tLoss: 718.876221\n",
            "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 726.934082\n",
            "Train Epoch: 22 [16640/60000 (28%)]\tLoss: 729.611267\n",
            "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 747.092041\n",
            "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 733.987610\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 733.932251\n",
            "Train Epoch: 22 [21760/60000 (36%)]\tLoss: 710.592102\n",
            "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 733.038940\n",
            "Train Epoch: 22 [24320/60000 (41%)]\tLoss: 719.360779\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 730.225769\n",
            "Train Epoch: 22 [26880/60000 (45%)]\tLoss: 735.146362\n",
            "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 738.818542\n",
            "Train Epoch: 22 [29440/60000 (49%)]\tLoss: 743.081665\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 762.755005\n",
            "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 725.769287\n",
            "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 772.603149\n",
            "Train Epoch: 22 [34560/60000 (58%)]\tLoss: 736.874573\n",
            "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 710.660828\n",
            "Train Epoch: 22 [37120/60000 (62%)]\tLoss: 703.598511\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 754.449463\n",
            "Train Epoch: 22 [39680/60000 (66%)]\tLoss: 754.021057\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 766.395447\n",
            "Train Epoch: 22 [42240/60000 (70%)]\tLoss: 752.616272\n",
            "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 744.407288\n",
            "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 753.596252\n",
            "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 733.852173\n",
            "Train Epoch: 22 [47360/60000 (79%)]\tLoss: 748.080383\n",
            "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 724.498108\n",
            "Train Epoch: 22 [49920/60000 (83%)]\tLoss: 726.074402\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 716.538452\n",
            "Train Epoch: 22 [52480/60000 (87%)]\tLoss: 762.337891\n",
            "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 729.945007\n",
            "Train Epoch: 22 [55040/60000 (92%)]\tLoss: 704.154175\n",
            "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 750.421692\n",
            "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 755.711670\n",
            "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 732.512878\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786177575588226\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 720.123047\n",
            "Train Epoch: 23 [1280/60000 (2%)]\tLoss: 738.721985\n",
            "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 753.649414\n",
            "Train Epoch: 23 [3840/60000 (6%)]\tLoss: 756.173889\n",
            "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 727.724792\n",
            "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 747.020203\n",
            "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 707.797302\n",
            "Train Epoch: 23 [8960/60000 (15%)]\tLoss: 752.537903\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 748.278564\n",
            "Train Epoch: 23 [11520/60000 (19%)]\tLoss: 725.849121\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 711.126465\n",
            "Train Epoch: 23 [14080/60000 (23%)]\tLoss: 742.236267\n",
            "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 733.850037\n",
            "Train Epoch: 23 [16640/60000 (28%)]\tLoss: 749.924377\n",
            "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 725.914673\n",
            "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 750.775818\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 739.914246\n",
            "Train Epoch: 23 [21760/60000 (36%)]\tLoss: 743.895569\n",
            "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 721.802002\n",
            "Train Epoch: 23 [24320/60000 (41%)]\tLoss: 715.621582\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 729.668945\n",
            "Train Epoch: 23 [26880/60000 (45%)]\tLoss: 748.323853\n",
            "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 729.713928\n",
            "Train Epoch: 23 [29440/60000 (49%)]\tLoss: 766.277832\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 703.899780\n",
            "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 718.372314\n",
            "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 743.121826\n",
            "Train Epoch: 23 [34560/60000 (58%)]\tLoss: 726.893799\n",
            "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 753.329773\n",
            "Train Epoch: 23 [37120/60000 (62%)]\tLoss: 732.732910\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 727.039124\n",
            "Train Epoch: 23 [39680/60000 (66%)]\tLoss: 732.764343\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 733.792480\n",
            "Train Epoch: 23 [42240/60000 (70%)]\tLoss: 734.731628\n",
            "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 713.318787\n",
            "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 730.411682\n",
            "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 708.749451\n",
            "Train Epoch: 23 [47360/60000 (79%)]\tLoss: 735.214844\n",
            "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 745.826599\n",
            "Train Epoch: 23 [49920/60000 (83%)]\tLoss: 725.039368\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 742.012817\n",
            "Train Epoch: 23 [52480/60000 (87%)]\tLoss: 718.735596\n",
            "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 745.076538\n",
            "Train Epoch: 23 [55040/60000 (92%)]\tLoss: 730.106750\n",
            "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 725.501465\n",
            "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 717.954102\n",
            "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 735.916748\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786322116851807\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 734.283936\n",
            "Train Epoch: 24 [1280/60000 (2%)]\tLoss: 727.598755\n",
            "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 736.217590\n",
            "Train Epoch: 24 [3840/60000 (6%)]\tLoss: 742.108154\n",
            "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 723.353455\n",
            "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 743.199890\n",
            "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 729.666016\n",
            "Train Epoch: 24 [8960/60000 (15%)]\tLoss: 703.317139\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 721.840515\n",
            "Train Epoch: 24 [11520/60000 (19%)]\tLoss: 731.055176\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 718.116455\n",
            "Train Epoch: 24 [14080/60000 (23%)]\tLoss: 739.893799\n",
            "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 712.096680\n",
            "Train Epoch: 24 [16640/60000 (28%)]\tLoss: 749.226074\n",
            "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 732.424866\n",
            "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 758.484558\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 748.165161\n",
            "Train Epoch: 24 [21760/60000 (36%)]\tLoss: 711.974304\n",
            "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 708.894348\n",
            "Train Epoch: 24 [24320/60000 (41%)]\tLoss: 742.902710\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 746.197510\n",
            "Train Epoch: 24 [26880/60000 (45%)]\tLoss: 734.793762\n",
            "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 733.231934\n",
            "Train Epoch: 24 [29440/60000 (49%)]\tLoss: 736.446838\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 742.734314\n",
            "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 716.713257\n",
            "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 757.469238\n",
            "Train Epoch: 24 [34560/60000 (58%)]\tLoss: 736.795471\n",
            "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 734.763672\n",
            "Train Epoch: 24 [37120/60000 (62%)]\tLoss: 726.425049\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 729.130798\n",
            "Train Epoch: 24 [39680/60000 (66%)]\tLoss: 744.678528\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 719.106506\n",
            "Train Epoch: 24 [42240/60000 (70%)]\tLoss: 718.588989\n",
            "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 748.220398\n",
            "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 746.919189\n",
            "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 746.862610\n",
            "Train Epoch: 24 [47360/60000 (79%)]\tLoss: 718.503357\n",
            "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 767.661560\n",
            "Train Epoch: 24 [49920/60000 (83%)]\tLoss: 744.282349\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 712.432251\n",
            "Train Epoch: 24 [52480/60000 (87%)]\tLoss: 735.223999\n",
            "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 731.853088\n",
            "Train Epoch: 24 [55040/60000 (92%)]\tLoss: 728.743713\n",
            "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 748.973999\n",
            "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 763.565247\n",
            "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 744.427429\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784437119960785\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 748.170532\n",
            "Train Epoch: 25 [1280/60000 (2%)]\tLoss: 702.411926\n",
            "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 729.677246\n",
            "Train Epoch: 25 [3840/60000 (6%)]\tLoss: 749.539429\n",
            "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 752.136169\n",
            "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 762.657959\n",
            "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 739.232361\n",
            "Train Epoch: 25 [8960/60000 (15%)]\tLoss: 723.185608\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 733.468567\n",
            "Train Epoch: 25 [11520/60000 (19%)]\tLoss: 744.280273\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 712.627747\n",
            "Train Epoch: 25 [14080/60000 (23%)]\tLoss: 743.450378\n",
            "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 739.085083\n",
            "Train Epoch: 25 [16640/60000 (28%)]\tLoss: 740.494995\n",
            "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 739.007935\n",
            "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 755.840271\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 737.990051\n",
            "Train Epoch: 25 [21760/60000 (36%)]\tLoss: 737.271912\n",
            "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 738.267212\n",
            "Train Epoch: 25 [24320/60000 (41%)]\tLoss: 723.764709\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 728.939514\n",
            "Train Epoch: 25 [26880/60000 (45%)]\tLoss: 745.577698\n",
            "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 722.294250\n",
            "Train Epoch: 25 [29440/60000 (49%)]\tLoss: 739.907288\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 750.433167\n",
            "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 736.708191\n",
            "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 749.846436\n",
            "Train Epoch: 25 [34560/60000 (58%)]\tLoss: 761.375305\n",
            "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 762.865601\n",
            "Train Epoch: 25 [37120/60000 (62%)]\tLoss: 743.454041\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 752.467041\n",
            "Train Epoch: 25 [39680/60000 (66%)]\tLoss: 720.845276\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 729.867310\n",
            "Train Epoch: 25 [42240/60000 (70%)]\tLoss: 726.153809\n",
            "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 748.699768\n",
            "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 714.425354\n",
            "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 705.860107\n",
            "Train Epoch: 25 [47360/60000 (79%)]\tLoss: 724.925293\n",
            "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 744.604309\n",
            "Train Epoch: 25 [49920/60000 (83%)]\tLoss: 753.047241\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 719.945374\n",
            "Train Epoch: 25 [52480/60000 (87%)]\tLoss: 740.611816\n",
            "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 715.635315\n",
            "Train Epoch: 25 [55040/60000 (92%)]\tLoss: 756.196533\n",
            "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 758.294800\n",
            "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 726.141418\n",
            "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 723.173645\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785617291927338\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 768.308655\n",
            "Train Epoch: 26 [1280/60000 (2%)]\tLoss: 722.555603\n",
            "Train Epoch: 26 [2560/60000 (4%)]\tLoss: 732.874878\n",
            "Train Epoch: 26 [3840/60000 (6%)]\tLoss: 746.625732\n",
            "Train Epoch: 26 [5120/60000 (9%)]\tLoss: 712.790222\n",
            "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 748.189514\n",
            "Train Epoch: 26 [7680/60000 (13%)]\tLoss: 745.458496\n",
            "Train Epoch: 26 [8960/60000 (15%)]\tLoss: 719.477356\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 742.823975\n",
            "Train Epoch: 26 [11520/60000 (19%)]\tLoss: 755.535217\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 718.491943\n",
            "Train Epoch: 26 [14080/60000 (23%)]\tLoss: 726.007935\n",
            "Train Epoch: 26 [15360/60000 (26%)]\tLoss: 740.104065\n",
            "Train Epoch: 26 [16640/60000 (28%)]\tLoss: 740.755432\n",
            "Train Epoch: 26 [17920/60000 (30%)]\tLoss: 754.060913\n",
            "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 762.481567\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 751.743896\n",
            "Train Epoch: 26 [21760/60000 (36%)]\tLoss: 763.440125\n",
            "Train Epoch: 26 [23040/60000 (38%)]\tLoss: 729.004883\n",
            "Train Epoch: 26 [24320/60000 (41%)]\tLoss: 721.149597\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 717.178772\n",
            "Train Epoch: 26 [26880/60000 (45%)]\tLoss: 765.115234\n",
            "Train Epoch: 26 [28160/60000 (47%)]\tLoss: 742.826782\n",
            "Train Epoch: 26 [29440/60000 (49%)]\tLoss: 726.815247\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 723.285278\n",
            "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 730.339661\n",
            "Train Epoch: 26 [33280/60000 (55%)]\tLoss: 742.381287\n",
            "Train Epoch: 26 [34560/60000 (58%)]\tLoss: 724.706604\n",
            "Train Epoch: 26 [35840/60000 (60%)]\tLoss: 726.659790\n",
            "Train Epoch: 26 [37120/60000 (62%)]\tLoss: 726.899658\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 744.411499\n",
            "Train Epoch: 26 [39680/60000 (66%)]\tLoss: 739.692200\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 717.556458\n",
            "Train Epoch: 26 [42240/60000 (70%)]\tLoss: 735.405212\n",
            "Train Epoch: 26 [43520/60000 (72%)]\tLoss: 727.116333\n",
            "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 728.535889\n",
            "Train Epoch: 26 [46080/60000 (77%)]\tLoss: 762.472229\n",
            "Train Epoch: 26 [47360/60000 (79%)]\tLoss: 738.597168\n",
            "Train Epoch: 26 [48640/60000 (81%)]\tLoss: 745.122253\n",
            "Train Epoch: 26 [49920/60000 (83%)]\tLoss: 721.627136\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 743.560913\n",
            "Train Epoch: 26 [52480/60000 (87%)]\tLoss: 759.292236\n",
            "Train Epoch: 26 [53760/60000 (90%)]\tLoss: 729.954834\n",
            "Train Epoch: 26 [55040/60000 (92%)]\tLoss: 773.438416\n",
            "Train Epoch: 26 [56320/60000 (94%)]\tLoss: 753.025635\n",
            "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 739.790527\n",
            "Train Epoch: 26 [58880/60000 (98%)]\tLoss: 732.201050\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978580206632614\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 751.623779\n",
            "Train Epoch: 27 [1280/60000 (2%)]\tLoss: 745.475342\n",
            "Train Epoch: 27 [2560/60000 (4%)]\tLoss: 738.818481\n",
            "Train Epoch: 27 [3840/60000 (6%)]\tLoss: 744.631165\n",
            "Train Epoch: 27 [5120/60000 (9%)]\tLoss: 739.922424\n",
            "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 756.844971\n",
            "Train Epoch: 27 [7680/60000 (13%)]\tLoss: 723.987488\n",
            "Train Epoch: 27 [8960/60000 (15%)]\tLoss: 719.918945\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 735.566467\n",
            "Train Epoch: 27 [11520/60000 (19%)]\tLoss: 746.044617\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 738.392090\n",
            "Train Epoch: 27 [14080/60000 (23%)]\tLoss: 712.617310\n",
            "Train Epoch: 27 [15360/60000 (26%)]\tLoss: 731.554199\n",
            "Train Epoch: 27 [16640/60000 (28%)]\tLoss: 724.746704\n",
            "Train Epoch: 27 [17920/60000 (30%)]\tLoss: 712.583252\n",
            "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 758.317200\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 723.192566\n",
            "Train Epoch: 27 [21760/60000 (36%)]\tLoss: 742.250732\n",
            "Train Epoch: 27 [23040/60000 (38%)]\tLoss: 731.426819\n",
            "Train Epoch: 27 [24320/60000 (41%)]\tLoss: 728.971680\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 721.251160\n",
            "Train Epoch: 27 [26880/60000 (45%)]\tLoss: 736.773926\n",
            "Train Epoch: 27 [28160/60000 (47%)]\tLoss: 734.273621\n",
            "Train Epoch: 27 [29440/60000 (49%)]\tLoss: 732.374512\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 731.247925\n",
            "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 735.942932\n",
            "Train Epoch: 27 [33280/60000 (55%)]\tLoss: 725.814209\n",
            "Train Epoch: 27 [34560/60000 (58%)]\tLoss: 719.517090\n",
            "Train Epoch: 27 [35840/60000 (60%)]\tLoss: 746.315308\n",
            "Train Epoch: 27 [37120/60000 (62%)]\tLoss: 735.331116\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 745.472595\n",
            "Train Epoch: 27 [39680/60000 (66%)]\tLoss: 739.336548\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 748.469849\n",
            "Train Epoch: 27 [42240/60000 (70%)]\tLoss: 752.559265\n",
            "Train Epoch: 27 [43520/60000 (72%)]\tLoss: 735.716736\n",
            "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 737.243652\n",
            "Train Epoch: 27 [46080/60000 (77%)]\tLoss: 725.032471\n",
            "Train Epoch: 27 [47360/60000 (79%)]\tLoss: 730.894775\n",
            "Train Epoch: 27 [48640/60000 (81%)]\tLoss: 769.721008\n",
            "Train Epoch: 27 [49920/60000 (83%)]\tLoss: 736.692749\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 719.943787\n",
            "Train Epoch: 27 [52480/60000 (87%)]\tLoss: 743.750732\n",
            "Train Epoch: 27 [53760/60000 (90%)]\tLoss: 746.056458\n",
            "Train Epoch: 27 [55040/60000 (92%)]\tLoss: 710.039612\n",
            "Train Epoch: 27 [56320/60000 (94%)]\tLoss: 734.203186\n",
            "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 767.569153\n",
            "Train Epoch: 27 [58880/60000 (98%)]\tLoss: 720.680237\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785577058792114\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 728.432312\n",
            "Train Epoch: 28 [1280/60000 (2%)]\tLoss: 735.907349\n",
            "Train Epoch: 28 [2560/60000 (4%)]\tLoss: 743.632080\n",
            "Train Epoch: 28 [3840/60000 (6%)]\tLoss: 730.228943\n",
            "Train Epoch: 28 [5120/60000 (9%)]\tLoss: 773.557068\n",
            "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 733.582947\n",
            "Train Epoch: 28 [7680/60000 (13%)]\tLoss: 745.190430\n",
            "Train Epoch: 28 [8960/60000 (15%)]\tLoss: 760.395386\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 728.616333\n",
            "Train Epoch: 28 [11520/60000 (19%)]\tLoss: 736.371033\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 713.466492\n",
            "Train Epoch: 28 [14080/60000 (23%)]\tLoss: 738.287903\n",
            "Train Epoch: 28 [15360/60000 (26%)]\tLoss: 730.496277\n",
            "Train Epoch: 28 [16640/60000 (28%)]\tLoss: 722.841309\n",
            "Train Epoch: 28 [17920/60000 (30%)]\tLoss: 754.421936\n",
            "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 733.773987\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 727.744141\n",
            "Train Epoch: 28 [21760/60000 (36%)]\tLoss: 730.877075\n",
            "Train Epoch: 28 [23040/60000 (38%)]\tLoss: 743.275757\n",
            "Train Epoch: 28 [24320/60000 (41%)]\tLoss: 744.207764\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 743.438416\n",
            "Train Epoch: 28 [26880/60000 (45%)]\tLoss: 746.946594\n",
            "Train Epoch: 28 [28160/60000 (47%)]\tLoss: 746.706909\n",
            "Train Epoch: 28 [29440/60000 (49%)]\tLoss: 741.463379\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 753.907715\n",
            "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 737.585815\n",
            "Train Epoch: 28 [33280/60000 (55%)]\tLoss: 746.985962\n",
            "Train Epoch: 28 [34560/60000 (58%)]\tLoss: 761.023682\n",
            "Train Epoch: 28 [35840/60000 (60%)]\tLoss: 729.098816\n",
            "Train Epoch: 28 [37120/60000 (62%)]\tLoss: 735.649902\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 736.321472\n",
            "Train Epoch: 28 [39680/60000 (66%)]\tLoss: 743.299194\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 745.739319\n",
            "Train Epoch: 28 [42240/60000 (70%)]\tLoss: 744.425964\n",
            "Train Epoch: 28 [43520/60000 (72%)]\tLoss: 716.349976\n",
            "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 726.718872\n",
            "Train Epoch: 28 [46080/60000 (77%)]\tLoss: 730.219299\n",
            "Train Epoch: 28 [47360/60000 (79%)]\tLoss: 742.844177\n",
            "Train Epoch: 28 [48640/60000 (81%)]\tLoss: 741.005188\n",
            "Train Epoch: 28 [49920/60000 (83%)]\tLoss: 758.205627\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 741.050659\n",
            "Train Epoch: 28 [52480/60000 (87%)]\tLoss: 729.559814\n",
            "Train Epoch: 28 [53760/60000 (90%)]\tLoss: 710.802856\n",
            "Train Epoch: 28 [55040/60000 (92%)]\tLoss: 730.708618\n",
            "Train Epoch: 28 [56320/60000 (94%)]\tLoss: 746.539673\n",
            "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 735.720215\n",
            "Train Epoch: 28 [58880/60000 (98%)]\tLoss: 724.270386\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782762229442596\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 740.991943\n",
            "Train Epoch: 29 [1280/60000 (2%)]\tLoss: 711.792664\n",
            "Train Epoch: 29 [2560/60000 (4%)]\tLoss: 753.168152\n",
            "Train Epoch: 29 [3840/60000 (6%)]\tLoss: 740.767700\n",
            "Train Epoch: 29 [5120/60000 (9%)]\tLoss: 739.995544\n",
            "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 740.518982\n",
            "Train Epoch: 29 [7680/60000 (13%)]\tLoss: 699.449158\n",
            "Train Epoch: 29 [8960/60000 (15%)]\tLoss: 721.629578\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 727.574341\n",
            "Train Epoch: 29 [11520/60000 (19%)]\tLoss: 727.817566\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 732.382263\n",
            "Train Epoch: 29 [14080/60000 (23%)]\tLoss: 747.960693\n",
            "Train Epoch: 29 [15360/60000 (26%)]\tLoss: 734.360718\n",
            "Train Epoch: 29 [16640/60000 (28%)]\tLoss: 733.417908\n",
            "Train Epoch: 29 [17920/60000 (30%)]\tLoss: 752.442322\n",
            "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 717.176758\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 727.282776\n",
            "Train Epoch: 29 [21760/60000 (36%)]\tLoss: 703.762207\n",
            "Train Epoch: 29 [23040/60000 (38%)]\tLoss: 734.921143\n",
            "Train Epoch: 29 [24320/60000 (41%)]\tLoss: 720.694092\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 732.640198\n",
            "Train Epoch: 29 [26880/60000 (45%)]\tLoss: 739.037537\n",
            "Train Epoch: 29 [28160/60000 (47%)]\tLoss: 729.873230\n",
            "Train Epoch: 29 [29440/60000 (49%)]\tLoss: 744.214233\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 736.475342\n",
            "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 771.497437\n",
            "Train Epoch: 29 [33280/60000 (55%)]\tLoss: 713.807800\n",
            "Train Epoch: 29 [34560/60000 (58%)]\tLoss: 731.758301\n",
            "Train Epoch: 29 [35840/60000 (60%)]\tLoss: 713.688354\n",
            "Train Epoch: 29 [37120/60000 (62%)]\tLoss: 745.259644\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 729.241333\n",
            "Train Epoch: 29 [39680/60000 (66%)]\tLoss: 717.046814\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 729.249268\n",
            "Train Epoch: 29 [42240/60000 (70%)]\tLoss: 718.202087\n",
            "Train Epoch: 29 [43520/60000 (72%)]\tLoss: 752.169739\n",
            "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 731.282471\n",
            "Train Epoch: 29 [46080/60000 (77%)]\tLoss: 712.325317\n",
            "Train Epoch: 29 [47360/60000 (79%)]\tLoss: 752.383362\n",
            "Train Epoch: 29 [48640/60000 (81%)]\tLoss: 752.932312\n",
            "Train Epoch: 29 [49920/60000 (83%)]\tLoss: 736.010498\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 724.953857\n",
            "Train Epoch: 29 [52480/60000 (87%)]\tLoss: 752.495972\n",
            "Train Epoch: 29 [53760/60000 (90%)]\tLoss: 740.700500\n",
            "Train Epoch: 29 [55040/60000 (92%)]\tLoss: 738.154846\n",
            "Train Epoch: 29 [56320/60000 (94%)]\tLoss: 720.068420\n",
            "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 745.141663\n",
            "Train Epoch: 29 [58880/60000 (98%)]\tLoss: 722.503418\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978432983160019\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 726.578735\n",
            "Train Epoch: 30 [1280/60000 (2%)]\tLoss: 745.898621\n",
            "Train Epoch: 30 [2560/60000 (4%)]\tLoss: 737.407776\n",
            "Train Epoch: 30 [3840/60000 (6%)]\tLoss: 731.297607\n",
            "Train Epoch: 30 [5120/60000 (9%)]\tLoss: 754.366699\n",
            "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 769.498291\n",
            "Train Epoch: 30 [7680/60000 (13%)]\tLoss: 749.832153\n",
            "Train Epoch: 30 [8960/60000 (15%)]\tLoss: 725.801331\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 740.128174\n",
            "Train Epoch: 30 [11520/60000 (19%)]\tLoss: 743.889893\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 732.204529\n",
            "Train Epoch: 30 [14080/60000 (23%)]\tLoss: 727.824951\n",
            "Train Epoch: 30 [15360/60000 (26%)]\tLoss: 736.138794\n",
            "Train Epoch: 30 [16640/60000 (28%)]\tLoss: 717.714661\n",
            "Train Epoch: 30 [17920/60000 (30%)]\tLoss: 743.785339\n",
            "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 743.267517\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 738.359131\n",
            "Train Epoch: 30 [21760/60000 (36%)]\tLoss: 762.758789\n",
            "Train Epoch: 30 [23040/60000 (38%)]\tLoss: 740.449768\n",
            "Train Epoch: 30 [24320/60000 (41%)]\tLoss: 730.090942\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 730.619751\n",
            "Train Epoch: 30 [26880/60000 (45%)]\tLoss: 746.876099\n",
            "Train Epoch: 30 [28160/60000 (47%)]\tLoss: 720.819885\n",
            "Train Epoch: 30 [29440/60000 (49%)]\tLoss: 733.584961\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 739.827515\n",
            "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 731.899780\n",
            "Train Epoch: 30 [33280/60000 (55%)]\tLoss: 748.700867\n",
            "Train Epoch: 30 [34560/60000 (58%)]\tLoss: 746.528381\n",
            "Train Epoch: 30 [35840/60000 (60%)]\tLoss: 723.039368\n",
            "Train Epoch: 30 [37120/60000 (62%)]\tLoss: 723.997925\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 734.729065\n",
            "Train Epoch: 30 [39680/60000 (66%)]\tLoss: 731.865173\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 717.703247\n",
            "Train Epoch: 30 [42240/60000 (70%)]\tLoss: 746.371460\n",
            "Train Epoch: 30 [43520/60000 (72%)]\tLoss: 756.495483\n",
            "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 739.848022\n",
            "Train Epoch: 30 [46080/60000 (77%)]\tLoss: 754.761414\n",
            "Train Epoch: 30 [47360/60000 (79%)]\tLoss: 736.541138\n",
            "Train Epoch: 30 [48640/60000 (81%)]\tLoss: 715.065369\n",
            "Train Epoch: 30 [49920/60000 (83%)]\tLoss: 740.894409\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 742.056152\n",
            "Train Epoch: 30 [52480/60000 (87%)]\tLoss: 764.284668\n",
            "Train Epoch: 30 [53760/60000 (90%)]\tLoss: 721.520874\n",
            "Train Epoch: 30 [55040/60000 (92%)]\tLoss: 746.165100\n",
            "Train Epoch: 30 [56320/60000 (94%)]\tLoss: 732.685120\n",
            "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 762.589172\n",
            "Train Epoch: 30 [58880/60000 (98%)]\tLoss: 731.967041\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782648980617523\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 722.030396\n",
            "Train Epoch: 31 [1280/60000 (2%)]\tLoss: 719.045715\n",
            "Train Epoch: 31 [2560/60000 (4%)]\tLoss: 723.050720\n",
            "Train Epoch: 31 [3840/60000 (6%)]\tLoss: 738.973633\n",
            "Train Epoch: 31 [5120/60000 (9%)]\tLoss: 740.784912\n",
            "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 733.224915\n",
            "Train Epoch: 31 [7680/60000 (13%)]\tLoss: 739.538086\n",
            "Train Epoch: 31 [8960/60000 (15%)]\tLoss: 723.618225\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 734.011780\n",
            "Train Epoch: 31 [11520/60000 (19%)]\tLoss: 745.636841\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 732.916992\n",
            "Train Epoch: 31 [14080/60000 (23%)]\tLoss: 719.606812\n",
            "Train Epoch: 31 [15360/60000 (26%)]\tLoss: 737.441650\n",
            "Train Epoch: 31 [16640/60000 (28%)]\tLoss: 732.990845\n",
            "Train Epoch: 31 [17920/60000 (30%)]\tLoss: 725.282410\n",
            "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 734.718262\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 749.314636\n",
            "Train Epoch: 31 [21760/60000 (36%)]\tLoss: 758.294128\n",
            "Train Epoch: 31 [23040/60000 (38%)]\tLoss: 726.042847\n",
            "Train Epoch: 31 [24320/60000 (41%)]\tLoss: 729.644531\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 735.983337\n",
            "Train Epoch: 31 [26880/60000 (45%)]\tLoss: 728.067322\n",
            "Train Epoch: 31 [28160/60000 (47%)]\tLoss: 718.028015\n",
            "Train Epoch: 31 [29440/60000 (49%)]\tLoss: 737.740906\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 746.870422\n",
            "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 729.261597\n",
            "Train Epoch: 31 [33280/60000 (55%)]\tLoss: 729.388611\n",
            "Train Epoch: 31 [34560/60000 (58%)]\tLoss: 751.766724\n",
            "Train Epoch: 31 [35840/60000 (60%)]\tLoss: 747.376343\n",
            "Train Epoch: 31 [37120/60000 (62%)]\tLoss: 721.402649\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 699.690308\n",
            "Train Epoch: 31 [39680/60000 (66%)]\tLoss: 726.666504\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 727.386353\n",
            "Train Epoch: 31 [42240/60000 (70%)]\tLoss: 747.515137\n",
            "Train Epoch: 31 [43520/60000 (72%)]\tLoss: 750.176697\n",
            "Train Epoch: 31 [44800/60000 (75%)]\tLoss: 727.112671\n",
            "Train Epoch: 31 [46080/60000 (77%)]\tLoss: 727.241272\n",
            "Train Epoch: 31 [47360/60000 (79%)]\tLoss: 743.161560\n",
            "Train Epoch: 31 [48640/60000 (81%)]\tLoss: 726.543823\n",
            "Train Epoch: 31 [49920/60000 (83%)]\tLoss: 712.169678\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 737.542542\n",
            "Train Epoch: 31 [52480/60000 (87%)]\tLoss: 760.817871\n",
            "Train Epoch: 31 [53760/60000 (90%)]\tLoss: 732.919006\n",
            "Train Epoch: 31 [55040/60000 (92%)]\tLoss: 748.114136\n",
            "Train Epoch: 31 [56320/60000 (94%)]\tLoss: 725.510437\n",
            "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 734.198181\n",
            "Train Epoch: 31 [58880/60000 (98%)]\tLoss: 717.749023\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978209912776947\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 734.136536\n",
            "Train Epoch: 32 [1280/60000 (2%)]\tLoss: 778.539917\n",
            "Train Epoch: 32 [2560/60000 (4%)]\tLoss: 739.338196\n",
            "Train Epoch: 32 [3840/60000 (6%)]\tLoss: 733.084045\n",
            "Train Epoch: 32 [5120/60000 (9%)]\tLoss: 731.789978\n",
            "Train Epoch: 32 [6400/60000 (11%)]\tLoss: 752.151733\n",
            "Train Epoch: 32 [7680/60000 (13%)]\tLoss: 740.741516\n",
            "Train Epoch: 32 [8960/60000 (15%)]\tLoss: 747.106323\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 756.892456\n",
            "Train Epoch: 32 [11520/60000 (19%)]\tLoss: 745.692444\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 722.665405\n",
            "Train Epoch: 32 [14080/60000 (23%)]\tLoss: 741.131470\n",
            "Train Epoch: 32 [15360/60000 (26%)]\tLoss: 730.417603\n",
            "Train Epoch: 32 [16640/60000 (28%)]\tLoss: 759.652283\n",
            "Train Epoch: 32 [17920/60000 (30%)]\tLoss: 735.994263\n",
            "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 735.605469\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 734.796936\n",
            "Train Epoch: 32 [21760/60000 (36%)]\tLoss: 740.486755\n",
            "Train Epoch: 32 [23040/60000 (38%)]\tLoss: 755.312012\n",
            "Train Epoch: 32 [24320/60000 (41%)]\tLoss: 712.338684\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 756.955994\n",
            "Train Epoch: 32 [26880/60000 (45%)]\tLoss: 712.302979\n",
            "Train Epoch: 32 [28160/60000 (47%)]\tLoss: 750.057739\n",
            "Train Epoch: 32 [29440/60000 (49%)]\tLoss: 746.768494\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 742.531189\n",
            "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 732.904358\n",
            "Train Epoch: 32 [33280/60000 (55%)]\tLoss: 740.634216\n",
            "Train Epoch: 32 [34560/60000 (58%)]\tLoss: 733.579712\n",
            "Train Epoch: 32 [35840/60000 (60%)]\tLoss: 751.700317\n",
            "Train Epoch: 32 [37120/60000 (62%)]\tLoss: 732.197937\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 755.580811\n",
            "Train Epoch: 32 [39680/60000 (66%)]\tLoss: 765.513306\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 711.542114\n",
            "Train Epoch: 32 [42240/60000 (70%)]\tLoss: 714.540588\n",
            "Train Epoch: 32 [43520/60000 (72%)]\tLoss: 745.714050\n",
            "Train Epoch: 32 [44800/60000 (75%)]\tLoss: 725.624939\n",
            "Train Epoch: 32 [46080/60000 (77%)]\tLoss: 748.504944\n",
            "Train Epoch: 32 [47360/60000 (79%)]\tLoss: 735.120178\n",
            "Train Epoch: 32 [48640/60000 (81%)]\tLoss: 728.275940\n",
            "Train Epoch: 32 [49920/60000 (83%)]\tLoss: 720.603516\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 771.448914\n",
            "Train Epoch: 32 [52480/60000 (87%)]\tLoss: 734.821777\n",
            "Train Epoch: 32 [53760/60000 (90%)]\tLoss: 753.250183\n",
            "Train Epoch: 32 [55040/60000 (92%)]\tLoss: 731.411987\n",
            "Train Epoch: 32 [56320/60000 (94%)]\tLoss: 733.222778\n",
            "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 743.107483\n",
            "Train Epoch: 32 [58880/60000 (98%)]\tLoss: 741.939514\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784317910671234\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 718.493774\n",
            "Train Epoch: 33 [1280/60000 (2%)]\tLoss: 728.598633\n",
            "Train Epoch: 33 [2560/60000 (4%)]\tLoss: 755.428955\n",
            "Train Epoch: 33 [3840/60000 (6%)]\tLoss: 723.753174\n",
            "Train Epoch: 33 [5120/60000 (9%)]\tLoss: 730.783264\n",
            "Train Epoch: 33 [6400/60000 (11%)]\tLoss: 772.108826\n",
            "Train Epoch: 33 [7680/60000 (13%)]\tLoss: 746.031433\n",
            "Train Epoch: 33 [8960/60000 (15%)]\tLoss: 726.497742\n",
            "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 729.335266\n",
            "Train Epoch: 33 [11520/60000 (19%)]\tLoss: 768.370605\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 708.884155\n",
            "Train Epoch: 33 [14080/60000 (23%)]\tLoss: 726.132935\n",
            "Train Epoch: 33 [15360/60000 (26%)]\tLoss: 738.959351\n",
            "Train Epoch: 33 [16640/60000 (28%)]\tLoss: 736.460693\n",
            "Train Epoch: 33 [17920/60000 (30%)]\tLoss: 720.986938\n",
            "Train Epoch: 33 [19200/60000 (32%)]\tLoss: 734.747620\n",
            "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 735.441345\n",
            "Train Epoch: 33 [21760/60000 (36%)]\tLoss: 721.708191\n",
            "Train Epoch: 33 [23040/60000 (38%)]\tLoss: 715.340027\n",
            "Train Epoch: 33 [24320/60000 (41%)]\tLoss: 741.166870\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 732.723145\n",
            "Train Epoch: 33 [26880/60000 (45%)]\tLoss: 719.852356\n",
            "Train Epoch: 33 [28160/60000 (47%)]\tLoss: 729.365784\n",
            "Train Epoch: 33 [29440/60000 (49%)]\tLoss: 719.156677\n",
            "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 711.914673\n",
            "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 712.775330\n",
            "Train Epoch: 33 [33280/60000 (55%)]\tLoss: 712.343140\n",
            "Train Epoch: 33 [34560/60000 (58%)]\tLoss: 752.729187\n",
            "Train Epoch: 33 [35840/60000 (60%)]\tLoss: 744.131775\n",
            "Train Epoch: 33 [37120/60000 (62%)]\tLoss: 724.330688\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 735.359253\n",
            "Train Epoch: 33 [39680/60000 (66%)]\tLoss: 718.369263\n",
            "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 725.916687\n",
            "Train Epoch: 33 [42240/60000 (70%)]\tLoss: 717.627380\n",
            "Train Epoch: 33 [43520/60000 (72%)]\tLoss: 737.167786\n",
            "Train Epoch: 33 [44800/60000 (75%)]\tLoss: 756.587585\n",
            "Train Epoch: 33 [46080/60000 (77%)]\tLoss: 746.140808\n",
            "Train Epoch: 33 [47360/60000 (79%)]\tLoss: 727.649963\n",
            "Train Epoch: 33 [48640/60000 (81%)]\tLoss: 731.033386\n",
            "Train Epoch: 33 [49920/60000 (83%)]\tLoss: 731.180908\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 741.480225\n",
            "Train Epoch: 33 [52480/60000 (87%)]\tLoss: 753.302185\n",
            "Train Epoch: 33 [53760/60000 (90%)]\tLoss: 723.021912\n",
            "Train Epoch: 33 [55040/60000 (92%)]\tLoss: 736.193787\n",
            "Train Epoch: 33 [56320/60000 (94%)]\tLoss: 763.505432\n",
            "Train Epoch: 33 [57600/60000 (96%)]\tLoss: 746.761108\n",
            "Train Epoch: 33 [58880/60000 (98%)]\tLoss: 730.795959\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978764832019806\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 728.085266\n",
            "Train Epoch: 34 [1280/60000 (2%)]\tLoss: 728.873474\n",
            "Train Epoch: 34 [2560/60000 (4%)]\tLoss: 720.761230\n",
            "Train Epoch: 34 [3840/60000 (6%)]\tLoss: 729.100342\n",
            "Train Epoch: 34 [5120/60000 (9%)]\tLoss: 709.644775\n",
            "Train Epoch: 34 [6400/60000 (11%)]\tLoss: 735.945679\n",
            "Train Epoch: 34 [7680/60000 (13%)]\tLoss: 713.091736\n",
            "Train Epoch: 34 [8960/60000 (15%)]\tLoss: 740.919800\n",
            "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 729.601379\n",
            "Train Epoch: 34 [11520/60000 (19%)]\tLoss: 738.853699\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 749.659485\n",
            "Train Epoch: 34 [14080/60000 (23%)]\tLoss: 729.473999\n",
            "Train Epoch: 34 [15360/60000 (26%)]\tLoss: 757.447388\n",
            "Train Epoch: 34 [16640/60000 (28%)]\tLoss: 740.493164\n",
            "Train Epoch: 34 [17920/60000 (30%)]\tLoss: 723.275757\n",
            "Train Epoch: 34 [19200/60000 (32%)]\tLoss: 728.538025\n",
            "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 730.356873\n",
            "Train Epoch: 34 [21760/60000 (36%)]\tLoss: 744.380676\n",
            "Train Epoch: 34 [23040/60000 (38%)]\tLoss: 764.397766\n",
            "Train Epoch: 34 [24320/60000 (41%)]\tLoss: 736.095825\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 756.639465\n",
            "Train Epoch: 34 [26880/60000 (45%)]\tLoss: 724.804443\n",
            "Train Epoch: 34 [28160/60000 (47%)]\tLoss: 740.471802\n",
            "Train Epoch: 34 [29440/60000 (49%)]\tLoss: 722.962524\n",
            "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 740.921753\n",
            "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 719.109802\n",
            "Train Epoch: 34 [33280/60000 (55%)]\tLoss: 740.228149\n",
            "Train Epoch: 34 [34560/60000 (58%)]\tLoss: 724.306213\n",
            "Train Epoch: 34 [35840/60000 (60%)]\tLoss: 750.510864\n",
            "Train Epoch: 34 [37120/60000 (62%)]\tLoss: 715.770386\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 726.005798\n",
            "Train Epoch: 34 [39680/60000 (66%)]\tLoss: 733.206238\n",
            "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 740.182617\n",
            "Train Epoch: 34 [42240/60000 (70%)]\tLoss: 728.701416\n",
            "Train Epoch: 34 [43520/60000 (72%)]\tLoss: 745.933594\n",
            "Train Epoch: 34 [44800/60000 (75%)]\tLoss: 725.428589\n",
            "Train Epoch: 34 [46080/60000 (77%)]\tLoss: 736.545776\n",
            "Train Epoch: 34 [47360/60000 (79%)]\tLoss: 725.201599\n",
            "Train Epoch: 34 [48640/60000 (81%)]\tLoss: 756.990112\n",
            "Train Epoch: 34 [49920/60000 (83%)]\tLoss: 719.339417\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 717.603882\n",
            "Train Epoch: 34 [52480/60000 (87%)]\tLoss: 743.359009\n",
            "Train Epoch: 34 [53760/60000 (90%)]\tLoss: 739.669189\n",
            "Train Epoch: 34 [55040/60000 (92%)]\tLoss: 752.569702\n",
            "Train Epoch: 34 [56320/60000 (94%)]\tLoss: 735.550232\n",
            "Train Epoch: 34 [57600/60000 (96%)]\tLoss: 731.400085\n",
            "Train Epoch: 34 [58880/60000 (98%)]\tLoss: 699.612427\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781562685966492\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 727.149292\n",
            "Train Epoch: 35 [1280/60000 (2%)]\tLoss: 722.791565\n",
            "Train Epoch: 35 [2560/60000 (4%)]\tLoss: 758.596436\n",
            "Train Epoch: 35 [3840/60000 (6%)]\tLoss: 744.004822\n",
            "Train Epoch: 35 [5120/60000 (9%)]\tLoss: 735.915100\n",
            "Train Epoch: 35 [6400/60000 (11%)]\tLoss: 724.043152\n",
            "Train Epoch: 35 [7680/60000 (13%)]\tLoss: 742.320435\n",
            "Train Epoch: 35 [8960/60000 (15%)]\tLoss: 731.874573\n",
            "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 742.097473\n",
            "Train Epoch: 35 [11520/60000 (19%)]\tLoss: 748.256042\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 741.738708\n",
            "Train Epoch: 35 [14080/60000 (23%)]\tLoss: 759.243835\n",
            "Train Epoch: 35 [15360/60000 (26%)]\tLoss: 737.416077\n",
            "Train Epoch: 35 [16640/60000 (28%)]\tLoss: 751.506531\n",
            "Train Epoch: 35 [17920/60000 (30%)]\tLoss: 736.430298\n",
            "Train Epoch: 35 [19200/60000 (32%)]\tLoss: 742.137756\n",
            "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 745.283081\n",
            "Train Epoch: 35 [21760/60000 (36%)]\tLoss: 734.548523\n",
            "Train Epoch: 35 [23040/60000 (38%)]\tLoss: 722.567505\n",
            "Train Epoch: 35 [24320/60000 (41%)]\tLoss: 754.926575\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 736.415833\n",
            "Train Epoch: 35 [26880/60000 (45%)]\tLoss: 722.027344\n",
            "Train Epoch: 35 [28160/60000 (47%)]\tLoss: 740.519775\n",
            "Train Epoch: 35 [29440/60000 (49%)]\tLoss: 739.412109\n",
            "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 745.250916\n",
            "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 741.724487\n",
            "Train Epoch: 35 [33280/60000 (55%)]\tLoss: 761.329285\n",
            "Train Epoch: 35 [34560/60000 (58%)]\tLoss: 727.195862\n",
            "Train Epoch: 35 [35840/60000 (60%)]\tLoss: 716.159241\n",
            "Train Epoch: 35 [37120/60000 (62%)]\tLoss: 745.324829\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 725.596863\n",
            "Train Epoch: 35 [39680/60000 (66%)]\tLoss: 735.015137\n",
            "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 749.596436\n",
            "Train Epoch: 35 [42240/60000 (70%)]\tLoss: 729.696106\n",
            "Train Epoch: 35 [43520/60000 (72%)]\tLoss: 722.157471\n",
            "Train Epoch: 35 [44800/60000 (75%)]\tLoss: 764.952332\n",
            "Train Epoch: 35 [46080/60000 (77%)]\tLoss: 700.566528\n",
            "Train Epoch: 35 [47360/60000 (79%)]\tLoss: 708.649231\n",
            "Train Epoch: 35 [48640/60000 (81%)]\tLoss: 730.598022\n",
            "Train Epoch: 35 [49920/60000 (83%)]\tLoss: 752.299500\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 754.297546\n",
            "Train Epoch: 35 [52480/60000 (87%)]\tLoss: 737.469421\n",
            "Train Epoch: 35 [53760/60000 (90%)]\tLoss: 768.699219\n",
            "Train Epoch: 35 [55040/60000 (92%)]\tLoss: 738.613098\n",
            "Train Epoch: 35 [56320/60000 (94%)]\tLoss: 709.251343\n",
            "Train Epoch: 35 [57600/60000 (96%)]\tLoss: 741.975647\n",
            "Train Epoch: 35 [58880/60000 (98%)]\tLoss: 729.342529\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978478878736496\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 745.568054\n",
            "Train Epoch: 36 [1280/60000 (2%)]\tLoss: 760.865906\n",
            "Train Epoch: 36 [2560/60000 (4%)]\tLoss: 743.158264\n",
            "Train Epoch: 36 [3840/60000 (6%)]\tLoss: 727.603455\n",
            "Train Epoch: 36 [5120/60000 (9%)]\tLoss: 727.918091\n",
            "Train Epoch: 36 [6400/60000 (11%)]\tLoss: 724.856445\n",
            "Train Epoch: 36 [7680/60000 (13%)]\tLoss: 727.213257\n",
            "Train Epoch: 36 [8960/60000 (15%)]\tLoss: 724.567627\n",
            "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 749.697632\n",
            "Train Epoch: 36 [11520/60000 (19%)]\tLoss: 754.406433\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 734.581787\n",
            "Train Epoch: 36 [14080/60000 (23%)]\tLoss: 734.410095\n",
            "Train Epoch: 36 [15360/60000 (26%)]\tLoss: 740.206604\n",
            "Train Epoch: 36 [16640/60000 (28%)]\tLoss: 750.175293\n",
            "Train Epoch: 36 [17920/60000 (30%)]\tLoss: 740.211609\n",
            "Train Epoch: 36 [19200/60000 (32%)]\tLoss: 743.147217\n",
            "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 725.159180\n",
            "Train Epoch: 36 [21760/60000 (36%)]\tLoss: 754.748474\n",
            "Train Epoch: 36 [23040/60000 (38%)]\tLoss: 720.783325\n",
            "Train Epoch: 36 [24320/60000 (41%)]\tLoss: 747.102661\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 753.337524\n",
            "Train Epoch: 36 [26880/60000 (45%)]\tLoss: 709.787964\n",
            "Train Epoch: 36 [28160/60000 (47%)]\tLoss: 732.260681\n",
            "Train Epoch: 36 [29440/60000 (49%)]\tLoss: 732.348267\n",
            "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 740.260742\n",
            "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 723.926575\n",
            "Train Epoch: 36 [33280/60000 (55%)]\tLoss: 738.293640\n",
            "Train Epoch: 36 [34560/60000 (58%)]\tLoss: 738.675903\n",
            "Train Epoch: 36 [35840/60000 (60%)]\tLoss: 736.717773\n",
            "Train Epoch: 36 [37120/60000 (62%)]\tLoss: 760.957886\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 745.829773\n",
            "Train Epoch: 36 [39680/60000 (66%)]\tLoss: 739.402832\n",
            "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 735.198730\n",
            "Train Epoch: 36 [42240/60000 (70%)]\tLoss: 743.379395\n",
            "Train Epoch: 36 [43520/60000 (72%)]\tLoss: 745.264343\n",
            "Train Epoch: 36 [44800/60000 (75%)]\tLoss: 729.019836\n",
            "Train Epoch: 36 [46080/60000 (77%)]\tLoss: 753.643066\n",
            "Train Epoch: 36 [47360/60000 (79%)]\tLoss: 731.439453\n",
            "Train Epoch: 36 [48640/60000 (81%)]\tLoss: 732.031799\n",
            "Train Epoch: 36 [49920/60000 (83%)]\tLoss: 744.099915\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 738.547791\n",
            "Train Epoch: 36 [52480/60000 (87%)]\tLoss: 724.228882\n",
            "Train Epoch: 36 [53760/60000 (90%)]\tLoss: 730.504150\n",
            "Train Epoch: 36 [55040/60000 (92%)]\tLoss: 767.290649\n",
            "Train Epoch: 36 [56320/60000 (94%)]\tLoss: 747.834167\n",
            "Train Epoch: 36 [57600/60000 (96%)]\tLoss: 748.990601\n",
            "Train Epoch: 36 [58880/60000 (98%)]\tLoss: 732.298279\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784218072891235\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 741.434448\n",
            "Train Epoch: 37 [1280/60000 (2%)]\tLoss: 745.042297\n",
            "Train Epoch: 37 [2560/60000 (4%)]\tLoss: 729.907471\n",
            "Train Epoch: 37 [3840/60000 (6%)]\tLoss: 746.292175\n",
            "Train Epoch: 37 [5120/60000 (9%)]\tLoss: 729.783203\n",
            "Train Epoch: 37 [6400/60000 (11%)]\tLoss: 711.313477\n",
            "Train Epoch: 37 [7680/60000 (13%)]\tLoss: 739.143250\n",
            "Train Epoch: 37 [8960/60000 (15%)]\tLoss: 745.958557\n",
            "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 719.976624\n",
            "Train Epoch: 37 [11520/60000 (19%)]\tLoss: 720.396545\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 719.658264\n",
            "Train Epoch: 37 [14080/60000 (23%)]\tLoss: 745.736267\n",
            "Train Epoch: 37 [15360/60000 (26%)]\tLoss: 761.914795\n",
            "Train Epoch: 37 [16640/60000 (28%)]\tLoss: 729.470581\n",
            "Train Epoch: 37 [17920/60000 (30%)]\tLoss: 720.639709\n",
            "Train Epoch: 37 [19200/60000 (32%)]\tLoss: 753.739807\n",
            "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 753.228821\n",
            "Train Epoch: 37 [21760/60000 (36%)]\tLoss: 726.157654\n",
            "Train Epoch: 37 [23040/60000 (38%)]\tLoss: 720.671753\n",
            "Train Epoch: 37 [24320/60000 (41%)]\tLoss: 737.703003\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 729.837341\n",
            "Train Epoch: 37 [26880/60000 (45%)]\tLoss: 720.396545\n",
            "Train Epoch: 37 [28160/60000 (47%)]\tLoss: 748.916321\n",
            "Train Epoch: 37 [29440/60000 (49%)]\tLoss: 748.098206\n",
            "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 740.137207\n",
            "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 726.605225\n",
            "Train Epoch: 37 [33280/60000 (55%)]\tLoss: 730.157715\n",
            "Train Epoch: 37 [34560/60000 (58%)]\tLoss: 742.517639\n",
            "Train Epoch: 37 [35840/60000 (60%)]\tLoss: 715.015076\n",
            "Train Epoch: 37 [37120/60000 (62%)]\tLoss: 731.993408\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 746.495178\n",
            "Train Epoch: 37 [39680/60000 (66%)]\tLoss: 752.808044\n",
            "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 759.838562\n",
            "Train Epoch: 37 [42240/60000 (70%)]\tLoss: 730.224121\n",
            "Train Epoch: 37 [43520/60000 (72%)]\tLoss: 746.045959\n",
            "Train Epoch: 37 [44800/60000 (75%)]\tLoss: 744.693665\n",
            "Train Epoch: 37 [46080/60000 (77%)]\tLoss: 727.780701\n",
            "Train Epoch: 37 [47360/60000 (79%)]\tLoss: 752.012146\n",
            "Train Epoch: 37 [48640/60000 (81%)]\tLoss: 750.428345\n",
            "Train Epoch: 37 [49920/60000 (83%)]\tLoss: 724.499756\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 732.151428\n",
            "Train Epoch: 37 [52480/60000 (87%)]\tLoss: 715.806885\n",
            "Train Epoch: 37 [53760/60000 (90%)]\tLoss: 720.501221\n",
            "Train Epoch: 37 [55040/60000 (92%)]\tLoss: 750.046692\n",
            "Train Epoch: 37 [56320/60000 (94%)]\tLoss: 738.295898\n",
            "Train Epoch: 37 [57600/60000 (96%)]\tLoss: 731.289978\n",
            "Train Epoch: 37 [58880/60000 (98%)]\tLoss: 742.687927\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784681499004364\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 736.294189\n",
            "Train Epoch: 38 [1280/60000 (2%)]\tLoss: 738.377808\n",
            "Train Epoch: 38 [2560/60000 (4%)]\tLoss: 731.303711\n",
            "Train Epoch: 38 [3840/60000 (6%)]\tLoss: 729.588806\n",
            "Train Epoch: 38 [5120/60000 (9%)]\tLoss: 731.173889\n",
            "Train Epoch: 38 [6400/60000 (11%)]\tLoss: 735.891357\n",
            "Train Epoch: 38 [7680/60000 (13%)]\tLoss: 718.003723\n",
            "Train Epoch: 38 [8960/60000 (15%)]\tLoss: 754.769470\n",
            "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 702.994690\n",
            "Train Epoch: 38 [11520/60000 (19%)]\tLoss: 732.101990\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 717.191040\n",
            "Train Epoch: 38 [14080/60000 (23%)]\tLoss: 740.960449\n",
            "Train Epoch: 38 [15360/60000 (26%)]\tLoss: 744.941406\n",
            "Train Epoch: 38 [16640/60000 (28%)]\tLoss: 745.935486\n",
            "Train Epoch: 38 [17920/60000 (30%)]\tLoss: 731.820679\n",
            "Train Epoch: 38 [19200/60000 (32%)]\tLoss: 758.075134\n",
            "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 737.195862\n",
            "Train Epoch: 38 [21760/60000 (36%)]\tLoss: 761.225403\n",
            "Train Epoch: 38 [23040/60000 (38%)]\tLoss: 744.882812\n",
            "Train Epoch: 38 [24320/60000 (41%)]\tLoss: 737.515564\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 727.233948\n",
            "Train Epoch: 38 [26880/60000 (45%)]\tLoss: 752.157410\n",
            "Train Epoch: 38 [28160/60000 (47%)]\tLoss: 744.436890\n",
            "Train Epoch: 38 [29440/60000 (49%)]\tLoss: 737.704041\n",
            "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 737.505676\n",
            "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 731.169250\n",
            "Train Epoch: 38 [33280/60000 (55%)]\tLoss: 727.470520\n",
            "Train Epoch: 38 [34560/60000 (58%)]\tLoss: 726.194214\n",
            "Train Epoch: 38 [35840/60000 (60%)]\tLoss: 728.339966\n",
            "Train Epoch: 38 [37120/60000 (62%)]\tLoss: 730.512390\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 756.049805\n",
            "Train Epoch: 38 [39680/60000 (66%)]\tLoss: 733.634705\n",
            "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 764.186584\n",
            "Train Epoch: 38 [42240/60000 (70%)]\tLoss: 726.297852\n",
            "Train Epoch: 38 [43520/60000 (72%)]\tLoss: 742.436218\n",
            "Train Epoch: 38 [44800/60000 (75%)]\tLoss: 731.412170\n",
            "Train Epoch: 38 [46080/60000 (77%)]\tLoss: 713.279358\n",
            "Train Epoch: 38 [47360/60000 (79%)]\tLoss: 708.528687\n",
            "Train Epoch: 38 [48640/60000 (81%)]\tLoss: 727.371765\n",
            "Train Epoch: 38 [49920/60000 (83%)]\tLoss: 726.236450\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 733.380066\n",
            "Train Epoch: 38 [52480/60000 (87%)]\tLoss: 740.780884\n",
            "Train Epoch: 38 [53760/60000 (90%)]\tLoss: 732.156555\n",
            "Train Epoch: 38 [55040/60000 (92%)]\tLoss: 749.873962\n",
            "Train Epoch: 38 [56320/60000 (94%)]\tLoss: 763.128601\n",
            "Train Epoch: 38 [57600/60000 (96%)]\tLoss: 720.337341\n",
            "Train Epoch: 38 [58880/60000 (98%)]\tLoss: 735.981628\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19779621064662933\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 740.730957\n",
            "Train Epoch: 39 [1280/60000 (2%)]\tLoss: 736.516968\n",
            "Train Epoch: 39 [2560/60000 (4%)]\tLoss: 719.595337\n",
            "Train Epoch: 39 [3840/60000 (6%)]\tLoss: 736.125000\n",
            "Train Epoch: 39 [5120/60000 (9%)]\tLoss: 740.116150\n",
            "Train Epoch: 39 [6400/60000 (11%)]\tLoss: 733.554016\n",
            "Train Epoch: 39 [7680/60000 (13%)]\tLoss: 740.591797\n",
            "Train Epoch: 39 [8960/60000 (15%)]\tLoss: 738.764160\n",
            "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 748.064209\n",
            "Train Epoch: 39 [11520/60000 (19%)]\tLoss: 756.632263\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 745.337952\n",
            "Train Epoch: 39 [14080/60000 (23%)]\tLoss: 743.330444\n",
            "Train Epoch: 39 [15360/60000 (26%)]\tLoss: 709.921692\n",
            "Train Epoch: 39 [16640/60000 (28%)]\tLoss: 715.972351\n",
            "Train Epoch: 39 [17920/60000 (30%)]\tLoss: 728.203918\n",
            "Train Epoch: 39 [19200/60000 (32%)]\tLoss: 730.684692\n",
            "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 743.856934\n",
            "Train Epoch: 39 [21760/60000 (36%)]\tLoss: 726.406677\n",
            "Train Epoch: 39 [23040/60000 (38%)]\tLoss: 747.118530\n",
            "Train Epoch: 39 [24320/60000 (41%)]\tLoss: 730.698120\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 724.903381\n",
            "Train Epoch: 39 [26880/60000 (45%)]\tLoss: 738.493408\n",
            "Train Epoch: 39 [28160/60000 (47%)]\tLoss: 738.825562\n",
            "Train Epoch: 39 [29440/60000 (49%)]\tLoss: 713.997192\n",
            "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 747.232056\n",
            "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 744.622559\n",
            "Train Epoch: 39 [33280/60000 (55%)]\tLoss: 746.849121\n",
            "Train Epoch: 39 [34560/60000 (58%)]\tLoss: 716.871460\n",
            "Train Epoch: 39 [35840/60000 (60%)]\tLoss: 746.179199\n",
            "Train Epoch: 39 [37120/60000 (62%)]\tLoss: 713.826172\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 757.827759\n",
            "Train Epoch: 39 [39680/60000 (66%)]\tLoss: 748.340515\n",
            "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 738.305298\n",
            "Train Epoch: 39 [42240/60000 (70%)]\tLoss: 762.640564\n",
            "Train Epoch: 39 [43520/60000 (72%)]\tLoss: 756.523682\n",
            "Train Epoch: 39 [44800/60000 (75%)]\tLoss: 741.971558\n",
            "Train Epoch: 39 [46080/60000 (77%)]\tLoss: 737.480164\n",
            "Train Epoch: 39 [47360/60000 (79%)]\tLoss: 738.777771\n",
            "Train Epoch: 39 [48640/60000 (81%)]\tLoss: 721.647644\n",
            "Train Epoch: 39 [49920/60000 (83%)]\tLoss: 773.942261\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 726.904785\n",
            "Train Epoch: 39 [52480/60000 (87%)]\tLoss: 710.496094\n",
            "Train Epoch: 39 [53760/60000 (90%)]\tLoss: 726.239014\n",
            "Train Epoch: 39 [55040/60000 (92%)]\tLoss: 757.380432\n",
            "Train Epoch: 39 [56320/60000 (94%)]\tLoss: 718.338745\n",
            "Train Epoch: 39 [57600/60000 (96%)]\tLoss: 743.426514\n",
            "Train Epoch: 39 [58880/60000 (98%)]\tLoss: 725.101868\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978185623884201\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 724.091370\n",
            "Train Epoch: 40 [1280/60000 (2%)]\tLoss: 752.720703\n",
            "Train Epoch: 40 [2560/60000 (4%)]\tLoss: 764.933533\n",
            "Train Epoch: 40 [3840/60000 (6%)]\tLoss: 736.065979\n",
            "Train Epoch: 40 [5120/60000 (9%)]\tLoss: 713.333069\n",
            "Train Epoch: 40 [6400/60000 (11%)]\tLoss: 736.805176\n",
            "Train Epoch: 40 [7680/60000 (13%)]\tLoss: 697.419678\n",
            "Train Epoch: 40 [8960/60000 (15%)]\tLoss: 721.637634\n",
            "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 761.196472\n",
            "Train Epoch: 40 [11520/60000 (19%)]\tLoss: 742.068176\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 721.027954\n",
            "Train Epoch: 40 [14080/60000 (23%)]\tLoss: 738.706726\n",
            "Train Epoch: 40 [15360/60000 (26%)]\tLoss: 723.945068\n",
            "Train Epoch: 40 [16640/60000 (28%)]\tLoss: 705.064636\n",
            "Train Epoch: 40 [17920/60000 (30%)]\tLoss: 741.357178\n",
            "Train Epoch: 40 [19200/60000 (32%)]\tLoss: 724.721130\n",
            "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 728.338562\n",
            "Train Epoch: 40 [21760/60000 (36%)]\tLoss: 723.385193\n",
            "Train Epoch: 40 [23040/60000 (38%)]\tLoss: 738.840393\n",
            "Train Epoch: 40 [24320/60000 (41%)]\tLoss: 741.339417\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 752.535217\n",
            "Train Epoch: 40 [26880/60000 (45%)]\tLoss: 743.620422\n",
            "Train Epoch: 40 [28160/60000 (47%)]\tLoss: 730.914124\n",
            "Train Epoch: 40 [29440/60000 (49%)]\tLoss: 765.314148\n",
            "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 752.837708\n",
            "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 707.579468\n",
            "Train Epoch: 40 [33280/60000 (55%)]\tLoss: 716.903931\n",
            "Train Epoch: 40 [34560/60000 (58%)]\tLoss: 742.581116\n",
            "Train Epoch: 40 [35840/60000 (60%)]\tLoss: 736.813171\n",
            "Train Epoch: 40 [37120/60000 (62%)]\tLoss: 756.050781\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 744.022888\n",
            "Train Epoch: 40 [39680/60000 (66%)]\tLoss: 738.648987\n",
            "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 708.388855\n",
            "Train Epoch: 40 [42240/60000 (70%)]\tLoss: 699.089905\n",
            "Train Epoch: 40 [43520/60000 (72%)]\tLoss: 721.720459\n",
            "Train Epoch: 40 [44800/60000 (75%)]\tLoss: 756.981934\n",
            "Train Epoch: 40 [46080/60000 (77%)]\tLoss: 748.383301\n",
            "Train Epoch: 40 [47360/60000 (79%)]\tLoss: 739.237610\n",
            "Train Epoch: 40 [48640/60000 (81%)]\tLoss: 757.155151\n",
            "Train Epoch: 40 [49920/60000 (83%)]\tLoss: 757.073608\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 734.072144\n",
            "Train Epoch: 40 [52480/60000 (87%)]\tLoss: 728.385498\n",
            "Train Epoch: 40 [53760/60000 (90%)]\tLoss: 707.714355\n",
            "Train Epoch: 40 [55040/60000 (92%)]\tLoss: 743.919312\n",
            "Train Epoch: 40 [56320/60000 (94%)]\tLoss: 740.078186\n",
            "Train Epoch: 40 [57600/60000 (96%)]\tLoss: 716.144775\n",
            "Train Epoch: 40 [58880/60000 (98%)]\tLoss: 747.283752\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978374570608139\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 761.725830\n",
            "Train Epoch: 41 [1280/60000 (2%)]\tLoss: 732.561584\n",
            "Train Epoch: 41 [2560/60000 (4%)]\tLoss: 749.725891\n",
            "Train Epoch: 41 [3840/60000 (6%)]\tLoss: 740.108704\n",
            "Train Epoch: 41 [5120/60000 (9%)]\tLoss: 750.062073\n",
            "Train Epoch: 41 [6400/60000 (11%)]\tLoss: 733.038574\n",
            "Train Epoch: 41 [7680/60000 (13%)]\tLoss: 732.922241\n",
            "Train Epoch: 41 [8960/60000 (15%)]\tLoss: 751.011353\n",
            "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 724.304565\n",
            "Train Epoch: 41 [11520/60000 (19%)]\tLoss: 730.915161\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 726.268921\n",
            "Train Epoch: 41 [14080/60000 (23%)]\tLoss: 725.256592\n",
            "Train Epoch: 41 [15360/60000 (26%)]\tLoss: 727.485046\n",
            "Train Epoch: 41 [16640/60000 (28%)]\tLoss: 764.988098\n",
            "Train Epoch: 41 [17920/60000 (30%)]\tLoss: 752.193481\n",
            "Train Epoch: 41 [19200/60000 (32%)]\tLoss: 745.507019\n",
            "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 737.178955\n",
            "Train Epoch: 41 [21760/60000 (36%)]\tLoss: 747.342041\n",
            "Train Epoch: 41 [23040/60000 (38%)]\tLoss: 706.105286\n",
            "Train Epoch: 41 [24320/60000 (41%)]\tLoss: 720.129883\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 716.751953\n",
            "Train Epoch: 41 [26880/60000 (45%)]\tLoss: 735.172058\n",
            "Train Epoch: 41 [28160/60000 (47%)]\tLoss: 728.783325\n",
            "Train Epoch: 41 [29440/60000 (49%)]\tLoss: 744.375671\n",
            "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 737.150330\n",
            "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 730.477051\n",
            "Train Epoch: 41 [33280/60000 (55%)]\tLoss: 746.052124\n",
            "Train Epoch: 41 [34560/60000 (58%)]\tLoss: 733.890320\n",
            "Train Epoch: 41 [35840/60000 (60%)]\tLoss: 742.942566\n",
            "Train Epoch: 41 [37120/60000 (62%)]\tLoss: 718.752930\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 721.864258\n",
            "Train Epoch: 41 [39680/60000 (66%)]\tLoss: 736.366577\n",
            "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 761.209412\n",
            "Train Epoch: 41 [42240/60000 (70%)]\tLoss: 725.668335\n",
            "Train Epoch: 41 [43520/60000 (72%)]\tLoss: 754.747131\n",
            "Train Epoch: 41 [44800/60000 (75%)]\tLoss: 734.796143\n",
            "Train Epoch: 41 [46080/60000 (77%)]\tLoss: 755.473206\n",
            "Train Epoch: 41 [47360/60000 (79%)]\tLoss: 728.184814\n",
            "Train Epoch: 41 [48640/60000 (81%)]\tLoss: 737.164795\n",
            "Train Epoch: 41 [49920/60000 (83%)]\tLoss: 712.475342\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 733.706238\n",
            "Train Epoch: 41 [52480/60000 (87%)]\tLoss: 772.951050\n",
            "Train Epoch: 41 [53760/60000 (90%)]\tLoss: 748.294678\n",
            "Train Epoch: 41 [55040/60000 (92%)]\tLoss: 757.817505\n",
            "Train Epoch: 41 [56320/60000 (94%)]\tLoss: 721.335327\n",
            "Train Epoch: 41 [57600/60000 (96%)]\tLoss: 735.569519\n",
            "Train Epoch: 41 [58880/60000 (98%)]\tLoss: 736.937378\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784428179264069\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 732.364197\n",
            "Train Epoch: 42 [1280/60000 (2%)]\tLoss: 737.361633\n",
            "Train Epoch: 42 [2560/60000 (4%)]\tLoss: 753.923218\n",
            "Train Epoch: 42 [3840/60000 (6%)]\tLoss: 731.048706\n",
            "Train Epoch: 42 [5120/60000 (9%)]\tLoss: 741.448608\n",
            "Train Epoch: 42 [6400/60000 (11%)]\tLoss: 716.391663\n",
            "Train Epoch: 42 [7680/60000 (13%)]\tLoss: 717.870789\n",
            "Train Epoch: 42 [8960/60000 (15%)]\tLoss: 742.369568\n",
            "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 706.422729\n",
            "Train Epoch: 42 [11520/60000 (19%)]\tLoss: 737.758362\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 736.411804\n",
            "Train Epoch: 42 [14080/60000 (23%)]\tLoss: 743.366455\n",
            "Train Epoch: 42 [15360/60000 (26%)]\tLoss: 734.893555\n",
            "Train Epoch: 42 [16640/60000 (28%)]\tLoss: 723.420715\n",
            "Train Epoch: 42 [17920/60000 (30%)]\tLoss: 753.169434\n",
            "Train Epoch: 42 [19200/60000 (32%)]\tLoss: 738.369995\n",
            "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 750.436401\n",
            "Train Epoch: 42 [21760/60000 (36%)]\tLoss: 742.331970\n",
            "Train Epoch: 42 [23040/60000 (38%)]\tLoss: 761.964294\n",
            "Train Epoch: 42 [24320/60000 (41%)]\tLoss: 750.036743\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 722.145935\n",
            "Train Epoch: 42 [26880/60000 (45%)]\tLoss: 743.777100\n",
            "Train Epoch: 42 [28160/60000 (47%)]\tLoss: 727.698975\n",
            "Train Epoch: 42 [29440/60000 (49%)]\tLoss: 718.226440\n",
            "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 719.518738\n",
            "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 735.537048\n",
            "Train Epoch: 42 [33280/60000 (55%)]\tLoss: 747.216614\n",
            "Train Epoch: 42 [34560/60000 (58%)]\tLoss: 752.822998\n",
            "Train Epoch: 42 [35840/60000 (60%)]\tLoss: 748.629639\n",
            "Train Epoch: 42 [37120/60000 (62%)]\tLoss: 752.355347\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 734.708740\n",
            "Train Epoch: 42 [39680/60000 (66%)]\tLoss: 766.189514\n",
            "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 738.951904\n",
            "Train Epoch: 42 [42240/60000 (70%)]\tLoss: 729.092346\n",
            "Train Epoch: 42 [43520/60000 (72%)]\tLoss: 760.746826\n",
            "Train Epoch: 42 [44800/60000 (75%)]\tLoss: 739.589172\n",
            "Train Epoch: 42 [46080/60000 (77%)]\tLoss: 754.006592\n",
            "Train Epoch: 42 [47360/60000 (79%)]\tLoss: 725.203735\n",
            "Train Epoch: 42 [48640/60000 (81%)]\tLoss: 742.429688\n",
            "Train Epoch: 42 [49920/60000 (83%)]\tLoss: 732.509338\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 757.354248\n",
            "Train Epoch: 42 [52480/60000 (87%)]\tLoss: 730.280151\n",
            "Train Epoch: 42 [53760/60000 (90%)]\tLoss: 741.236023\n",
            "Train Epoch: 42 [55040/60000 (92%)]\tLoss: 740.925354\n",
            "Train Epoch: 42 [56320/60000 (94%)]\tLoss: 713.270691\n",
            "Train Epoch: 42 [57600/60000 (96%)]\tLoss: 738.840759\n",
            "Train Epoch: 42 [58880/60000 (98%)]\tLoss: 743.451782\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782955944538116\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 736.018005\n",
            "Train Epoch: 43 [1280/60000 (2%)]\tLoss: 733.593994\n",
            "Train Epoch: 43 [2560/60000 (4%)]\tLoss: 717.564941\n",
            "Train Epoch: 43 [3840/60000 (6%)]\tLoss: 733.321106\n",
            "Train Epoch: 43 [5120/60000 (9%)]\tLoss: 739.482056\n",
            "Train Epoch: 43 [6400/60000 (11%)]\tLoss: 721.590088\n",
            "Train Epoch: 43 [7680/60000 (13%)]\tLoss: 750.750366\n",
            "Train Epoch: 43 [8960/60000 (15%)]\tLoss: 733.102966\n",
            "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 752.848450\n",
            "Train Epoch: 43 [11520/60000 (19%)]\tLoss: 777.949829\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 732.681885\n",
            "Train Epoch: 43 [14080/60000 (23%)]\tLoss: 736.581726\n",
            "Train Epoch: 43 [15360/60000 (26%)]\tLoss: 730.117981\n",
            "Train Epoch: 43 [16640/60000 (28%)]\tLoss: 730.587158\n",
            "Train Epoch: 43 [17920/60000 (30%)]\tLoss: 745.978333\n",
            "Train Epoch: 43 [19200/60000 (32%)]\tLoss: 747.831238\n",
            "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 720.110413\n",
            "Train Epoch: 43 [21760/60000 (36%)]\tLoss: 725.071533\n",
            "Train Epoch: 43 [23040/60000 (38%)]\tLoss: 726.390625\n",
            "Train Epoch: 43 [24320/60000 (41%)]\tLoss: 740.219910\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 739.104736\n",
            "Train Epoch: 43 [26880/60000 (45%)]\tLoss: 726.901978\n",
            "Train Epoch: 43 [28160/60000 (47%)]\tLoss: 741.815308\n",
            "Train Epoch: 43 [29440/60000 (49%)]\tLoss: 739.571899\n",
            "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 758.635742\n",
            "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 726.061462\n",
            "Train Epoch: 43 [33280/60000 (55%)]\tLoss: 712.795654\n",
            "Train Epoch: 43 [34560/60000 (58%)]\tLoss: 729.687988\n",
            "Train Epoch: 43 [35840/60000 (60%)]\tLoss: 765.729309\n",
            "Train Epoch: 43 [37120/60000 (62%)]\tLoss: 750.897766\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 746.624939\n",
            "Train Epoch: 43 [39680/60000 (66%)]\tLoss: 750.036438\n",
            "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 720.803772\n",
            "Train Epoch: 43 [42240/60000 (70%)]\tLoss: 728.218689\n",
            "Train Epoch: 43 [43520/60000 (72%)]\tLoss: 737.283020\n",
            "Train Epoch: 43 [44800/60000 (75%)]\tLoss: 748.021606\n",
            "Train Epoch: 43 [46080/60000 (77%)]\tLoss: 742.267822\n",
            "Train Epoch: 43 [47360/60000 (79%)]\tLoss: 735.327026\n",
            "Train Epoch: 43 [48640/60000 (81%)]\tLoss: 744.568542\n",
            "Train Epoch: 43 [49920/60000 (83%)]\tLoss: 758.106445\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 756.132446\n",
            "Train Epoch: 43 [52480/60000 (87%)]\tLoss: 738.979675\n",
            "Train Epoch: 43 [53760/60000 (90%)]\tLoss: 743.023315\n",
            "Train Epoch: 43 [55040/60000 (92%)]\tLoss: 739.709045\n",
            "Train Epoch: 43 [56320/60000 (94%)]\tLoss: 758.193787\n",
            "Train Epoch: 43 [57600/60000 (96%)]\tLoss: 708.590210\n",
            "Train Epoch: 43 [58880/60000 (98%)]\tLoss: 757.875732\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978415995836258\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 731.876709\n",
            "Train Epoch: 44 [1280/60000 (2%)]\tLoss: 751.491760\n",
            "Train Epoch: 44 [2560/60000 (4%)]\tLoss: 734.768555\n",
            "Train Epoch: 44 [3840/60000 (6%)]\tLoss: 736.214478\n",
            "Train Epoch: 44 [5120/60000 (9%)]\tLoss: 727.832886\n",
            "Train Epoch: 44 [6400/60000 (11%)]\tLoss: 721.213257\n",
            "Train Epoch: 44 [7680/60000 (13%)]\tLoss: 749.526672\n",
            "Train Epoch: 44 [8960/60000 (15%)]\tLoss: 707.402344\n",
            "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 745.680176\n",
            "Train Epoch: 44 [11520/60000 (19%)]\tLoss: 735.577637\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 740.682373\n",
            "Train Epoch: 44 [14080/60000 (23%)]\tLoss: 707.303833\n",
            "Train Epoch: 44 [15360/60000 (26%)]\tLoss: 786.385864\n",
            "Train Epoch: 44 [16640/60000 (28%)]\tLoss: 727.538696\n",
            "Train Epoch: 44 [17920/60000 (30%)]\tLoss: 724.685120\n",
            "Train Epoch: 44 [19200/60000 (32%)]\tLoss: 731.944885\n",
            "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 729.988770\n",
            "Train Epoch: 44 [21760/60000 (36%)]\tLoss: 756.173645\n",
            "Train Epoch: 44 [23040/60000 (38%)]\tLoss: 737.429810\n",
            "Train Epoch: 44 [24320/60000 (41%)]\tLoss: 725.704651\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 713.527893\n",
            "Train Epoch: 44 [26880/60000 (45%)]\tLoss: 757.600830\n",
            "Train Epoch: 44 [28160/60000 (47%)]\tLoss: 734.958191\n",
            "Train Epoch: 44 [29440/60000 (49%)]\tLoss: 729.609131\n",
            "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 773.360474\n",
            "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 734.464844\n",
            "Train Epoch: 44 [33280/60000 (55%)]\tLoss: 729.565491\n",
            "Train Epoch: 44 [34560/60000 (58%)]\tLoss: 722.684021\n",
            "Train Epoch: 44 [35840/60000 (60%)]\tLoss: 728.486816\n",
            "Train Epoch: 44 [37120/60000 (62%)]\tLoss: 764.102905\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 738.528198\n",
            "Train Epoch: 44 [39680/60000 (66%)]\tLoss: 757.931580\n",
            "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 728.170227\n",
            "Train Epoch: 44 [42240/60000 (70%)]\tLoss: 749.612732\n",
            "Train Epoch: 44 [43520/60000 (72%)]\tLoss: 734.128296\n",
            "Train Epoch: 44 [44800/60000 (75%)]\tLoss: 737.977051\n",
            "Train Epoch: 44 [46080/60000 (77%)]\tLoss: 777.551331\n",
            "Train Epoch: 44 [47360/60000 (79%)]\tLoss: 735.814819\n",
            "Train Epoch: 44 [48640/60000 (81%)]\tLoss: 767.166870\n",
            "Train Epoch: 44 [49920/60000 (83%)]\tLoss: 710.984314\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 712.701843\n",
            "Train Epoch: 44 [52480/60000 (87%)]\tLoss: 721.868164\n",
            "Train Epoch: 44 [53760/60000 (90%)]\tLoss: 739.094177\n",
            "Train Epoch: 44 [55040/60000 (92%)]\tLoss: 724.523499\n",
            "Train Epoch: 44 [56320/60000 (94%)]\tLoss: 723.738342\n",
            "Train Epoch: 44 [57600/60000 (96%)]\tLoss: 731.363159\n",
            "Train Epoch: 44 [58880/60000 (98%)]\tLoss: 739.910522\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785702228546143\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 721.283447\n",
            "Train Epoch: 45 [1280/60000 (2%)]\tLoss: 741.590332\n",
            "Train Epoch: 45 [2560/60000 (4%)]\tLoss: 727.646423\n",
            "Train Epoch: 45 [3840/60000 (6%)]\tLoss: 737.307068\n",
            "Train Epoch: 45 [5120/60000 (9%)]\tLoss: 731.511475\n",
            "Train Epoch: 45 [6400/60000 (11%)]\tLoss: 697.981995\n",
            "Train Epoch: 45 [7680/60000 (13%)]\tLoss: 724.783691\n",
            "Train Epoch: 45 [8960/60000 (15%)]\tLoss: 720.547607\n",
            "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 713.751404\n",
            "Train Epoch: 45 [11520/60000 (19%)]\tLoss: 737.956360\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 738.079590\n",
            "Train Epoch: 45 [14080/60000 (23%)]\tLoss: 715.252136\n",
            "Train Epoch: 45 [15360/60000 (26%)]\tLoss: 748.541077\n",
            "Train Epoch: 45 [16640/60000 (28%)]\tLoss: 721.907104\n",
            "Train Epoch: 45 [17920/60000 (30%)]\tLoss: 734.592285\n",
            "Train Epoch: 45 [19200/60000 (32%)]\tLoss: 731.354553\n",
            "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 729.790710\n",
            "Train Epoch: 45 [21760/60000 (36%)]\tLoss: 714.385620\n",
            "Train Epoch: 45 [23040/60000 (38%)]\tLoss: 735.431641\n",
            "Train Epoch: 45 [24320/60000 (41%)]\tLoss: 719.955200\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 735.974487\n",
            "Train Epoch: 45 [26880/60000 (45%)]\tLoss: 725.281311\n",
            "Train Epoch: 45 [28160/60000 (47%)]\tLoss: 716.290283\n",
            "Train Epoch: 45 [29440/60000 (49%)]\tLoss: 728.802002\n",
            "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 752.258911\n",
            "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 722.499084\n",
            "Train Epoch: 45 [33280/60000 (55%)]\tLoss: 756.979431\n",
            "Train Epoch: 45 [34560/60000 (58%)]\tLoss: 747.907715\n",
            "Train Epoch: 45 [35840/60000 (60%)]\tLoss: 734.110718\n",
            "Train Epoch: 45 [37120/60000 (62%)]\tLoss: 747.637512\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 746.087097\n",
            "Train Epoch: 45 [39680/60000 (66%)]\tLoss: 740.135254\n",
            "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 705.192017\n",
            "Train Epoch: 45 [42240/60000 (70%)]\tLoss: 725.949341\n",
            "Train Epoch: 45 [43520/60000 (72%)]\tLoss: 732.185669\n",
            "Train Epoch: 45 [44800/60000 (75%)]\tLoss: 734.563232\n",
            "Train Epoch: 45 [46080/60000 (77%)]\tLoss: 729.714539\n",
            "Train Epoch: 45 [47360/60000 (79%)]\tLoss: 737.037415\n",
            "Train Epoch: 45 [48640/60000 (81%)]\tLoss: 732.364929\n",
            "Train Epoch: 45 [49920/60000 (83%)]\tLoss: 747.166992\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 756.147217\n",
            "Train Epoch: 45 [52480/60000 (87%)]\tLoss: 740.818176\n",
            "Train Epoch: 45 [53760/60000 (90%)]\tLoss: 753.991882\n",
            "Train Epoch: 45 [55040/60000 (92%)]\tLoss: 748.242188\n",
            "Train Epoch: 45 [56320/60000 (94%)]\tLoss: 737.345337\n",
            "Train Epoch: 45 [57600/60000 (96%)]\tLoss: 741.282715\n",
            "Train Epoch: 45 [58880/60000 (98%)]\tLoss: 747.293579\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781655073165894\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 716.217712\n",
            "Train Epoch: 46 [1280/60000 (2%)]\tLoss: 729.150330\n",
            "Train Epoch: 46 [2560/60000 (4%)]\tLoss: 715.749023\n",
            "Train Epoch: 46 [3840/60000 (6%)]\tLoss: 748.274536\n",
            "Train Epoch: 46 [5120/60000 (9%)]\tLoss: 739.662048\n",
            "Train Epoch: 46 [6400/60000 (11%)]\tLoss: 698.932678\n",
            "Train Epoch: 46 [7680/60000 (13%)]\tLoss: 739.252991\n",
            "Train Epoch: 46 [8960/60000 (15%)]\tLoss: 729.255981\n",
            "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 764.155090\n",
            "Train Epoch: 46 [11520/60000 (19%)]\tLoss: 718.035400\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 755.419189\n",
            "Train Epoch: 46 [14080/60000 (23%)]\tLoss: 726.321228\n",
            "Train Epoch: 46 [15360/60000 (26%)]\tLoss: 732.522339\n",
            "Train Epoch: 46 [16640/60000 (28%)]\tLoss: 739.598694\n",
            "Train Epoch: 46 [17920/60000 (30%)]\tLoss: 734.035461\n",
            "Train Epoch: 46 [19200/60000 (32%)]\tLoss: 737.846252\n",
            "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 757.067444\n",
            "Train Epoch: 46 [21760/60000 (36%)]\tLoss: 730.418823\n",
            "Train Epoch: 46 [23040/60000 (38%)]\tLoss: 756.175720\n",
            "Train Epoch: 46 [24320/60000 (41%)]\tLoss: 744.266541\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 755.137573\n",
            "Train Epoch: 46 [26880/60000 (45%)]\tLoss: 755.368958\n",
            "Train Epoch: 46 [28160/60000 (47%)]\tLoss: 735.414551\n",
            "Train Epoch: 46 [29440/60000 (49%)]\tLoss: 752.377808\n",
            "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 712.630859\n",
            "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 749.026611\n",
            "Train Epoch: 46 [33280/60000 (55%)]\tLoss: 740.776672\n",
            "Train Epoch: 46 [34560/60000 (58%)]\tLoss: 712.182922\n",
            "Train Epoch: 46 [35840/60000 (60%)]\tLoss: 742.833069\n",
            "Train Epoch: 46 [37120/60000 (62%)]\tLoss: 711.013489\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 758.974426\n",
            "Train Epoch: 46 [39680/60000 (66%)]\tLoss: 741.659851\n",
            "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 756.193054\n",
            "Train Epoch: 46 [42240/60000 (70%)]\tLoss: 735.272644\n",
            "Train Epoch: 46 [43520/60000 (72%)]\tLoss: 728.147888\n",
            "Train Epoch: 46 [44800/60000 (75%)]\tLoss: 741.705994\n",
            "Train Epoch: 46 [46080/60000 (77%)]\tLoss: 723.179749\n",
            "Train Epoch: 46 [47360/60000 (79%)]\tLoss: 742.032349\n",
            "Train Epoch: 46 [48640/60000 (81%)]\tLoss: 725.890869\n",
            "Train Epoch: 46 [49920/60000 (83%)]\tLoss: 724.324097\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 749.025330\n",
            "Train Epoch: 46 [52480/60000 (87%)]\tLoss: 732.571289\n",
            "Train Epoch: 46 [53760/60000 (90%)]\tLoss: 762.758423\n",
            "Train Epoch: 46 [55040/60000 (92%)]\tLoss: 731.617798\n",
            "Train Epoch: 46 [56320/60000 (94%)]\tLoss: 738.613953\n",
            "Train Epoch: 46 [57600/60000 (96%)]\tLoss: 755.800110\n",
            "Train Epoch: 46 [58880/60000 (98%)]\tLoss: 733.933472\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1977968066930771\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 739.730652\n",
            "Train Epoch: 47 [1280/60000 (2%)]\tLoss: 710.265564\n",
            "Train Epoch: 47 [2560/60000 (4%)]\tLoss: 731.093567\n",
            "Train Epoch: 47 [3840/60000 (6%)]\tLoss: 741.098328\n",
            "Train Epoch: 47 [5120/60000 (9%)]\tLoss: 716.267090\n",
            "Train Epoch: 47 [6400/60000 (11%)]\tLoss: 764.811951\n",
            "Train Epoch: 47 [7680/60000 (13%)]\tLoss: 735.245361\n",
            "Train Epoch: 47 [8960/60000 (15%)]\tLoss: 730.567749\n",
            "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 724.028748\n",
            "Train Epoch: 47 [11520/60000 (19%)]\tLoss: 717.915955\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 754.933167\n",
            "Train Epoch: 47 [14080/60000 (23%)]\tLoss: 766.101135\n",
            "Train Epoch: 47 [15360/60000 (26%)]\tLoss: 742.773254\n",
            "Train Epoch: 47 [16640/60000 (28%)]\tLoss: 746.526428\n",
            "Train Epoch: 47 [17920/60000 (30%)]\tLoss: 717.161438\n",
            "Train Epoch: 47 [19200/60000 (32%)]\tLoss: 725.694092\n",
            "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 746.094727\n",
            "Train Epoch: 47 [21760/60000 (36%)]\tLoss: 744.565918\n",
            "Train Epoch: 47 [23040/60000 (38%)]\tLoss: 746.628296\n",
            "Train Epoch: 47 [24320/60000 (41%)]\tLoss: 751.941467\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 754.501709\n",
            "Train Epoch: 47 [26880/60000 (45%)]\tLoss: 736.195435\n",
            "Train Epoch: 47 [28160/60000 (47%)]\tLoss: 726.333740\n",
            "Train Epoch: 47 [29440/60000 (49%)]\tLoss: 730.048279\n",
            "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 705.770935\n",
            "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 751.415161\n",
            "Train Epoch: 47 [33280/60000 (55%)]\tLoss: 742.554443\n",
            "Train Epoch: 47 [34560/60000 (58%)]\tLoss: 724.705383\n",
            "Train Epoch: 47 [35840/60000 (60%)]\tLoss: 727.350403\n",
            "Train Epoch: 47 [37120/60000 (62%)]\tLoss: 744.749207\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 740.563660\n",
            "Train Epoch: 47 [39680/60000 (66%)]\tLoss: 753.663025\n",
            "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 732.914795\n",
            "Train Epoch: 47 [42240/60000 (70%)]\tLoss: 746.609924\n",
            "Train Epoch: 47 [43520/60000 (72%)]\tLoss: 703.699646\n",
            "Train Epoch: 47 [44800/60000 (75%)]\tLoss: 725.180908\n",
            "Train Epoch: 47 [46080/60000 (77%)]\tLoss: 749.931641\n",
            "Train Epoch: 47 [47360/60000 (79%)]\tLoss: 731.491028\n",
            "Train Epoch: 47 [48640/60000 (81%)]\tLoss: 757.921570\n",
            "Train Epoch: 47 [49920/60000 (83%)]\tLoss: 749.031189\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 717.969727\n",
            "Train Epoch: 47 [52480/60000 (87%)]\tLoss: 749.823181\n",
            "Train Epoch: 47 [53760/60000 (90%)]\tLoss: 733.883118\n",
            "Train Epoch: 47 [55040/60000 (92%)]\tLoss: 744.499146\n",
            "Train Epoch: 47 [56320/60000 (94%)]\tLoss: 746.014099\n",
            "Train Epoch: 47 [57600/60000 (96%)]\tLoss: 749.515930\n",
            "Train Epoch: 47 [58880/60000 (98%)]\tLoss: 735.136780\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784361124038696\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 739.001282\n",
            "Train Epoch: 48 [1280/60000 (2%)]\tLoss: 743.941772\n",
            "Train Epoch: 48 [2560/60000 (4%)]\tLoss: 747.409485\n",
            "Train Epoch: 48 [3840/60000 (6%)]\tLoss: 726.906250\n",
            "Train Epoch: 48 [5120/60000 (9%)]\tLoss: 739.015015\n",
            "Train Epoch: 48 [6400/60000 (11%)]\tLoss: 757.292786\n",
            "Train Epoch: 48 [7680/60000 (13%)]\tLoss: 740.388489\n",
            "Train Epoch: 48 [8960/60000 (15%)]\tLoss: 743.490417\n",
            "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 741.157715\n",
            "Train Epoch: 48 [11520/60000 (19%)]\tLoss: 718.617493\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 724.458801\n",
            "Train Epoch: 48 [14080/60000 (23%)]\tLoss: 719.495361\n",
            "Train Epoch: 48 [15360/60000 (26%)]\tLoss: 729.009460\n",
            "Train Epoch: 48 [16640/60000 (28%)]\tLoss: 738.661926\n",
            "Train Epoch: 48 [17920/60000 (30%)]\tLoss: 749.166626\n",
            "Train Epoch: 48 [19200/60000 (32%)]\tLoss: 749.146301\n",
            "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 750.745056\n",
            "Train Epoch: 48 [21760/60000 (36%)]\tLoss: 735.900940\n",
            "Train Epoch: 48 [23040/60000 (38%)]\tLoss: 741.667175\n",
            "Train Epoch: 48 [24320/60000 (41%)]\tLoss: 721.169495\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 754.058960\n",
            "Train Epoch: 48 [26880/60000 (45%)]\tLoss: 759.898010\n",
            "Train Epoch: 48 [28160/60000 (47%)]\tLoss: 707.280579\n",
            "Train Epoch: 48 [29440/60000 (49%)]\tLoss: 745.962769\n",
            "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 723.651184\n",
            "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 752.719910\n",
            "Train Epoch: 48 [33280/60000 (55%)]\tLoss: 722.349792\n",
            "Train Epoch: 48 [34560/60000 (58%)]\tLoss: 722.842468\n",
            "Train Epoch: 48 [35840/60000 (60%)]\tLoss: 756.641174\n",
            "Train Epoch: 48 [37120/60000 (62%)]\tLoss: 736.307617\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 733.350891\n",
            "Train Epoch: 48 [39680/60000 (66%)]\tLoss: 737.578003\n",
            "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 706.591431\n",
            "Train Epoch: 48 [42240/60000 (70%)]\tLoss: 738.560974\n",
            "Train Epoch: 48 [43520/60000 (72%)]\tLoss: 727.514832\n",
            "Train Epoch: 48 [44800/60000 (75%)]\tLoss: 706.103821\n",
            "Train Epoch: 48 [46080/60000 (77%)]\tLoss: 722.108154\n",
            "Train Epoch: 48 [47360/60000 (79%)]\tLoss: 749.900269\n",
            "Train Epoch: 48 [48640/60000 (81%)]\tLoss: 721.321411\n",
            "Train Epoch: 48 [49920/60000 (83%)]\tLoss: 723.056274\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 719.893738\n",
            "Train Epoch: 48 [52480/60000 (87%)]\tLoss: 723.329651\n",
            "Train Epoch: 48 [53760/60000 (90%)]\tLoss: 737.457031\n",
            "Train Epoch: 48 [55040/60000 (92%)]\tLoss: 737.351318\n",
            "Train Epoch: 48 [56320/60000 (94%)]\tLoss: 754.820801\n",
            "Train Epoch: 48 [57600/60000 (96%)]\tLoss: 706.189026\n",
            "Train Epoch: 48 [58880/60000 (98%)]\tLoss: 742.125854\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978210210800171\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 752.529602\n",
            "Train Epoch: 49 [1280/60000 (2%)]\tLoss: 720.089905\n",
            "Train Epoch: 49 [2560/60000 (4%)]\tLoss: 749.954834\n",
            "Train Epoch: 49 [3840/60000 (6%)]\tLoss: 766.007751\n",
            "Train Epoch: 49 [5120/60000 (9%)]\tLoss: 750.819275\n",
            "Train Epoch: 49 [6400/60000 (11%)]\tLoss: 751.217102\n",
            "Train Epoch: 49 [7680/60000 (13%)]\tLoss: 726.320862\n",
            "Train Epoch: 49 [8960/60000 (15%)]\tLoss: 736.949219\n",
            "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 738.438416\n",
            "Train Epoch: 49 [11520/60000 (19%)]\tLoss: 732.217712\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 732.354980\n",
            "Train Epoch: 49 [14080/60000 (23%)]\tLoss: 719.920776\n",
            "Train Epoch: 49 [15360/60000 (26%)]\tLoss: 743.134094\n",
            "Train Epoch: 49 [16640/60000 (28%)]\tLoss: 740.806946\n",
            "Train Epoch: 49 [17920/60000 (30%)]\tLoss: 723.952881\n",
            "Train Epoch: 49 [19200/60000 (32%)]\tLoss: 714.825684\n",
            "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 742.656677\n",
            "Train Epoch: 49 [21760/60000 (36%)]\tLoss: 732.118530\n",
            "Train Epoch: 49 [23040/60000 (38%)]\tLoss: 747.623535\n",
            "Train Epoch: 49 [24320/60000 (41%)]\tLoss: 714.370361\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 722.782043\n",
            "Train Epoch: 49 [26880/60000 (45%)]\tLoss: 782.098572\n",
            "Train Epoch: 49 [28160/60000 (47%)]\tLoss: 734.198914\n",
            "Train Epoch: 49 [29440/60000 (49%)]\tLoss: 730.388611\n",
            "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 736.797180\n",
            "Train Epoch: 49 [32000/60000 (53%)]\tLoss: 744.679260\n",
            "Train Epoch: 49 [33280/60000 (55%)]\tLoss: 750.120728\n",
            "Train Epoch: 49 [34560/60000 (58%)]\tLoss: 749.145386\n",
            "Train Epoch: 49 [35840/60000 (60%)]\tLoss: 742.256348\n",
            "Train Epoch: 49 [37120/60000 (62%)]\tLoss: 736.762390\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 746.952820\n",
            "Train Epoch: 49 [39680/60000 (66%)]\tLoss: 749.050781\n",
            "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 726.646973\n",
            "Train Epoch: 49 [42240/60000 (70%)]\tLoss: 762.606628\n",
            "Train Epoch: 49 [43520/60000 (72%)]\tLoss: 760.796814\n",
            "Train Epoch: 49 [44800/60000 (75%)]\tLoss: 732.024414\n",
            "Train Epoch: 49 [46080/60000 (77%)]\tLoss: 745.870117\n",
            "Train Epoch: 49 [47360/60000 (79%)]\tLoss: 711.580261\n",
            "Train Epoch: 49 [48640/60000 (81%)]\tLoss: 720.999390\n",
            "Train Epoch: 49 [49920/60000 (83%)]\tLoss: 729.945251\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 731.973450\n",
            "Train Epoch: 49 [52480/60000 (87%)]\tLoss: 716.867554\n",
            "Train Epoch: 49 [53760/60000 (90%)]\tLoss: 713.724731\n",
            "Train Epoch: 49 [55040/60000 (92%)]\tLoss: 741.265503\n",
            "Train Epoch: 49 [56320/60000 (94%)]\tLoss: 748.090149\n",
            "Train Epoch: 49 [57600/60000 (96%)]\tLoss: 729.477234\n",
            "Train Epoch: 49 [58880/60000 (98%)]\tLoss: 724.915527\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781425595283508\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 735.972290\n",
            "Train Epoch: 50 [1280/60000 (2%)]\tLoss: 742.370422\n",
            "Train Epoch: 50 [2560/60000 (4%)]\tLoss: 742.402954\n",
            "Train Epoch: 50 [3840/60000 (6%)]\tLoss: 760.964233\n",
            "Train Epoch: 50 [5120/60000 (9%)]\tLoss: 716.368713\n",
            "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 747.203796\n",
            "Train Epoch: 50 [7680/60000 (13%)]\tLoss: 744.306458\n",
            "Train Epoch: 50 [8960/60000 (15%)]\tLoss: 730.315613\n",
            "Train Epoch: 50 [10240/60000 (17%)]\tLoss: 766.504822\n",
            "Train Epoch: 50 [11520/60000 (19%)]\tLoss: 761.319885\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 739.526428\n",
            "Train Epoch: 50 [14080/60000 (23%)]\tLoss: 737.705444\n",
            "Train Epoch: 50 [15360/60000 (26%)]\tLoss: 731.116577\n",
            "Train Epoch: 50 [16640/60000 (28%)]\tLoss: 728.595276\n",
            "Train Epoch: 50 [17920/60000 (30%)]\tLoss: 742.582397\n",
            "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 700.379822\n",
            "Train Epoch: 50 [20480/60000 (34%)]\tLoss: 725.513306\n",
            "Train Epoch: 50 [21760/60000 (36%)]\tLoss: 739.590820\n",
            "Train Epoch: 50 [23040/60000 (38%)]\tLoss: 723.631348\n",
            "Train Epoch: 50 [24320/60000 (41%)]\tLoss: 737.403442\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 724.697815\n",
            "Train Epoch: 50 [26880/60000 (45%)]\tLoss: 732.321594\n",
            "Train Epoch: 50 [28160/60000 (47%)]\tLoss: 710.583923\n",
            "Train Epoch: 50 [29440/60000 (49%)]\tLoss: 746.465088\n",
            "Train Epoch: 50 [30720/60000 (51%)]\tLoss: 745.777222\n",
            "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 723.344482\n",
            "Train Epoch: 50 [33280/60000 (55%)]\tLoss: 744.711365\n",
            "Train Epoch: 50 [34560/60000 (58%)]\tLoss: 737.973389\n",
            "Train Epoch: 50 [35840/60000 (60%)]\tLoss: 746.773438\n",
            "Train Epoch: 50 [37120/60000 (62%)]\tLoss: 744.346558\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 733.768311\n",
            "Train Epoch: 50 [39680/60000 (66%)]\tLoss: 744.334595\n",
            "Train Epoch: 50 [40960/60000 (68%)]\tLoss: 723.343140\n",
            "Train Epoch: 50 [42240/60000 (70%)]\tLoss: 746.819397\n",
            "Train Epoch: 50 [43520/60000 (72%)]\tLoss: 719.367310\n",
            "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 720.351685\n",
            "Train Epoch: 50 [46080/60000 (77%)]\tLoss: 729.422058\n",
            "Train Epoch: 50 [47360/60000 (79%)]\tLoss: 734.133972\n",
            "Train Epoch: 50 [48640/60000 (81%)]\tLoss: 735.811829\n",
            "Train Epoch: 50 [49920/60000 (83%)]\tLoss: 754.646912\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 724.270508\n",
            "Train Epoch: 50 [52480/60000 (87%)]\tLoss: 758.785156\n",
            "Train Epoch: 50 [53760/60000 (90%)]\tLoss: 749.619324\n",
            "Train Epoch: 50 [55040/60000 (92%)]\tLoss: 746.242188\n",
            "Train Epoch: 50 [56320/60000 (94%)]\tLoss: 759.927673\n",
            "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 752.624329\n",
            "Train Epoch: 50 [58880/60000 (98%)]\tLoss: 733.343628\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.197846457362175\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 746.239197\n",
            "Train Epoch: 51 [1280/60000 (2%)]\tLoss: 725.402832\n",
            "Train Epoch: 51 [2560/60000 (4%)]\tLoss: 746.956482\n",
            "Train Epoch: 51 [3840/60000 (6%)]\tLoss: 750.767883\n",
            "Train Epoch: 51 [5120/60000 (9%)]\tLoss: 749.604492\n",
            "Train Epoch: 51 [6400/60000 (11%)]\tLoss: 734.352356\n",
            "Train Epoch: 51 [7680/60000 (13%)]\tLoss: 740.440063\n",
            "Train Epoch: 51 [8960/60000 (15%)]\tLoss: 752.362305\n",
            "Train Epoch: 51 [10240/60000 (17%)]\tLoss: 700.731628\n",
            "Train Epoch: 51 [11520/60000 (19%)]\tLoss: 740.048462\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 758.529846\n",
            "Train Epoch: 51 [14080/60000 (23%)]\tLoss: 728.329712\n",
            "Train Epoch: 51 [15360/60000 (26%)]\tLoss: 745.068726\n",
            "Train Epoch: 51 [16640/60000 (28%)]\tLoss: 743.024719\n",
            "Train Epoch: 51 [17920/60000 (30%)]\tLoss: 726.346802\n",
            "Train Epoch: 51 [19200/60000 (32%)]\tLoss: 733.308289\n",
            "Train Epoch: 51 [20480/60000 (34%)]\tLoss: 733.424500\n",
            "Train Epoch: 51 [21760/60000 (36%)]\tLoss: 706.718262\n",
            "Train Epoch: 51 [23040/60000 (38%)]\tLoss: 745.195862\n",
            "Train Epoch: 51 [24320/60000 (41%)]\tLoss: 730.346008\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 752.502808\n",
            "Train Epoch: 51 [26880/60000 (45%)]\tLoss: 727.945374\n",
            "Train Epoch: 51 [28160/60000 (47%)]\tLoss: 749.214600\n",
            "Train Epoch: 51 [29440/60000 (49%)]\tLoss: 738.164795\n",
            "Train Epoch: 51 [30720/60000 (51%)]\tLoss: 730.530273\n",
            "Train Epoch: 51 [32000/60000 (53%)]\tLoss: 749.390320\n",
            "Train Epoch: 51 [33280/60000 (55%)]\tLoss: 748.467163\n",
            "Train Epoch: 51 [34560/60000 (58%)]\tLoss: 760.709045\n",
            "Train Epoch: 51 [35840/60000 (60%)]\tLoss: 722.285461\n",
            "Train Epoch: 51 [37120/60000 (62%)]\tLoss: 730.752563\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 739.881226\n",
            "Train Epoch: 51 [39680/60000 (66%)]\tLoss: 756.829163\n",
            "Train Epoch: 51 [40960/60000 (68%)]\tLoss: 727.334839\n",
            "Train Epoch: 51 [42240/60000 (70%)]\tLoss: 732.080566\n",
            "Train Epoch: 51 [43520/60000 (72%)]\tLoss: 763.131775\n",
            "Train Epoch: 51 [44800/60000 (75%)]\tLoss: 744.648132\n",
            "Train Epoch: 51 [46080/60000 (77%)]\tLoss: 735.102722\n",
            "Train Epoch: 51 [47360/60000 (79%)]\tLoss: 735.423340\n",
            "Train Epoch: 51 [48640/60000 (81%)]\tLoss: 728.746704\n",
            "Train Epoch: 51 [49920/60000 (83%)]\tLoss: 720.768433\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 760.769104\n",
            "Train Epoch: 51 [52480/60000 (87%)]\tLoss: 734.443726\n",
            "Train Epoch: 51 [53760/60000 (90%)]\tLoss: 767.047424\n",
            "Train Epoch: 51 [55040/60000 (92%)]\tLoss: 757.965027\n",
            "Train Epoch: 51 [56320/60000 (94%)]\tLoss: 711.331116\n",
            "Train Epoch: 51 [57600/60000 (96%)]\tLoss: 737.975281\n",
            "Train Epoch: 51 [58880/60000 (98%)]\tLoss: 723.641357\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.197829008102417\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 715.463867\n",
            "Train Epoch: 52 [1280/60000 (2%)]\tLoss: 728.515625\n",
            "Train Epoch: 52 [2560/60000 (4%)]\tLoss: 738.161499\n",
            "Train Epoch: 52 [3840/60000 (6%)]\tLoss: 747.681641\n",
            "Train Epoch: 52 [5120/60000 (9%)]\tLoss: 734.008423\n",
            "Train Epoch: 52 [6400/60000 (11%)]\tLoss: 719.008179\n",
            "Train Epoch: 52 [7680/60000 (13%)]\tLoss: 729.591003\n",
            "Train Epoch: 52 [8960/60000 (15%)]\tLoss: 741.057068\n",
            "Train Epoch: 52 [10240/60000 (17%)]\tLoss: 750.378235\n",
            "Train Epoch: 52 [11520/60000 (19%)]\tLoss: 719.035645\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 759.470764\n",
            "Train Epoch: 52 [14080/60000 (23%)]\tLoss: 754.271179\n",
            "Train Epoch: 52 [15360/60000 (26%)]\tLoss: 753.360962\n",
            "Train Epoch: 52 [16640/60000 (28%)]\tLoss: 740.672668\n",
            "Train Epoch: 52 [17920/60000 (30%)]\tLoss: 741.131104\n",
            "Train Epoch: 52 [19200/60000 (32%)]\tLoss: 737.890076\n",
            "Train Epoch: 52 [20480/60000 (34%)]\tLoss: 758.297119\n",
            "Train Epoch: 52 [21760/60000 (36%)]\tLoss: 729.876709\n",
            "Train Epoch: 52 [23040/60000 (38%)]\tLoss: 730.871155\n",
            "Train Epoch: 52 [24320/60000 (41%)]\tLoss: 729.867065\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 720.161133\n",
            "Train Epoch: 52 [26880/60000 (45%)]\tLoss: 733.570618\n",
            "Train Epoch: 52 [28160/60000 (47%)]\tLoss: 734.144592\n",
            "Train Epoch: 52 [29440/60000 (49%)]\tLoss: 774.036377\n",
            "Train Epoch: 52 [30720/60000 (51%)]\tLoss: 721.642395\n",
            "Train Epoch: 52 [32000/60000 (53%)]\tLoss: 735.011292\n",
            "Train Epoch: 52 [33280/60000 (55%)]\tLoss: 720.078064\n",
            "Train Epoch: 52 [34560/60000 (58%)]\tLoss: 724.293396\n",
            "Train Epoch: 52 [35840/60000 (60%)]\tLoss: 743.936401\n",
            "Train Epoch: 52 [37120/60000 (62%)]\tLoss: 736.534973\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 747.872559\n",
            "Train Epoch: 52 [39680/60000 (66%)]\tLoss: 739.815613\n",
            "Train Epoch: 52 [40960/60000 (68%)]\tLoss: 740.861267\n",
            "Train Epoch: 52 [42240/60000 (70%)]\tLoss: 732.905640\n",
            "Train Epoch: 52 [43520/60000 (72%)]\tLoss: 745.873657\n",
            "Train Epoch: 52 [44800/60000 (75%)]\tLoss: 752.167786\n",
            "Train Epoch: 52 [46080/60000 (77%)]\tLoss: 726.683472\n",
            "Train Epoch: 52 [47360/60000 (79%)]\tLoss: 741.342651\n",
            "Train Epoch: 52 [48640/60000 (81%)]\tLoss: 757.592102\n",
            "Train Epoch: 52 [49920/60000 (83%)]\tLoss: 743.412292\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 764.067688\n",
            "Train Epoch: 52 [52480/60000 (87%)]\tLoss: 710.947754\n",
            "Train Epoch: 52 [53760/60000 (90%)]\tLoss: 731.059875\n",
            "Train Epoch: 52 [55040/60000 (92%)]\tLoss: 739.585205\n",
            "Train Epoch: 52 [56320/60000 (94%)]\tLoss: 719.208191\n",
            "Train Epoch: 52 [57600/60000 (96%)]\tLoss: 723.173523\n",
            "Train Epoch: 52 [58880/60000 (98%)]\tLoss: 749.470398\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787859916687012\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 741.103699\n",
            "Train Epoch: 53 [1280/60000 (2%)]\tLoss: 720.888855\n",
            "Train Epoch: 53 [2560/60000 (4%)]\tLoss: 731.622192\n",
            "Train Epoch: 53 [3840/60000 (6%)]\tLoss: 726.527771\n",
            "Train Epoch: 53 [5120/60000 (9%)]\tLoss: 763.629272\n",
            "Train Epoch: 53 [6400/60000 (11%)]\tLoss: 737.164551\n",
            "Train Epoch: 53 [7680/60000 (13%)]\tLoss: 735.518921\n",
            "Train Epoch: 53 [8960/60000 (15%)]\tLoss: 738.196533\n",
            "Train Epoch: 53 [10240/60000 (17%)]\tLoss: 763.903870\n",
            "Train Epoch: 53 [11520/60000 (19%)]\tLoss: 708.890320\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 747.376465\n",
            "Train Epoch: 53 [14080/60000 (23%)]\tLoss: 740.029480\n",
            "Train Epoch: 53 [15360/60000 (26%)]\tLoss: 734.522400\n",
            "Train Epoch: 53 [16640/60000 (28%)]\tLoss: 738.225708\n",
            "Train Epoch: 53 [17920/60000 (30%)]\tLoss: 719.975891\n",
            "Train Epoch: 53 [19200/60000 (32%)]\tLoss: 754.184875\n",
            "Train Epoch: 53 [20480/60000 (34%)]\tLoss: 746.019104\n",
            "Train Epoch: 53 [21760/60000 (36%)]\tLoss: 708.920837\n",
            "Train Epoch: 53 [23040/60000 (38%)]\tLoss: 744.869995\n",
            "Train Epoch: 53 [24320/60000 (41%)]\tLoss: 737.262024\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 736.911377\n",
            "Train Epoch: 53 [26880/60000 (45%)]\tLoss: 743.640320\n",
            "Train Epoch: 53 [28160/60000 (47%)]\tLoss: 744.217285\n",
            "Train Epoch: 53 [29440/60000 (49%)]\tLoss: 733.235535\n",
            "Train Epoch: 53 [30720/60000 (51%)]\tLoss: 767.847412\n",
            "Train Epoch: 53 [32000/60000 (53%)]\tLoss: 750.694458\n",
            "Train Epoch: 53 [33280/60000 (55%)]\tLoss: 743.730530\n",
            "Train Epoch: 53 [34560/60000 (58%)]\tLoss: 729.090637\n",
            "Train Epoch: 53 [35840/60000 (60%)]\tLoss: 728.689331\n",
            "Train Epoch: 53 [37120/60000 (62%)]\tLoss: 720.932434\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 746.200073\n",
            "Train Epoch: 53 [39680/60000 (66%)]\tLoss: 737.539368\n",
            "Train Epoch: 53 [40960/60000 (68%)]\tLoss: 744.564392\n",
            "Train Epoch: 53 [42240/60000 (70%)]\tLoss: 748.477966\n",
            "Train Epoch: 53 [43520/60000 (72%)]\tLoss: 722.419434\n",
            "Train Epoch: 53 [44800/60000 (75%)]\tLoss: 709.895142\n",
            "Train Epoch: 53 [46080/60000 (77%)]\tLoss: 731.189575\n",
            "Train Epoch: 53 [47360/60000 (79%)]\tLoss: 720.934448\n",
            "Train Epoch: 53 [48640/60000 (81%)]\tLoss: 756.646790\n",
            "Train Epoch: 53 [49920/60000 (83%)]\tLoss: 743.570740\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 751.675903\n",
            "Train Epoch: 53 [52480/60000 (87%)]\tLoss: 747.418335\n",
            "Train Epoch: 53 [53760/60000 (90%)]\tLoss: 731.610596\n",
            "Train Epoch: 53 [55040/60000 (92%)]\tLoss: 723.768433\n",
            "Train Epoch: 53 [56320/60000 (94%)]\tLoss: 752.186951\n",
            "Train Epoch: 53 [57600/60000 (96%)]\tLoss: 730.410278\n",
            "Train Epoch: 53 [58880/60000 (98%)]\tLoss: 726.688782\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781489670276642\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 737.718445\n",
            "Train Epoch: 54 [1280/60000 (2%)]\tLoss: 747.181030\n",
            "Train Epoch: 54 [2560/60000 (4%)]\tLoss: 741.523926\n",
            "Train Epoch: 54 [3840/60000 (6%)]\tLoss: 714.103577\n",
            "Train Epoch: 54 [5120/60000 (9%)]\tLoss: 734.305542\n",
            "Train Epoch: 54 [6400/60000 (11%)]\tLoss: 724.118225\n",
            "Train Epoch: 54 [7680/60000 (13%)]\tLoss: 767.199707\n",
            "Train Epoch: 54 [8960/60000 (15%)]\tLoss: 729.130432\n",
            "Train Epoch: 54 [10240/60000 (17%)]\tLoss: 719.616760\n",
            "Train Epoch: 54 [11520/60000 (19%)]\tLoss: 731.742371\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 740.257263\n",
            "Train Epoch: 54 [14080/60000 (23%)]\tLoss: 737.239319\n",
            "Train Epoch: 54 [15360/60000 (26%)]\tLoss: 730.675354\n",
            "Train Epoch: 54 [16640/60000 (28%)]\tLoss: 748.221436\n",
            "Train Epoch: 54 [17920/60000 (30%)]\tLoss: 763.302002\n",
            "Train Epoch: 54 [19200/60000 (32%)]\tLoss: 735.970703\n",
            "Train Epoch: 54 [20480/60000 (34%)]\tLoss: 732.802856\n",
            "Train Epoch: 54 [21760/60000 (36%)]\tLoss: 730.383667\n",
            "Train Epoch: 54 [23040/60000 (38%)]\tLoss: 744.021057\n",
            "Train Epoch: 54 [24320/60000 (41%)]\tLoss: 745.519653\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 755.328430\n",
            "Train Epoch: 54 [26880/60000 (45%)]\tLoss: 727.788208\n",
            "Train Epoch: 54 [28160/60000 (47%)]\tLoss: 742.713806\n",
            "Train Epoch: 54 [29440/60000 (49%)]\tLoss: 750.771606\n",
            "Train Epoch: 54 [30720/60000 (51%)]\tLoss: 734.991638\n",
            "Train Epoch: 54 [32000/60000 (53%)]\tLoss: 739.580078\n",
            "Train Epoch: 54 [33280/60000 (55%)]\tLoss: 739.459351\n",
            "Train Epoch: 54 [34560/60000 (58%)]\tLoss: 758.864624\n",
            "Train Epoch: 54 [35840/60000 (60%)]\tLoss: 748.522522\n",
            "Train Epoch: 54 [37120/60000 (62%)]\tLoss: 734.960876\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 722.622925\n",
            "Train Epoch: 54 [39680/60000 (66%)]\tLoss: 772.390930\n",
            "Train Epoch: 54 [40960/60000 (68%)]\tLoss: 745.783508\n",
            "Train Epoch: 54 [42240/60000 (70%)]\tLoss: 729.188538\n",
            "Train Epoch: 54 [43520/60000 (72%)]\tLoss: 772.905701\n",
            "Train Epoch: 54 [44800/60000 (75%)]\tLoss: 749.098816\n",
            "Train Epoch: 54 [46080/60000 (77%)]\tLoss: 706.834839\n",
            "Train Epoch: 54 [47360/60000 (79%)]\tLoss: 739.483826\n",
            "Train Epoch: 54 [48640/60000 (81%)]\tLoss: 727.778076\n",
            "Train Epoch: 54 [49920/60000 (83%)]\tLoss: 727.313232\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 737.600464\n",
            "Train Epoch: 54 [52480/60000 (87%)]\tLoss: 721.425903\n",
            "Train Epoch: 54 [53760/60000 (90%)]\tLoss: 763.652771\n",
            "Train Epoch: 54 [55040/60000 (92%)]\tLoss: 728.695496\n",
            "Train Epoch: 54 [56320/60000 (94%)]\tLoss: 711.874207\n",
            "Train Epoch: 54 [57600/60000 (96%)]\tLoss: 714.439209\n",
            "Train Epoch: 54 [58880/60000 (98%)]\tLoss: 750.878540\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978568732738495\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 729.461243\n",
            "Train Epoch: 55 [1280/60000 (2%)]\tLoss: 721.624756\n",
            "Train Epoch: 55 [2560/60000 (4%)]\tLoss: 732.966736\n",
            "Train Epoch: 55 [3840/60000 (6%)]\tLoss: 732.600037\n",
            "Train Epoch: 55 [5120/60000 (9%)]\tLoss: 719.610535\n",
            "Train Epoch: 55 [6400/60000 (11%)]\tLoss: 750.705688\n",
            "Train Epoch: 55 [7680/60000 (13%)]\tLoss: 738.373657\n",
            "Train Epoch: 55 [8960/60000 (15%)]\tLoss: 715.476318\n",
            "Train Epoch: 55 [10240/60000 (17%)]\tLoss: 733.921631\n",
            "Train Epoch: 55 [11520/60000 (19%)]\tLoss: 747.315979\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 770.845215\n",
            "Train Epoch: 55 [14080/60000 (23%)]\tLoss: 711.729370\n",
            "Train Epoch: 55 [15360/60000 (26%)]\tLoss: 730.381104\n",
            "Train Epoch: 55 [16640/60000 (28%)]\tLoss: 713.947876\n",
            "Train Epoch: 55 [17920/60000 (30%)]\tLoss: 737.070129\n",
            "Train Epoch: 55 [19200/60000 (32%)]\tLoss: 730.888123\n",
            "Train Epoch: 55 [20480/60000 (34%)]\tLoss: 732.829529\n",
            "Train Epoch: 55 [21760/60000 (36%)]\tLoss: 731.087341\n",
            "Train Epoch: 55 [23040/60000 (38%)]\tLoss: 749.596191\n",
            "Train Epoch: 55 [24320/60000 (41%)]\tLoss: 735.036560\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 756.492126\n",
            "Train Epoch: 55 [26880/60000 (45%)]\tLoss: 731.638916\n",
            "Train Epoch: 55 [28160/60000 (47%)]\tLoss: 742.318054\n",
            "Train Epoch: 55 [29440/60000 (49%)]\tLoss: 720.964355\n",
            "Train Epoch: 55 [30720/60000 (51%)]\tLoss: 721.833069\n",
            "Train Epoch: 55 [32000/60000 (53%)]\tLoss: 723.303345\n",
            "Train Epoch: 55 [33280/60000 (55%)]\tLoss: 742.017151\n",
            "Train Epoch: 55 [34560/60000 (58%)]\tLoss: 737.605835\n",
            "Train Epoch: 55 [35840/60000 (60%)]\tLoss: 747.880920\n",
            "Train Epoch: 55 [37120/60000 (62%)]\tLoss: 718.886353\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 755.180054\n",
            "Train Epoch: 55 [39680/60000 (66%)]\tLoss: 715.904358\n",
            "Train Epoch: 55 [40960/60000 (68%)]\tLoss: 723.970032\n",
            "Train Epoch: 55 [42240/60000 (70%)]\tLoss: 707.722168\n",
            "Train Epoch: 55 [43520/60000 (72%)]\tLoss: 733.379211\n",
            "Train Epoch: 55 [44800/60000 (75%)]\tLoss: 739.825745\n",
            "Train Epoch: 55 [46080/60000 (77%)]\tLoss: 731.708496\n",
            "Train Epoch: 55 [47360/60000 (79%)]\tLoss: 753.975708\n",
            "Train Epoch: 55 [48640/60000 (81%)]\tLoss: 714.023865\n",
            "Train Epoch: 55 [49920/60000 (83%)]\tLoss: 743.897644\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 727.031921\n",
            "Train Epoch: 55 [52480/60000 (87%)]\tLoss: 735.765442\n",
            "Train Epoch: 55 [53760/60000 (90%)]\tLoss: 707.706970\n",
            "Train Epoch: 55 [55040/60000 (92%)]\tLoss: 755.324341\n",
            "Train Epoch: 55 [56320/60000 (94%)]\tLoss: 736.657349\n",
            "Train Epoch: 55 [57600/60000 (96%)]\tLoss: 741.642883\n",
            "Train Epoch: 55 [58880/60000 (98%)]\tLoss: 724.518494\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978493183851242\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 741.454773\n",
            "Train Epoch: 56 [1280/60000 (2%)]\tLoss: 745.132874\n",
            "Train Epoch: 56 [2560/60000 (4%)]\tLoss: 733.534973\n",
            "Train Epoch: 56 [3840/60000 (6%)]\tLoss: 713.732971\n",
            "Train Epoch: 56 [5120/60000 (9%)]\tLoss: 734.551025\n",
            "Train Epoch: 56 [6400/60000 (11%)]\tLoss: 758.827087\n",
            "Train Epoch: 56 [7680/60000 (13%)]\tLoss: 752.140198\n",
            "Train Epoch: 56 [8960/60000 (15%)]\tLoss: 741.681763\n",
            "Train Epoch: 56 [10240/60000 (17%)]\tLoss: 741.101685\n",
            "Train Epoch: 56 [11520/60000 (19%)]\tLoss: 748.564697\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 730.920227\n",
            "Train Epoch: 56 [14080/60000 (23%)]\tLoss: 747.546814\n",
            "Train Epoch: 56 [15360/60000 (26%)]\tLoss: 739.460754\n",
            "Train Epoch: 56 [16640/60000 (28%)]\tLoss: 737.634644\n",
            "Train Epoch: 56 [17920/60000 (30%)]\tLoss: 731.847656\n",
            "Train Epoch: 56 [19200/60000 (32%)]\tLoss: 739.406860\n",
            "Train Epoch: 56 [20480/60000 (34%)]\tLoss: 729.570801\n",
            "Train Epoch: 56 [21760/60000 (36%)]\tLoss: 731.315063\n",
            "Train Epoch: 56 [23040/60000 (38%)]\tLoss: 743.761963\n",
            "Train Epoch: 56 [24320/60000 (41%)]\tLoss: 725.037537\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 730.982910\n",
            "Train Epoch: 56 [26880/60000 (45%)]\tLoss: 725.136536\n",
            "Train Epoch: 56 [28160/60000 (47%)]\tLoss: 753.647522\n",
            "Train Epoch: 56 [29440/60000 (49%)]\tLoss: 722.735046\n",
            "Train Epoch: 56 [30720/60000 (51%)]\tLoss: 742.575439\n",
            "Train Epoch: 56 [32000/60000 (53%)]\tLoss: 741.036560\n",
            "Train Epoch: 56 [33280/60000 (55%)]\tLoss: 713.725159\n",
            "Train Epoch: 56 [34560/60000 (58%)]\tLoss: 746.332336\n",
            "Train Epoch: 56 [35840/60000 (60%)]\tLoss: 741.613281\n",
            "Train Epoch: 56 [37120/60000 (62%)]\tLoss: 733.281860\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 714.609253\n",
            "Train Epoch: 56 [39680/60000 (66%)]\tLoss: 722.049011\n",
            "Train Epoch: 56 [40960/60000 (68%)]\tLoss: 749.702637\n",
            "Train Epoch: 56 [42240/60000 (70%)]\tLoss: 732.616638\n",
            "Train Epoch: 56 [43520/60000 (72%)]\tLoss: 717.555664\n",
            "Train Epoch: 56 [44800/60000 (75%)]\tLoss: 747.946106\n",
            "Train Epoch: 56 [46080/60000 (77%)]\tLoss: 712.280701\n",
            "Train Epoch: 56 [47360/60000 (79%)]\tLoss: 724.565552\n",
            "Train Epoch: 56 [48640/60000 (81%)]\tLoss: 728.550659\n",
            "Train Epoch: 56 [49920/60000 (83%)]\tLoss: 721.347961\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 752.720642\n",
            "Train Epoch: 56 [52480/60000 (87%)]\tLoss: 720.656250\n",
            "Train Epoch: 56 [53760/60000 (90%)]\tLoss: 743.937744\n",
            "Train Epoch: 56 [55040/60000 (92%)]\tLoss: 753.793030\n",
            "Train Epoch: 56 [56320/60000 (94%)]\tLoss: 732.123108\n",
            "Train Epoch: 56 [57600/60000 (96%)]\tLoss: 763.954956\n",
            "Train Epoch: 56 [58880/60000 (98%)]\tLoss: 726.548523\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978415548801422\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 734.128357\n",
            "Train Epoch: 57 [1280/60000 (2%)]\tLoss: 748.289246\n",
            "Train Epoch: 57 [2560/60000 (4%)]\tLoss: 737.449280\n",
            "Train Epoch: 57 [3840/60000 (6%)]\tLoss: 748.100159\n",
            "Train Epoch: 57 [5120/60000 (9%)]\tLoss: 743.411621\n",
            "Train Epoch: 57 [6400/60000 (11%)]\tLoss: 717.294250\n",
            "Train Epoch: 57 [7680/60000 (13%)]\tLoss: 726.108215\n",
            "Train Epoch: 57 [8960/60000 (15%)]\tLoss: 733.696472\n",
            "Train Epoch: 57 [10240/60000 (17%)]\tLoss: 739.462891\n",
            "Train Epoch: 57 [11520/60000 (19%)]\tLoss: 729.194580\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 731.047363\n",
            "Train Epoch: 57 [14080/60000 (23%)]\tLoss: 768.678589\n",
            "Train Epoch: 57 [15360/60000 (26%)]\tLoss: 727.348450\n",
            "Train Epoch: 57 [16640/60000 (28%)]\tLoss: 748.803040\n",
            "Train Epoch: 57 [17920/60000 (30%)]\tLoss: 709.140198\n",
            "Train Epoch: 57 [19200/60000 (32%)]\tLoss: 758.811462\n",
            "Train Epoch: 57 [20480/60000 (34%)]\tLoss: 759.843262\n",
            "Train Epoch: 57 [21760/60000 (36%)]\tLoss: 728.935242\n",
            "Train Epoch: 57 [23040/60000 (38%)]\tLoss: 738.498779\n",
            "Train Epoch: 57 [24320/60000 (41%)]\tLoss: 729.553406\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 739.688416\n",
            "Train Epoch: 57 [26880/60000 (45%)]\tLoss: 749.616760\n",
            "Train Epoch: 57 [28160/60000 (47%)]\tLoss: 756.214050\n",
            "Train Epoch: 57 [29440/60000 (49%)]\tLoss: 742.174011\n",
            "Train Epoch: 57 [30720/60000 (51%)]\tLoss: 734.811462\n",
            "Train Epoch: 57 [32000/60000 (53%)]\tLoss: 741.703125\n",
            "Train Epoch: 57 [33280/60000 (55%)]\tLoss: 723.446960\n",
            "Train Epoch: 57 [34560/60000 (58%)]\tLoss: 734.102173\n",
            "Train Epoch: 57 [35840/60000 (60%)]\tLoss: 742.072632\n",
            "Train Epoch: 57 [37120/60000 (62%)]\tLoss: 719.886292\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 720.751709\n",
            "Train Epoch: 57 [39680/60000 (66%)]\tLoss: 743.750793\n",
            "Train Epoch: 57 [40960/60000 (68%)]\tLoss: 744.637146\n",
            "Train Epoch: 57 [42240/60000 (70%)]\tLoss: 724.356628\n",
            "Train Epoch: 57 [43520/60000 (72%)]\tLoss: 739.539185\n",
            "Train Epoch: 57 [44800/60000 (75%)]\tLoss: 772.386780\n",
            "Train Epoch: 57 [46080/60000 (77%)]\tLoss: 726.362000\n",
            "Train Epoch: 57 [47360/60000 (79%)]\tLoss: 745.381409\n",
            "Train Epoch: 57 [48640/60000 (81%)]\tLoss: 725.265686\n",
            "Train Epoch: 57 [49920/60000 (83%)]\tLoss: 734.490906\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 729.386902\n",
            "Train Epoch: 57 [52480/60000 (87%)]\tLoss: 732.875122\n",
            "Train Epoch: 57 [53760/60000 (90%)]\tLoss: 766.252197\n",
            "Train Epoch: 57 [55040/60000 (92%)]\tLoss: 740.558167\n",
            "Train Epoch: 57 [56320/60000 (94%)]\tLoss: 739.814758\n",
            "Train Epoch: 57 [57600/60000 (96%)]\tLoss: 733.763611\n",
            "Train Epoch: 57 [58880/60000 (98%)]\tLoss: 730.781738\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780507683753967\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 730.664856\n",
            "Train Epoch: 58 [1280/60000 (2%)]\tLoss: 745.689514\n",
            "Train Epoch: 58 [2560/60000 (4%)]\tLoss: 723.832458\n",
            "Train Epoch: 58 [3840/60000 (6%)]\tLoss: 726.466797\n",
            "Train Epoch: 58 [5120/60000 (9%)]\tLoss: 759.638184\n",
            "Train Epoch: 58 [6400/60000 (11%)]\tLoss: 729.492065\n",
            "Train Epoch: 58 [7680/60000 (13%)]\tLoss: 732.970398\n",
            "Train Epoch: 58 [8960/60000 (15%)]\tLoss: 718.999390\n",
            "Train Epoch: 58 [10240/60000 (17%)]\tLoss: 745.677551\n",
            "Train Epoch: 58 [11520/60000 (19%)]\tLoss: 758.826111\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 738.365112\n",
            "Train Epoch: 58 [14080/60000 (23%)]\tLoss: 743.078430\n",
            "Train Epoch: 58 [15360/60000 (26%)]\tLoss: 698.622681\n",
            "Train Epoch: 58 [16640/60000 (28%)]\tLoss: 736.067505\n",
            "Train Epoch: 58 [17920/60000 (30%)]\tLoss: 736.559387\n",
            "Train Epoch: 58 [19200/60000 (32%)]\tLoss: 714.505371\n",
            "Train Epoch: 58 [20480/60000 (34%)]\tLoss: 742.086060\n",
            "Train Epoch: 58 [21760/60000 (36%)]\tLoss: 722.679810\n",
            "Train Epoch: 58 [23040/60000 (38%)]\tLoss: 728.088379\n",
            "Train Epoch: 58 [24320/60000 (41%)]\tLoss: 729.696899\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 721.455811\n",
            "Train Epoch: 58 [26880/60000 (45%)]\tLoss: 732.636536\n",
            "Train Epoch: 58 [28160/60000 (47%)]\tLoss: 740.735046\n",
            "Train Epoch: 58 [29440/60000 (49%)]\tLoss: 723.343140\n",
            "Train Epoch: 58 [30720/60000 (51%)]\tLoss: 731.665161\n",
            "Train Epoch: 58 [32000/60000 (53%)]\tLoss: 767.874939\n",
            "Train Epoch: 58 [33280/60000 (55%)]\tLoss: 716.883057\n",
            "Train Epoch: 58 [34560/60000 (58%)]\tLoss: 760.251465\n",
            "Train Epoch: 58 [35840/60000 (60%)]\tLoss: 721.691589\n",
            "Train Epoch: 58 [37120/60000 (62%)]\tLoss: 739.612427\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 733.105530\n",
            "Train Epoch: 58 [39680/60000 (66%)]\tLoss: 750.774109\n",
            "Train Epoch: 58 [40960/60000 (68%)]\tLoss: 716.078796\n",
            "Train Epoch: 58 [42240/60000 (70%)]\tLoss: 742.034668\n",
            "Train Epoch: 58 [43520/60000 (72%)]\tLoss: 712.512024\n",
            "Train Epoch: 58 [44800/60000 (75%)]\tLoss: 720.840698\n",
            "Train Epoch: 58 [46080/60000 (77%)]\tLoss: 731.874878\n",
            "Train Epoch: 58 [47360/60000 (79%)]\tLoss: 728.153564\n",
            "Train Epoch: 58 [48640/60000 (81%)]\tLoss: 758.989624\n",
            "Train Epoch: 58 [49920/60000 (83%)]\tLoss: 735.713989\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 709.584167\n",
            "Train Epoch: 58 [52480/60000 (87%)]\tLoss: 746.021240\n",
            "Train Epoch: 58 [53760/60000 (90%)]\tLoss: 749.516113\n",
            "Train Epoch: 58 [55040/60000 (92%)]\tLoss: 737.136841\n",
            "Train Epoch: 58 [56320/60000 (94%)]\tLoss: 768.696777\n",
            "Train Epoch: 58 [57600/60000 (96%)]\tLoss: 749.598999\n",
            "Train Epoch: 58 [58880/60000 (98%)]\tLoss: 732.923218\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784659147262573\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 726.753418\n",
            "Train Epoch: 59 [1280/60000 (2%)]\tLoss: 733.602051\n",
            "Train Epoch: 59 [2560/60000 (4%)]\tLoss: 746.004333\n",
            "Train Epoch: 59 [3840/60000 (6%)]\tLoss: 759.953735\n",
            "Train Epoch: 59 [5120/60000 (9%)]\tLoss: 750.122192\n",
            "Train Epoch: 59 [6400/60000 (11%)]\tLoss: 722.135498\n",
            "Train Epoch: 59 [7680/60000 (13%)]\tLoss: 720.760986\n",
            "Train Epoch: 59 [8960/60000 (15%)]\tLoss: 757.826843\n",
            "Train Epoch: 59 [10240/60000 (17%)]\tLoss: 747.172241\n",
            "Train Epoch: 59 [11520/60000 (19%)]\tLoss: 754.100708\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 753.550537\n",
            "Train Epoch: 59 [14080/60000 (23%)]\tLoss: 739.014465\n",
            "Train Epoch: 59 [15360/60000 (26%)]\tLoss: 728.799866\n",
            "Train Epoch: 59 [16640/60000 (28%)]\tLoss: 731.491882\n",
            "Train Epoch: 59 [17920/60000 (30%)]\tLoss: 726.127136\n",
            "Train Epoch: 59 [19200/60000 (32%)]\tLoss: 733.051453\n",
            "Train Epoch: 59 [20480/60000 (34%)]\tLoss: 732.238708\n",
            "Train Epoch: 59 [21760/60000 (36%)]\tLoss: 717.433105\n",
            "Train Epoch: 59 [23040/60000 (38%)]\tLoss: 754.744873\n",
            "Train Epoch: 59 [24320/60000 (41%)]\tLoss: 713.650024\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 749.649658\n",
            "Train Epoch: 59 [26880/60000 (45%)]\tLoss: 728.209045\n",
            "Train Epoch: 59 [28160/60000 (47%)]\tLoss: 738.171326\n",
            "Train Epoch: 59 [29440/60000 (49%)]\tLoss: 734.511719\n",
            "Train Epoch: 59 [30720/60000 (51%)]\tLoss: 710.414368\n",
            "Train Epoch: 59 [32000/60000 (53%)]\tLoss: 718.115784\n",
            "Train Epoch: 59 [33280/60000 (55%)]\tLoss: 734.245239\n",
            "Train Epoch: 59 [34560/60000 (58%)]\tLoss: 731.213379\n",
            "Train Epoch: 59 [35840/60000 (60%)]\tLoss: 775.533936\n",
            "Train Epoch: 59 [37120/60000 (62%)]\tLoss: 723.585266\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 744.752563\n",
            "Train Epoch: 59 [39680/60000 (66%)]\tLoss: 737.356995\n",
            "Train Epoch: 59 [40960/60000 (68%)]\tLoss: 755.579163\n",
            "Train Epoch: 59 [42240/60000 (70%)]\tLoss: 746.910095\n",
            "Train Epoch: 59 [43520/60000 (72%)]\tLoss: 742.643494\n",
            "Train Epoch: 59 [44800/60000 (75%)]\tLoss: 754.609802\n",
            "Train Epoch: 59 [46080/60000 (77%)]\tLoss: 744.135864\n",
            "Train Epoch: 59 [47360/60000 (79%)]\tLoss: 746.412537\n",
            "Train Epoch: 59 [48640/60000 (81%)]\tLoss: 769.518555\n",
            "Train Epoch: 59 [49920/60000 (83%)]\tLoss: 728.933289\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 750.514587\n",
            "Train Epoch: 59 [52480/60000 (87%)]\tLoss: 717.880737\n",
            "Train Epoch: 59 [53760/60000 (90%)]\tLoss: 737.698669\n",
            "Train Epoch: 59 [55040/60000 (92%)]\tLoss: 748.913635\n",
            "Train Epoch: 59 [56320/60000 (94%)]\tLoss: 714.987183\n",
            "Train Epoch: 59 [57600/60000 (96%)]\tLoss: 715.481201\n",
            "Train Epoch: 59 [58880/60000 (98%)]\tLoss: 711.779724\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785617291927338\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 744.875122\n",
            "Train Epoch: 60 [1280/60000 (2%)]\tLoss: 760.105225\n",
            "Train Epoch: 60 [2560/60000 (4%)]\tLoss: 734.136963\n",
            "Train Epoch: 60 [3840/60000 (6%)]\tLoss: 759.131409\n",
            "Train Epoch: 60 [5120/60000 (9%)]\tLoss: 739.342102\n",
            "Train Epoch: 60 [6400/60000 (11%)]\tLoss: 721.448730\n",
            "Train Epoch: 60 [7680/60000 (13%)]\tLoss: 742.954102\n",
            "Train Epoch: 60 [8960/60000 (15%)]\tLoss: 736.260742\n",
            "Train Epoch: 60 [10240/60000 (17%)]\tLoss: 723.675598\n",
            "Train Epoch: 60 [11520/60000 (19%)]\tLoss: 712.544739\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 761.375854\n",
            "Train Epoch: 60 [14080/60000 (23%)]\tLoss: 761.662720\n",
            "Train Epoch: 60 [15360/60000 (26%)]\tLoss: 717.979797\n",
            "Train Epoch: 60 [16640/60000 (28%)]\tLoss: 746.344666\n",
            "Train Epoch: 60 [17920/60000 (30%)]\tLoss: 727.696167\n",
            "Train Epoch: 60 [19200/60000 (32%)]\tLoss: 749.173401\n",
            "Train Epoch: 60 [20480/60000 (34%)]\tLoss: 734.516357\n",
            "Train Epoch: 60 [21760/60000 (36%)]\tLoss: 740.398560\n",
            "Train Epoch: 60 [23040/60000 (38%)]\tLoss: 756.888306\n",
            "Train Epoch: 60 [24320/60000 (41%)]\tLoss: 739.642029\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 722.839600\n",
            "Train Epoch: 60 [26880/60000 (45%)]\tLoss: 755.958496\n",
            "Train Epoch: 60 [28160/60000 (47%)]\tLoss: 737.323669\n",
            "Train Epoch: 60 [29440/60000 (49%)]\tLoss: 728.694092\n",
            "Train Epoch: 60 [30720/60000 (51%)]\tLoss: 748.378174\n",
            "Train Epoch: 60 [32000/60000 (53%)]\tLoss: 754.938843\n",
            "Train Epoch: 60 [33280/60000 (55%)]\tLoss: 715.350952\n",
            "Train Epoch: 60 [34560/60000 (58%)]\tLoss: 758.552368\n",
            "Train Epoch: 60 [35840/60000 (60%)]\tLoss: 756.873169\n",
            "Train Epoch: 60 [37120/60000 (62%)]\tLoss: 738.480469\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 759.681824\n",
            "Train Epoch: 60 [39680/60000 (66%)]\tLoss: 748.776917\n",
            "Train Epoch: 60 [40960/60000 (68%)]\tLoss: 706.956665\n",
            "Train Epoch: 60 [42240/60000 (70%)]\tLoss: 753.302979\n",
            "Train Epoch: 60 [43520/60000 (72%)]\tLoss: 742.911438\n",
            "Train Epoch: 60 [44800/60000 (75%)]\tLoss: 725.438538\n",
            "Train Epoch: 60 [46080/60000 (77%)]\tLoss: 747.332275\n",
            "Train Epoch: 60 [47360/60000 (79%)]\tLoss: 746.366028\n",
            "Train Epoch: 60 [48640/60000 (81%)]\tLoss: 718.130615\n",
            "Train Epoch: 60 [49920/60000 (83%)]\tLoss: 731.252319\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 739.789185\n",
            "Train Epoch: 60 [52480/60000 (87%)]\tLoss: 746.198120\n",
            "Train Epoch: 60 [53760/60000 (90%)]\tLoss: 715.281921\n",
            "Train Epoch: 60 [55040/60000 (92%)]\tLoss: 725.485046\n",
            "Train Epoch: 60 [56320/60000 (94%)]\tLoss: 734.464172\n",
            "Train Epoch: 60 [57600/60000 (96%)]\tLoss: 721.184204\n",
            "Train Epoch: 60 [58880/60000 (98%)]\tLoss: 742.338501\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786955416202545\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 745.528198\n",
            "Train Epoch: 61 [1280/60000 (2%)]\tLoss: 720.700928\n",
            "Train Epoch: 61 [2560/60000 (4%)]\tLoss: 730.940186\n",
            "Train Epoch: 61 [3840/60000 (6%)]\tLoss: 743.843689\n",
            "Train Epoch: 61 [5120/60000 (9%)]\tLoss: 719.324402\n",
            "Train Epoch: 61 [6400/60000 (11%)]\tLoss: 765.631592\n",
            "Train Epoch: 61 [7680/60000 (13%)]\tLoss: 754.334839\n",
            "Train Epoch: 61 [8960/60000 (15%)]\tLoss: 722.596313\n",
            "Train Epoch: 61 [10240/60000 (17%)]\tLoss: 740.541382\n",
            "Train Epoch: 61 [11520/60000 (19%)]\tLoss: 756.201599\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 734.771057\n",
            "Train Epoch: 61 [14080/60000 (23%)]\tLoss: 734.700439\n",
            "Train Epoch: 61 [15360/60000 (26%)]\tLoss: 729.097229\n",
            "Train Epoch: 61 [16640/60000 (28%)]\tLoss: 732.628601\n",
            "Train Epoch: 61 [17920/60000 (30%)]\tLoss: 735.890564\n",
            "Train Epoch: 61 [19200/60000 (32%)]\tLoss: 736.702209\n",
            "Train Epoch: 61 [20480/60000 (34%)]\tLoss: 759.331787\n",
            "Train Epoch: 61 [21760/60000 (36%)]\tLoss: 714.009216\n",
            "Train Epoch: 61 [23040/60000 (38%)]\tLoss: 715.837341\n",
            "Train Epoch: 61 [24320/60000 (41%)]\tLoss: 732.468750\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 729.330505\n",
            "Train Epoch: 61 [26880/60000 (45%)]\tLoss: 756.899292\n",
            "Train Epoch: 61 [28160/60000 (47%)]\tLoss: 746.970459\n",
            "Train Epoch: 61 [29440/60000 (49%)]\tLoss: 710.648071\n",
            "Train Epoch: 61 [30720/60000 (51%)]\tLoss: 770.021301\n",
            "Train Epoch: 61 [32000/60000 (53%)]\tLoss: 743.989075\n",
            "Train Epoch: 61 [33280/60000 (55%)]\tLoss: 730.962463\n",
            "Train Epoch: 61 [34560/60000 (58%)]\tLoss: 722.892212\n",
            "Train Epoch: 61 [35840/60000 (60%)]\tLoss: 723.075012\n",
            "Train Epoch: 61 [37120/60000 (62%)]\tLoss: 715.075745\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 731.160034\n",
            "Train Epoch: 61 [39680/60000 (66%)]\tLoss: 744.877686\n",
            "Train Epoch: 61 [40960/60000 (68%)]\tLoss: 728.066956\n",
            "Train Epoch: 61 [42240/60000 (70%)]\tLoss: 739.123657\n",
            "Train Epoch: 61 [43520/60000 (72%)]\tLoss: 701.955505\n",
            "Train Epoch: 61 [44800/60000 (75%)]\tLoss: 764.247620\n",
            "Train Epoch: 61 [46080/60000 (77%)]\tLoss: 724.836182\n",
            "Train Epoch: 61 [47360/60000 (79%)]\tLoss: 749.682556\n",
            "Train Epoch: 61 [48640/60000 (81%)]\tLoss: 736.383057\n",
            "Train Epoch: 61 [49920/60000 (83%)]\tLoss: 725.065308\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 759.537842\n",
            "Train Epoch: 61 [52480/60000 (87%)]\tLoss: 743.053772\n",
            "Train Epoch: 61 [53760/60000 (90%)]\tLoss: 738.461792\n",
            "Train Epoch: 61 [55040/60000 (92%)]\tLoss: 730.218567\n",
            "Train Epoch: 61 [56320/60000 (94%)]\tLoss: 742.072754\n",
            "Train Epoch: 61 [57600/60000 (96%)]\tLoss: 722.301819\n",
            "Train Epoch: 61 [58880/60000 (98%)]\tLoss: 743.951355\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978486031293869\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 745.597778\n",
            "Train Epoch: 62 [1280/60000 (2%)]\tLoss: 728.599182\n",
            "Train Epoch: 62 [2560/60000 (4%)]\tLoss: 709.685486\n",
            "Train Epoch: 62 [3840/60000 (6%)]\tLoss: 737.229065\n",
            "Train Epoch: 62 [5120/60000 (9%)]\tLoss: 731.822205\n",
            "Train Epoch: 62 [6400/60000 (11%)]\tLoss: 754.759766\n",
            "Train Epoch: 62 [7680/60000 (13%)]\tLoss: 731.004761\n",
            "Train Epoch: 62 [8960/60000 (15%)]\tLoss: 727.696472\n",
            "Train Epoch: 62 [10240/60000 (17%)]\tLoss: 743.515442\n",
            "Train Epoch: 62 [11520/60000 (19%)]\tLoss: 712.379761\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 726.434387\n",
            "Train Epoch: 62 [14080/60000 (23%)]\tLoss: 725.603149\n",
            "Train Epoch: 62 [15360/60000 (26%)]\tLoss: 717.378601\n",
            "Train Epoch: 62 [16640/60000 (28%)]\tLoss: 702.416565\n",
            "Train Epoch: 62 [17920/60000 (30%)]\tLoss: 728.647705\n",
            "Train Epoch: 62 [19200/60000 (32%)]\tLoss: 705.630798\n",
            "Train Epoch: 62 [20480/60000 (34%)]\tLoss: 748.283936\n",
            "Train Epoch: 62 [21760/60000 (36%)]\tLoss: 751.096375\n",
            "Train Epoch: 62 [23040/60000 (38%)]\tLoss: 750.165710\n",
            "Train Epoch: 62 [24320/60000 (41%)]\tLoss: 728.023010\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 744.055176\n",
            "Train Epoch: 62 [26880/60000 (45%)]\tLoss: 749.606445\n",
            "Train Epoch: 62 [28160/60000 (47%)]\tLoss: 736.680054\n",
            "Train Epoch: 62 [29440/60000 (49%)]\tLoss: 735.921387\n",
            "Train Epoch: 62 [30720/60000 (51%)]\tLoss: 725.034973\n",
            "Train Epoch: 62 [32000/60000 (53%)]\tLoss: 746.956543\n",
            "Train Epoch: 62 [33280/60000 (55%)]\tLoss: 728.091614\n",
            "Train Epoch: 62 [34560/60000 (58%)]\tLoss: 765.118713\n",
            "Train Epoch: 62 [35840/60000 (60%)]\tLoss: 726.744751\n",
            "Train Epoch: 62 [37120/60000 (62%)]\tLoss: 752.698914\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 724.404724\n",
            "Train Epoch: 62 [39680/60000 (66%)]\tLoss: 726.139648\n",
            "Train Epoch: 62 [40960/60000 (68%)]\tLoss: 755.332581\n",
            "Train Epoch: 62 [42240/60000 (70%)]\tLoss: 738.284546\n",
            "Train Epoch: 62 [43520/60000 (72%)]\tLoss: 726.374329\n",
            "Train Epoch: 62 [44800/60000 (75%)]\tLoss: 756.729187\n",
            "Train Epoch: 62 [46080/60000 (77%)]\tLoss: 734.859863\n",
            "Train Epoch: 62 [47360/60000 (79%)]\tLoss: 738.126892\n",
            "Train Epoch: 62 [48640/60000 (81%)]\tLoss: 741.618286\n",
            "Train Epoch: 62 [49920/60000 (83%)]\tLoss: 734.071045\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 738.366821\n",
            "Train Epoch: 62 [52480/60000 (87%)]\tLoss: 706.227051\n",
            "Train Epoch: 62 [53760/60000 (90%)]\tLoss: 700.298950\n",
            "Train Epoch: 62 [55040/60000 (92%)]\tLoss: 710.922974\n",
            "Train Epoch: 62 [56320/60000 (94%)]\tLoss: 756.374634\n",
            "Train Epoch: 62 [57600/60000 (96%)]\tLoss: 698.375488\n",
            "Train Epoch: 62 [58880/60000 (98%)]\tLoss: 750.274841\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788214564323425\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 727.333862\n",
            "Train Epoch: 63 [1280/60000 (2%)]\tLoss: 736.145325\n",
            "Train Epoch: 63 [2560/60000 (4%)]\tLoss: 747.117432\n",
            "Train Epoch: 63 [3840/60000 (6%)]\tLoss: 732.729187\n",
            "Train Epoch: 63 [5120/60000 (9%)]\tLoss: 732.105347\n",
            "Train Epoch: 63 [6400/60000 (11%)]\tLoss: 745.557190\n",
            "Train Epoch: 63 [7680/60000 (13%)]\tLoss: 723.370544\n",
            "Train Epoch: 63 [8960/60000 (15%)]\tLoss: 718.207031\n",
            "Train Epoch: 63 [10240/60000 (17%)]\tLoss: 758.347351\n",
            "Train Epoch: 63 [11520/60000 (19%)]\tLoss: 722.235840\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 728.963013\n",
            "Train Epoch: 63 [14080/60000 (23%)]\tLoss: 758.374939\n",
            "Train Epoch: 63 [15360/60000 (26%)]\tLoss: 711.346313\n",
            "Train Epoch: 63 [16640/60000 (28%)]\tLoss: 738.838379\n",
            "Train Epoch: 63 [17920/60000 (30%)]\tLoss: 744.177490\n",
            "Train Epoch: 63 [19200/60000 (32%)]\tLoss: 714.527710\n",
            "Train Epoch: 63 [20480/60000 (34%)]\tLoss: 736.672180\n",
            "Train Epoch: 63 [21760/60000 (36%)]\tLoss: 732.989685\n",
            "Train Epoch: 63 [23040/60000 (38%)]\tLoss: 742.029358\n",
            "Train Epoch: 63 [24320/60000 (41%)]\tLoss: 742.453247\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 734.756348\n",
            "Train Epoch: 63 [26880/60000 (45%)]\tLoss: 743.196106\n",
            "Train Epoch: 63 [28160/60000 (47%)]\tLoss: 718.697144\n",
            "Train Epoch: 63 [29440/60000 (49%)]\tLoss: 734.088928\n",
            "Train Epoch: 63 [30720/60000 (51%)]\tLoss: 733.612793\n",
            "Train Epoch: 63 [32000/60000 (53%)]\tLoss: 730.597473\n",
            "Train Epoch: 63 [33280/60000 (55%)]\tLoss: 743.737488\n",
            "Train Epoch: 63 [34560/60000 (58%)]\tLoss: 742.455688\n",
            "Train Epoch: 63 [35840/60000 (60%)]\tLoss: 749.601990\n",
            "Train Epoch: 63 [37120/60000 (62%)]\tLoss: 757.294006\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 727.219360\n",
            "Train Epoch: 63 [39680/60000 (66%)]\tLoss: 728.352112\n",
            "Train Epoch: 63 [40960/60000 (68%)]\tLoss: 701.844543\n",
            "Train Epoch: 63 [42240/60000 (70%)]\tLoss: 749.707092\n",
            "Train Epoch: 63 [43520/60000 (72%)]\tLoss: 722.309082\n",
            "Train Epoch: 63 [44800/60000 (75%)]\tLoss: 741.074219\n",
            "Train Epoch: 63 [46080/60000 (77%)]\tLoss: 736.246094\n",
            "Train Epoch: 63 [47360/60000 (79%)]\tLoss: 723.754639\n",
            "Train Epoch: 63 [48640/60000 (81%)]\tLoss: 753.969543\n",
            "Train Epoch: 63 [49920/60000 (83%)]\tLoss: 738.678711\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 759.731812\n",
            "Train Epoch: 63 [52480/60000 (87%)]\tLoss: 739.088745\n",
            "Train Epoch: 63 [53760/60000 (90%)]\tLoss: 756.265442\n",
            "Train Epoch: 63 [55040/60000 (92%)]\tLoss: 732.221375\n",
            "Train Epoch: 63 [56320/60000 (94%)]\tLoss: 727.872314\n",
            "Train Epoch: 63 [57600/60000 (96%)]\tLoss: 695.764404\n",
            "Train Epoch: 63 [58880/60000 (98%)]\tLoss: 720.319397\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782371819019318\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 731.041870\n",
            "Train Epoch: 64 [1280/60000 (2%)]\tLoss: 754.200195\n",
            "Train Epoch: 64 [2560/60000 (4%)]\tLoss: 734.099426\n",
            "Train Epoch: 64 [3840/60000 (6%)]\tLoss: 748.883789\n",
            "Train Epoch: 64 [5120/60000 (9%)]\tLoss: 760.988953\n",
            "Train Epoch: 64 [6400/60000 (11%)]\tLoss: 747.082642\n",
            "Train Epoch: 64 [7680/60000 (13%)]\tLoss: 744.410645\n",
            "Train Epoch: 64 [8960/60000 (15%)]\tLoss: 717.884888\n",
            "Train Epoch: 64 [10240/60000 (17%)]\tLoss: 728.247742\n",
            "Train Epoch: 64 [11520/60000 (19%)]\tLoss: 723.635742\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 737.918823\n",
            "Train Epoch: 64 [14080/60000 (23%)]\tLoss: 730.700134\n",
            "Train Epoch: 64 [15360/60000 (26%)]\tLoss: 762.754272\n",
            "Train Epoch: 64 [16640/60000 (28%)]\tLoss: 727.853821\n",
            "Train Epoch: 64 [17920/60000 (30%)]\tLoss: 752.727600\n",
            "Train Epoch: 64 [19200/60000 (32%)]\tLoss: 724.535461\n",
            "Train Epoch: 64 [20480/60000 (34%)]\tLoss: 747.965454\n",
            "Train Epoch: 64 [21760/60000 (36%)]\tLoss: 741.956238\n",
            "Train Epoch: 64 [23040/60000 (38%)]\tLoss: 741.773682\n",
            "Train Epoch: 64 [24320/60000 (41%)]\tLoss: 764.840088\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 734.606201\n",
            "Train Epoch: 64 [26880/60000 (45%)]\tLoss: 736.754517\n",
            "Train Epoch: 64 [28160/60000 (47%)]\tLoss: 751.553894\n",
            "Train Epoch: 64 [29440/60000 (49%)]\tLoss: 735.058960\n",
            "Train Epoch: 64 [30720/60000 (51%)]\tLoss: 713.611145\n",
            "Train Epoch: 64 [32000/60000 (53%)]\tLoss: 716.446289\n",
            "Train Epoch: 64 [33280/60000 (55%)]\tLoss: 715.601074\n",
            "Train Epoch: 64 [34560/60000 (58%)]\tLoss: 733.322876\n",
            "Train Epoch: 64 [35840/60000 (60%)]\tLoss: 741.536316\n",
            "Train Epoch: 64 [37120/60000 (62%)]\tLoss: 747.189880\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 754.624695\n",
            "Train Epoch: 64 [39680/60000 (66%)]\tLoss: 731.872070\n",
            "Train Epoch: 64 [40960/60000 (68%)]\tLoss: 753.972778\n",
            "Train Epoch: 64 [42240/60000 (70%)]\tLoss: 723.024597\n",
            "Train Epoch: 64 [43520/60000 (72%)]\tLoss: 726.616516\n",
            "Train Epoch: 64 [44800/60000 (75%)]\tLoss: 740.431152\n",
            "Train Epoch: 64 [46080/60000 (77%)]\tLoss: 732.985107\n",
            "Train Epoch: 64 [47360/60000 (79%)]\tLoss: 747.648315\n",
            "Train Epoch: 64 [48640/60000 (81%)]\tLoss: 743.531433\n",
            "Train Epoch: 64 [49920/60000 (83%)]\tLoss: 746.234863\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 741.996643\n",
            "Train Epoch: 64 [52480/60000 (87%)]\tLoss: 741.132874\n",
            "Train Epoch: 64 [53760/60000 (90%)]\tLoss: 705.557922\n",
            "Train Epoch: 64 [55040/60000 (92%)]\tLoss: 727.109985\n",
            "Train Epoch: 64 [56320/60000 (94%)]\tLoss: 744.347046\n",
            "Train Epoch: 64 [57600/60000 (96%)]\tLoss: 732.577881\n",
            "Train Epoch: 64 [58880/60000 (98%)]\tLoss: 756.826111\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784322381019592\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 726.187439\n",
            "Train Epoch: 65 [1280/60000 (2%)]\tLoss: 716.535095\n",
            "Train Epoch: 65 [2560/60000 (4%)]\tLoss: 728.878052\n",
            "Train Epoch: 65 [3840/60000 (6%)]\tLoss: 703.332581\n",
            "Train Epoch: 65 [5120/60000 (9%)]\tLoss: 747.174988\n",
            "Train Epoch: 65 [6400/60000 (11%)]\tLoss: 772.472229\n",
            "Train Epoch: 65 [7680/60000 (13%)]\tLoss: 723.386108\n",
            "Train Epoch: 65 [8960/60000 (15%)]\tLoss: 724.157288\n",
            "Train Epoch: 65 [10240/60000 (17%)]\tLoss: 757.672424\n",
            "Train Epoch: 65 [11520/60000 (19%)]\tLoss: 725.594727\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 749.421997\n",
            "Train Epoch: 65 [14080/60000 (23%)]\tLoss: 739.215637\n",
            "Train Epoch: 65 [15360/60000 (26%)]\tLoss: 731.828918\n",
            "Train Epoch: 65 [16640/60000 (28%)]\tLoss: 723.177917\n",
            "Train Epoch: 65 [17920/60000 (30%)]\tLoss: 716.921753\n",
            "Train Epoch: 65 [19200/60000 (32%)]\tLoss: 748.935120\n",
            "Train Epoch: 65 [20480/60000 (34%)]\tLoss: 726.292908\n",
            "Train Epoch: 65 [21760/60000 (36%)]\tLoss: 721.245483\n",
            "Train Epoch: 65 [23040/60000 (38%)]\tLoss: 752.358765\n",
            "Train Epoch: 65 [24320/60000 (41%)]\tLoss: 732.766418\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 735.619385\n",
            "Train Epoch: 65 [26880/60000 (45%)]\tLoss: 709.492737\n",
            "Train Epoch: 65 [28160/60000 (47%)]\tLoss: 723.535706\n",
            "Train Epoch: 65 [29440/60000 (49%)]\tLoss: 751.613098\n",
            "Train Epoch: 65 [30720/60000 (51%)]\tLoss: 718.493652\n",
            "Train Epoch: 65 [32000/60000 (53%)]\tLoss: 761.164246\n",
            "Train Epoch: 65 [33280/60000 (55%)]\tLoss: 711.167969\n",
            "Train Epoch: 65 [34560/60000 (58%)]\tLoss: 764.707947\n",
            "Train Epoch: 65 [35840/60000 (60%)]\tLoss: 730.415222\n",
            "Train Epoch: 65 [37120/60000 (62%)]\tLoss: 759.903625\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 721.587769\n",
            "Train Epoch: 65 [39680/60000 (66%)]\tLoss: 734.422485\n",
            "Train Epoch: 65 [40960/60000 (68%)]\tLoss: 748.396362\n",
            "Train Epoch: 65 [42240/60000 (70%)]\tLoss: 740.256531\n",
            "Train Epoch: 65 [43520/60000 (72%)]\tLoss: 726.215210\n",
            "Train Epoch: 65 [44800/60000 (75%)]\tLoss: 715.179504\n",
            "Train Epoch: 65 [46080/60000 (77%)]\tLoss: 740.083069\n",
            "Train Epoch: 65 [47360/60000 (79%)]\tLoss: 747.454346\n",
            "Train Epoch: 65 [48640/60000 (81%)]\tLoss: 750.968384\n",
            "Train Epoch: 65 [49920/60000 (83%)]\tLoss: 730.538208\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 741.816345\n",
            "Train Epoch: 65 [52480/60000 (87%)]\tLoss: 743.428528\n",
            "Train Epoch: 65 [53760/60000 (90%)]\tLoss: 747.959473\n",
            "Train Epoch: 65 [55040/60000 (92%)]\tLoss: 740.025879\n",
            "Train Epoch: 65 [56320/60000 (94%)]\tLoss: 745.193481\n",
            "Train Epoch: 65 [57600/60000 (96%)]\tLoss: 743.747681\n",
            "Train Epoch: 65 [58880/60000 (98%)]\tLoss: 724.947632\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978163719177246\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 769.266846\n",
            "Train Epoch: 66 [1280/60000 (2%)]\tLoss: 703.857178\n",
            "Train Epoch: 66 [2560/60000 (4%)]\tLoss: 720.940186\n",
            "Train Epoch: 66 [3840/60000 (6%)]\tLoss: 761.653870\n",
            "Train Epoch: 66 [5120/60000 (9%)]\tLoss: 741.610535\n",
            "Train Epoch: 66 [6400/60000 (11%)]\tLoss: 718.833496\n",
            "Train Epoch: 66 [7680/60000 (13%)]\tLoss: 744.474304\n",
            "Train Epoch: 66 [8960/60000 (15%)]\tLoss: 735.236511\n",
            "Train Epoch: 66 [10240/60000 (17%)]\tLoss: 737.295471\n",
            "Train Epoch: 66 [11520/60000 (19%)]\tLoss: 726.580750\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 737.911926\n",
            "Train Epoch: 66 [14080/60000 (23%)]\tLoss: 738.337891\n",
            "Train Epoch: 66 [15360/60000 (26%)]\tLoss: 740.209534\n",
            "Train Epoch: 66 [16640/60000 (28%)]\tLoss: 739.676758\n",
            "Train Epoch: 66 [17920/60000 (30%)]\tLoss: 704.204651\n",
            "Train Epoch: 66 [19200/60000 (32%)]\tLoss: 737.837830\n",
            "Train Epoch: 66 [20480/60000 (34%)]\tLoss: 736.831848\n",
            "Train Epoch: 66 [21760/60000 (36%)]\tLoss: 746.464539\n",
            "Train Epoch: 66 [23040/60000 (38%)]\tLoss: 733.755432\n",
            "Train Epoch: 66 [24320/60000 (41%)]\tLoss: 737.502930\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 745.225708\n",
            "Train Epoch: 66 [26880/60000 (45%)]\tLoss: 751.216919\n",
            "Train Epoch: 66 [28160/60000 (47%)]\tLoss: 740.230713\n",
            "Train Epoch: 66 [29440/60000 (49%)]\tLoss: 727.401062\n",
            "Train Epoch: 66 [30720/60000 (51%)]\tLoss: 751.601501\n",
            "Train Epoch: 66 [32000/60000 (53%)]\tLoss: 728.600220\n",
            "Train Epoch: 66 [33280/60000 (55%)]\tLoss: 734.358032\n",
            "Train Epoch: 66 [34560/60000 (58%)]\tLoss: 732.445190\n",
            "Train Epoch: 66 [35840/60000 (60%)]\tLoss: 745.005066\n",
            "Train Epoch: 66 [37120/60000 (62%)]\tLoss: 732.207336\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 705.914246\n",
            "Train Epoch: 66 [39680/60000 (66%)]\tLoss: 727.362000\n",
            "Train Epoch: 66 [40960/60000 (68%)]\tLoss: 722.038574\n",
            "Train Epoch: 66 [42240/60000 (70%)]\tLoss: 736.091125\n",
            "Train Epoch: 66 [43520/60000 (72%)]\tLoss: 706.683960\n",
            "Train Epoch: 66 [44800/60000 (75%)]\tLoss: 721.021179\n",
            "Train Epoch: 66 [46080/60000 (77%)]\tLoss: 722.922607\n",
            "Train Epoch: 66 [47360/60000 (79%)]\tLoss: 747.585876\n",
            "Train Epoch: 66 [48640/60000 (81%)]\tLoss: 728.639343\n",
            "Train Epoch: 66 [49920/60000 (83%)]\tLoss: 761.171082\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 742.401367\n",
            "Train Epoch: 66 [52480/60000 (87%)]\tLoss: 716.727234\n",
            "Train Epoch: 66 [53760/60000 (90%)]\tLoss: 739.071167\n",
            "Train Epoch: 66 [55040/60000 (92%)]\tLoss: 747.603149\n",
            "Train Epoch: 66 [56320/60000 (94%)]\tLoss: 720.023926\n",
            "Train Epoch: 66 [57600/60000 (96%)]\tLoss: 736.800842\n",
            "Train Epoch: 66 [58880/60000 (98%)]\tLoss: 760.465637\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786706566810608\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 737.341064\n",
            "Train Epoch: 67 [1280/60000 (2%)]\tLoss: 730.051453\n",
            "Train Epoch: 67 [2560/60000 (4%)]\tLoss: 730.636047\n",
            "Train Epoch: 67 [3840/60000 (6%)]\tLoss: 738.404419\n",
            "Train Epoch: 67 [5120/60000 (9%)]\tLoss: 735.088135\n",
            "Train Epoch: 67 [6400/60000 (11%)]\tLoss: 733.833130\n",
            "Train Epoch: 67 [7680/60000 (13%)]\tLoss: 764.197632\n",
            "Train Epoch: 67 [8960/60000 (15%)]\tLoss: 755.711609\n",
            "Train Epoch: 67 [10240/60000 (17%)]\tLoss: 739.548706\n",
            "Train Epoch: 67 [11520/60000 (19%)]\tLoss: 729.365784\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 734.519531\n",
            "Train Epoch: 67 [14080/60000 (23%)]\tLoss: 727.575134\n",
            "Train Epoch: 67 [15360/60000 (26%)]\tLoss: 747.341248\n",
            "Train Epoch: 67 [16640/60000 (28%)]\tLoss: 767.954102\n",
            "Train Epoch: 67 [17920/60000 (30%)]\tLoss: 718.066284\n",
            "Train Epoch: 67 [19200/60000 (32%)]\tLoss: 718.868958\n",
            "Train Epoch: 67 [20480/60000 (34%)]\tLoss: 757.717773\n",
            "Train Epoch: 67 [21760/60000 (36%)]\tLoss: 763.636719\n",
            "Train Epoch: 67 [23040/60000 (38%)]\tLoss: 754.509033\n",
            "Train Epoch: 67 [24320/60000 (41%)]\tLoss: 727.069092\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 742.652405\n",
            "Train Epoch: 67 [26880/60000 (45%)]\tLoss: 735.930908\n",
            "Train Epoch: 67 [28160/60000 (47%)]\tLoss: 716.728027\n",
            "Train Epoch: 67 [29440/60000 (49%)]\tLoss: 708.612915\n",
            "Train Epoch: 67 [30720/60000 (51%)]\tLoss: 752.381348\n",
            "Train Epoch: 67 [32000/60000 (53%)]\tLoss: 754.850220\n",
            "Train Epoch: 67 [33280/60000 (55%)]\tLoss: 738.689453\n",
            "Train Epoch: 67 [34560/60000 (58%)]\tLoss: 746.183411\n",
            "Train Epoch: 67 [35840/60000 (60%)]\tLoss: 705.709534\n",
            "Train Epoch: 67 [37120/60000 (62%)]\tLoss: 746.586365\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 721.137634\n",
            "Train Epoch: 67 [39680/60000 (66%)]\tLoss: 721.786865\n",
            "Train Epoch: 67 [40960/60000 (68%)]\tLoss: 739.345520\n",
            "Train Epoch: 67 [42240/60000 (70%)]\tLoss: 755.799438\n",
            "Train Epoch: 67 [43520/60000 (72%)]\tLoss: 734.641846\n",
            "Train Epoch: 67 [44800/60000 (75%)]\tLoss: 750.322449\n",
            "Train Epoch: 67 [46080/60000 (77%)]\tLoss: 747.324402\n",
            "Train Epoch: 67 [47360/60000 (79%)]\tLoss: 776.535339\n",
            "Train Epoch: 67 [48640/60000 (81%)]\tLoss: 762.015747\n",
            "Train Epoch: 67 [49920/60000 (83%)]\tLoss: 719.081238\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 756.895813\n",
            "Train Epoch: 67 [52480/60000 (87%)]\tLoss: 748.419983\n",
            "Train Epoch: 67 [53760/60000 (90%)]\tLoss: 746.141968\n",
            "Train Epoch: 67 [55040/60000 (92%)]\tLoss: 728.837402\n",
            "Train Epoch: 67 [56320/60000 (94%)]\tLoss: 703.342712\n",
            "Train Epoch: 67 [57600/60000 (96%)]\tLoss: 715.243530\n",
            "Train Epoch: 67 [58880/60000 (98%)]\tLoss: 739.644714\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785457849502563\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 723.044678\n",
            "Train Epoch: 68 [1280/60000 (2%)]\tLoss: 733.731995\n",
            "Train Epoch: 68 [2560/60000 (4%)]\tLoss: 736.089783\n",
            "Train Epoch: 68 [3840/60000 (6%)]\tLoss: 732.277100\n",
            "Train Epoch: 68 [5120/60000 (9%)]\tLoss: 747.515259\n",
            "Train Epoch: 68 [6400/60000 (11%)]\tLoss: 746.800964\n",
            "Train Epoch: 68 [7680/60000 (13%)]\tLoss: 742.370850\n",
            "Train Epoch: 68 [8960/60000 (15%)]\tLoss: 747.242554\n",
            "Train Epoch: 68 [10240/60000 (17%)]\tLoss: 732.099670\n",
            "Train Epoch: 68 [11520/60000 (19%)]\tLoss: 746.317810\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 746.261536\n",
            "Train Epoch: 68 [14080/60000 (23%)]\tLoss: 723.815063\n",
            "Train Epoch: 68 [15360/60000 (26%)]\tLoss: 744.298340\n",
            "Train Epoch: 68 [16640/60000 (28%)]\tLoss: 743.199219\n",
            "Train Epoch: 68 [17920/60000 (30%)]\tLoss: 738.163818\n",
            "Train Epoch: 68 [19200/60000 (32%)]\tLoss: 740.194641\n",
            "Train Epoch: 68 [20480/60000 (34%)]\tLoss: 739.759888\n",
            "Train Epoch: 68 [21760/60000 (36%)]\tLoss: 724.486145\n",
            "Train Epoch: 68 [23040/60000 (38%)]\tLoss: 723.816956\n",
            "Train Epoch: 68 [24320/60000 (41%)]\tLoss: 742.599670\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 742.027100\n",
            "Train Epoch: 68 [26880/60000 (45%)]\tLoss: 736.397766\n",
            "Train Epoch: 68 [28160/60000 (47%)]\tLoss: 720.493896\n",
            "Train Epoch: 68 [29440/60000 (49%)]\tLoss: 751.558533\n",
            "Train Epoch: 68 [30720/60000 (51%)]\tLoss: 743.690491\n",
            "Train Epoch: 68 [32000/60000 (53%)]\tLoss: 725.039062\n",
            "Train Epoch: 68 [33280/60000 (55%)]\tLoss: 724.517273\n",
            "Train Epoch: 68 [34560/60000 (58%)]\tLoss: 718.119995\n",
            "Train Epoch: 68 [35840/60000 (60%)]\tLoss: 754.576233\n",
            "Train Epoch: 68 [37120/60000 (62%)]\tLoss: 742.544128\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 738.890930\n",
            "Train Epoch: 68 [39680/60000 (66%)]\tLoss: 738.930664\n",
            "Train Epoch: 68 [40960/60000 (68%)]\tLoss: 727.723755\n",
            "Train Epoch: 68 [42240/60000 (70%)]\tLoss: 727.755920\n",
            "Train Epoch: 68 [43520/60000 (72%)]\tLoss: 728.107056\n",
            "Train Epoch: 68 [44800/60000 (75%)]\tLoss: 743.464844\n",
            "Train Epoch: 68 [46080/60000 (77%)]\tLoss: 739.765137\n",
            "Train Epoch: 68 [47360/60000 (79%)]\tLoss: 728.573853\n",
            "Train Epoch: 68 [48640/60000 (81%)]\tLoss: 738.285217\n",
            "Train Epoch: 68 [49920/60000 (83%)]\tLoss: 732.838867\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 753.272034\n",
            "Train Epoch: 68 [52480/60000 (87%)]\tLoss: 744.924561\n",
            "Train Epoch: 68 [53760/60000 (90%)]\tLoss: 728.607178\n",
            "Train Epoch: 68 [55040/60000 (92%)]\tLoss: 733.474976\n",
            "Train Epoch: 68 [56320/60000 (94%)]\tLoss: 737.615295\n",
            "Train Epoch: 68 [57600/60000 (96%)]\tLoss: 736.992676\n",
            "Train Epoch: 68 [58880/60000 (98%)]\tLoss: 745.407532\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978340744972229\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 728.863953\n",
            "Train Epoch: 69 [1280/60000 (2%)]\tLoss: 765.690796\n",
            "Train Epoch: 69 [2560/60000 (4%)]\tLoss: 752.795227\n",
            "Train Epoch: 69 [3840/60000 (6%)]\tLoss: 715.375977\n",
            "Train Epoch: 69 [5120/60000 (9%)]\tLoss: 749.289124\n",
            "Train Epoch: 69 [6400/60000 (11%)]\tLoss: 752.704285\n",
            "Train Epoch: 69 [7680/60000 (13%)]\tLoss: 729.898376\n",
            "Train Epoch: 69 [8960/60000 (15%)]\tLoss: 724.067383\n",
            "Train Epoch: 69 [10240/60000 (17%)]\tLoss: 742.112305\n",
            "Train Epoch: 69 [11520/60000 (19%)]\tLoss: 721.714233\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 747.837280\n",
            "Train Epoch: 69 [14080/60000 (23%)]\tLoss: 741.130432\n",
            "Train Epoch: 69 [15360/60000 (26%)]\tLoss: 730.327759\n",
            "Train Epoch: 69 [16640/60000 (28%)]\tLoss: 770.185303\n",
            "Train Epoch: 69 [17920/60000 (30%)]\tLoss: 741.931152\n",
            "Train Epoch: 69 [19200/60000 (32%)]\tLoss: 747.992310\n",
            "Train Epoch: 69 [20480/60000 (34%)]\tLoss: 760.843811\n",
            "Train Epoch: 69 [21760/60000 (36%)]\tLoss: 747.336487\n",
            "Train Epoch: 69 [23040/60000 (38%)]\tLoss: 739.993835\n",
            "Train Epoch: 69 [24320/60000 (41%)]\tLoss: 734.373901\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 736.098267\n",
            "Train Epoch: 69 [26880/60000 (45%)]\tLoss: 731.378784\n",
            "Train Epoch: 69 [28160/60000 (47%)]\tLoss: 730.788391\n",
            "Train Epoch: 69 [29440/60000 (49%)]\tLoss: 747.681213\n",
            "Train Epoch: 69 [30720/60000 (51%)]\tLoss: 721.677307\n",
            "Train Epoch: 69 [32000/60000 (53%)]\tLoss: 730.975525\n",
            "Train Epoch: 69 [33280/60000 (55%)]\tLoss: 759.566162\n",
            "Train Epoch: 69 [34560/60000 (58%)]\tLoss: 729.231384\n",
            "Train Epoch: 69 [35840/60000 (60%)]\tLoss: 757.025330\n",
            "Train Epoch: 69 [37120/60000 (62%)]\tLoss: 735.712646\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 731.616577\n",
            "Train Epoch: 69 [39680/60000 (66%)]\tLoss: 730.628479\n",
            "Train Epoch: 69 [40960/60000 (68%)]\tLoss: 720.989502\n",
            "Train Epoch: 69 [42240/60000 (70%)]\tLoss: 737.814148\n",
            "Train Epoch: 69 [43520/60000 (72%)]\tLoss: 719.763123\n",
            "Train Epoch: 69 [44800/60000 (75%)]\tLoss: 740.898193\n",
            "Train Epoch: 69 [46080/60000 (77%)]\tLoss: 730.471924\n",
            "Train Epoch: 69 [47360/60000 (79%)]\tLoss: 727.687073\n",
            "Train Epoch: 69 [48640/60000 (81%)]\tLoss: 740.607117\n",
            "Train Epoch: 69 [49920/60000 (83%)]\tLoss: 720.430298\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 750.784973\n",
            "Train Epoch: 69 [52480/60000 (87%)]\tLoss: 742.061462\n",
            "Train Epoch: 69 [53760/60000 (90%)]\tLoss: 730.520447\n",
            "Train Epoch: 69 [55040/60000 (92%)]\tLoss: 729.745789\n",
            "Train Epoch: 69 [56320/60000 (94%)]\tLoss: 709.660828\n",
            "Train Epoch: 69 [57600/60000 (96%)]\tLoss: 726.018738\n",
            "Train Epoch: 69 [58880/60000 (98%)]\tLoss: 746.369080\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978408694267273\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 754.550293\n",
            "Train Epoch: 70 [1280/60000 (2%)]\tLoss: 753.323303\n",
            "Train Epoch: 70 [2560/60000 (4%)]\tLoss: 731.378357\n",
            "Train Epoch: 70 [3840/60000 (6%)]\tLoss: 757.107605\n",
            "Train Epoch: 70 [5120/60000 (9%)]\tLoss: 746.109253\n",
            "Train Epoch: 70 [6400/60000 (11%)]\tLoss: 744.507690\n",
            "Train Epoch: 70 [7680/60000 (13%)]\tLoss: 739.355896\n",
            "Train Epoch: 70 [8960/60000 (15%)]\tLoss: 746.870972\n",
            "Train Epoch: 70 [10240/60000 (17%)]\tLoss: 760.545593\n",
            "Train Epoch: 70 [11520/60000 (19%)]\tLoss: 723.421021\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 718.163513\n",
            "Train Epoch: 70 [14080/60000 (23%)]\tLoss: 730.437500\n",
            "Train Epoch: 70 [15360/60000 (26%)]\tLoss: 739.925659\n",
            "Train Epoch: 70 [16640/60000 (28%)]\tLoss: 748.611755\n",
            "Train Epoch: 70 [17920/60000 (30%)]\tLoss: 737.545654\n",
            "Train Epoch: 70 [19200/60000 (32%)]\tLoss: 723.359314\n",
            "Train Epoch: 70 [20480/60000 (34%)]\tLoss: 724.590576\n",
            "Train Epoch: 70 [21760/60000 (36%)]\tLoss: 745.734741\n",
            "Train Epoch: 70 [23040/60000 (38%)]\tLoss: 736.211792\n",
            "Train Epoch: 70 [24320/60000 (41%)]\tLoss: 723.621948\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 750.921387\n",
            "Train Epoch: 70 [26880/60000 (45%)]\tLoss: 745.602173\n",
            "Train Epoch: 70 [28160/60000 (47%)]\tLoss: 749.423645\n",
            "Train Epoch: 70 [29440/60000 (49%)]\tLoss: 736.785095\n",
            "Train Epoch: 70 [30720/60000 (51%)]\tLoss: 725.771667\n",
            "Train Epoch: 70 [32000/60000 (53%)]\tLoss: 744.738464\n",
            "Train Epoch: 70 [33280/60000 (55%)]\tLoss: 748.373596\n",
            "Train Epoch: 70 [34560/60000 (58%)]\tLoss: 743.934753\n",
            "Train Epoch: 70 [35840/60000 (60%)]\tLoss: 750.868530\n",
            "Train Epoch: 70 [37120/60000 (62%)]\tLoss: 740.779175\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 719.786133\n",
            "Train Epoch: 70 [39680/60000 (66%)]\tLoss: 715.265625\n",
            "Train Epoch: 70 [40960/60000 (68%)]\tLoss: 743.936157\n",
            "Train Epoch: 70 [42240/60000 (70%)]\tLoss: 756.031189\n",
            "Train Epoch: 70 [43520/60000 (72%)]\tLoss: 736.778015\n",
            "Train Epoch: 70 [44800/60000 (75%)]\tLoss: 737.723022\n",
            "Train Epoch: 70 [46080/60000 (77%)]\tLoss: 738.017090\n",
            "Train Epoch: 70 [47360/60000 (79%)]\tLoss: 716.536987\n",
            "Train Epoch: 70 [48640/60000 (81%)]\tLoss: 745.799744\n",
            "Train Epoch: 70 [49920/60000 (83%)]\tLoss: 753.355225\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 753.791504\n",
            "Train Epoch: 70 [52480/60000 (87%)]\tLoss: 723.143555\n",
            "Train Epoch: 70 [53760/60000 (90%)]\tLoss: 746.221375\n",
            "Train Epoch: 70 [55040/60000 (92%)]\tLoss: 755.322266\n",
            "Train Epoch: 70 [56320/60000 (94%)]\tLoss: 728.120361\n",
            "Train Epoch: 70 [57600/60000 (96%)]\tLoss: 728.270996\n",
            "Train Epoch: 70 [58880/60000 (98%)]\tLoss: 731.402100\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782768189907074\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 742.058533\n",
            "Train Epoch: 71 [1280/60000 (2%)]\tLoss: 724.585693\n",
            "Train Epoch: 71 [2560/60000 (4%)]\tLoss: 744.239563\n",
            "Train Epoch: 71 [3840/60000 (6%)]\tLoss: 736.674927\n",
            "Train Epoch: 71 [5120/60000 (9%)]\tLoss: 759.291748\n",
            "Train Epoch: 71 [6400/60000 (11%)]\tLoss: 739.581970\n",
            "Train Epoch: 71 [7680/60000 (13%)]\tLoss: 758.869751\n",
            "Train Epoch: 71 [8960/60000 (15%)]\tLoss: 723.783142\n",
            "Train Epoch: 71 [10240/60000 (17%)]\tLoss: 744.602051\n",
            "Train Epoch: 71 [11520/60000 (19%)]\tLoss: 738.624451\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 710.164368\n",
            "Train Epoch: 71 [14080/60000 (23%)]\tLoss: 743.249268\n",
            "Train Epoch: 71 [15360/60000 (26%)]\tLoss: 730.256226\n",
            "Train Epoch: 71 [16640/60000 (28%)]\tLoss: 741.474854\n",
            "Train Epoch: 71 [17920/60000 (30%)]\tLoss: 725.547913\n",
            "Train Epoch: 71 [19200/60000 (32%)]\tLoss: 752.112061\n",
            "Train Epoch: 71 [20480/60000 (34%)]\tLoss: 752.918091\n",
            "Train Epoch: 71 [21760/60000 (36%)]\tLoss: 731.673340\n",
            "Train Epoch: 71 [23040/60000 (38%)]\tLoss: 716.301086\n",
            "Train Epoch: 71 [24320/60000 (41%)]\tLoss: 757.029114\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 747.482483\n",
            "Train Epoch: 71 [26880/60000 (45%)]\tLoss: 743.123596\n",
            "Train Epoch: 71 [28160/60000 (47%)]\tLoss: 724.157288\n",
            "Train Epoch: 71 [29440/60000 (49%)]\tLoss: 720.544800\n",
            "Train Epoch: 71 [30720/60000 (51%)]\tLoss: 733.435181\n",
            "Train Epoch: 71 [32000/60000 (53%)]\tLoss: 750.480774\n",
            "Train Epoch: 71 [33280/60000 (55%)]\tLoss: 721.570923\n",
            "Train Epoch: 71 [34560/60000 (58%)]\tLoss: 731.928223\n",
            "Train Epoch: 71 [35840/60000 (60%)]\tLoss: 739.515808\n",
            "Train Epoch: 71 [37120/60000 (62%)]\tLoss: 719.275330\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 698.378174\n",
            "Train Epoch: 71 [39680/60000 (66%)]\tLoss: 726.538513\n",
            "Train Epoch: 71 [40960/60000 (68%)]\tLoss: 730.459778\n",
            "Train Epoch: 71 [42240/60000 (70%)]\tLoss: 732.761230\n",
            "Train Epoch: 71 [43520/60000 (72%)]\tLoss: 737.935059\n",
            "Train Epoch: 71 [44800/60000 (75%)]\tLoss: 727.961731\n",
            "Train Epoch: 71 [46080/60000 (77%)]\tLoss: 726.942627\n",
            "Train Epoch: 71 [47360/60000 (79%)]\tLoss: 744.286682\n",
            "Train Epoch: 71 [48640/60000 (81%)]\tLoss: 735.287720\n",
            "Train Epoch: 71 [49920/60000 (83%)]\tLoss: 722.520508\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 764.645020\n",
            "Train Epoch: 71 [52480/60000 (87%)]\tLoss: 742.101074\n",
            "Train Epoch: 71 [53760/60000 (90%)]\tLoss: 757.926758\n",
            "Train Epoch: 71 [55040/60000 (92%)]\tLoss: 716.509827\n",
            "Train Epoch: 71 [56320/60000 (94%)]\tLoss: 724.866943\n",
            "Train Epoch: 71 [57600/60000 (96%)]\tLoss: 741.372070\n",
            "Train Epoch: 71 [58880/60000 (98%)]\tLoss: 728.646790\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785073399543762\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 730.680908\n",
            "Train Epoch: 72 [1280/60000 (2%)]\tLoss: 722.282776\n",
            "Train Epoch: 72 [2560/60000 (4%)]\tLoss: 724.984070\n",
            "Train Epoch: 72 [3840/60000 (6%)]\tLoss: 723.144226\n",
            "Train Epoch: 72 [5120/60000 (9%)]\tLoss: 711.516785\n",
            "Train Epoch: 72 [6400/60000 (11%)]\tLoss: 747.096497\n",
            "Train Epoch: 72 [7680/60000 (13%)]\tLoss: 739.493225\n",
            "Train Epoch: 72 [8960/60000 (15%)]\tLoss: 737.670959\n",
            "Train Epoch: 72 [10240/60000 (17%)]\tLoss: 742.750671\n",
            "Train Epoch: 72 [11520/60000 (19%)]\tLoss: 735.417114\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 742.673645\n",
            "Train Epoch: 72 [14080/60000 (23%)]\tLoss: 742.512390\n",
            "Train Epoch: 72 [15360/60000 (26%)]\tLoss: 723.666687\n",
            "Train Epoch: 72 [16640/60000 (28%)]\tLoss: 722.221191\n",
            "Train Epoch: 72 [17920/60000 (30%)]\tLoss: 723.310303\n",
            "Train Epoch: 72 [19200/60000 (32%)]\tLoss: 734.831055\n",
            "Train Epoch: 72 [20480/60000 (34%)]\tLoss: 725.579956\n",
            "Train Epoch: 72 [21760/60000 (36%)]\tLoss: 753.445312\n",
            "Train Epoch: 72 [23040/60000 (38%)]\tLoss: 722.996094\n",
            "Train Epoch: 72 [24320/60000 (41%)]\tLoss: 743.793640\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 734.029175\n",
            "Train Epoch: 72 [26880/60000 (45%)]\tLoss: 712.272461\n",
            "Train Epoch: 72 [28160/60000 (47%)]\tLoss: 736.533752\n",
            "Train Epoch: 72 [29440/60000 (49%)]\tLoss: 744.733459\n",
            "Train Epoch: 72 [30720/60000 (51%)]\tLoss: 731.769531\n",
            "Train Epoch: 72 [32000/60000 (53%)]\tLoss: 764.314209\n",
            "Train Epoch: 72 [33280/60000 (55%)]\tLoss: 735.267273\n",
            "Train Epoch: 72 [34560/60000 (58%)]\tLoss: 768.235413\n",
            "Train Epoch: 72 [35840/60000 (60%)]\tLoss: 755.592590\n",
            "Train Epoch: 72 [37120/60000 (62%)]\tLoss: 727.751465\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 756.913025\n",
            "Train Epoch: 72 [39680/60000 (66%)]\tLoss: 717.950684\n",
            "Train Epoch: 72 [40960/60000 (68%)]\tLoss: 729.910828\n",
            "Train Epoch: 72 [42240/60000 (70%)]\tLoss: 744.850464\n",
            "Train Epoch: 72 [43520/60000 (72%)]\tLoss: 730.098572\n",
            "Train Epoch: 72 [44800/60000 (75%)]\tLoss: 720.667480\n",
            "Train Epoch: 72 [46080/60000 (77%)]\tLoss: 742.648010\n",
            "Train Epoch: 72 [47360/60000 (79%)]\tLoss: 726.301514\n",
            "Train Epoch: 72 [48640/60000 (81%)]\tLoss: 735.138977\n",
            "Train Epoch: 72 [49920/60000 (83%)]\tLoss: 747.691467\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 732.363098\n",
            "Train Epoch: 72 [52480/60000 (87%)]\tLoss: 728.801147\n",
            "Train Epoch: 72 [53760/60000 (90%)]\tLoss: 733.939697\n",
            "Train Epoch: 72 [55040/60000 (92%)]\tLoss: 731.243469\n",
            "Train Epoch: 72 [56320/60000 (94%)]\tLoss: 739.608765\n",
            "Train Epoch: 72 [57600/60000 (96%)]\tLoss: 724.006470\n",
            "Train Epoch: 72 [58880/60000 (98%)]\tLoss: 739.575134\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786253571510315\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 736.500793\n",
            "Train Epoch: 73 [1280/60000 (2%)]\tLoss: 720.030579\n",
            "Train Epoch: 73 [2560/60000 (4%)]\tLoss: 744.645813\n",
            "Train Epoch: 73 [3840/60000 (6%)]\tLoss: 721.627258\n",
            "Train Epoch: 73 [5120/60000 (9%)]\tLoss: 720.098999\n",
            "Train Epoch: 73 [6400/60000 (11%)]\tLoss: 700.805969\n",
            "Train Epoch: 73 [7680/60000 (13%)]\tLoss: 716.576172\n",
            "Train Epoch: 73 [8960/60000 (15%)]\tLoss: 733.488220\n",
            "Train Epoch: 73 [10240/60000 (17%)]\tLoss: 730.999329\n",
            "Train Epoch: 73 [11520/60000 (19%)]\tLoss: 751.787842\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 732.553650\n",
            "Train Epoch: 73 [14080/60000 (23%)]\tLoss: 745.560120\n",
            "Train Epoch: 73 [15360/60000 (26%)]\tLoss: 717.038940\n",
            "Train Epoch: 73 [16640/60000 (28%)]\tLoss: 720.210510\n",
            "Train Epoch: 73 [17920/60000 (30%)]\tLoss: 722.824158\n",
            "Train Epoch: 73 [19200/60000 (32%)]\tLoss: 734.097412\n",
            "Train Epoch: 73 [20480/60000 (34%)]\tLoss: 728.392456\n",
            "Train Epoch: 73 [21760/60000 (36%)]\tLoss: 726.180237\n",
            "Train Epoch: 73 [23040/60000 (38%)]\tLoss: 720.819763\n",
            "Train Epoch: 73 [24320/60000 (41%)]\tLoss: 710.309265\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 733.439026\n",
            "Train Epoch: 73 [26880/60000 (45%)]\tLoss: 756.397766\n",
            "Train Epoch: 73 [28160/60000 (47%)]\tLoss: 731.130859\n",
            "Train Epoch: 73 [29440/60000 (49%)]\tLoss: 748.781860\n",
            "Train Epoch: 73 [30720/60000 (51%)]\tLoss: 727.431335\n",
            "Train Epoch: 73 [32000/60000 (53%)]\tLoss: 745.932495\n",
            "Train Epoch: 73 [33280/60000 (55%)]\tLoss: 764.051086\n",
            "Train Epoch: 73 [34560/60000 (58%)]\tLoss: 732.603149\n",
            "Train Epoch: 73 [35840/60000 (60%)]\tLoss: 717.910278\n",
            "Train Epoch: 73 [37120/60000 (62%)]\tLoss: 744.787476\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 717.909363\n",
            "Train Epoch: 73 [39680/60000 (66%)]\tLoss: 744.531189\n",
            "Train Epoch: 73 [40960/60000 (68%)]\tLoss: 756.609863\n",
            "Train Epoch: 73 [42240/60000 (70%)]\tLoss: 750.750854\n",
            "Train Epoch: 73 [43520/60000 (72%)]\tLoss: 734.541809\n",
            "Train Epoch: 73 [44800/60000 (75%)]\tLoss: 750.070679\n",
            "Train Epoch: 73 [46080/60000 (77%)]\tLoss: 747.292175\n",
            "Train Epoch: 73 [47360/60000 (79%)]\tLoss: 725.811401\n",
            "Train Epoch: 73 [48640/60000 (81%)]\tLoss: 755.501831\n",
            "Train Epoch: 73 [49920/60000 (83%)]\tLoss: 749.858765\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 760.634338\n",
            "Train Epoch: 73 [52480/60000 (87%)]\tLoss: 739.454102\n",
            "Train Epoch: 73 [53760/60000 (90%)]\tLoss: 744.589355\n",
            "Train Epoch: 73 [55040/60000 (92%)]\tLoss: 725.377380\n",
            "Train Epoch: 73 [56320/60000 (94%)]\tLoss: 739.718933\n",
            "Train Epoch: 73 [57600/60000 (96%)]\tLoss: 726.935120\n",
            "Train Epoch: 73 [58880/60000 (98%)]\tLoss: 753.653076\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783130288124084\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 736.821045\n",
            "Train Epoch: 74 [1280/60000 (2%)]\tLoss: 723.945801\n",
            "Train Epoch: 74 [2560/60000 (4%)]\tLoss: 711.781067\n",
            "Train Epoch: 74 [3840/60000 (6%)]\tLoss: 740.206482\n",
            "Train Epoch: 74 [5120/60000 (9%)]\tLoss: 747.058289\n",
            "Train Epoch: 74 [6400/60000 (11%)]\tLoss: 733.838684\n",
            "Train Epoch: 74 [7680/60000 (13%)]\tLoss: 724.110107\n",
            "Train Epoch: 74 [8960/60000 (15%)]\tLoss: 732.957214\n",
            "Train Epoch: 74 [10240/60000 (17%)]\tLoss: 739.348511\n",
            "Train Epoch: 74 [11520/60000 (19%)]\tLoss: 755.442871\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 737.370361\n",
            "Train Epoch: 74 [14080/60000 (23%)]\tLoss: 740.742065\n",
            "Train Epoch: 74 [15360/60000 (26%)]\tLoss: 745.368225\n",
            "Train Epoch: 74 [16640/60000 (28%)]\tLoss: 740.986389\n",
            "Train Epoch: 74 [17920/60000 (30%)]\tLoss: 734.286743\n",
            "Train Epoch: 74 [19200/60000 (32%)]\tLoss: 699.896667\n",
            "Train Epoch: 74 [20480/60000 (34%)]\tLoss: 734.726318\n",
            "Train Epoch: 74 [21760/60000 (36%)]\tLoss: 741.578491\n",
            "Train Epoch: 74 [23040/60000 (38%)]\tLoss: 741.349060\n",
            "Train Epoch: 74 [24320/60000 (41%)]\tLoss: 722.841187\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 747.155212\n",
            "Train Epoch: 74 [26880/60000 (45%)]\tLoss: 761.253906\n",
            "Train Epoch: 74 [28160/60000 (47%)]\tLoss: 718.659119\n",
            "Train Epoch: 74 [29440/60000 (49%)]\tLoss: 747.714905\n",
            "Train Epoch: 74 [30720/60000 (51%)]\tLoss: 737.913513\n",
            "Train Epoch: 74 [32000/60000 (53%)]\tLoss: 740.868103\n",
            "Train Epoch: 74 [33280/60000 (55%)]\tLoss: 739.376404\n",
            "Train Epoch: 74 [34560/60000 (58%)]\tLoss: 754.307922\n",
            "Train Epoch: 74 [35840/60000 (60%)]\tLoss: 737.619995\n",
            "Train Epoch: 74 [37120/60000 (62%)]\tLoss: 763.434082\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 762.902893\n",
            "Train Epoch: 74 [39680/60000 (66%)]\tLoss: 723.852417\n",
            "Train Epoch: 74 [40960/60000 (68%)]\tLoss: 746.862854\n",
            "Train Epoch: 74 [42240/60000 (70%)]\tLoss: 724.320068\n",
            "Train Epoch: 74 [43520/60000 (72%)]\tLoss: 720.710266\n",
            "Train Epoch: 74 [44800/60000 (75%)]\tLoss: 747.789185\n",
            "Train Epoch: 74 [46080/60000 (77%)]\tLoss: 740.599609\n",
            "Train Epoch: 74 [47360/60000 (79%)]\tLoss: 728.776672\n",
            "Train Epoch: 74 [48640/60000 (81%)]\tLoss: 720.880798\n",
            "Train Epoch: 74 [49920/60000 (83%)]\tLoss: 739.375244\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 726.429443\n",
            "Train Epoch: 74 [52480/60000 (87%)]\tLoss: 748.214661\n",
            "Train Epoch: 74 [53760/60000 (90%)]\tLoss: 731.624756\n",
            "Train Epoch: 74 [55040/60000 (92%)]\tLoss: 728.690552\n",
            "Train Epoch: 74 [56320/60000 (94%)]\tLoss: 721.167542\n",
            "Train Epoch: 74 [57600/60000 (96%)]\tLoss: 752.276062\n",
            "Train Epoch: 74 [58880/60000 (98%)]\tLoss: 742.015747\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784052670001984\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 725.393677\n",
            "Train Epoch: 75 [1280/60000 (2%)]\tLoss: 748.742981\n",
            "Train Epoch: 75 [2560/60000 (4%)]\tLoss: 762.003906\n",
            "Train Epoch: 75 [3840/60000 (6%)]\tLoss: 741.924438\n",
            "Train Epoch: 75 [5120/60000 (9%)]\tLoss: 711.280334\n",
            "Train Epoch: 75 [6400/60000 (11%)]\tLoss: 721.679443\n",
            "Train Epoch: 75 [7680/60000 (13%)]\tLoss: 731.433411\n",
            "Train Epoch: 75 [8960/60000 (15%)]\tLoss: 735.513367\n",
            "Train Epoch: 75 [10240/60000 (17%)]\tLoss: 738.509644\n",
            "Train Epoch: 75 [11520/60000 (19%)]\tLoss: 744.860535\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 739.621887\n",
            "Train Epoch: 75 [14080/60000 (23%)]\tLoss: 742.019531\n",
            "Train Epoch: 75 [15360/60000 (26%)]\tLoss: 733.279114\n",
            "Train Epoch: 75 [16640/60000 (28%)]\tLoss: 752.862305\n",
            "Train Epoch: 75 [17920/60000 (30%)]\tLoss: 730.192932\n",
            "Train Epoch: 75 [19200/60000 (32%)]\tLoss: 740.149597\n",
            "Train Epoch: 75 [20480/60000 (34%)]\tLoss: 750.919434\n",
            "Train Epoch: 75 [21760/60000 (36%)]\tLoss: 732.296997\n",
            "Train Epoch: 75 [23040/60000 (38%)]\tLoss: 736.569458\n",
            "Train Epoch: 75 [24320/60000 (41%)]\tLoss: 727.006226\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 727.356934\n",
            "Train Epoch: 75 [26880/60000 (45%)]\tLoss: 721.298279\n",
            "Train Epoch: 75 [28160/60000 (47%)]\tLoss: 729.070190\n",
            "Train Epoch: 75 [29440/60000 (49%)]\tLoss: 752.482727\n",
            "Train Epoch: 75 [30720/60000 (51%)]\tLoss: 737.728699\n",
            "Train Epoch: 75 [32000/60000 (53%)]\tLoss: 738.778870\n",
            "Train Epoch: 75 [33280/60000 (55%)]\tLoss: 726.406494\n",
            "Train Epoch: 75 [34560/60000 (58%)]\tLoss: 751.824768\n",
            "Train Epoch: 75 [35840/60000 (60%)]\tLoss: 755.541748\n",
            "Train Epoch: 75 [37120/60000 (62%)]\tLoss: 717.974976\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 721.945435\n",
            "Train Epoch: 75 [39680/60000 (66%)]\tLoss: 720.108582\n",
            "Train Epoch: 75 [40960/60000 (68%)]\tLoss: 734.489685\n",
            "Train Epoch: 75 [42240/60000 (70%)]\tLoss: 732.311218\n",
            "Train Epoch: 75 [43520/60000 (72%)]\tLoss: 728.506470\n",
            "Train Epoch: 75 [44800/60000 (75%)]\tLoss: 754.319275\n",
            "Train Epoch: 75 [46080/60000 (77%)]\tLoss: 739.946228\n",
            "Train Epoch: 75 [47360/60000 (79%)]\tLoss: 725.156067\n",
            "Train Epoch: 75 [48640/60000 (81%)]\tLoss: 748.022827\n",
            "Train Epoch: 75 [49920/60000 (83%)]\tLoss: 733.151123\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 751.251343\n",
            "Train Epoch: 75 [52480/60000 (87%)]\tLoss: 753.193298\n",
            "Train Epoch: 75 [53760/60000 (90%)]\tLoss: 761.636536\n",
            "Train Epoch: 75 [55040/60000 (92%)]\tLoss: 727.686523\n",
            "Train Epoch: 75 [56320/60000 (94%)]\tLoss: 753.875488\n",
            "Train Epoch: 75 [57600/60000 (96%)]\tLoss: 730.642639\n",
            "Train Epoch: 75 [58880/60000 (98%)]\tLoss: 749.010010\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787396490573883\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 756.081116\n",
            "Train Epoch: 76 [1280/60000 (2%)]\tLoss: 732.032654\n",
            "Train Epoch: 76 [2560/60000 (4%)]\tLoss: 726.402344\n",
            "Train Epoch: 76 [3840/60000 (6%)]\tLoss: 729.525391\n",
            "Train Epoch: 76 [5120/60000 (9%)]\tLoss: 740.780640\n",
            "Train Epoch: 76 [6400/60000 (11%)]\tLoss: 770.146362\n",
            "Train Epoch: 76 [7680/60000 (13%)]\tLoss: 747.814514\n",
            "Train Epoch: 76 [8960/60000 (15%)]\tLoss: 729.633484\n",
            "Train Epoch: 76 [10240/60000 (17%)]\tLoss: 733.191345\n",
            "Train Epoch: 76 [11520/60000 (19%)]\tLoss: 743.822937\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 718.408508\n",
            "Train Epoch: 76 [14080/60000 (23%)]\tLoss: 719.418396\n",
            "Train Epoch: 76 [15360/60000 (26%)]\tLoss: 729.256470\n",
            "Train Epoch: 76 [16640/60000 (28%)]\tLoss: 717.350647\n",
            "Train Epoch: 76 [17920/60000 (30%)]\tLoss: 747.001526\n",
            "Train Epoch: 76 [19200/60000 (32%)]\tLoss: 729.879700\n",
            "Train Epoch: 76 [20480/60000 (34%)]\tLoss: 722.448181\n",
            "Train Epoch: 76 [21760/60000 (36%)]\tLoss: 728.113098\n",
            "Train Epoch: 76 [23040/60000 (38%)]\tLoss: 757.970032\n",
            "Train Epoch: 76 [24320/60000 (41%)]\tLoss: 727.706360\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 753.280334\n",
            "Train Epoch: 76 [26880/60000 (45%)]\tLoss: 767.246643\n",
            "Train Epoch: 76 [28160/60000 (47%)]\tLoss: 750.492432\n",
            "Train Epoch: 76 [29440/60000 (49%)]\tLoss: 760.240723\n",
            "Train Epoch: 76 [30720/60000 (51%)]\tLoss: 737.342957\n",
            "Train Epoch: 76 [32000/60000 (53%)]\tLoss: 720.299194\n",
            "Train Epoch: 76 [33280/60000 (55%)]\tLoss: 725.037964\n",
            "Train Epoch: 76 [34560/60000 (58%)]\tLoss: 742.589355\n",
            "Train Epoch: 76 [35840/60000 (60%)]\tLoss: 743.444397\n",
            "Train Epoch: 76 [37120/60000 (62%)]\tLoss: 730.450989\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 740.247437\n",
            "Train Epoch: 76 [39680/60000 (66%)]\tLoss: 735.949768\n",
            "Train Epoch: 76 [40960/60000 (68%)]\tLoss: 732.434998\n",
            "Train Epoch: 76 [42240/60000 (70%)]\tLoss: 733.355835\n",
            "Train Epoch: 76 [43520/60000 (72%)]\tLoss: 749.088196\n",
            "Train Epoch: 76 [44800/60000 (75%)]\tLoss: 740.381592\n",
            "Train Epoch: 76 [46080/60000 (77%)]\tLoss: 732.004700\n",
            "Train Epoch: 76 [47360/60000 (79%)]\tLoss: 737.699707\n",
            "Train Epoch: 76 [48640/60000 (81%)]\tLoss: 734.146851\n",
            "Train Epoch: 76 [49920/60000 (83%)]\tLoss: 727.638977\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 715.504456\n",
            "Train Epoch: 76 [52480/60000 (87%)]\tLoss: 760.882874\n",
            "Train Epoch: 76 [53760/60000 (90%)]\tLoss: 750.214111\n",
            "Train Epoch: 76 [55040/60000 (92%)]\tLoss: 726.363586\n",
            "Train Epoch: 76 [56320/60000 (94%)]\tLoss: 726.434143\n",
            "Train Epoch: 76 [57600/60000 (96%)]\tLoss: 734.322693\n",
            "Train Epoch: 76 [58880/60000 (98%)]\tLoss: 748.510986\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978311389684677\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 747.148926\n",
            "Train Epoch: 77 [1280/60000 (2%)]\tLoss: 739.490845\n",
            "Train Epoch: 77 [2560/60000 (4%)]\tLoss: 728.750671\n",
            "Train Epoch: 77 [3840/60000 (6%)]\tLoss: 744.885437\n",
            "Train Epoch: 77 [5120/60000 (9%)]\tLoss: 746.095154\n",
            "Train Epoch: 77 [6400/60000 (11%)]\tLoss: 757.773621\n",
            "Train Epoch: 77 [7680/60000 (13%)]\tLoss: 722.998657\n",
            "Train Epoch: 77 [8960/60000 (15%)]\tLoss: 758.189880\n",
            "Train Epoch: 77 [10240/60000 (17%)]\tLoss: 715.264099\n",
            "Train Epoch: 77 [11520/60000 (19%)]\tLoss: 739.573486\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 732.745850\n",
            "Train Epoch: 77 [14080/60000 (23%)]\tLoss: 751.933777\n",
            "Train Epoch: 77 [15360/60000 (26%)]\tLoss: 763.318420\n",
            "Train Epoch: 77 [16640/60000 (28%)]\tLoss: 772.268250\n",
            "Train Epoch: 77 [17920/60000 (30%)]\tLoss: 721.095398\n",
            "Train Epoch: 77 [19200/60000 (32%)]\tLoss: 743.881348\n",
            "Train Epoch: 77 [20480/60000 (34%)]\tLoss: 746.449280\n",
            "Train Epoch: 77 [21760/60000 (36%)]\tLoss: 754.485596\n",
            "Train Epoch: 77 [23040/60000 (38%)]\tLoss: 736.242004\n",
            "Train Epoch: 77 [24320/60000 (41%)]\tLoss: 729.294800\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 739.729126\n",
            "Train Epoch: 77 [26880/60000 (45%)]\tLoss: 732.137695\n",
            "Train Epoch: 77 [28160/60000 (47%)]\tLoss: 718.695862\n",
            "Train Epoch: 77 [29440/60000 (49%)]\tLoss: 763.166504\n",
            "Train Epoch: 77 [30720/60000 (51%)]\tLoss: 728.474976\n",
            "Train Epoch: 77 [32000/60000 (53%)]\tLoss: 745.265808\n",
            "Train Epoch: 77 [33280/60000 (55%)]\tLoss: 720.566406\n",
            "Train Epoch: 77 [34560/60000 (58%)]\tLoss: 736.188721\n",
            "Train Epoch: 77 [35840/60000 (60%)]\tLoss: 722.032776\n",
            "Train Epoch: 77 [37120/60000 (62%)]\tLoss: 725.899048\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 720.748840\n",
            "Train Epoch: 77 [39680/60000 (66%)]\tLoss: 741.445312\n",
            "Train Epoch: 77 [40960/60000 (68%)]\tLoss: 742.773865\n",
            "Train Epoch: 77 [42240/60000 (70%)]\tLoss: 696.373901\n",
            "Train Epoch: 77 [43520/60000 (72%)]\tLoss: 721.184875\n",
            "Train Epoch: 77 [44800/60000 (75%)]\tLoss: 729.213440\n",
            "Train Epoch: 77 [46080/60000 (77%)]\tLoss: 711.275391\n",
            "Train Epoch: 77 [47360/60000 (79%)]\tLoss: 743.461304\n",
            "Train Epoch: 77 [48640/60000 (81%)]\tLoss: 736.773010\n",
            "Train Epoch: 77 [49920/60000 (83%)]\tLoss: 750.758362\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 738.117737\n",
            "Train Epoch: 77 [52480/60000 (87%)]\tLoss: 729.882202\n",
            "Train Epoch: 77 [53760/60000 (90%)]\tLoss: 723.786194\n",
            "Train Epoch: 77 [55040/60000 (92%)]\tLoss: 737.031006\n",
            "Train Epoch: 77 [56320/60000 (94%)]\tLoss: 728.536987\n",
            "Train Epoch: 77 [57600/60000 (96%)]\tLoss: 745.188354\n",
            "Train Epoch: 77 [58880/60000 (98%)]\tLoss: 756.439941\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787241518497467\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 769.751709\n",
            "Train Epoch: 78 [1280/60000 (2%)]\tLoss: 717.134888\n",
            "Train Epoch: 78 [2560/60000 (4%)]\tLoss: 754.013611\n",
            "Train Epoch: 78 [3840/60000 (6%)]\tLoss: 714.677612\n",
            "Train Epoch: 78 [5120/60000 (9%)]\tLoss: 733.938843\n",
            "Train Epoch: 78 [6400/60000 (11%)]\tLoss: 736.849426\n",
            "Train Epoch: 78 [7680/60000 (13%)]\tLoss: 719.574463\n",
            "Train Epoch: 78 [8960/60000 (15%)]\tLoss: 728.307373\n",
            "Train Epoch: 78 [10240/60000 (17%)]\tLoss: 736.052307\n",
            "Train Epoch: 78 [11520/60000 (19%)]\tLoss: 729.501221\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 731.064880\n",
            "Train Epoch: 78 [14080/60000 (23%)]\tLoss: 747.498962\n",
            "Train Epoch: 78 [15360/60000 (26%)]\tLoss: 717.589294\n",
            "Train Epoch: 78 [16640/60000 (28%)]\tLoss: 724.402954\n",
            "Train Epoch: 78 [17920/60000 (30%)]\tLoss: 742.168579\n",
            "Train Epoch: 78 [19200/60000 (32%)]\tLoss: 707.449341\n",
            "Train Epoch: 78 [20480/60000 (34%)]\tLoss: 738.742371\n",
            "Train Epoch: 78 [21760/60000 (36%)]\tLoss: 753.987183\n",
            "Train Epoch: 78 [23040/60000 (38%)]\tLoss: 722.434509\n",
            "Train Epoch: 78 [24320/60000 (41%)]\tLoss: 749.689392\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 719.694580\n",
            "Train Epoch: 78 [26880/60000 (45%)]\tLoss: 750.228882\n",
            "Train Epoch: 78 [28160/60000 (47%)]\tLoss: 723.141663\n",
            "Train Epoch: 78 [29440/60000 (49%)]\tLoss: 717.000244\n",
            "Train Epoch: 78 [30720/60000 (51%)]\tLoss: 743.042786\n",
            "Train Epoch: 78 [32000/60000 (53%)]\tLoss: 720.673462\n",
            "Train Epoch: 78 [33280/60000 (55%)]\tLoss: 727.838623\n",
            "Train Epoch: 78 [34560/60000 (58%)]\tLoss: 712.852234\n",
            "Train Epoch: 78 [35840/60000 (60%)]\tLoss: 744.423157\n",
            "Train Epoch: 78 [37120/60000 (62%)]\tLoss: 757.655640\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 742.951538\n",
            "Train Epoch: 78 [39680/60000 (66%)]\tLoss: 738.986755\n",
            "Train Epoch: 78 [40960/60000 (68%)]\tLoss: 747.205627\n",
            "Train Epoch: 78 [42240/60000 (70%)]\tLoss: 744.326294\n",
            "Train Epoch: 78 [43520/60000 (72%)]\tLoss: 726.470276\n",
            "Train Epoch: 78 [44800/60000 (75%)]\tLoss: 741.446899\n",
            "Train Epoch: 78 [46080/60000 (77%)]\tLoss: 726.943176\n",
            "Train Epoch: 78 [47360/60000 (79%)]\tLoss: 744.900269\n",
            "Train Epoch: 78 [48640/60000 (81%)]\tLoss: 712.407166\n",
            "Train Epoch: 78 [49920/60000 (83%)]\tLoss: 746.064087\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 749.645935\n",
            "Train Epoch: 78 [52480/60000 (87%)]\tLoss: 742.509949\n",
            "Train Epoch: 78 [53760/60000 (90%)]\tLoss: 716.821716\n",
            "Train Epoch: 78 [55040/60000 (92%)]\tLoss: 746.881348\n",
            "Train Epoch: 78 [56320/60000 (94%)]\tLoss: 730.087830\n",
            "Train Epoch: 78 [57600/60000 (96%)]\tLoss: 719.765198\n",
            "Train Epoch: 78 [58880/60000 (98%)]\tLoss: 719.504761\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783851504325867\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 736.521362\n",
            "Train Epoch: 79 [1280/60000 (2%)]\tLoss: 721.195557\n",
            "Train Epoch: 79 [2560/60000 (4%)]\tLoss: 714.941650\n",
            "Train Epoch: 79 [3840/60000 (6%)]\tLoss: 721.208862\n",
            "Train Epoch: 79 [5120/60000 (9%)]\tLoss: 739.133606\n",
            "Train Epoch: 79 [6400/60000 (11%)]\tLoss: 764.668884\n",
            "Train Epoch: 79 [7680/60000 (13%)]\tLoss: 728.893860\n",
            "Train Epoch: 79 [8960/60000 (15%)]\tLoss: 750.368408\n",
            "Train Epoch: 79 [10240/60000 (17%)]\tLoss: 751.500793\n",
            "Train Epoch: 79 [11520/60000 (19%)]\tLoss: 740.534302\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 753.740723\n",
            "Train Epoch: 79 [14080/60000 (23%)]\tLoss: 738.838989\n",
            "Train Epoch: 79 [15360/60000 (26%)]\tLoss: 740.747681\n",
            "Train Epoch: 79 [16640/60000 (28%)]\tLoss: 752.688110\n",
            "Train Epoch: 79 [17920/60000 (30%)]\tLoss: 744.787720\n",
            "Train Epoch: 79 [19200/60000 (32%)]\tLoss: 733.938965\n",
            "Train Epoch: 79 [20480/60000 (34%)]\tLoss: 722.261902\n",
            "Train Epoch: 79 [21760/60000 (36%)]\tLoss: 741.793518\n",
            "Train Epoch: 79 [23040/60000 (38%)]\tLoss: 758.519104\n",
            "Train Epoch: 79 [24320/60000 (41%)]\tLoss: 737.646851\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 734.432861\n",
            "Train Epoch: 79 [26880/60000 (45%)]\tLoss: 752.221558\n",
            "Train Epoch: 79 [28160/60000 (47%)]\tLoss: 765.387634\n",
            "Train Epoch: 79 [29440/60000 (49%)]\tLoss: 718.680603\n",
            "Train Epoch: 79 [30720/60000 (51%)]\tLoss: 742.100464\n",
            "Train Epoch: 79 [32000/60000 (53%)]\tLoss: 746.304504\n",
            "Train Epoch: 79 [33280/60000 (55%)]\tLoss: 743.968445\n",
            "Train Epoch: 79 [34560/60000 (58%)]\tLoss: 746.540771\n",
            "Train Epoch: 79 [35840/60000 (60%)]\tLoss: 735.996277\n",
            "Train Epoch: 79 [37120/60000 (62%)]\tLoss: 745.030518\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 726.291382\n",
            "Train Epoch: 79 [39680/60000 (66%)]\tLoss: 744.017639\n",
            "Train Epoch: 79 [40960/60000 (68%)]\tLoss: 736.115479\n",
            "Train Epoch: 79 [42240/60000 (70%)]\tLoss: 724.299072\n",
            "Train Epoch: 79 [43520/60000 (72%)]\tLoss: 775.204834\n",
            "Train Epoch: 79 [44800/60000 (75%)]\tLoss: 724.331726\n",
            "Train Epoch: 79 [46080/60000 (77%)]\tLoss: 737.139404\n",
            "Train Epoch: 79 [47360/60000 (79%)]\tLoss: 712.231445\n",
            "Train Epoch: 79 [48640/60000 (81%)]\tLoss: 718.831848\n",
            "Train Epoch: 79 [49920/60000 (83%)]\tLoss: 776.328918\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 743.812073\n",
            "Train Epoch: 79 [52480/60000 (87%)]\tLoss: 705.075073\n",
            "Train Epoch: 79 [53760/60000 (90%)]\tLoss: 734.503906\n",
            "Train Epoch: 79 [55040/60000 (92%)]\tLoss: 730.491577\n",
            "Train Epoch: 79 [56320/60000 (94%)]\tLoss: 741.500549\n",
            "Train Epoch: 79 [57600/60000 (96%)]\tLoss: 728.787292\n",
            "Train Epoch: 79 [58880/60000 (98%)]\tLoss: 710.074219\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787220656871796\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 738.240051\n",
            "Train Epoch: 80 [1280/60000 (2%)]\tLoss: 742.503357\n",
            "Train Epoch: 80 [2560/60000 (4%)]\tLoss: 742.195374\n",
            "Train Epoch: 80 [3840/60000 (6%)]\tLoss: 738.862427\n",
            "Train Epoch: 80 [5120/60000 (9%)]\tLoss: 704.089050\n",
            "Train Epoch: 80 [6400/60000 (11%)]\tLoss: 739.203674\n",
            "Train Epoch: 80 [7680/60000 (13%)]\tLoss: 727.794922\n",
            "Train Epoch: 80 [8960/60000 (15%)]\tLoss: 741.346436\n",
            "Train Epoch: 80 [10240/60000 (17%)]\tLoss: 724.701172\n",
            "Train Epoch: 80 [11520/60000 (19%)]\tLoss: 780.131409\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 729.590820\n",
            "Train Epoch: 80 [14080/60000 (23%)]\tLoss: 739.660339\n",
            "Train Epoch: 80 [15360/60000 (26%)]\tLoss: 734.274841\n",
            "Train Epoch: 80 [16640/60000 (28%)]\tLoss: 730.491333\n",
            "Train Epoch: 80 [17920/60000 (30%)]\tLoss: 728.296936\n",
            "Train Epoch: 80 [19200/60000 (32%)]\tLoss: 735.851624\n",
            "Train Epoch: 80 [20480/60000 (34%)]\tLoss: 731.331848\n",
            "Train Epoch: 80 [21760/60000 (36%)]\tLoss: 759.565552\n",
            "Train Epoch: 80 [23040/60000 (38%)]\tLoss: 748.795166\n",
            "Train Epoch: 80 [24320/60000 (41%)]\tLoss: 744.523010\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 732.016663\n",
            "Train Epoch: 80 [26880/60000 (45%)]\tLoss: 721.189575\n",
            "Train Epoch: 80 [28160/60000 (47%)]\tLoss: 716.047363\n",
            "Train Epoch: 80 [29440/60000 (49%)]\tLoss: 741.951721\n",
            "Train Epoch: 80 [30720/60000 (51%)]\tLoss: 758.425781\n",
            "Train Epoch: 80 [32000/60000 (53%)]\tLoss: 726.944702\n",
            "Train Epoch: 80 [33280/60000 (55%)]\tLoss: 726.234009\n",
            "Train Epoch: 80 [34560/60000 (58%)]\tLoss: 741.084595\n",
            "Train Epoch: 80 [35840/60000 (60%)]\tLoss: 736.568115\n",
            "Train Epoch: 80 [37120/60000 (62%)]\tLoss: 725.601196\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 727.255493\n",
            "Train Epoch: 80 [39680/60000 (66%)]\tLoss: 749.485229\n",
            "Train Epoch: 80 [40960/60000 (68%)]\tLoss: 726.226624\n",
            "Train Epoch: 80 [42240/60000 (70%)]\tLoss: 724.154968\n",
            "Train Epoch: 80 [43520/60000 (72%)]\tLoss: 703.708069\n",
            "Train Epoch: 80 [44800/60000 (75%)]\tLoss: 730.192749\n",
            "Train Epoch: 80 [46080/60000 (77%)]\tLoss: 704.985046\n",
            "Train Epoch: 80 [47360/60000 (79%)]\tLoss: 753.457275\n",
            "Train Epoch: 80 [48640/60000 (81%)]\tLoss: 735.291870\n",
            "Train Epoch: 80 [49920/60000 (83%)]\tLoss: 732.700989\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 745.583374\n",
            "Train Epoch: 80 [52480/60000 (87%)]\tLoss: 717.936218\n",
            "Train Epoch: 80 [53760/60000 (90%)]\tLoss: 746.475098\n",
            "Train Epoch: 80 [55040/60000 (92%)]\tLoss: 743.481384\n",
            "Train Epoch: 80 [56320/60000 (94%)]\tLoss: 736.399353\n",
            "Train Epoch: 80 [57600/60000 (96%)]\tLoss: 724.054688\n",
            "Train Epoch: 80 [58880/60000 (98%)]\tLoss: 712.011719\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978302001953125\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 758.962219\n",
            "Train Epoch: 81 [1280/60000 (2%)]\tLoss: 719.246460\n",
            "Train Epoch: 81 [2560/60000 (4%)]\tLoss: 747.902405\n",
            "Train Epoch: 81 [3840/60000 (6%)]\tLoss: 758.112610\n",
            "Train Epoch: 81 [5120/60000 (9%)]\tLoss: 737.217163\n",
            "Train Epoch: 81 [6400/60000 (11%)]\tLoss: 728.635925\n",
            "Train Epoch: 81 [7680/60000 (13%)]\tLoss: 729.899902\n",
            "Train Epoch: 81 [8960/60000 (15%)]\tLoss: 734.639771\n",
            "Train Epoch: 81 [10240/60000 (17%)]\tLoss: 761.564453\n",
            "Train Epoch: 81 [11520/60000 (19%)]\tLoss: 733.313477\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 732.722229\n",
            "Train Epoch: 81 [14080/60000 (23%)]\tLoss: 737.137634\n",
            "Train Epoch: 81 [15360/60000 (26%)]\tLoss: 726.924255\n",
            "Train Epoch: 81 [16640/60000 (28%)]\tLoss: 718.697205\n",
            "Train Epoch: 81 [17920/60000 (30%)]\tLoss: 749.054321\n",
            "Train Epoch: 81 [19200/60000 (32%)]\tLoss: 737.489990\n",
            "Train Epoch: 81 [20480/60000 (34%)]\tLoss: 736.861694\n",
            "Train Epoch: 81 [21760/60000 (36%)]\tLoss: 738.059143\n",
            "Train Epoch: 81 [23040/60000 (38%)]\tLoss: 779.033325\n",
            "Train Epoch: 81 [24320/60000 (41%)]\tLoss: 736.124084\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 744.409424\n",
            "Train Epoch: 81 [26880/60000 (45%)]\tLoss: 763.468201\n",
            "Train Epoch: 81 [28160/60000 (47%)]\tLoss: 740.679504\n",
            "Train Epoch: 81 [29440/60000 (49%)]\tLoss: 699.035767\n",
            "Train Epoch: 81 [30720/60000 (51%)]\tLoss: 721.378723\n",
            "Train Epoch: 81 [32000/60000 (53%)]\tLoss: 730.473328\n",
            "Train Epoch: 81 [33280/60000 (55%)]\tLoss: 752.867676\n",
            "Train Epoch: 81 [34560/60000 (58%)]\tLoss: 750.748474\n",
            "Train Epoch: 81 [35840/60000 (60%)]\tLoss: 711.566040\n",
            "Train Epoch: 81 [37120/60000 (62%)]\tLoss: 750.987915\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 716.664551\n",
            "Train Epoch: 81 [39680/60000 (66%)]\tLoss: 723.668457\n",
            "Train Epoch: 81 [40960/60000 (68%)]\tLoss: 754.509399\n",
            "Train Epoch: 81 [42240/60000 (70%)]\tLoss: 739.961609\n",
            "Train Epoch: 81 [43520/60000 (72%)]\tLoss: 722.787292\n",
            "Train Epoch: 81 [44800/60000 (75%)]\tLoss: 739.895935\n",
            "Train Epoch: 81 [46080/60000 (77%)]\tLoss: 705.184265\n",
            "Train Epoch: 81 [47360/60000 (79%)]\tLoss: 761.111938\n",
            "Train Epoch: 81 [48640/60000 (81%)]\tLoss: 743.331543\n",
            "Train Epoch: 81 [49920/60000 (83%)]\tLoss: 740.123169\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 753.000732\n",
            "Train Epoch: 81 [52480/60000 (87%)]\tLoss: 722.917725\n",
            "Train Epoch: 81 [53760/60000 (90%)]\tLoss: 730.413147\n",
            "Train Epoch: 81 [55040/60000 (92%)]\tLoss: 728.401611\n",
            "Train Epoch: 81 [56320/60000 (94%)]\tLoss: 730.139465\n",
            "Train Epoch: 81 [57600/60000 (96%)]\tLoss: 755.717651\n",
            "Train Epoch: 81 [58880/60000 (98%)]\tLoss: 727.031494\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978016495704651\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 712.778076\n",
            "Train Epoch: 82 [1280/60000 (2%)]\tLoss: 738.397522\n",
            "Train Epoch: 82 [2560/60000 (4%)]\tLoss: 727.604126\n",
            "Train Epoch: 82 [3840/60000 (6%)]\tLoss: 724.333557\n",
            "Train Epoch: 82 [5120/60000 (9%)]\tLoss: 743.729187\n",
            "Train Epoch: 82 [6400/60000 (11%)]\tLoss: 729.233521\n",
            "Train Epoch: 82 [7680/60000 (13%)]\tLoss: 763.920349\n",
            "Train Epoch: 82 [8960/60000 (15%)]\tLoss: 750.165100\n",
            "Train Epoch: 82 [10240/60000 (17%)]\tLoss: 726.917419\n",
            "Train Epoch: 82 [11520/60000 (19%)]\tLoss: 742.516174\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 736.056580\n",
            "Train Epoch: 82 [14080/60000 (23%)]\tLoss: 750.291016\n",
            "Train Epoch: 82 [15360/60000 (26%)]\tLoss: 753.826538\n",
            "Train Epoch: 82 [16640/60000 (28%)]\tLoss: 752.474304\n",
            "Train Epoch: 82 [17920/60000 (30%)]\tLoss: 744.247620\n",
            "Train Epoch: 82 [19200/60000 (32%)]\tLoss: 719.595581\n",
            "Train Epoch: 82 [20480/60000 (34%)]\tLoss: 734.303467\n",
            "Train Epoch: 82 [21760/60000 (36%)]\tLoss: 738.350220\n",
            "Train Epoch: 82 [23040/60000 (38%)]\tLoss: 719.582703\n",
            "Train Epoch: 82 [24320/60000 (41%)]\tLoss: 763.734070\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 734.873108\n",
            "Train Epoch: 82 [26880/60000 (45%)]\tLoss: 774.230286\n",
            "Train Epoch: 82 [28160/60000 (47%)]\tLoss: 731.189941\n",
            "Train Epoch: 82 [29440/60000 (49%)]\tLoss: 711.498169\n",
            "Train Epoch: 82 [30720/60000 (51%)]\tLoss: 763.466492\n",
            "Train Epoch: 82 [32000/60000 (53%)]\tLoss: 721.020386\n",
            "Train Epoch: 82 [33280/60000 (55%)]\tLoss: 756.937500\n",
            "Train Epoch: 82 [34560/60000 (58%)]\tLoss: 714.658020\n",
            "Train Epoch: 82 [35840/60000 (60%)]\tLoss: 734.710510\n",
            "Train Epoch: 82 [37120/60000 (62%)]\tLoss: 750.583008\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 740.092285\n",
            "Train Epoch: 82 [39680/60000 (66%)]\tLoss: 746.185120\n",
            "Train Epoch: 82 [40960/60000 (68%)]\tLoss: 742.218933\n",
            "Train Epoch: 82 [42240/60000 (70%)]\tLoss: 718.243591\n",
            "Train Epoch: 82 [43520/60000 (72%)]\tLoss: 733.059082\n",
            "Train Epoch: 82 [44800/60000 (75%)]\tLoss: 724.258850\n",
            "Train Epoch: 82 [46080/60000 (77%)]\tLoss: 768.983704\n",
            "Train Epoch: 82 [47360/60000 (79%)]\tLoss: 743.979858\n",
            "Train Epoch: 82 [48640/60000 (81%)]\tLoss: 722.500183\n",
            "Train Epoch: 82 [49920/60000 (83%)]\tLoss: 741.522705\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 698.675354\n",
            "Train Epoch: 82 [52480/60000 (87%)]\tLoss: 736.059937\n",
            "Train Epoch: 82 [53760/60000 (90%)]\tLoss: 732.408752\n",
            "Train Epoch: 82 [55040/60000 (92%)]\tLoss: 730.740051\n",
            "Train Epoch: 82 [56320/60000 (94%)]\tLoss: 753.917969\n",
            "Train Epoch: 82 [57600/60000 (96%)]\tLoss: 714.999084\n",
            "Train Epoch: 82 [58880/60000 (98%)]\tLoss: 718.947998\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978163868188858\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 707.550964\n",
            "Train Epoch: 83 [1280/60000 (2%)]\tLoss: 742.124451\n",
            "Train Epoch: 83 [2560/60000 (4%)]\tLoss: 730.439392\n",
            "Train Epoch: 83 [3840/60000 (6%)]\tLoss: 732.093140\n",
            "Train Epoch: 83 [5120/60000 (9%)]\tLoss: 764.322876\n",
            "Train Epoch: 83 [6400/60000 (11%)]\tLoss: 731.240906\n",
            "Train Epoch: 83 [7680/60000 (13%)]\tLoss: 723.305298\n",
            "Train Epoch: 83 [8960/60000 (15%)]\tLoss: 717.310730\n",
            "Train Epoch: 83 [10240/60000 (17%)]\tLoss: 743.313782\n",
            "Train Epoch: 83 [11520/60000 (19%)]\tLoss: 738.642395\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 741.006287\n",
            "Train Epoch: 83 [14080/60000 (23%)]\tLoss: 735.303528\n",
            "Train Epoch: 83 [15360/60000 (26%)]\tLoss: 730.306519\n",
            "Train Epoch: 83 [16640/60000 (28%)]\tLoss: 726.127319\n",
            "Train Epoch: 83 [17920/60000 (30%)]\tLoss: 748.776978\n",
            "Train Epoch: 83 [19200/60000 (32%)]\tLoss: 746.968811\n",
            "Train Epoch: 83 [20480/60000 (34%)]\tLoss: 746.810364\n",
            "Train Epoch: 83 [21760/60000 (36%)]\tLoss: 723.030029\n",
            "Train Epoch: 83 [23040/60000 (38%)]\tLoss: 777.695801\n",
            "Train Epoch: 83 [24320/60000 (41%)]\tLoss: 726.362732\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 738.984985\n",
            "Train Epoch: 83 [26880/60000 (45%)]\tLoss: 732.018799\n",
            "Train Epoch: 83 [28160/60000 (47%)]\tLoss: 753.612183\n",
            "Train Epoch: 83 [29440/60000 (49%)]\tLoss: 761.388062\n",
            "Train Epoch: 83 [30720/60000 (51%)]\tLoss: 747.678406\n",
            "Train Epoch: 83 [32000/60000 (53%)]\tLoss: 745.740723\n",
            "Train Epoch: 83 [33280/60000 (55%)]\tLoss: 733.928223\n",
            "Train Epoch: 83 [34560/60000 (58%)]\tLoss: 724.195251\n",
            "Train Epoch: 83 [35840/60000 (60%)]\tLoss: 723.814270\n",
            "Train Epoch: 83 [37120/60000 (62%)]\tLoss: 730.222168\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 731.049683\n",
            "Train Epoch: 83 [39680/60000 (66%)]\tLoss: 745.468567\n",
            "Train Epoch: 83 [40960/60000 (68%)]\tLoss: 753.244812\n",
            "Train Epoch: 83 [42240/60000 (70%)]\tLoss: 733.800110\n",
            "Train Epoch: 83 [43520/60000 (72%)]\tLoss: 740.017517\n",
            "Train Epoch: 83 [44800/60000 (75%)]\tLoss: 755.992004\n",
            "Train Epoch: 83 [46080/60000 (77%)]\tLoss: 727.231628\n",
            "Train Epoch: 83 [47360/60000 (79%)]\tLoss: 735.060242\n",
            "Train Epoch: 83 [48640/60000 (81%)]\tLoss: 756.395203\n",
            "Train Epoch: 83 [49920/60000 (83%)]\tLoss: 745.664795\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 737.310730\n",
            "Train Epoch: 83 [52480/60000 (87%)]\tLoss: 734.898804\n",
            "Train Epoch: 83 [53760/60000 (90%)]\tLoss: 734.279663\n",
            "Train Epoch: 83 [55040/60000 (92%)]\tLoss: 700.605286\n",
            "Train Epoch: 83 [56320/60000 (94%)]\tLoss: 765.669373\n",
            "Train Epoch: 83 [57600/60000 (96%)]\tLoss: 748.290161\n",
            "Train Epoch: 83 [58880/60000 (98%)]\tLoss: 737.703430\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783766567707062\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 738.058655\n",
            "Train Epoch: 84 [1280/60000 (2%)]\tLoss: 713.785339\n",
            "Train Epoch: 84 [2560/60000 (4%)]\tLoss: 731.299561\n",
            "Train Epoch: 84 [3840/60000 (6%)]\tLoss: 749.555420\n",
            "Train Epoch: 84 [5120/60000 (9%)]\tLoss: 730.988159\n",
            "Train Epoch: 84 [6400/60000 (11%)]\tLoss: 740.861206\n",
            "Train Epoch: 84 [7680/60000 (13%)]\tLoss: 747.898315\n",
            "Train Epoch: 84 [8960/60000 (15%)]\tLoss: 730.746643\n",
            "Train Epoch: 84 [10240/60000 (17%)]\tLoss: 734.058350\n",
            "Train Epoch: 84 [11520/60000 (19%)]\tLoss: 723.169617\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 726.085083\n",
            "Train Epoch: 84 [14080/60000 (23%)]\tLoss: 733.356018\n",
            "Train Epoch: 84 [15360/60000 (26%)]\tLoss: 757.673706\n",
            "Train Epoch: 84 [16640/60000 (28%)]\tLoss: 727.448181\n",
            "Train Epoch: 84 [17920/60000 (30%)]\tLoss: 741.293274\n",
            "Train Epoch: 84 [19200/60000 (32%)]\tLoss: 732.910278\n",
            "Train Epoch: 84 [20480/60000 (34%)]\tLoss: 749.617249\n",
            "Train Epoch: 84 [21760/60000 (36%)]\tLoss: 734.972412\n",
            "Train Epoch: 84 [23040/60000 (38%)]\tLoss: 746.713196\n",
            "Train Epoch: 84 [24320/60000 (41%)]\tLoss: 750.468933\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 748.060547\n",
            "Train Epoch: 84 [26880/60000 (45%)]\tLoss: 739.771484\n",
            "Train Epoch: 84 [28160/60000 (47%)]\tLoss: 739.290955\n",
            "Train Epoch: 84 [29440/60000 (49%)]\tLoss: 754.208069\n",
            "Train Epoch: 84 [30720/60000 (51%)]\tLoss: 708.360107\n",
            "Train Epoch: 84 [32000/60000 (53%)]\tLoss: 701.791138\n",
            "Train Epoch: 84 [33280/60000 (55%)]\tLoss: 750.038147\n",
            "Train Epoch: 84 [34560/60000 (58%)]\tLoss: 737.886353\n",
            "Train Epoch: 84 [35840/60000 (60%)]\tLoss: 747.056946\n",
            "Train Epoch: 84 [37120/60000 (62%)]\tLoss: 735.701660\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 751.563660\n",
            "Train Epoch: 84 [39680/60000 (66%)]\tLoss: 749.877441\n",
            "Train Epoch: 84 [40960/60000 (68%)]\tLoss: 737.285583\n",
            "Train Epoch: 84 [42240/60000 (70%)]\tLoss: 762.742065\n",
            "Train Epoch: 84 [43520/60000 (72%)]\tLoss: 726.806824\n",
            "Train Epoch: 84 [44800/60000 (75%)]\tLoss: 737.500122\n",
            "Train Epoch: 84 [46080/60000 (77%)]\tLoss: 757.044739\n",
            "Train Epoch: 84 [47360/60000 (79%)]\tLoss: 710.521606\n",
            "Train Epoch: 84 [48640/60000 (81%)]\tLoss: 748.359131\n",
            "Train Epoch: 84 [49920/60000 (83%)]\tLoss: 727.523315\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 761.204407\n",
            "Train Epoch: 84 [52480/60000 (87%)]\tLoss: 730.522400\n",
            "Train Epoch: 84 [53760/60000 (90%)]\tLoss: 752.052002\n",
            "Train Epoch: 84 [55040/60000 (92%)]\tLoss: 761.044373\n",
            "Train Epoch: 84 [56320/60000 (94%)]\tLoss: 732.615723\n",
            "Train Epoch: 84 [57600/60000 (96%)]\tLoss: 745.255554\n",
            "Train Epoch: 84 [58880/60000 (98%)]\tLoss: 736.683472\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785551726818085\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 741.193054\n",
            "Train Epoch: 85 [1280/60000 (2%)]\tLoss: 721.674316\n",
            "Train Epoch: 85 [2560/60000 (4%)]\tLoss: 737.080811\n",
            "Train Epoch: 85 [3840/60000 (6%)]\tLoss: 743.684143\n",
            "Train Epoch: 85 [5120/60000 (9%)]\tLoss: 718.477051\n",
            "Train Epoch: 85 [6400/60000 (11%)]\tLoss: 738.595825\n",
            "Train Epoch: 85 [7680/60000 (13%)]\tLoss: 736.651917\n",
            "Train Epoch: 85 [8960/60000 (15%)]\tLoss: 728.501587\n",
            "Train Epoch: 85 [10240/60000 (17%)]\tLoss: 724.023254\n",
            "Train Epoch: 85 [11520/60000 (19%)]\tLoss: 731.714539\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 762.487000\n",
            "Train Epoch: 85 [14080/60000 (23%)]\tLoss: 752.356079\n",
            "Train Epoch: 85 [15360/60000 (26%)]\tLoss: 729.574890\n",
            "Train Epoch: 85 [16640/60000 (28%)]\tLoss: 717.750549\n",
            "Train Epoch: 85 [17920/60000 (30%)]\tLoss: 723.270813\n",
            "Train Epoch: 85 [19200/60000 (32%)]\tLoss: 748.628723\n",
            "Train Epoch: 85 [20480/60000 (34%)]\tLoss: 711.988281\n",
            "Train Epoch: 85 [21760/60000 (36%)]\tLoss: 761.339355\n",
            "Train Epoch: 85 [23040/60000 (38%)]\tLoss: 738.400635\n",
            "Train Epoch: 85 [24320/60000 (41%)]\tLoss: 727.148682\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 740.433960\n",
            "Train Epoch: 85 [26880/60000 (45%)]\tLoss: 729.856323\n",
            "Train Epoch: 85 [28160/60000 (47%)]\tLoss: 735.177368\n",
            "Train Epoch: 85 [29440/60000 (49%)]\tLoss: 738.775269\n",
            "Train Epoch: 85 [30720/60000 (51%)]\tLoss: 737.254028\n",
            "Train Epoch: 85 [32000/60000 (53%)]\tLoss: 733.132202\n",
            "Train Epoch: 85 [33280/60000 (55%)]\tLoss: 724.081116\n",
            "Train Epoch: 85 [34560/60000 (58%)]\tLoss: 720.521912\n",
            "Train Epoch: 85 [35840/60000 (60%)]\tLoss: 725.606995\n",
            "Train Epoch: 85 [37120/60000 (62%)]\tLoss: 713.062378\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 741.580688\n",
            "Train Epoch: 85 [39680/60000 (66%)]\tLoss: 744.650024\n",
            "Train Epoch: 85 [40960/60000 (68%)]\tLoss: 760.719543\n",
            "Train Epoch: 85 [42240/60000 (70%)]\tLoss: 732.527954\n",
            "Train Epoch: 85 [43520/60000 (72%)]\tLoss: 732.033264\n",
            "Train Epoch: 85 [44800/60000 (75%)]\tLoss: 730.668030\n",
            "Train Epoch: 85 [46080/60000 (77%)]\tLoss: 745.963562\n",
            "Train Epoch: 85 [47360/60000 (79%)]\tLoss: 750.703491\n",
            "Train Epoch: 85 [48640/60000 (81%)]\tLoss: 749.165039\n",
            "Train Epoch: 85 [49920/60000 (83%)]\tLoss: 725.828247\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 735.923645\n",
            "Train Epoch: 85 [52480/60000 (87%)]\tLoss: 752.268433\n",
            "Train Epoch: 85 [53760/60000 (90%)]\tLoss: 747.343811\n",
            "Train Epoch: 85 [55040/60000 (92%)]\tLoss: 743.910217\n",
            "Train Epoch: 85 [56320/60000 (94%)]\tLoss: 727.322754\n",
            "Train Epoch: 85 [57600/60000 (96%)]\tLoss: 728.046753\n",
            "Train Epoch: 85 [58880/60000 (98%)]\tLoss: 718.190552\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781745970249176\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 728.255371\n",
            "Train Epoch: 86 [1280/60000 (2%)]\tLoss: 719.614868\n",
            "Train Epoch: 86 [2560/60000 (4%)]\tLoss: 726.001221\n",
            "Train Epoch: 86 [3840/60000 (6%)]\tLoss: 731.978027\n",
            "Train Epoch: 86 [5120/60000 (9%)]\tLoss: 737.560669\n",
            "Train Epoch: 86 [6400/60000 (11%)]\tLoss: 737.584717\n",
            "Train Epoch: 86 [7680/60000 (13%)]\tLoss: 742.990967\n",
            "Train Epoch: 86 [8960/60000 (15%)]\tLoss: 737.432068\n",
            "Train Epoch: 86 [10240/60000 (17%)]\tLoss: 744.412170\n",
            "Train Epoch: 86 [11520/60000 (19%)]\tLoss: 749.402771\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 745.690247\n",
            "Train Epoch: 86 [14080/60000 (23%)]\tLoss: 737.611694\n",
            "Train Epoch: 86 [15360/60000 (26%)]\tLoss: 730.224731\n",
            "Train Epoch: 86 [16640/60000 (28%)]\tLoss: 739.923584\n",
            "Train Epoch: 86 [17920/60000 (30%)]\tLoss: 722.530945\n",
            "Train Epoch: 86 [19200/60000 (32%)]\tLoss: 748.460327\n",
            "Train Epoch: 86 [20480/60000 (34%)]\tLoss: 721.001221\n",
            "Train Epoch: 86 [21760/60000 (36%)]\tLoss: 746.044495\n",
            "Train Epoch: 86 [23040/60000 (38%)]\tLoss: 748.523193\n",
            "Train Epoch: 86 [24320/60000 (41%)]\tLoss: 768.760620\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 729.148376\n",
            "Train Epoch: 86 [26880/60000 (45%)]\tLoss: 731.324463\n",
            "Train Epoch: 86 [28160/60000 (47%)]\tLoss: 748.453003\n",
            "Train Epoch: 86 [29440/60000 (49%)]\tLoss: 711.831848\n",
            "Train Epoch: 86 [30720/60000 (51%)]\tLoss: 744.034241\n",
            "Train Epoch: 86 [32000/60000 (53%)]\tLoss: 755.496094\n",
            "Train Epoch: 86 [33280/60000 (55%)]\tLoss: 736.643555\n",
            "Train Epoch: 86 [34560/60000 (58%)]\tLoss: 723.861023\n",
            "Train Epoch: 86 [35840/60000 (60%)]\tLoss: 753.990784\n",
            "Train Epoch: 86 [37120/60000 (62%)]\tLoss: 731.103699\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 752.074097\n",
            "Train Epoch: 86 [39680/60000 (66%)]\tLoss: 732.091187\n",
            "Train Epoch: 86 [40960/60000 (68%)]\tLoss: 737.337769\n",
            "Train Epoch: 86 [42240/60000 (70%)]\tLoss: 740.436523\n",
            "Train Epoch: 86 [43520/60000 (72%)]\tLoss: 747.959534\n",
            "Train Epoch: 86 [44800/60000 (75%)]\tLoss: 726.966858\n",
            "Train Epoch: 86 [46080/60000 (77%)]\tLoss: 716.311462\n",
            "Train Epoch: 86 [47360/60000 (79%)]\tLoss: 743.607300\n",
            "Train Epoch: 86 [48640/60000 (81%)]\tLoss: 729.162659\n",
            "Train Epoch: 86 [49920/60000 (83%)]\tLoss: 727.884460\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 722.578979\n",
            "Train Epoch: 86 [52480/60000 (87%)]\tLoss: 743.675659\n",
            "Train Epoch: 86 [53760/60000 (90%)]\tLoss: 749.820496\n",
            "Train Epoch: 86 [55040/60000 (92%)]\tLoss: 750.541382\n",
            "Train Epoch: 86 [56320/60000 (94%)]\tLoss: 734.781189\n",
            "Train Epoch: 86 [57600/60000 (96%)]\tLoss: 728.729614\n",
            "Train Epoch: 86 [58880/60000 (98%)]\tLoss: 745.867920\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785276055335999\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 719.978577\n",
            "Train Epoch: 87 [1280/60000 (2%)]\tLoss: 718.765198\n",
            "Train Epoch: 87 [2560/60000 (4%)]\tLoss: 726.486755\n",
            "Train Epoch: 87 [3840/60000 (6%)]\tLoss: 755.967896\n",
            "Train Epoch: 87 [5120/60000 (9%)]\tLoss: 725.756775\n",
            "Train Epoch: 87 [6400/60000 (11%)]\tLoss: 737.508972\n",
            "Train Epoch: 87 [7680/60000 (13%)]\tLoss: 764.156982\n",
            "Train Epoch: 87 [8960/60000 (15%)]\tLoss: 750.429138\n",
            "Train Epoch: 87 [10240/60000 (17%)]\tLoss: 759.250427\n",
            "Train Epoch: 87 [11520/60000 (19%)]\tLoss: 715.901550\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 757.214539\n",
            "Train Epoch: 87 [14080/60000 (23%)]\tLoss: 743.425415\n",
            "Train Epoch: 87 [15360/60000 (26%)]\tLoss: 770.129700\n",
            "Train Epoch: 87 [16640/60000 (28%)]\tLoss: 705.045105\n",
            "Train Epoch: 87 [17920/60000 (30%)]\tLoss: 750.344849\n",
            "Train Epoch: 87 [19200/60000 (32%)]\tLoss: 744.685730\n",
            "Train Epoch: 87 [20480/60000 (34%)]\tLoss: 712.101318\n",
            "Train Epoch: 87 [21760/60000 (36%)]\tLoss: 735.688110\n",
            "Train Epoch: 87 [23040/60000 (38%)]\tLoss: 718.337646\n",
            "Train Epoch: 87 [24320/60000 (41%)]\tLoss: 729.415588\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 715.408020\n",
            "Train Epoch: 87 [26880/60000 (45%)]\tLoss: 736.507080\n",
            "Train Epoch: 87 [28160/60000 (47%)]\tLoss: 716.480347\n",
            "Train Epoch: 87 [29440/60000 (49%)]\tLoss: 736.339722\n",
            "Train Epoch: 87 [30720/60000 (51%)]\tLoss: 724.769287\n",
            "Train Epoch: 87 [32000/60000 (53%)]\tLoss: 737.103333\n",
            "Train Epoch: 87 [33280/60000 (55%)]\tLoss: 720.101685\n",
            "Train Epoch: 87 [34560/60000 (58%)]\tLoss: 737.260742\n",
            "Train Epoch: 87 [35840/60000 (60%)]\tLoss: 752.101807\n",
            "Train Epoch: 87 [37120/60000 (62%)]\tLoss: 732.845459\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 725.547546\n",
            "Train Epoch: 87 [39680/60000 (66%)]\tLoss: 713.355286\n",
            "Train Epoch: 87 [40960/60000 (68%)]\tLoss: 752.517883\n",
            "Train Epoch: 87 [42240/60000 (70%)]\tLoss: 739.014038\n",
            "Train Epoch: 87 [43520/60000 (72%)]\tLoss: 704.055664\n",
            "Train Epoch: 87 [44800/60000 (75%)]\tLoss: 725.859070\n",
            "Train Epoch: 87 [46080/60000 (77%)]\tLoss: 726.411926\n",
            "Train Epoch: 87 [47360/60000 (79%)]\tLoss: 743.900879\n",
            "Train Epoch: 87 [48640/60000 (81%)]\tLoss: 711.497803\n",
            "Train Epoch: 87 [49920/60000 (83%)]\tLoss: 719.974304\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 744.535767\n",
            "Train Epoch: 87 [52480/60000 (87%)]\tLoss: 728.425171\n",
            "Train Epoch: 87 [53760/60000 (90%)]\tLoss: 719.561707\n",
            "Train Epoch: 87 [55040/60000 (92%)]\tLoss: 731.906128\n",
            "Train Epoch: 87 [56320/60000 (94%)]\tLoss: 729.832458\n",
            "Train Epoch: 87 [57600/60000 (96%)]\tLoss: 753.056091\n",
            "Train Epoch: 87 [58880/60000 (98%)]\tLoss: 736.082153\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978420615196228\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 729.760803\n",
            "Train Epoch: 88 [1280/60000 (2%)]\tLoss: 736.102539\n",
            "Train Epoch: 88 [2560/60000 (4%)]\tLoss: 740.096375\n",
            "Train Epoch: 88 [3840/60000 (6%)]\tLoss: 724.724854\n",
            "Train Epoch: 88 [5120/60000 (9%)]\tLoss: 721.869629\n",
            "Train Epoch: 88 [6400/60000 (11%)]\tLoss: 706.566589\n",
            "Train Epoch: 88 [7680/60000 (13%)]\tLoss: 743.853088\n",
            "Train Epoch: 88 [8960/60000 (15%)]\tLoss: 739.222107\n",
            "Train Epoch: 88 [10240/60000 (17%)]\tLoss: 720.635864\n",
            "Train Epoch: 88 [11520/60000 (19%)]\tLoss: 747.141113\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 743.638733\n",
            "Train Epoch: 88 [14080/60000 (23%)]\tLoss: 757.050476\n",
            "Train Epoch: 88 [15360/60000 (26%)]\tLoss: 743.078857\n",
            "Train Epoch: 88 [16640/60000 (28%)]\tLoss: 758.837769\n",
            "Train Epoch: 88 [17920/60000 (30%)]\tLoss: 722.796509\n",
            "Train Epoch: 88 [19200/60000 (32%)]\tLoss: 755.133240\n",
            "Train Epoch: 88 [20480/60000 (34%)]\tLoss: 744.803467\n",
            "Train Epoch: 88 [21760/60000 (36%)]\tLoss: 730.468018\n",
            "Train Epoch: 88 [23040/60000 (38%)]\tLoss: 751.075012\n",
            "Train Epoch: 88 [24320/60000 (41%)]\tLoss: 695.713989\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 709.751831\n",
            "Train Epoch: 88 [26880/60000 (45%)]\tLoss: 738.577515\n",
            "Train Epoch: 88 [28160/60000 (47%)]\tLoss: 723.647522\n",
            "Train Epoch: 88 [29440/60000 (49%)]\tLoss: 738.161133\n",
            "Train Epoch: 88 [30720/60000 (51%)]\tLoss: 761.071167\n",
            "Train Epoch: 88 [32000/60000 (53%)]\tLoss: 745.322815\n",
            "Train Epoch: 88 [33280/60000 (55%)]\tLoss: 738.235046\n",
            "Train Epoch: 88 [34560/60000 (58%)]\tLoss: 736.916870\n",
            "Train Epoch: 88 [35840/60000 (60%)]\tLoss: 740.702759\n",
            "Train Epoch: 88 [37120/60000 (62%)]\tLoss: 743.127380\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 723.236816\n",
            "Train Epoch: 88 [39680/60000 (66%)]\tLoss: 732.564575\n",
            "Train Epoch: 88 [40960/60000 (68%)]\tLoss: 733.638611\n",
            "Train Epoch: 88 [42240/60000 (70%)]\tLoss: 725.573486\n",
            "Train Epoch: 88 [43520/60000 (72%)]\tLoss: 739.328369\n",
            "Train Epoch: 88 [44800/60000 (75%)]\tLoss: 745.012573\n",
            "Train Epoch: 88 [46080/60000 (77%)]\tLoss: 742.481384\n",
            "Train Epoch: 88 [47360/60000 (79%)]\tLoss: 748.346436\n",
            "Train Epoch: 88 [48640/60000 (81%)]\tLoss: 737.899719\n",
            "Train Epoch: 88 [49920/60000 (83%)]\tLoss: 726.170593\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 747.240845\n",
            "Train Epoch: 88 [52480/60000 (87%)]\tLoss: 725.892822\n",
            "Train Epoch: 88 [53760/60000 (90%)]\tLoss: 744.168030\n",
            "Train Epoch: 88 [55040/60000 (92%)]\tLoss: 734.269470\n",
            "Train Epoch: 88 [56320/60000 (94%)]\tLoss: 722.539734\n",
            "Train Epoch: 88 [57600/60000 (96%)]\tLoss: 745.425415\n",
            "Train Epoch: 88 [58880/60000 (98%)]\tLoss: 738.684387\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784289598464966\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 743.046692\n",
            "Train Epoch: 89 [1280/60000 (2%)]\tLoss: 744.066467\n",
            "Train Epoch: 89 [2560/60000 (4%)]\tLoss: 737.544678\n",
            "Train Epoch: 89 [3840/60000 (6%)]\tLoss: 735.997192\n",
            "Train Epoch: 89 [5120/60000 (9%)]\tLoss: 729.820679\n",
            "Train Epoch: 89 [6400/60000 (11%)]\tLoss: 762.944824\n",
            "Train Epoch: 89 [7680/60000 (13%)]\tLoss: 734.865723\n",
            "Train Epoch: 89 [8960/60000 (15%)]\tLoss: 738.551575\n",
            "Train Epoch: 89 [10240/60000 (17%)]\tLoss: 734.989197\n",
            "Train Epoch: 89 [11520/60000 (19%)]\tLoss: 726.807068\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 721.430420\n",
            "Train Epoch: 89 [14080/60000 (23%)]\tLoss: 716.551697\n",
            "Train Epoch: 89 [15360/60000 (26%)]\tLoss: 732.429810\n",
            "Train Epoch: 89 [16640/60000 (28%)]\tLoss: 735.098267\n",
            "Train Epoch: 89 [17920/60000 (30%)]\tLoss: 720.429382\n",
            "Train Epoch: 89 [19200/60000 (32%)]\tLoss: 723.999084\n",
            "Train Epoch: 89 [20480/60000 (34%)]\tLoss: 724.937256\n",
            "Train Epoch: 89 [21760/60000 (36%)]\tLoss: 707.267822\n",
            "Train Epoch: 89 [23040/60000 (38%)]\tLoss: 738.574707\n",
            "Train Epoch: 89 [24320/60000 (41%)]\tLoss: 737.329285\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 741.869141\n",
            "Train Epoch: 89 [26880/60000 (45%)]\tLoss: 752.551575\n",
            "Train Epoch: 89 [28160/60000 (47%)]\tLoss: 731.586304\n",
            "Train Epoch: 89 [29440/60000 (49%)]\tLoss: 730.701843\n",
            "Train Epoch: 89 [30720/60000 (51%)]\tLoss: 724.557495\n",
            "Train Epoch: 89 [32000/60000 (53%)]\tLoss: 737.014771\n",
            "Train Epoch: 89 [33280/60000 (55%)]\tLoss: 735.108521\n",
            "Train Epoch: 89 [34560/60000 (58%)]\tLoss: 744.154663\n",
            "Train Epoch: 89 [35840/60000 (60%)]\tLoss: 717.670715\n",
            "Train Epoch: 89 [37120/60000 (62%)]\tLoss: 731.404236\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 713.864502\n",
            "Train Epoch: 89 [39680/60000 (66%)]\tLoss: 712.365417\n",
            "Train Epoch: 89 [40960/60000 (68%)]\tLoss: 732.351562\n",
            "Train Epoch: 89 [42240/60000 (70%)]\tLoss: 735.697449\n",
            "Train Epoch: 89 [43520/60000 (72%)]\tLoss: 755.983643\n",
            "Train Epoch: 89 [44800/60000 (75%)]\tLoss: 756.202087\n",
            "Train Epoch: 89 [46080/60000 (77%)]\tLoss: 738.692444\n",
            "Train Epoch: 89 [47360/60000 (79%)]\tLoss: 718.847351\n",
            "Train Epoch: 89 [48640/60000 (81%)]\tLoss: 757.023987\n",
            "Train Epoch: 89 [49920/60000 (83%)]\tLoss: 749.691040\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 742.132507\n",
            "Train Epoch: 89 [52480/60000 (87%)]\tLoss: 732.385071\n",
            "Train Epoch: 89 [53760/60000 (90%)]\tLoss: 743.393616\n",
            "Train Epoch: 89 [55040/60000 (92%)]\tLoss: 755.065125\n",
            "Train Epoch: 89 [56320/60000 (94%)]\tLoss: 743.628906\n",
            "Train Epoch: 89 [57600/60000 (96%)]\tLoss: 740.821655\n",
            "Train Epoch: 89 [58880/60000 (98%)]\tLoss: 717.588867\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978011131286621\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 729.067810\n",
            "Train Epoch: 90 [1280/60000 (2%)]\tLoss: 726.766052\n",
            "Train Epoch: 90 [2560/60000 (4%)]\tLoss: 762.323425\n",
            "Train Epoch: 90 [3840/60000 (6%)]\tLoss: 731.397766\n",
            "Train Epoch: 90 [5120/60000 (9%)]\tLoss: 752.813599\n",
            "Train Epoch: 90 [6400/60000 (11%)]\tLoss: 739.884766\n",
            "Train Epoch: 90 [7680/60000 (13%)]\tLoss: 723.275879\n",
            "Train Epoch: 90 [8960/60000 (15%)]\tLoss: 733.980530\n",
            "Train Epoch: 90 [10240/60000 (17%)]\tLoss: 756.149902\n",
            "Train Epoch: 90 [11520/60000 (19%)]\tLoss: 732.493408\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 742.729736\n",
            "Train Epoch: 90 [14080/60000 (23%)]\tLoss: 757.640198\n",
            "Train Epoch: 90 [15360/60000 (26%)]\tLoss: 734.427856\n",
            "Train Epoch: 90 [16640/60000 (28%)]\tLoss: 736.954224\n",
            "Train Epoch: 90 [17920/60000 (30%)]\tLoss: 739.593811\n",
            "Train Epoch: 90 [19200/60000 (32%)]\tLoss: 747.684753\n",
            "Train Epoch: 90 [20480/60000 (34%)]\tLoss: 722.893127\n",
            "Train Epoch: 90 [21760/60000 (36%)]\tLoss: 757.184570\n",
            "Train Epoch: 90 [23040/60000 (38%)]\tLoss: 740.362183\n",
            "Train Epoch: 90 [24320/60000 (41%)]\tLoss: 735.581665\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 744.734802\n",
            "Train Epoch: 90 [26880/60000 (45%)]\tLoss: 727.302734\n",
            "Train Epoch: 90 [28160/60000 (47%)]\tLoss: 738.870483\n",
            "Train Epoch: 90 [29440/60000 (49%)]\tLoss: 746.287292\n",
            "Train Epoch: 90 [30720/60000 (51%)]\tLoss: 733.295227\n",
            "Train Epoch: 90 [32000/60000 (53%)]\tLoss: 724.448181\n",
            "Train Epoch: 90 [33280/60000 (55%)]\tLoss: 748.295898\n",
            "Train Epoch: 90 [34560/60000 (58%)]\tLoss: 748.381287\n",
            "Train Epoch: 90 [35840/60000 (60%)]\tLoss: 742.395874\n",
            "Train Epoch: 90 [37120/60000 (62%)]\tLoss: 759.668457\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 747.120605\n",
            "Train Epoch: 90 [39680/60000 (66%)]\tLoss: 748.259949\n",
            "Train Epoch: 90 [40960/60000 (68%)]\tLoss: 736.956177\n",
            "Train Epoch: 90 [42240/60000 (70%)]\tLoss: 710.138428\n",
            "Train Epoch: 90 [43520/60000 (72%)]\tLoss: 737.263794\n",
            "Train Epoch: 90 [44800/60000 (75%)]\tLoss: 744.993530\n",
            "Train Epoch: 90 [46080/60000 (77%)]\tLoss: 737.050415\n",
            "Train Epoch: 90 [47360/60000 (79%)]\tLoss: 721.345154\n",
            "Train Epoch: 90 [48640/60000 (81%)]\tLoss: 741.620789\n",
            "Train Epoch: 90 [49920/60000 (83%)]\tLoss: 745.365540\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 747.899109\n",
            "Train Epoch: 90 [52480/60000 (87%)]\tLoss: 753.027832\n",
            "Train Epoch: 90 [53760/60000 (90%)]\tLoss: 740.051270\n",
            "Train Epoch: 90 [55040/60000 (92%)]\tLoss: 764.433411\n",
            "Train Epoch: 90 [56320/60000 (94%)]\tLoss: 733.407410\n",
            "Train Epoch: 90 [57600/60000 (96%)]\tLoss: 699.842224\n",
            "Train Epoch: 90 [58880/60000 (98%)]\tLoss: 749.032654\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786526262760162\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 723.401550\n",
            "Train Epoch: 91 [1280/60000 (2%)]\tLoss: 740.292419\n",
            "Train Epoch: 91 [2560/60000 (4%)]\tLoss: 721.348450\n",
            "Train Epoch: 91 [3840/60000 (6%)]\tLoss: 748.277954\n",
            "Train Epoch: 91 [5120/60000 (9%)]\tLoss: 731.096863\n",
            "Train Epoch: 91 [6400/60000 (11%)]\tLoss: 727.908142\n",
            "Train Epoch: 91 [7680/60000 (13%)]\tLoss: 732.007202\n",
            "Train Epoch: 91 [8960/60000 (15%)]\tLoss: 731.681335\n",
            "Train Epoch: 91 [10240/60000 (17%)]\tLoss: 711.674500\n",
            "Train Epoch: 91 [11520/60000 (19%)]\tLoss: 744.148865\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 754.576599\n",
            "Train Epoch: 91 [14080/60000 (23%)]\tLoss: 732.170349\n",
            "Train Epoch: 91 [15360/60000 (26%)]\tLoss: 738.245789\n",
            "Train Epoch: 91 [16640/60000 (28%)]\tLoss: 758.976929\n",
            "Train Epoch: 91 [17920/60000 (30%)]\tLoss: 740.196960\n",
            "Train Epoch: 91 [19200/60000 (32%)]\tLoss: 750.481750\n",
            "Train Epoch: 91 [20480/60000 (34%)]\tLoss: 750.293030\n",
            "Train Epoch: 91 [21760/60000 (36%)]\tLoss: 718.241028\n",
            "Train Epoch: 91 [23040/60000 (38%)]\tLoss: 741.939087\n",
            "Train Epoch: 91 [24320/60000 (41%)]\tLoss: 732.685913\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 728.474976\n",
            "Train Epoch: 91 [26880/60000 (45%)]\tLoss: 724.889832\n",
            "Train Epoch: 91 [28160/60000 (47%)]\tLoss: 753.403748\n",
            "Train Epoch: 91 [29440/60000 (49%)]\tLoss: 736.586487\n",
            "Train Epoch: 91 [30720/60000 (51%)]\tLoss: 728.504944\n",
            "Train Epoch: 91 [32000/60000 (53%)]\tLoss: 746.053528\n",
            "Train Epoch: 91 [33280/60000 (55%)]\tLoss: 727.069458\n",
            "Train Epoch: 91 [34560/60000 (58%)]\tLoss: 736.532043\n",
            "Train Epoch: 91 [35840/60000 (60%)]\tLoss: 735.854065\n",
            "Train Epoch: 91 [37120/60000 (62%)]\tLoss: 735.784424\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 743.531067\n",
            "Train Epoch: 91 [39680/60000 (66%)]\tLoss: 739.238403\n",
            "Train Epoch: 91 [40960/60000 (68%)]\tLoss: 751.803894\n",
            "Train Epoch: 91 [42240/60000 (70%)]\tLoss: 746.971741\n",
            "Train Epoch: 91 [43520/60000 (72%)]\tLoss: 755.825562\n",
            "Train Epoch: 91 [44800/60000 (75%)]\tLoss: 758.980225\n",
            "Train Epoch: 91 [46080/60000 (77%)]\tLoss: 742.653381\n",
            "Train Epoch: 91 [47360/60000 (79%)]\tLoss: 758.923523\n",
            "Train Epoch: 91 [48640/60000 (81%)]\tLoss: 745.697876\n",
            "Train Epoch: 91 [49920/60000 (83%)]\tLoss: 713.025146\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 753.008423\n",
            "Train Epoch: 91 [52480/60000 (87%)]\tLoss: 739.260193\n",
            "Train Epoch: 91 [53760/60000 (90%)]\tLoss: 731.311096\n",
            "Train Epoch: 91 [55040/60000 (92%)]\tLoss: 722.419434\n",
            "Train Epoch: 91 [56320/60000 (94%)]\tLoss: 771.067139\n",
            "Train Epoch: 91 [57600/60000 (96%)]\tLoss: 743.724670\n",
            "Train Epoch: 91 [58880/60000 (98%)]\tLoss: 738.475342\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785559177398682\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 715.703308\n",
            "Train Epoch: 92 [1280/60000 (2%)]\tLoss: 719.297302\n",
            "Train Epoch: 92 [2560/60000 (4%)]\tLoss: 717.920227\n",
            "Train Epoch: 92 [3840/60000 (6%)]\tLoss: 729.192139\n",
            "Train Epoch: 92 [5120/60000 (9%)]\tLoss: 726.669006\n",
            "Train Epoch: 92 [6400/60000 (11%)]\tLoss: 724.426880\n",
            "Train Epoch: 92 [7680/60000 (13%)]\tLoss: 725.014465\n",
            "Train Epoch: 92 [8960/60000 (15%)]\tLoss: 771.563843\n",
            "Train Epoch: 92 [10240/60000 (17%)]\tLoss: 745.307739\n",
            "Train Epoch: 92 [11520/60000 (19%)]\tLoss: 746.009094\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 751.280518\n",
            "Train Epoch: 92 [14080/60000 (23%)]\tLoss: 764.132263\n",
            "Train Epoch: 92 [15360/60000 (26%)]\tLoss: 733.164612\n",
            "Train Epoch: 92 [16640/60000 (28%)]\tLoss: 730.338623\n",
            "Train Epoch: 92 [17920/60000 (30%)]\tLoss: 696.457214\n",
            "Train Epoch: 92 [19200/60000 (32%)]\tLoss: 720.093384\n",
            "Train Epoch: 92 [20480/60000 (34%)]\tLoss: 753.920288\n",
            "Train Epoch: 92 [21760/60000 (36%)]\tLoss: 745.211365\n",
            "Train Epoch: 92 [23040/60000 (38%)]\tLoss: 734.895386\n",
            "Train Epoch: 92 [24320/60000 (41%)]\tLoss: 753.812195\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 718.158569\n",
            "Train Epoch: 92 [26880/60000 (45%)]\tLoss: 717.685974\n",
            "Train Epoch: 92 [28160/60000 (47%)]\tLoss: 756.095764\n",
            "Train Epoch: 92 [29440/60000 (49%)]\tLoss: 734.005798\n",
            "Train Epoch: 92 [30720/60000 (51%)]\tLoss: 735.503723\n",
            "Train Epoch: 92 [32000/60000 (53%)]\tLoss: 740.535706\n",
            "Train Epoch: 92 [33280/60000 (55%)]\tLoss: 763.025269\n",
            "Train Epoch: 92 [34560/60000 (58%)]\tLoss: 725.321594\n",
            "Train Epoch: 92 [35840/60000 (60%)]\tLoss: 721.906799\n",
            "Train Epoch: 92 [37120/60000 (62%)]\tLoss: 752.853577\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 735.158813\n",
            "Train Epoch: 92 [39680/60000 (66%)]\tLoss: 745.224487\n",
            "Train Epoch: 92 [40960/60000 (68%)]\tLoss: 768.133545\n",
            "Train Epoch: 92 [42240/60000 (70%)]\tLoss: 735.945068\n",
            "Train Epoch: 92 [43520/60000 (72%)]\tLoss: 718.553467\n",
            "Train Epoch: 92 [44800/60000 (75%)]\tLoss: 732.849365\n",
            "Train Epoch: 92 [46080/60000 (77%)]\tLoss: 741.587524\n",
            "Train Epoch: 92 [47360/60000 (79%)]\tLoss: 741.393311\n",
            "Train Epoch: 92 [48640/60000 (81%)]\tLoss: 734.668091\n",
            "Train Epoch: 92 [49920/60000 (83%)]\tLoss: 743.428528\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 722.315308\n",
            "Train Epoch: 92 [52480/60000 (87%)]\tLoss: 725.266418\n",
            "Train Epoch: 92 [53760/60000 (90%)]\tLoss: 714.081848\n",
            "Train Epoch: 92 [55040/60000 (92%)]\tLoss: 748.850891\n",
            "Train Epoch: 92 [56320/60000 (94%)]\tLoss: 724.003235\n",
            "Train Epoch: 92 [57600/60000 (96%)]\tLoss: 743.140015\n",
            "Train Epoch: 92 [58880/60000 (98%)]\tLoss: 728.649292\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19778543710708618\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 713.261719\n",
            "Train Epoch: 93 [1280/60000 (2%)]\tLoss: 728.695007\n",
            "Train Epoch: 93 [2560/60000 (4%)]\tLoss: 718.948547\n",
            "Train Epoch: 93 [3840/60000 (6%)]\tLoss: 735.193665\n",
            "Train Epoch: 93 [5120/60000 (9%)]\tLoss: 755.388428\n",
            "Train Epoch: 93 [6400/60000 (11%)]\tLoss: 765.053711\n",
            "Train Epoch: 93 [7680/60000 (13%)]\tLoss: 722.553833\n",
            "Train Epoch: 93 [8960/60000 (15%)]\tLoss: 738.302063\n",
            "Train Epoch: 93 [10240/60000 (17%)]\tLoss: 743.977417\n",
            "Train Epoch: 93 [11520/60000 (19%)]\tLoss: 708.663025\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 740.668701\n",
            "Train Epoch: 93 [14080/60000 (23%)]\tLoss: 716.466370\n",
            "Train Epoch: 93 [15360/60000 (26%)]\tLoss: 714.747253\n",
            "Train Epoch: 93 [16640/60000 (28%)]\tLoss: 754.923096\n",
            "Train Epoch: 93 [17920/60000 (30%)]\tLoss: 734.973450\n",
            "Train Epoch: 93 [19200/60000 (32%)]\tLoss: 741.375732\n",
            "Train Epoch: 93 [20480/60000 (34%)]\tLoss: 717.119812\n",
            "Train Epoch: 93 [21760/60000 (36%)]\tLoss: 731.982727\n",
            "Train Epoch: 93 [23040/60000 (38%)]\tLoss: 744.208252\n",
            "Train Epoch: 93 [24320/60000 (41%)]\tLoss: 741.497681\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 735.987610\n",
            "Train Epoch: 93 [26880/60000 (45%)]\tLoss: 734.890747\n",
            "Train Epoch: 93 [28160/60000 (47%)]\tLoss: 732.954529\n",
            "Train Epoch: 93 [29440/60000 (49%)]\tLoss: 737.456848\n",
            "Train Epoch: 93 [30720/60000 (51%)]\tLoss: 729.033508\n",
            "Train Epoch: 93 [32000/60000 (53%)]\tLoss: 740.354553\n",
            "Train Epoch: 93 [33280/60000 (55%)]\tLoss: 718.028137\n",
            "Train Epoch: 93 [34560/60000 (58%)]\tLoss: 732.261414\n",
            "Train Epoch: 93 [35840/60000 (60%)]\tLoss: 738.588501\n",
            "Train Epoch: 93 [37120/60000 (62%)]\tLoss: 743.437927\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 753.571411\n",
            "Train Epoch: 93 [39680/60000 (66%)]\tLoss: 740.706177\n",
            "Train Epoch: 93 [40960/60000 (68%)]\tLoss: 741.246765\n",
            "Train Epoch: 93 [42240/60000 (70%)]\tLoss: 734.469604\n",
            "Train Epoch: 93 [43520/60000 (72%)]\tLoss: 719.085999\n",
            "Train Epoch: 93 [44800/60000 (75%)]\tLoss: 713.492493\n",
            "Train Epoch: 93 [46080/60000 (77%)]\tLoss: 728.386597\n",
            "Train Epoch: 93 [47360/60000 (79%)]\tLoss: 730.890259\n",
            "Train Epoch: 93 [48640/60000 (81%)]\tLoss: 729.192200\n",
            "Train Epoch: 93 [49920/60000 (83%)]\tLoss: 737.680603\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 744.881836\n",
            "Train Epoch: 93 [52480/60000 (87%)]\tLoss: 762.549255\n",
            "Train Epoch: 93 [53760/60000 (90%)]\tLoss: 722.135986\n",
            "Train Epoch: 93 [55040/60000 (92%)]\tLoss: 737.492126\n",
            "Train Epoch: 93 [56320/60000 (94%)]\tLoss: 712.932434\n",
            "Train Epoch: 93 [57600/60000 (96%)]\tLoss: 724.975403\n",
            "Train Epoch: 93 [58880/60000 (98%)]\tLoss: 731.177856\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785363972187042\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 740.831116\n",
            "Train Epoch: 94 [1280/60000 (2%)]\tLoss: 752.098572\n",
            "Train Epoch: 94 [2560/60000 (4%)]\tLoss: 736.879639\n",
            "Train Epoch: 94 [3840/60000 (6%)]\tLoss: 751.785461\n",
            "Train Epoch: 94 [5120/60000 (9%)]\tLoss: 739.134277\n",
            "Train Epoch: 94 [6400/60000 (11%)]\tLoss: 734.848572\n",
            "Train Epoch: 94 [7680/60000 (13%)]\tLoss: 740.481873\n",
            "Train Epoch: 94 [8960/60000 (15%)]\tLoss: 740.082031\n",
            "Train Epoch: 94 [10240/60000 (17%)]\tLoss: 734.009033\n",
            "Train Epoch: 94 [11520/60000 (19%)]\tLoss: 749.297546\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 736.362915\n",
            "Train Epoch: 94 [14080/60000 (23%)]\tLoss: 738.289062\n",
            "Train Epoch: 94 [15360/60000 (26%)]\tLoss: 753.763916\n",
            "Train Epoch: 94 [16640/60000 (28%)]\tLoss: 743.367004\n",
            "Train Epoch: 94 [17920/60000 (30%)]\tLoss: 746.753418\n",
            "Train Epoch: 94 [19200/60000 (32%)]\tLoss: 731.847961\n",
            "Train Epoch: 94 [20480/60000 (34%)]\tLoss: 725.624573\n",
            "Train Epoch: 94 [21760/60000 (36%)]\tLoss: 736.625610\n",
            "Train Epoch: 94 [23040/60000 (38%)]\tLoss: 727.927124\n",
            "Train Epoch: 94 [24320/60000 (41%)]\tLoss: 712.014832\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 748.034241\n",
            "Train Epoch: 94 [26880/60000 (45%)]\tLoss: 737.585632\n",
            "Train Epoch: 94 [28160/60000 (47%)]\tLoss: 739.134399\n",
            "Train Epoch: 94 [29440/60000 (49%)]\tLoss: 718.493408\n",
            "Train Epoch: 94 [30720/60000 (51%)]\tLoss: 733.094421\n",
            "Train Epoch: 94 [32000/60000 (53%)]\tLoss: 735.171631\n",
            "Train Epoch: 94 [33280/60000 (55%)]\tLoss: 742.866882\n",
            "Train Epoch: 94 [34560/60000 (58%)]\tLoss: 741.147888\n",
            "Train Epoch: 94 [35840/60000 (60%)]\tLoss: 750.319641\n",
            "Train Epoch: 94 [37120/60000 (62%)]\tLoss: 745.745056\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 731.801758\n",
            "Train Epoch: 94 [39680/60000 (66%)]\tLoss: 721.058411\n",
            "Train Epoch: 94 [40960/60000 (68%)]\tLoss: 736.019104\n",
            "Train Epoch: 94 [42240/60000 (70%)]\tLoss: 734.112732\n",
            "Train Epoch: 94 [43520/60000 (72%)]\tLoss: 743.677795\n",
            "Train Epoch: 94 [44800/60000 (75%)]\tLoss: 733.168091\n",
            "Train Epoch: 94 [46080/60000 (77%)]\tLoss: 745.798340\n",
            "Train Epoch: 94 [47360/60000 (79%)]\tLoss: 743.494751\n",
            "Train Epoch: 94 [48640/60000 (81%)]\tLoss: 732.270386\n",
            "Train Epoch: 94 [49920/60000 (83%)]\tLoss: 738.393677\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 738.572998\n",
            "Train Epoch: 94 [52480/60000 (87%)]\tLoss: 753.216248\n",
            "Train Epoch: 94 [53760/60000 (90%)]\tLoss: 728.582886\n",
            "Train Epoch: 94 [55040/60000 (92%)]\tLoss: 746.452087\n",
            "Train Epoch: 94 [56320/60000 (94%)]\tLoss: 714.596497\n",
            "Train Epoch: 94 [57600/60000 (96%)]\tLoss: 729.943420\n",
            "Train Epoch: 94 [58880/60000 (98%)]\tLoss: 734.427063\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785475730895996\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 745.368713\n",
            "Train Epoch: 95 [1280/60000 (2%)]\tLoss: 756.949768\n",
            "Train Epoch: 95 [2560/60000 (4%)]\tLoss: 723.967468\n",
            "Train Epoch: 95 [3840/60000 (6%)]\tLoss: 743.759766\n",
            "Train Epoch: 95 [5120/60000 (9%)]\tLoss: 735.624268\n",
            "Train Epoch: 95 [6400/60000 (11%)]\tLoss: 705.970825\n",
            "Train Epoch: 95 [7680/60000 (13%)]\tLoss: 736.822083\n",
            "Train Epoch: 95 [8960/60000 (15%)]\tLoss: 760.955261\n",
            "Train Epoch: 95 [10240/60000 (17%)]\tLoss: 736.791443\n",
            "Train Epoch: 95 [11520/60000 (19%)]\tLoss: 774.129272\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 738.912720\n",
            "Train Epoch: 95 [14080/60000 (23%)]\tLoss: 737.079956\n",
            "Train Epoch: 95 [15360/60000 (26%)]\tLoss: 712.146545\n",
            "Train Epoch: 95 [16640/60000 (28%)]\tLoss: 757.673462\n",
            "Train Epoch: 95 [17920/60000 (30%)]\tLoss: 748.674011\n",
            "Train Epoch: 95 [19200/60000 (32%)]\tLoss: 741.876160\n",
            "Train Epoch: 95 [20480/60000 (34%)]\tLoss: 721.092468\n",
            "Train Epoch: 95 [21760/60000 (36%)]\tLoss: 719.643738\n",
            "Train Epoch: 95 [23040/60000 (38%)]\tLoss: 723.945435\n",
            "Train Epoch: 95 [24320/60000 (41%)]\tLoss: 767.733398\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 743.090637\n",
            "Train Epoch: 95 [26880/60000 (45%)]\tLoss: 759.425049\n",
            "Train Epoch: 95 [28160/60000 (47%)]\tLoss: 751.081360\n",
            "Train Epoch: 95 [29440/60000 (49%)]\tLoss: 728.250000\n",
            "Train Epoch: 95 [30720/60000 (51%)]\tLoss: 713.376831\n",
            "Train Epoch: 95 [32000/60000 (53%)]\tLoss: 718.173401\n",
            "Train Epoch: 95 [33280/60000 (55%)]\tLoss: 754.664124\n",
            "Train Epoch: 95 [34560/60000 (58%)]\tLoss: 718.202087\n",
            "Train Epoch: 95 [35840/60000 (60%)]\tLoss: 731.918091\n",
            "Train Epoch: 95 [37120/60000 (62%)]\tLoss: 733.418640\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 731.773682\n",
            "Train Epoch: 95 [39680/60000 (66%)]\tLoss: 745.890442\n",
            "Train Epoch: 95 [40960/60000 (68%)]\tLoss: 712.034363\n",
            "Train Epoch: 95 [42240/60000 (70%)]\tLoss: 740.007324\n",
            "Train Epoch: 95 [43520/60000 (72%)]\tLoss: 729.660461\n",
            "Train Epoch: 95 [44800/60000 (75%)]\tLoss: 723.472107\n",
            "Train Epoch: 95 [46080/60000 (77%)]\tLoss: 748.776672\n",
            "Train Epoch: 95 [47360/60000 (79%)]\tLoss: 765.547791\n",
            "Train Epoch: 95 [48640/60000 (81%)]\tLoss: 730.557495\n",
            "Train Epoch: 95 [49920/60000 (83%)]\tLoss: 739.458740\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 707.797363\n",
            "Train Epoch: 95 [52480/60000 (87%)]\tLoss: 743.581177\n",
            "Train Epoch: 95 [53760/60000 (90%)]\tLoss: 738.113220\n",
            "Train Epoch: 95 [55040/60000 (92%)]\tLoss: 719.202942\n",
            "Train Epoch: 95 [56320/60000 (94%)]\tLoss: 745.107056\n",
            "Train Epoch: 95 [57600/60000 (96%)]\tLoss: 729.085083\n",
            "Train Epoch: 95 [58880/60000 (98%)]\tLoss: 727.987427\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785797595977783\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 714.901001\n",
            "Train Epoch: 96 [1280/60000 (2%)]\tLoss: 751.444092\n",
            "Train Epoch: 96 [2560/60000 (4%)]\tLoss: 745.619751\n",
            "Train Epoch: 96 [3840/60000 (6%)]\tLoss: 721.149353\n",
            "Train Epoch: 96 [5120/60000 (9%)]\tLoss: 737.076477\n",
            "Train Epoch: 96 [6400/60000 (11%)]\tLoss: 742.841064\n",
            "Train Epoch: 96 [7680/60000 (13%)]\tLoss: 719.840759\n",
            "Train Epoch: 96 [8960/60000 (15%)]\tLoss: 751.837402\n",
            "Train Epoch: 96 [10240/60000 (17%)]\tLoss: 763.763306\n",
            "Train Epoch: 96 [11520/60000 (19%)]\tLoss: 711.533142\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 747.953247\n",
            "Train Epoch: 96 [14080/60000 (23%)]\tLoss: 716.293213\n",
            "Train Epoch: 96 [15360/60000 (26%)]\tLoss: 733.675720\n",
            "Train Epoch: 96 [16640/60000 (28%)]\tLoss: 717.622498\n",
            "Train Epoch: 96 [17920/60000 (30%)]\tLoss: 756.901855\n",
            "Train Epoch: 96 [19200/60000 (32%)]\tLoss: 746.249695\n",
            "Train Epoch: 96 [20480/60000 (34%)]\tLoss: 717.963562\n",
            "Train Epoch: 96 [21760/60000 (36%)]\tLoss: 738.332214\n",
            "Train Epoch: 96 [23040/60000 (38%)]\tLoss: 724.137146\n",
            "Train Epoch: 96 [24320/60000 (41%)]\tLoss: 758.307495\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 733.605835\n",
            "Train Epoch: 96 [26880/60000 (45%)]\tLoss: 735.909668\n",
            "Train Epoch: 96 [28160/60000 (47%)]\tLoss: 752.987122\n",
            "Train Epoch: 96 [29440/60000 (49%)]\tLoss: 748.060669\n",
            "Train Epoch: 96 [30720/60000 (51%)]\tLoss: 731.584167\n",
            "Train Epoch: 96 [32000/60000 (53%)]\tLoss: 741.044373\n",
            "Train Epoch: 96 [33280/60000 (55%)]\tLoss: 749.985352\n",
            "Train Epoch: 96 [34560/60000 (58%)]\tLoss: 745.480957\n",
            "Train Epoch: 96 [35840/60000 (60%)]\tLoss: 730.987610\n",
            "Train Epoch: 96 [37120/60000 (62%)]\tLoss: 730.620667\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 740.745422\n",
            "Train Epoch: 96 [39680/60000 (66%)]\tLoss: 752.147888\n",
            "Train Epoch: 96 [40960/60000 (68%)]\tLoss: 733.780273\n",
            "Train Epoch: 96 [42240/60000 (70%)]\tLoss: 739.274170\n",
            "Train Epoch: 96 [43520/60000 (72%)]\tLoss: 742.352905\n",
            "Train Epoch: 96 [44800/60000 (75%)]\tLoss: 733.538879\n",
            "Train Epoch: 96 [46080/60000 (77%)]\tLoss: 749.956055\n",
            "Train Epoch: 96 [47360/60000 (79%)]\tLoss: 728.891113\n",
            "Train Epoch: 96 [48640/60000 (81%)]\tLoss: 708.331421\n",
            "Train Epoch: 96 [49920/60000 (83%)]\tLoss: 747.719360\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 758.809937\n",
            "Train Epoch: 96 [52480/60000 (87%)]\tLoss: 727.654236\n",
            "Train Epoch: 96 [53760/60000 (90%)]\tLoss: 748.009216\n",
            "Train Epoch: 96 [55040/60000 (92%)]\tLoss: 735.734558\n",
            "Train Epoch: 96 [56320/60000 (94%)]\tLoss: 732.414307\n",
            "Train Epoch: 96 [57600/60000 (96%)]\tLoss: 749.905762\n",
            "Train Epoch: 96 [58880/60000 (98%)]\tLoss: 756.828308\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978624165058136\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 748.217285\n",
            "Train Epoch: 97 [1280/60000 (2%)]\tLoss: 759.744080\n",
            "Train Epoch: 97 [2560/60000 (4%)]\tLoss: 747.906799\n",
            "Train Epoch: 97 [3840/60000 (6%)]\tLoss: 765.312256\n",
            "Train Epoch: 97 [5120/60000 (9%)]\tLoss: 722.401123\n",
            "Train Epoch: 97 [6400/60000 (11%)]\tLoss: 719.448975\n",
            "Train Epoch: 97 [7680/60000 (13%)]\tLoss: 727.873169\n",
            "Train Epoch: 97 [8960/60000 (15%)]\tLoss: 722.059937\n",
            "Train Epoch: 97 [10240/60000 (17%)]\tLoss: 746.448608\n",
            "Train Epoch: 97 [11520/60000 (19%)]\tLoss: 720.953674\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 742.940247\n",
            "Train Epoch: 97 [14080/60000 (23%)]\tLoss: 742.621216\n",
            "Train Epoch: 97 [15360/60000 (26%)]\tLoss: 740.822388\n",
            "Train Epoch: 97 [16640/60000 (28%)]\tLoss: 692.745667\n",
            "Train Epoch: 97 [17920/60000 (30%)]\tLoss: 758.431213\n",
            "Train Epoch: 97 [19200/60000 (32%)]\tLoss: 739.117432\n",
            "Train Epoch: 97 [20480/60000 (34%)]\tLoss: 736.125061\n",
            "Train Epoch: 97 [21760/60000 (36%)]\tLoss: 751.153198\n",
            "Train Epoch: 97 [23040/60000 (38%)]\tLoss: 737.346985\n",
            "Train Epoch: 97 [24320/60000 (41%)]\tLoss: 731.968445\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 697.311279\n",
            "Train Epoch: 97 [26880/60000 (45%)]\tLoss: 749.218872\n",
            "Train Epoch: 97 [28160/60000 (47%)]\tLoss: 722.254822\n",
            "Train Epoch: 97 [29440/60000 (49%)]\tLoss: 718.252991\n",
            "Train Epoch: 97 [30720/60000 (51%)]\tLoss: 750.283691\n",
            "Train Epoch: 97 [32000/60000 (53%)]\tLoss: 755.588440\n",
            "Train Epoch: 97 [33280/60000 (55%)]\tLoss: 741.176819\n",
            "Train Epoch: 97 [34560/60000 (58%)]\tLoss: 740.350342\n",
            "Train Epoch: 97 [35840/60000 (60%)]\tLoss: 720.385559\n",
            "Train Epoch: 97 [37120/60000 (62%)]\tLoss: 762.543518\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 719.658386\n",
            "Train Epoch: 97 [39680/60000 (66%)]\tLoss: 744.359985\n",
            "Train Epoch: 97 [40960/60000 (68%)]\tLoss: 733.026611\n",
            "Train Epoch: 97 [42240/60000 (70%)]\tLoss: 727.629883\n",
            "Train Epoch: 97 [43520/60000 (72%)]\tLoss: 720.667786\n",
            "Train Epoch: 97 [44800/60000 (75%)]\tLoss: 743.907104\n",
            "Train Epoch: 97 [46080/60000 (77%)]\tLoss: 733.703613\n",
            "Train Epoch: 97 [47360/60000 (79%)]\tLoss: 723.391052\n",
            "Train Epoch: 97 [48640/60000 (81%)]\tLoss: 744.958801\n",
            "Train Epoch: 97 [49920/60000 (83%)]\tLoss: 740.719482\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 782.805542\n",
            "Train Epoch: 97 [52480/60000 (87%)]\tLoss: 730.883484\n",
            "Train Epoch: 97 [53760/60000 (90%)]\tLoss: 745.987061\n",
            "Train Epoch: 97 [55040/60000 (92%)]\tLoss: 734.047058\n",
            "Train Epoch: 97 [56320/60000 (94%)]\tLoss: 742.913147\n",
            "Train Epoch: 97 [57600/60000 (96%)]\tLoss: 723.184937\n",
            "Train Epoch: 97 [58880/60000 (98%)]\tLoss: 748.291199\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786524772644043\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 731.299683\n",
            "Train Epoch: 98 [1280/60000 (2%)]\tLoss: 754.119141\n",
            "Train Epoch: 98 [2560/60000 (4%)]\tLoss: 740.524231\n",
            "Train Epoch: 98 [3840/60000 (6%)]\tLoss: 740.302856\n",
            "Train Epoch: 98 [5120/60000 (9%)]\tLoss: 721.232727\n",
            "Train Epoch: 98 [6400/60000 (11%)]\tLoss: 744.984375\n",
            "Train Epoch: 98 [7680/60000 (13%)]\tLoss: 742.807617\n",
            "Train Epoch: 98 [8960/60000 (15%)]\tLoss: 729.988953\n",
            "Train Epoch: 98 [10240/60000 (17%)]\tLoss: 721.631592\n",
            "Train Epoch: 98 [11520/60000 (19%)]\tLoss: 726.578491\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 742.432312\n",
            "Train Epoch: 98 [14080/60000 (23%)]\tLoss: 748.941528\n",
            "Train Epoch: 98 [15360/60000 (26%)]\tLoss: 737.665405\n",
            "Train Epoch: 98 [16640/60000 (28%)]\tLoss: 729.863220\n",
            "Train Epoch: 98 [17920/60000 (30%)]\tLoss: 710.560547\n",
            "Train Epoch: 98 [19200/60000 (32%)]\tLoss: 722.346558\n",
            "Train Epoch: 98 [20480/60000 (34%)]\tLoss: 773.329834\n",
            "Train Epoch: 98 [21760/60000 (36%)]\tLoss: 720.816772\n",
            "Train Epoch: 98 [23040/60000 (38%)]\tLoss: 733.982910\n",
            "Train Epoch: 98 [24320/60000 (41%)]\tLoss: 721.636169\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 746.446228\n",
            "Train Epoch: 98 [26880/60000 (45%)]\tLoss: 750.233887\n",
            "Train Epoch: 98 [28160/60000 (47%)]\tLoss: 763.786499\n",
            "Train Epoch: 98 [29440/60000 (49%)]\tLoss: 757.897278\n",
            "Train Epoch: 98 [30720/60000 (51%)]\tLoss: 736.994934\n",
            "Train Epoch: 98 [32000/60000 (53%)]\tLoss: 754.547546\n",
            "Train Epoch: 98 [33280/60000 (55%)]\tLoss: 749.619507\n",
            "Train Epoch: 98 [34560/60000 (58%)]\tLoss: 748.430725\n",
            "Train Epoch: 98 [35840/60000 (60%)]\tLoss: 720.113831\n",
            "Train Epoch: 98 [37120/60000 (62%)]\tLoss: 735.627319\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 726.318665\n",
            "Train Epoch: 98 [39680/60000 (66%)]\tLoss: 736.697144\n",
            "Train Epoch: 98 [40960/60000 (68%)]\tLoss: 738.675964\n",
            "Train Epoch: 98 [42240/60000 (70%)]\tLoss: 754.878967\n",
            "Train Epoch: 98 [43520/60000 (72%)]\tLoss: 731.213379\n",
            "Train Epoch: 98 [44800/60000 (75%)]\tLoss: 709.469421\n",
            "Train Epoch: 98 [46080/60000 (77%)]\tLoss: 752.478455\n",
            "Train Epoch: 98 [47360/60000 (79%)]\tLoss: 736.894653\n",
            "Train Epoch: 98 [48640/60000 (81%)]\tLoss: 755.735229\n",
            "Train Epoch: 98 [49920/60000 (83%)]\tLoss: 747.548279\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 752.943237\n",
            "Train Epoch: 98 [52480/60000 (87%)]\tLoss: 738.799316\n",
            "Train Epoch: 98 [53760/60000 (90%)]\tLoss: 714.674316\n",
            "Train Epoch: 98 [55040/60000 (92%)]\tLoss: 746.064636\n",
            "Train Epoch: 98 [56320/60000 (94%)]\tLoss: 746.345886\n",
            "Train Epoch: 98 [57600/60000 (96%)]\tLoss: 733.666809\n",
            "Train Epoch: 98 [58880/60000 (98%)]\tLoss: 728.377808\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.197822704911232\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 708.142395\n",
            "Train Epoch: 99 [1280/60000 (2%)]\tLoss: 718.273010\n",
            "Train Epoch: 99 [2560/60000 (4%)]\tLoss: 741.046936\n",
            "Train Epoch: 99 [3840/60000 (6%)]\tLoss: 721.412231\n",
            "Train Epoch: 99 [5120/60000 (9%)]\tLoss: 711.910339\n",
            "Train Epoch: 99 [6400/60000 (11%)]\tLoss: 735.252502\n",
            "Train Epoch: 99 [7680/60000 (13%)]\tLoss: 725.182434\n",
            "Train Epoch: 99 [8960/60000 (15%)]\tLoss: 737.635437\n",
            "Train Epoch: 99 [10240/60000 (17%)]\tLoss: 745.764709\n",
            "Train Epoch: 99 [11520/60000 (19%)]\tLoss: 749.911072\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 745.448120\n",
            "Train Epoch: 99 [14080/60000 (23%)]\tLoss: 740.216431\n",
            "Train Epoch: 99 [15360/60000 (26%)]\tLoss: 723.710083\n",
            "Train Epoch: 99 [16640/60000 (28%)]\tLoss: 726.567566\n",
            "Train Epoch: 99 [17920/60000 (30%)]\tLoss: 733.869507\n",
            "Train Epoch: 99 [19200/60000 (32%)]\tLoss: 723.818054\n",
            "Train Epoch: 99 [20480/60000 (34%)]\tLoss: 715.749268\n",
            "Train Epoch: 99 [21760/60000 (36%)]\tLoss: 760.499695\n",
            "Train Epoch: 99 [23040/60000 (38%)]\tLoss: 742.216370\n",
            "Train Epoch: 99 [24320/60000 (41%)]\tLoss: 735.553711\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 745.668884\n",
            "Train Epoch: 99 [26880/60000 (45%)]\tLoss: 721.067871\n",
            "Train Epoch: 99 [28160/60000 (47%)]\tLoss: 748.248413\n",
            "Train Epoch: 99 [29440/60000 (49%)]\tLoss: 746.901367\n",
            "Train Epoch: 99 [30720/60000 (51%)]\tLoss: 753.661560\n",
            "Train Epoch: 99 [32000/60000 (53%)]\tLoss: 721.156677\n",
            "Train Epoch: 99 [33280/60000 (55%)]\tLoss: 745.653503\n",
            "Train Epoch: 99 [34560/60000 (58%)]\tLoss: 735.186829\n",
            "Train Epoch: 99 [35840/60000 (60%)]\tLoss: 724.433472\n",
            "Train Epoch: 99 [37120/60000 (62%)]\tLoss: 745.627319\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 699.347351\n",
            "Train Epoch: 99 [39680/60000 (66%)]\tLoss: 769.816956\n",
            "Train Epoch: 99 [40960/60000 (68%)]\tLoss: 757.482483\n",
            "Train Epoch: 99 [42240/60000 (70%)]\tLoss: 732.424255\n",
            "Train Epoch: 99 [43520/60000 (72%)]\tLoss: 717.136230\n",
            "Train Epoch: 99 [44800/60000 (75%)]\tLoss: 743.042847\n",
            "Train Epoch: 99 [46080/60000 (77%)]\tLoss: 736.505615\n",
            "Train Epoch: 99 [47360/60000 (79%)]\tLoss: 725.061584\n",
            "Train Epoch: 99 [48640/60000 (81%)]\tLoss: 738.771667\n",
            "Train Epoch: 99 [49920/60000 (83%)]\tLoss: 711.521851\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 728.083130\n",
            "Train Epoch: 99 [52480/60000 (87%)]\tLoss: 744.948059\n",
            "Train Epoch: 99 [53760/60000 (90%)]\tLoss: 726.552917\n",
            "Train Epoch: 99 [55040/60000 (92%)]\tLoss: 734.104980\n",
            "Train Epoch: 99 [56320/60000 (94%)]\tLoss: 728.265625\n",
            "Train Epoch: 99 [57600/60000 (96%)]\tLoss: 722.910217\n",
            "Train Epoch: 99 [58880/60000 (98%)]\tLoss: 743.132263\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788140058517456\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 741.166809\n",
            "Train Epoch: 100 [1280/60000 (2%)]\tLoss: 728.210083\n",
            "Train Epoch: 100 [2560/60000 (4%)]\tLoss: 743.568726\n",
            "Train Epoch: 100 [3840/60000 (6%)]\tLoss: 717.394592\n",
            "Train Epoch: 100 [5120/60000 (9%)]\tLoss: 718.380554\n",
            "Train Epoch: 100 [6400/60000 (11%)]\tLoss: 761.215698\n",
            "Train Epoch: 100 [7680/60000 (13%)]\tLoss: 729.189392\n",
            "Train Epoch: 100 [8960/60000 (15%)]\tLoss: 731.245056\n",
            "Train Epoch: 100 [10240/60000 (17%)]\tLoss: 746.477539\n",
            "Train Epoch: 100 [11520/60000 (19%)]\tLoss: 713.840149\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 718.674927\n",
            "Train Epoch: 100 [14080/60000 (23%)]\tLoss: 717.908142\n",
            "Train Epoch: 100 [15360/60000 (26%)]\tLoss: 727.404236\n",
            "Train Epoch: 100 [16640/60000 (28%)]\tLoss: 759.216370\n",
            "Train Epoch: 100 [17920/60000 (30%)]\tLoss: 733.200867\n",
            "Train Epoch: 100 [19200/60000 (32%)]\tLoss: 739.819763\n",
            "Train Epoch: 100 [20480/60000 (34%)]\tLoss: 717.956665\n",
            "Train Epoch: 100 [21760/60000 (36%)]\tLoss: 749.512024\n",
            "Train Epoch: 100 [23040/60000 (38%)]\tLoss: 739.842712\n",
            "Train Epoch: 100 [24320/60000 (41%)]\tLoss: 734.263123\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 753.522583\n",
            "Train Epoch: 100 [26880/60000 (45%)]\tLoss: 720.274658\n",
            "Train Epoch: 100 [28160/60000 (47%)]\tLoss: 743.936829\n",
            "Train Epoch: 100 [29440/60000 (49%)]\tLoss: 755.048584\n",
            "Train Epoch: 100 [30720/60000 (51%)]\tLoss: 732.830261\n",
            "Train Epoch: 100 [32000/60000 (53%)]\tLoss: 732.879150\n",
            "Train Epoch: 100 [33280/60000 (55%)]\tLoss: 725.325378\n",
            "Train Epoch: 100 [34560/60000 (58%)]\tLoss: 739.473999\n",
            "Train Epoch: 100 [35840/60000 (60%)]\tLoss: 726.890015\n",
            "Train Epoch: 100 [37120/60000 (62%)]\tLoss: 733.935486\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 721.137939\n",
            "Train Epoch: 100 [39680/60000 (66%)]\tLoss: 739.461792\n",
            "Train Epoch: 100 [40960/60000 (68%)]\tLoss: 742.944824\n",
            "Train Epoch: 100 [42240/60000 (70%)]\tLoss: 747.709045\n",
            "Train Epoch: 100 [43520/60000 (72%)]\tLoss: 692.632629\n",
            "Train Epoch: 100 [44800/60000 (75%)]\tLoss: 753.776428\n",
            "Train Epoch: 100 [46080/60000 (77%)]\tLoss: 727.005798\n",
            "Train Epoch: 100 [47360/60000 (79%)]\tLoss: 719.352356\n",
            "Train Epoch: 100 [48640/60000 (81%)]\tLoss: 772.431091\n",
            "Train Epoch: 100 [49920/60000 (83%)]\tLoss: 747.767090\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 749.501831\n",
            "Train Epoch: 100 [52480/60000 (87%)]\tLoss: 722.999084\n",
            "Train Epoch: 100 [53760/60000 (90%)]\tLoss: 768.392517\n",
            "Train Epoch: 100 [55040/60000 (92%)]\tLoss: 722.983154\n",
            "Train Epoch: 100 [56320/60000 (94%)]\tLoss: 721.205811\n",
            "Train Epoch: 100 [57600/60000 (96%)]\tLoss: 752.653137\n",
            "Train Epoch: 100 [58880/60000 (98%)]\tLoss: 757.377930\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786787033081055\n",
            "\n",
            "Train Epoch: 101 [0/60000 (0%)]\tLoss: 712.153870\n",
            "Train Epoch: 101 [1280/60000 (2%)]\tLoss: 735.295349\n",
            "Train Epoch: 101 [2560/60000 (4%)]\tLoss: 739.184509\n",
            "Train Epoch: 101 [3840/60000 (6%)]\tLoss: 732.367432\n",
            "Train Epoch: 101 [5120/60000 (9%)]\tLoss: 751.315063\n",
            "Train Epoch: 101 [6400/60000 (11%)]\tLoss: 734.294006\n",
            "Train Epoch: 101 [7680/60000 (13%)]\tLoss: 744.062439\n",
            "Train Epoch: 101 [8960/60000 (15%)]\tLoss: 730.362000\n",
            "Train Epoch: 101 [10240/60000 (17%)]\tLoss: 720.606812\n",
            "Train Epoch: 101 [11520/60000 (19%)]\tLoss: 732.179626\n",
            "Train Epoch: 101 [12800/60000 (21%)]\tLoss: 752.951599\n",
            "Train Epoch: 101 [14080/60000 (23%)]\tLoss: 720.839417\n",
            "Train Epoch: 101 [15360/60000 (26%)]\tLoss: 739.067261\n",
            "Train Epoch: 101 [16640/60000 (28%)]\tLoss: 747.791687\n",
            "Train Epoch: 101 [17920/60000 (30%)]\tLoss: 764.631714\n",
            "Train Epoch: 101 [19200/60000 (32%)]\tLoss: 765.905457\n",
            "Train Epoch: 101 [20480/60000 (34%)]\tLoss: 719.357544\n",
            "Train Epoch: 101 [21760/60000 (36%)]\tLoss: 743.638611\n",
            "Train Epoch: 101 [23040/60000 (38%)]\tLoss: 737.649414\n",
            "Train Epoch: 101 [24320/60000 (41%)]\tLoss: 727.870178\n",
            "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 743.989502\n",
            "Train Epoch: 101 [26880/60000 (45%)]\tLoss: 718.489807\n",
            "Train Epoch: 101 [28160/60000 (47%)]\tLoss: 742.410645\n",
            "Train Epoch: 101 [29440/60000 (49%)]\tLoss: 714.214905\n",
            "Train Epoch: 101 [30720/60000 (51%)]\tLoss: 739.820801\n",
            "Train Epoch: 101 [32000/60000 (53%)]\tLoss: 738.837708\n",
            "Train Epoch: 101 [33280/60000 (55%)]\tLoss: 758.080505\n",
            "Train Epoch: 101 [34560/60000 (58%)]\tLoss: 724.823547\n",
            "Train Epoch: 101 [35840/60000 (60%)]\tLoss: 744.770508\n",
            "Train Epoch: 101 [37120/60000 (62%)]\tLoss: 757.163147\n",
            "Train Epoch: 101 [38400/60000 (64%)]\tLoss: 742.007996\n",
            "Train Epoch: 101 [39680/60000 (66%)]\tLoss: 725.768311\n",
            "Train Epoch: 101 [40960/60000 (68%)]\tLoss: 708.625610\n",
            "Train Epoch: 101 [42240/60000 (70%)]\tLoss: 744.162476\n",
            "Train Epoch: 101 [43520/60000 (72%)]\tLoss: 704.365540\n",
            "Train Epoch: 101 [44800/60000 (75%)]\tLoss: 714.770264\n",
            "Train Epoch: 101 [46080/60000 (77%)]\tLoss: 768.165100\n",
            "Train Epoch: 101 [47360/60000 (79%)]\tLoss: 752.381042\n",
            "Train Epoch: 101 [48640/60000 (81%)]\tLoss: 718.270203\n",
            "Train Epoch: 101 [49920/60000 (83%)]\tLoss: 739.064148\n",
            "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 736.838074\n",
            "Train Epoch: 101 [52480/60000 (87%)]\tLoss: 718.333618\n",
            "Train Epoch: 101 [53760/60000 (90%)]\tLoss: 757.747864\n",
            "Train Epoch: 101 [55040/60000 (92%)]\tLoss: 728.766724\n",
            "Train Epoch: 101 [56320/60000 (94%)]\tLoss: 725.133972\n",
            "Train Epoch: 101 [57600/60000 (96%)]\tLoss: 729.896790\n",
            "Train Epoch: 101 [58880/60000 (98%)]\tLoss: 725.999329\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785310328006744\n",
            "\n",
            "Train Epoch: 102 [0/60000 (0%)]\tLoss: 730.460754\n",
            "Train Epoch: 102 [1280/60000 (2%)]\tLoss: 741.294617\n",
            "Train Epoch: 102 [2560/60000 (4%)]\tLoss: 726.423218\n",
            "Train Epoch: 102 [3840/60000 (6%)]\tLoss: 753.647278\n",
            "Train Epoch: 102 [5120/60000 (9%)]\tLoss: 741.943359\n",
            "Train Epoch: 102 [6400/60000 (11%)]\tLoss: 740.322876\n",
            "Train Epoch: 102 [7680/60000 (13%)]\tLoss: 730.456482\n",
            "Train Epoch: 102 [8960/60000 (15%)]\tLoss: 758.669373\n",
            "Train Epoch: 102 [10240/60000 (17%)]\tLoss: 715.519897\n",
            "Train Epoch: 102 [11520/60000 (19%)]\tLoss: 745.935181\n",
            "Train Epoch: 102 [12800/60000 (21%)]\tLoss: 728.351196\n",
            "Train Epoch: 102 [14080/60000 (23%)]\tLoss: 715.604126\n",
            "Train Epoch: 102 [15360/60000 (26%)]\tLoss: 757.142517\n",
            "Train Epoch: 102 [16640/60000 (28%)]\tLoss: 720.652344\n",
            "Train Epoch: 102 [17920/60000 (30%)]\tLoss: 747.231140\n",
            "Train Epoch: 102 [19200/60000 (32%)]\tLoss: 749.881226\n",
            "Train Epoch: 102 [20480/60000 (34%)]\tLoss: 724.758911\n",
            "Train Epoch: 102 [21760/60000 (36%)]\tLoss: 752.418274\n",
            "Train Epoch: 102 [23040/60000 (38%)]\tLoss: 720.643738\n",
            "Train Epoch: 102 [24320/60000 (41%)]\tLoss: 730.160583\n",
            "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 725.631653\n",
            "Train Epoch: 102 [26880/60000 (45%)]\tLoss: 761.010193\n",
            "Train Epoch: 102 [28160/60000 (47%)]\tLoss: 700.524597\n",
            "Train Epoch: 102 [29440/60000 (49%)]\tLoss: 708.088928\n",
            "Train Epoch: 102 [30720/60000 (51%)]\tLoss: 745.310059\n",
            "Train Epoch: 102 [32000/60000 (53%)]\tLoss: 741.344238\n",
            "Train Epoch: 102 [33280/60000 (55%)]\tLoss: 747.644958\n",
            "Train Epoch: 102 [34560/60000 (58%)]\tLoss: 721.100830\n",
            "Train Epoch: 102 [35840/60000 (60%)]\tLoss: 727.801575\n",
            "Train Epoch: 102 [37120/60000 (62%)]\tLoss: 745.450012\n",
            "Train Epoch: 102 [38400/60000 (64%)]\tLoss: 739.233765\n",
            "Train Epoch: 102 [39680/60000 (66%)]\tLoss: 722.287964\n",
            "Train Epoch: 102 [40960/60000 (68%)]\tLoss: 715.792419\n",
            "Train Epoch: 102 [42240/60000 (70%)]\tLoss: 732.751282\n",
            "Train Epoch: 102 [43520/60000 (72%)]\tLoss: 768.909363\n",
            "Train Epoch: 102 [44800/60000 (75%)]\tLoss: 739.930664\n",
            "Train Epoch: 102 [46080/60000 (77%)]\tLoss: 709.659607\n",
            "Train Epoch: 102 [47360/60000 (79%)]\tLoss: 747.449646\n",
            "Train Epoch: 102 [48640/60000 (81%)]\tLoss: 730.479309\n",
            "Train Epoch: 102 [49920/60000 (83%)]\tLoss: 739.554382\n",
            "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 721.769409\n",
            "Train Epoch: 102 [52480/60000 (87%)]\tLoss: 745.613403\n",
            "Train Epoch: 102 [53760/60000 (90%)]\tLoss: 730.824707\n",
            "Train Epoch: 102 [55040/60000 (92%)]\tLoss: 721.008850\n",
            "Train Epoch: 102 [56320/60000 (94%)]\tLoss: 736.300781\n",
            "Train Epoch: 102 [57600/60000 (96%)]\tLoss: 725.125427\n",
            "Train Epoch: 102 [58880/60000 (98%)]\tLoss: 750.233459\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785940647125244\n",
            "\n",
            "Train Epoch: 103 [0/60000 (0%)]\tLoss: 746.743408\n",
            "Train Epoch: 103 [1280/60000 (2%)]\tLoss: 728.302307\n",
            "Train Epoch: 103 [2560/60000 (4%)]\tLoss: 728.871826\n",
            "Train Epoch: 103 [3840/60000 (6%)]\tLoss: 711.504883\n",
            "Train Epoch: 103 [5120/60000 (9%)]\tLoss: 748.557861\n",
            "Train Epoch: 103 [6400/60000 (11%)]\tLoss: 726.274353\n",
            "Train Epoch: 103 [7680/60000 (13%)]\tLoss: 723.797485\n",
            "Train Epoch: 103 [8960/60000 (15%)]\tLoss: 730.104614\n",
            "Train Epoch: 103 [10240/60000 (17%)]\tLoss: 722.064880\n",
            "Train Epoch: 103 [11520/60000 (19%)]\tLoss: 737.366516\n",
            "Train Epoch: 103 [12800/60000 (21%)]\tLoss: 755.371155\n",
            "Train Epoch: 103 [14080/60000 (23%)]\tLoss: 756.213623\n",
            "Train Epoch: 103 [15360/60000 (26%)]\tLoss: 741.198303\n",
            "Train Epoch: 103 [16640/60000 (28%)]\tLoss: 735.801819\n",
            "Train Epoch: 103 [17920/60000 (30%)]\tLoss: 720.188538\n",
            "Train Epoch: 103 [19200/60000 (32%)]\tLoss: 747.567566\n",
            "Train Epoch: 103 [20480/60000 (34%)]\tLoss: 732.253174\n",
            "Train Epoch: 103 [21760/60000 (36%)]\tLoss: 750.444885\n",
            "Train Epoch: 103 [23040/60000 (38%)]\tLoss: 749.743286\n",
            "Train Epoch: 103 [24320/60000 (41%)]\tLoss: 729.872009\n",
            "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 781.608459\n",
            "Train Epoch: 103 [26880/60000 (45%)]\tLoss: 731.663330\n",
            "Train Epoch: 103 [28160/60000 (47%)]\tLoss: 723.419434\n",
            "Train Epoch: 103 [29440/60000 (49%)]\tLoss: 719.832886\n",
            "Train Epoch: 103 [30720/60000 (51%)]\tLoss: 744.389832\n",
            "Train Epoch: 103 [32000/60000 (53%)]\tLoss: 725.208435\n",
            "Train Epoch: 103 [33280/60000 (55%)]\tLoss: 712.274841\n",
            "Train Epoch: 103 [34560/60000 (58%)]\tLoss: 730.388672\n",
            "Train Epoch: 103 [35840/60000 (60%)]\tLoss: 746.929199\n",
            "Train Epoch: 103 [37120/60000 (62%)]\tLoss: 726.143555\n",
            "Train Epoch: 103 [38400/60000 (64%)]\tLoss: 736.037781\n",
            "Train Epoch: 103 [39680/60000 (66%)]\tLoss: 719.800293\n",
            "Train Epoch: 103 [40960/60000 (68%)]\tLoss: 744.631958\n",
            "Train Epoch: 103 [42240/60000 (70%)]\tLoss: 731.067993\n",
            "Train Epoch: 103 [43520/60000 (72%)]\tLoss: 711.795044\n",
            "Train Epoch: 103 [44800/60000 (75%)]\tLoss: 733.268555\n",
            "Train Epoch: 103 [46080/60000 (77%)]\tLoss: 753.548889\n",
            "Train Epoch: 103 [47360/60000 (79%)]\tLoss: 723.297180\n",
            "Train Epoch: 103 [48640/60000 (81%)]\tLoss: 722.388550\n",
            "Train Epoch: 103 [49920/60000 (83%)]\tLoss: 740.356323\n",
            "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 760.657593\n",
            "Train Epoch: 103 [52480/60000 (87%)]\tLoss: 712.977600\n",
            "Train Epoch: 103 [53760/60000 (90%)]\tLoss: 726.620972\n",
            "Train Epoch: 103 [55040/60000 (92%)]\tLoss: 722.343689\n",
            "Train Epoch: 103 [56320/60000 (94%)]\tLoss: 716.709900\n",
            "Train Epoch: 103 [57600/60000 (96%)]\tLoss: 741.212952\n",
            "Train Epoch: 103 [58880/60000 (98%)]\tLoss: 750.023804\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784274697303772\n",
            "\n",
            "Train Epoch: 104 [0/60000 (0%)]\tLoss: 714.039307\n",
            "Train Epoch: 104 [1280/60000 (2%)]\tLoss: 736.640198\n",
            "Train Epoch: 104 [2560/60000 (4%)]\tLoss: 749.272705\n",
            "Train Epoch: 104 [3840/60000 (6%)]\tLoss: 738.929688\n",
            "Train Epoch: 104 [5120/60000 (9%)]\tLoss: 753.757874\n",
            "Train Epoch: 104 [6400/60000 (11%)]\tLoss: 738.361023\n",
            "Train Epoch: 104 [7680/60000 (13%)]\tLoss: 729.108459\n",
            "Train Epoch: 104 [8960/60000 (15%)]\tLoss: 734.899414\n",
            "Train Epoch: 104 [10240/60000 (17%)]\tLoss: 724.068604\n",
            "Train Epoch: 104 [11520/60000 (19%)]\tLoss: 739.008789\n",
            "Train Epoch: 104 [12800/60000 (21%)]\tLoss: 741.614197\n",
            "Train Epoch: 104 [14080/60000 (23%)]\tLoss: 723.749268\n",
            "Train Epoch: 104 [15360/60000 (26%)]\tLoss: 728.280823\n",
            "Train Epoch: 104 [16640/60000 (28%)]\tLoss: 710.431641\n",
            "Train Epoch: 104 [17920/60000 (30%)]\tLoss: 716.164124\n",
            "Train Epoch: 104 [19200/60000 (32%)]\tLoss: 733.952820\n",
            "Train Epoch: 104 [20480/60000 (34%)]\tLoss: 723.259216\n",
            "Train Epoch: 104 [21760/60000 (36%)]\tLoss: 725.979736\n",
            "Train Epoch: 104 [23040/60000 (38%)]\tLoss: 738.389099\n",
            "Train Epoch: 104 [24320/60000 (41%)]\tLoss: 738.260315\n",
            "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 742.808167\n",
            "Train Epoch: 104 [26880/60000 (45%)]\tLoss: 728.936401\n",
            "Train Epoch: 104 [28160/60000 (47%)]\tLoss: 736.441650\n",
            "Train Epoch: 104 [29440/60000 (49%)]\tLoss: 734.594788\n",
            "Train Epoch: 104 [30720/60000 (51%)]\tLoss: 756.436035\n",
            "Train Epoch: 104 [32000/60000 (53%)]\tLoss: 733.879395\n",
            "Train Epoch: 104 [33280/60000 (55%)]\tLoss: 732.463989\n",
            "Train Epoch: 104 [34560/60000 (58%)]\tLoss: 733.023743\n",
            "Train Epoch: 104 [35840/60000 (60%)]\tLoss: 732.931030\n",
            "Train Epoch: 104 [37120/60000 (62%)]\tLoss: 707.411804\n",
            "Train Epoch: 104 [38400/60000 (64%)]\tLoss: 733.737366\n",
            "Train Epoch: 104 [39680/60000 (66%)]\tLoss: 728.314697\n",
            "Train Epoch: 104 [40960/60000 (68%)]\tLoss: 705.544983\n",
            "Train Epoch: 104 [42240/60000 (70%)]\tLoss: 727.374207\n",
            "Train Epoch: 104 [43520/60000 (72%)]\tLoss: 716.892273\n",
            "Train Epoch: 104 [44800/60000 (75%)]\tLoss: 747.092957\n",
            "Train Epoch: 104 [46080/60000 (77%)]\tLoss: 731.979126\n",
            "Train Epoch: 104 [47360/60000 (79%)]\tLoss: 711.423889\n",
            "Train Epoch: 104 [48640/60000 (81%)]\tLoss: 735.741577\n",
            "Train Epoch: 104 [49920/60000 (83%)]\tLoss: 731.667786\n",
            "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 740.075684\n",
            "Train Epoch: 104 [52480/60000 (87%)]\tLoss: 721.175476\n",
            "Train Epoch: 104 [53760/60000 (90%)]\tLoss: 727.530823\n",
            "Train Epoch: 104 [55040/60000 (92%)]\tLoss: 748.613953\n",
            "Train Epoch: 104 [56320/60000 (94%)]\tLoss: 755.883240\n",
            "Train Epoch: 104 [57600/60000 (96%)]\tLoss: 736.081482\n",
            "Train Epoch: 104 [58880/60000 (98%)]\tLoss: 751.712830\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780363142490387\n",
            "\n",
            "Train Epoch: 105 [0/60000 (0%)]\tLoss: 729.925598\n",
            "Train Epoch: 105 [1280/60000 (2%)]\tLoss: 757.347534\n",
            "Train Epoch: 105 [2560/60000 (4%)]\tLoss: 714.956055\n",
            "Train Epoch: 105 [3840/60000 (6%)]\tLoss: 726.436462\n",
            "Train Epoch: 105 [5120/60000 (9%)]\tLoss: 735.387695\n",
            "Train Epoch: 105 [6400/60000 (11%)]\tLoss: 739.801697\n",
            "Train Epoch: 105 [7680/60000 (13%)]\tLoss: 752.739929\n",
            "Train Epoch: 105 [8960/60000 (15%)]\tLoss: 750.667419\n",
            "Train Epoch: 105 [10240/60000 (17%)]\tLoss: 737.557983\n",
            "Train Epoch: 105 [11520/60000 (19%)]\tLoss: 724.670227\n",
            "Train Epoch: 105 [12800/60000 (21%)]\tLoss: 716.136963\n",
            "Train Epoch: 105 [14080/60000 (23%)]\tLoss: 736.059692\n",
            "Train Epoch: 105 [15360/60000 (26%)]\tLoss: 767.907043\n",
            "Train Epoch: 105 [16640/60000 (28%)]\tLoss: 765.054138\n",
            "Train Epoch: 105 [17920/60000 (30%)]\tLoss: 745.298950\n",
            "Train Epoch: 105 [19200/60000 (32%)]\tLoss: 747.853943\n",
            "Train Epoch: 105 [20480/60000 (34%)]\tLoss: 737.974731\n",
            "Train Epoch: 105 [21760/60000 (36%)]\tLoss: 733.146851\n",
            "Train Epoch: 105 [23040/60000 (38%)]\tLoss: 757.607178\n",
            "Train Epoch: 105 [24320/60000 (41%)]\tLoss: 718.559326\n",
            "Train Epoch: 105 [25600/60000 (43%)]\tLoss: 750.046692\n",
            "Train Epoch: 105 [26880/60000 (45%)]\tLoss: 729.280151\n",
            "Train Epoch: 105 [28160/60000 (47%)]\tLoss: 716.768188\n",
            "Train Epoch: 105 [29440/60000 (49%)]\tLoss: 760.822327\n",
            "Train Epoch: 105 [30720/60000 (51%)]\tLoss: 722.420898\n",
            "Train Epoch: 105 [32000/60000 (53%)]\tLoss: 727.832336\n",
            "Train Epoch: 105 [33280/60000 (55%)]\tLoss: 739.912415\n",
            "Train Epoch: 105 [34560/60000 (58%)]\tLoss: 746.672913\n",
            "Train Epoch: 105 [35840/60000 (60%)]\tLoss: 729.642578\n",
            "Train Epoch: 105 [37120/60000 (62%)]\tLoss: 750.101318\n",
            "Train Epoch: 105 [38400/60000 (64%)]\tLoss: 757.799255\n",
            "Train Epoch: 105 [39680/60000 (66%)]\tLoss: 750.950562\n",
            "Train Epoch: 105 [40960/60000 (68%)]\tLoss: 700.439697\n",
            "Train Epoch: 105 [42240/60000 (70%)]\tLoss: 736.015625\n",
            "Train Epoch: 105 [43520/60000 (72%)]\tLoss: 761.172302\n",
            "Train Epoch: 105 [44800/60000 (75%)]\tLoss: 742.387573\n",
            "Train Epoch: 105 [46080/60000 (77%)]\tLoss: 725.860718\n",
            "Train Epoch: 105 [47360/60000 (79%)]\tLoss: 740.139893\n",
            "Train Epoch: 105 [48640/60000 (81%)]\tLoss: 763.259338\n",
            "Train Epoch: 105 [49920/60000 (83%)]\tLoss: 739.755432\n",
            "Train Epoch: 105 [51200/60000 (85%)]\tLoss: 718.145874\n",
            "Train Epoch: 105 [52480/60000 (87%)]\tLoss: 708.088440\n",
            "Train Epoch: 105 [53760/60000 (90%)]\tLoss: 725.248901\n",
            "Train Epoch: 105 [55040/60000 (92%)]\tLoss: 732.601257\n",
            "Train Epoch: 105 [56320/60000 (94%)]\tLoss: 745.675964\n",
            "Train Epoch: 105 [57600/60000 (96%)]\tLoss: 725.928589\n",
            "Train Epoch: 105 [58880/60000 (98%)]\tLoss: 718.577148\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785456359386444\n",
            "\n",
            "Train Epoch: 106 [0/60000 (0%)]\tLoss: 734.693726\n",
            "Train Epoch: 106 [1280/60000 (2%)]\tLoss: 751.372803\n",
            "Train Epoch: 106 [2560/60000 (4%)]\tLoss: 736.417236\n",
            "Train Epoch: 106 [3840/60000 (6%)]\tLoss: 734.640259\n",
            "Train Epoch: 106 [5120/60000 (9%)]\tLoss: 739.873474\n",
            "Train Epoch: 106 [6400/60000 (11%)]\tLoss: 761.034546\n",
            "Train Epoch: 106 [7680/60000 (13%)]\tLoss: 731.671143\n",
            "Train Epoch: 106 [8960/60000 (15%)]\tLoss: 734.142883\n",
            "Train Epoch: 106 [10240/60000 (17%)]\tLoss: 736.298340\n",
            "Train Epoch: 106 [11520/60000 (19%)]\tLoss: 731.704102\n",
            "Train Epoch: 106 [12800/60000 (21%)]\tLoss: 731.759338\n",
            "Train Epoch: 106 [14080/60000 (23%)]\tLoss: 749.559998\n",
            "Train Epoch: 106 [15360/60000 (26%)]\tLoss: 753.600952\n",
            "Train Epoch: 106 [16640/60000 (28%)]\tLoss: 739.175720\n",
            "Train Epoch: 106 [17920/60000 (30%)]\tLoss: 711.409790\n",
            "Train Epoch: 106 [19200/60000 (32%)]\tLoss: 748.018982\n",
            "Train Epoch: 106 [20480/60000 (34%)]\tLoss: 724.710266\n",
            "Train Epoch: 106 [21760/60000 (36%)]\tLoss: 729.481323\n",
            "Train Epoch: 106 [23040/60000 (38%)]\tLoss: 728.774841\n",
            "Train Epoch: 106 [24320/60000 (41%)]\tLoss: 723.861694\n",
            "Train Epoch: 106 [25600/60000 (43%)]\tLoss: 724.670471\n",
            "Train Epoch: 106 [26880/60000 (45%)]\tLoss: 724.372192\n",
            "Train Epoch: 106 [28160/60000 (47%)]\tLoss: 723.533386\n",
            "Train Epoch: 106 [29440/60000 (49%)]\tLoss: 740.247070\n",
            "Train Epoch: 106 [30720/60000 (51%)]\tLoss: 722.270813\n",
            "Train Epoch: 106 [32000/60000 (53%)]\tLoss: 767.861084\n",
            "Train Epoch: 106 [33280/60000 (55%)]\tLoss: 743.834717\n",
            "Train Epoch: 106 [34560/60000 (58%)]\tLoss: 739.343933\n",
            "Train Epoch: 106 [35840/60000 (60%)]\tLoss: 755.315979\n",
            "Train Epoch: 106 [37120/60000 (62%)]\tLoss: 751.350769\n",
            "Train Epoch: 106 [38400/60000 (64%)]\tLoss: 722.982910\n",
            "Train Epoch: 106 [39680/60000 (66%)]\tLoss: 743.487244\n",
            "Train Epoch: 106 [40960/60000 (68%)]\tLoss: 762.398804\n",
            "Train Epoch: 106 [42240/60000 (70%)]\tLoss: 723.232422\n",
            "Train Epoch: 106 [43520/60000 (72%)]\tLoss: 750.674500\n",
            "Train Epoch: 106 [44800/60000 (75%)]\tLoss: 720.776062\n",
            "Train Epoch: 106 [46080/60000 (77%)]\tLoss: 742.072998\n",
            "Train Epoch: 106 [47360/60000 (79%)]\tLoss: 733.251831\n",
            "Train Epoch: 106 [48640/60000 (81%)]\tLoss: 740.686401\n",
            "Train Epoch: 106 [49920/60000 (83%)]\tLoss: 760.838257\n",
            "Train Epoch: 106 [51200/60000 (85%)]\tLoss: 738.648987\n",
            "Train Epoch: 106 [52480/60000 (87%)]\tLoss: 762.527832\n",
            "Train Epoch: 106 [53760/60000 (90%)]\tLoss: 732.989502\n",
            "Train Epoch: 106 [55040/60000 (92%)]\tLoss: 732.343018\n",
            "Train Epoch: 106 [56320/60000 (94%)]\tLoss: 743.390869\n",
            "Train Epoch: 106 [57600/60000 (96%)]\tLoss: 748.952759\n",
            "Train Epoch: 106 [58880/60000 (98%)]\tLoss: 759.651917\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784793257713318\n",
            "\n",
            "Train Epoch: 107 [0/60000 (0%)]\tLoss: 754.344971\n",
            "Train Epoch: 107 [1280/60000 (2%)]\tLoss: 738.955566\n",
            "Train Epoch: 107 [2560/60000 (4%)]\tLoss: 713.479126\n",
            "Train Epoch: 107 [3840/60000 (6%)]\tLoss: 732.081543\n",
            "Train Epoch: 107 [5120/60000 (9%)]\tLoss: 753.406738\n",
            "Train Epoch: 107 [6400/60000 (11%)]\tLoss: 723.190247\n",
            "Train Epoch: 107 [7680/60000 (13%)]\tLoss: 733.609192\n",
            "Train Epoch: 107 [8960/60000 (15%)]\tLoss: 731.853333\n",
            "Train Epoch: 107 [10240/60000 (17%)]\tLoss: 745.131836\n",
            "Train Epoch: 107 [11520/60000 (19%)]\tLoss: 743.727295\n",
            "Train Epoch: 107 [12800/60000 (21%)]\tLoss: 717.564087\n",
            "Train Epoch: 107 [14080/60000 (23%)]\tLoss: 743.452148\n",
            "Train Epoch: 107 [15360/60000 (26%)]\tLoss: 711.978516\n",
            "Train Epoch: 107 [16640/60000 (28%)]\tLoss: 741.571472\n",
            "Train Epoch: 107 [17920/60000 (30%)]\tLoss: 717.976746\n",
            "Train Epoch: 107 [19200/60000 (32%)]\tLoss: 741.002747\n",
            "Train Epoch: 107 [20480/60000 (34%)]\tLoss: 754.326965\n",
            "Train Epoch: 107 [21760/60000 (36%)]\tLoss: 740.433472\n",
            "Train Epoch: 107 [23040/60000 (38%)]\tLoss: 749.739563\n",
            "Train Epoch: 107 [24320/60000 (41%)]\tLoss: 734.947876\n",
            "Train Epoch: 107 [25600/60000 (43%)]\tLoss: 756.993408\n",
            "Train Epoch: 107 [26880/60000 (45%)]\tLoss: 751.444824\n",
            "Train Epoch: 107 [28160/60000 (47%)]\tLoss: 753.389648\n",
            "Train Epoch: 107 [29440/60000 (49%)]\tLoss: 741.703613\n",
            "Train Epoch: 107 [30720/60000 (51%)]\tLoss: 742.554993\n",
            "Train Epoch: 107 [32000/60000 (53%)]\tLoss: 738.708191\n",
            "Train Epoch: 107 [33280/60000 (55%)]\tLoss: 726.774597\n",
            "Train Epoch: 107 [34560/60000 (58%)]\tLoss: 716.181458\n",
            "Train Epoch: 107 [35840/60000 (60%)]\tLoss: 745.477966\n",
            "Train Epoch: 107 [37120/60000 (62%)]\tLoss: 733.822083\n",
            "Train Epoch: 107 [38400/60000 (64%)]\tLoss: 722.421509\n",
            "Train Epoch: 107 [39680/60000 (66%)]\tLoss: 755.315247\n",
            "Train Epoch: 107 [40960/60000 (68%)]\tLoss: 745.059265\n",
            "Train Epoch: 107 [42240/60000 (70%)]\tLoss: 738.746399\n",
            "Train Epoch: 107 [43520/60000 (72%)]\tLoss: 721.297241\n",
            "Train Epoch: 107 [44800/60000 (75%)]\tLoss: 736.109192\n",
            "Train Epoch: 107 [46080/60000 (77%)]\tLoss: 719.580688\n",
            "Train Epoch: 107 [47360/60000 (79%)]\tLoss: 736.479065\n",
            "Train Epoch: 107 [48640/60000 (81%)]\tLoss: 711.996826\n",
            "Train Epoch: 107 [49920/60000 (83%)]\tLoss: 746.977417\n",
            "Train Epoch: 107 [51200/60000 (85%)]\tLoss: 723.096252\n",
            "Train Epoch: 107 [52480/60000 (87%)]\tLoss: 744.245850\n",
            "Train Epoch: 107 [53760/60000 (90%)]\tLoss: 728.660217\n",
            "Train Epoch: 107 [55040/60000 (92%)]\tLoss: 735.033447\n",
            "Train Epoch: 107 [56320/60000 (94%)]\tLoss: 741.517639\n",
            "Train Epoch: 107 [57600/60000 (96%)]\tLoss: 728.644348\n",
            "Train Epoch: 107 [58880/60000 (98%)]\tLoss: 733.335388\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781628251075745\n",
            "\n",
            "Train Epoch: 108 [0/60000 (0%)]\tLoss: 732.476990\n",
            "Train Epoch: 108 [1280/60000 (2%)]\tLoss: 747.687988\n",
            "Train Epoch: 108 [2560/60000 (4%)]\tLoss: 766.359314\n",
            "Train Epoch: 108 [3840/60000 (6%)]\tLoss: 759.243774\n",
            "Train Epoch: 108 [5120/60000 (9%)]\tLoss: 734.039856\n",
            "Train Epoch: 108 [6400/60000 (11%)]\tLoss: 710.531006\n",
            "Train Epoch: 108 [7680/60000 (13%)]\tLoss: 733.176392\n",
            "Train Epoch: 108 [8960/60000 (15%)]\tLoss: 734.179810\n",
            "Train Epoch: 108 [10240/60000 (17%)]\tLoss: 729.255676\n",
            "Train Epoch: 108 [11520/60000 (19%)]\tLoss: 707.683777\n",
            "Train Epoch: 108 [12800/60000 (21%)]\tLoss: 762.585632\n",
            "Train Epoch: 108 [14080/60000 (23%)]\tLoss: 739.698486\n",
            "Train Epoch: 108 [15360/60000 (26%)]\tLoss: 739.029846\n",
            "Train Epoch: 108 [16640/60000 (28%)]\tLoss: 752.575989\n",
            "Train Epoch: 108 [17920/60000 (30%)]\tLoss: 697.751648\n",
            "Train Epoch: 108 [19200/60000 (32%)]\tLoss: 718.925720\n",
            "Train Epoch: 108 [20480/60000 (34%)]\tLoss: 764.337036\n",
            "Train Epoch: 108 [21760/60000 (36%)]\tLoss: 746.936157\n",
            "Train Epoch: 108 [23040/60000 (38%)]\tLoss: 749.846008\n",
            "Train Epoch: 108 [24320/60000 (41%)]\tLoss: 729.052734\n",
            "Train Epoch: 108 [25600/60000 (43%)]\tLoss: 729.099121\n",
            "Train Epoch: 108 [26880/60000 (45%)]\tLoss: 748.534241\n",
            "Train Epoch: 108 [28160/60000 (47%)]\tLoss: 742.145508\n",
            "Train Epoch: 108 [29440/60000 (49%)]\tLoss: 720.090149\n",
            "Train Epoch: 108 [30720/60000 (51%)]\tLoss: 731.482910\n",
            "Train Epoch: 108 [32000/60000 (53%)]\tLoss: 714.508057\n",
            "Train Epoch: 108 [33280/60000 (55%)]\tLoss: 725.015259\n",
            "Train Epoch: 108 [34560/60000 (58%)]\tLoss: 725.349304\n",
            "Train Epoch: 108 [35840/60000 (60%)]\tLoss: 738.988281\n",
            "Train Epoch: 108 [37120/60000 (62%)]\tLoss: 712.010254\n",
            "Train Epoch: 108 [38400/60000 (64%)]\tLoss: 713.556702\n",
            "Train Epoch: 108 [39680/60000 (66%)]\tLoss: 755.916260\n",
            "Train Epoch: 108 [40960/60000 (68%)]\tLoss: 730.158508\n",
            "Train Epoch: 108 [42240/60000 (70%)]\tLoss: 752.104309\n",
            "Train Epoch: 108 [43520/60000 (72%)]\tLoss: 747.668152\n",
            "Train Epoch: 108 [44800/60000 (75%)]\tLoss: 718.616333\n",
            "Train Epoch: 108 [46080/60000 (77%)]\tLoss: 744.862854\n",
            "Train Epoch: 108 [47360/60000 (79%)]\tLoss: 711.324341\n",
            "Train Epoch: 108 [48640/60000 (81%)]\tLoss: 732.269592\n",
            "Train Epoch: 108 [49920/60000 (83%)]\tLoss: 753.722473\n",
            "Train Epoch: 108 [51200/60000 (85%)]\tLoss: 733.845459\n",
            "Train Epoch: 108 [52480/60000 (87%)]\tLoss: 739.603882\n",
            "Train Epoch: 108 [53760/60000 (90%)]\tLoss: 759.681030\n",
            "Train Epoch: 108 [55040/60000 (92%)]\tLoss: 744.595703\n",
            "Train Epoch: 108 [56320/60000 (94%)]\tLoss: 731.608215\n",
            "Train Epoch: 108 [57600/60000 (96%)]\tLoss: 733.316589\n",
            "Train Epoch: 108 [58880/60000 (98%)]\tLoss: 748.509644\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783136248588562\n",
            "\n",
            "Train Epoch: 109 [0/60000 (0%)]\tLoss: 752.131653\n",
            "Train Epoch: 109 [1280/60000 (2%)]\tLoss: 731.607727\n",
            "Train Epoch: 109 [2560/60000 (4%)]\tLoss: 740.108398\n",
            "Train Epoch: 109 [3840/60000 (6%)]\tLoss: 736.788086\n",
            "Train Epoch: 109 [5120/60000 (9%)]\tLoss: 754.269287\n",
            "Train Epoch: 109 [6400/60000 (11%)]\tLoss: 733.338806\n",
            "Train Epoch: 109 [7680/60000 (13%)]\tLoss: 746.684448\n",
            "Train Epoch: 109 [8960/60000 (15%)]\tLoss: 739.812012\n",
            "Train Epoch: 109 [10240/60000 (17%)]\tLoss: 742.380005\n",
            "Train Epoch: 109 [11520/60000 (19%)]\tLoss: 738.258057\n",
            "Train Epoch: 109 [12800/60000 (21%)]\tLoss: 746.442444\n",
            "Train Epoch: 109 [14080/60000 (23%)]\tLoss: 709.104919\n",
            "Train Epoch: 109 [15360/60000 (26%)]\tLoss: 736.569763\n",
            "Train Epoch: 109 [16640/60000 (28%)]\tLoss: 739.547546\n",
            "Train Epoch: 109 [17920/60000 (30%)]\tLoss: 745.107910\n",
            "Train Epoch: 109 [19200/60000 (32%)]\tLoss: 721.527100\n",
            "Train Epoch: 109 [20480/60000 (34%)]\tLoss: 722.216492\n",
            "Train Epoch: 109 [21760/60000 (36%)]\tLoss: 760.021606\n",
            "Train Epoch: 109 [23040/60000 (38%)]\tLoss: 736.420166\n",
            "Train Epoch: 109 [24320/60000 (41%)]\tLoss: 736.770630\n",
            "Train Epoch: 109 [25600/60000 (43%)]\tLoss: 742.058167\n",
            "Train Epoch: 109 [26880/60000 (45%)]\tLoss: 718.109375\n",
            "Train Epoch: 109 [28160/60000 (47%)]\tLoss: 720.546021\n",
            "Train Epoch: 109 [29440/60000 (49%)]\tLoss: 689.615723\n",
            "Train Epoch: 109 [30720/60000 (51%)]\tLoss: 737.736877\n",
            "Train Epoch: 109 [32000/60000 (53%)]\tLoss: 722.431885\n",
            "Train Epoch: 109 [33280/60000 (55%)]\tLoss: 709.053040\n",
            "Train Epoch: 109 [34560/60000 (58%)]\tLoss: 737.643250\n",
            "Train Epoch: 109 [35840/60000 (60%)]\tLoss: 745.471924\n",
            "Train Epoch: 109 [37120/60000 (62%)]\tLoss: 739.630981\n",
            "Train Epoch: 109 [38400/60000 (64%)]\tLoss: 729.841858\n",
            "Train Epoch: 109 [39680/60000 (66%)]\tLoss: 724.123108\n",
            "Train Epoch: 109 [40960/60000 (68%)]\tLoss: 742.406921\n",
            "Train Epoch: 109 [42240/60000 (70%)]\tLoss: 711.072632\n",
            "Train Epoch: 109 [43520/60000 (72%)]\tLoss: 746.848145\n",
            "Train Epoch: 109 [44800/60000 (75%)]\tLoss: 727.395569\n",
            "Train Epoch: 109 [46080/60000 (77%)]\tLoss: 726.974854\n",
            "Train Epoch: 109 [47360/60000 (79%)]\tLoss: 763.520935\n",
            "Train Epoch: 109 [48640/60000 (81%)]\tLoss: 717.650635\n",
            "Train Epoch: 109 [49920/60000 (83%)]\tLoss: 726.094482\n",
            "Train Epoch: 109 [51200/60000 (85%)]\tLoss: 733.365479\n",
            "Train Epoch: 109 [52480/60000 (87%)]\tLoss: 756.199524\n",
            "Train Epoch: 109 [53760/60000 (90%)]\tLoss: 724.082031\n",
            "Train Epoch: 109 [55040/60000 (92%)]\tLoss: 745.505310\n",
            "Train Epoch: 109 [56320/60000 (94%)]\tLoss: 741.974243\n",
            "Train Epoch: 109 [57600/60000 (96%)]\tLoss: 769.167603\n",
            "Train Epoch: 109 [58880/60000 (98%)]\tLoss: 731.744263\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785062968730927\n",
            "\n",
            "Train Epoch: 110 [0/60000 (0%)]\tLoss: 766.643921\n",
            "Train Epoch: 110 [1280/60000 (2%)]\tLoss: 730.062866\n",
            "Train Epoch: 110 [2560/60000 (4%)]\tLoss: 756.477173\n",
            "Train Epoch: 110 [3840/60000 (6%)]\tLoss: 732.384094\n",
            "Train Epoch: 110 [5120/60000 (9%)]\tLoss: 759.369019\n",
            "Train Epoch: 110 [6400/60000 (11%)]\tLoss: 722.321228\n",
            "Train Epoch: 110 [7680/60000 (13%)]\tLoss: 729.640442\n",
            "Train Epoch: 110 [8960/60000 (15%)]\tLoss: 735.796204\n",
            "Train Epoch: 110 [10240/60000 (17%)]\tLoss: 757.857910\n",
            "Train Epoch: 110 [11520/60000 (19%)]\tLoss: 754.618835\n",
            "Train Epoch: 110 [12800/60000 (21%)]\tLoss: 727.892944\n",
            "Train Epoch: 110 [14080/60000 (23%)]\tLoss: 747.610107\n",
            "Train Epoch: 110 [15360/60000 (26%)]\tLoss: 759.083862\n",
            "Train Epoch: 110 [16640/60000 (28%)]\tLoss: 717.301697\n",
            "Train Epoch: 110 [17920/60000 (30%)]\tLoss: 737.019958\n",
            "Train Epoch: 110 [19200/60000 (32%)]\tLoss: 710.162720\n",
            "Train Epoch: 110 [20480/60000 (34%)]\tLoss: 734.867493\n",
            "Train Epoch: 110 [21760/60000 (36%)]\tLoss: 712.313171\n",
            "Train Epoch: 110 [23040/60000 (38%)]\tLoss: 761.321838\n",
            "Train Epoch: 110 [24320/60000 (41%)]\tLoss: 738.455383\n",
            "Train Epoch: 110 [25600/60000 (43%)]\tLoss: 712.197449\n",
            "Train Epoch: 110 [26880/60000 (45%)]\tLoss: 746.383545\n",
            "Train Epoch: 110 [28160/60000 (47%)]\tLoss: 736.779663\n",
            "Train Epoch: 110 [29440/60000 (49%)]\tLoss: 737.401245\n",
            "Train Epoch: 110 [30720/60000 (51%)]\tLoss: 756.271729\n",
            "Train Epoch: 110 [32000/60000 (53%)]\tLoss: 729.068909\n",
            "Train Epoch: 110 [33280/60000 (55%)]\tLoss: 741.340088\n",
            "Train Epoch: 110 [34560/60000 (58%)]\tLoss: 753.143433\n",
            "Train Epoch: 110 [35840/60000 (60%)]\tLoss: 723.100464\n",
            "Train Epoch: 110 [37120/60000 (62%)]\tLoss: 734.177063\n",
            "Train Epoch: 110 [38400/60000 (64%)]\tLoss: 733.501526\n",
            "Train Epoch: 110 [39680/60000 (66%)]\tLoss: 743.330566\n",
            "Train Epoch: 110 [40960/60000 (68%)]\tLoss: 767.322205\n",
            "Train Epoch: 110 [42240/60000 (70%)]\tLoss: 743.751770\n",
            "Train Epoch: 110 [43520/60000 (72%)]\tLoss: 741.709900\n",
            "Train Epoch: 110 [44800/60000 (75%)]\tLoss: 732.229858\n",
            "Train Epoch: 110 [46080/60000 (77%)]\tLoss: 723.874146\n",
            "Train Epoch: 110 [47360/60000 (79%)]\tLoss: 739.246216\n",
            "Train Epoch: 110 [48640/60000 (81%)]\tLoss: 752.379456\n",
            "Train Epoch: 110 [49920/60000 (83%)]\tLoss: 729.931152\n",
            "Train Epoch: 110 [51200/60000 (85%)]\tLoss: 723.554382\n",
            "Train Epoch: 110 [52480/60000 (87%)]\tLoss: 731.801636\n",
            "Train Epoch: 110 [53760/60000 (90%)]\tLoss: 727.773193\n",
            "Train Epoch: 110 [55040/60000 (92%)]\tLoss: 759.462463\n",
            "Train Epoch: 110 [56320/60000 (94%)]\tLoss: 723.730347\n",
            "Train Epoch: 110 [57600/60000 (96%)]\tLoss: 737.127502\n",
            "Train Epoch: 110 [58880/60000 (98%)]\tLoss: 732.759399\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978398859500885\n",
            "\n",
            "Train Epoch: 111 [0/60000 (0%)]\tLoss: 731.453796\n",
            "Train Epoch: 111 [1280/60000 (2%)]\tLoss: 749.070557\n",
            "Train Epoch: 111 [2560/60000 (4%)]\tLoss: 718.572754\n",
            "Train Epoch: 111 [3840/60000 (6%)]\tLoss: 737.200989\n",
            "Train Epoch: 111 [5120/60000 (9%)]\tLoss: 741.254761\n",
            "Train Epoch: 111 [6400/60000 (11%)]\tLoss: 742.207703\n",
            "Train Epoch: 111 [7680/60000 (13%)]\tLoss: 729.874634\n",
            "Train Epoch: 111 [8960/60000 (15%)]\tLoss: 722.951050\n",
            "Train Epoch: 111 [10240/60000 (17%)]\tLoss: 730.444458\n",
            "Train Epoch: 111 [11520/60000 (19%)]\tLoss: 752.649841\n",
            "Train Epoch: 111 [12800/60000 (21%)]\tLoss: 751.166931\n",
            "Train Epoch: 111 [14080/60000 (23%)]\tLoss: 728.135864\n",
            "Train Epoch: 111 [15360/60000 (26%)]\tLoss: 735.316345\n",
            "Train Epoch: 111 [16640/60000 (28%)]\tLoss: 730.425720\n",
            "Train Epoch: 111 [17920/60000 (30%)]\tLoss: 731.291687\n",
            "Train Epoch: 111 [19200/60000 (32%)]\tLoss: 751.754517\n",
            "Train Epoch: 111 [20480/60000 (34%)]\tLoss: 745.018494\n",
            "Train Epoch: 111 [21760/60000 (36%)]\tLoss: 735.856201\n",
            "Train Epoch: 111 [23040/60000 (38%)]\tLoss: 727.453491\n",
            "Train Epoch: 111 [24320/60000 (41%)]\tLoss: 702.676208\n",
            "Train Epoch: 111 [25600/60000 (43%)]\tLoss: 720.261719\n",
            "Train Epoch: 111 [26880/60000 (45%)]\tLoss: 745.508423\n",
            "Train Epoch: 111 [28160/60000 (47%)]\tLoss: 743.795166\n",
            "Train Epoch: 111 [29440/60000 (49%)]\tLoss: 725.072021\n",
            "Train Epoch: 111 [30720/60000 (51%)]\tLoss: 730.834900\n",
            "Train Epoch: 111 [32000/60000 (53%)]\tLoss: 725.216309\n",
            "Train Epoch: 111 [33280/60000 (55%)]\tLoss: 715.143860\n",
            "Train Epoch: 111 [34560/60000 (58%)]\tLoss: 747.233459\n",
            "Train Epoch: 111 [35840/60000 (60%)]\tLoss: 765.019165\n",
            "Train Epoch: 111 [37120/60000 (62%)]\tLoss: 743.985046\n",
            "Train Epoch: 111 [38400/60000 (64%)]\tLoss: 744.387085\n",
            "Train Epoch: 111 [39680/60000 (66%)]\tLoss: 740.824463\n",
            "Train Epoch: 111 [40960/60000 (68%)]\tLoss: 722.085938\n",
            "Train Epoch: 111 [42240/60000 (70%)]\tLoss: 769.157532\n",
            "Train Epoch: 111 [43520/60000 (72%)]\tLoss: 720.572327\n",
            "Train Epoch: 111 [44800/60000 (75%)]\tLoss: 760.147400\n",
            "Train Epoch: 111 [46080/60000 (77%)]\tLoss: 744.674927\n",
            "Train Epoch: 111 [47360/60000 (79%)]\tLoss: 766.313721\n",
            "Train Epoch: 111 [48640/60000 (81%)]\tLoss: 726.993896\n",
            "Train Epoch: 111 [49920/60000 (83%)]\tLoss: 731.556458\n",
            "Train Epoch: 111 [51200/60000 (85%)]\tLoss: 744.898499\n",
            "Train Epoch: 111 [52480/60000 (87%)]\tLoss: 733.559998\n",
            "Train Epoch: 111 [53760/60000 (90%)]\tLoss: 726.112549\n",
            "Train Epoch: 111 [55040/60000 (92%)]\tLoss: 719.181946\n",
            "Train Epoch: 111 [56320/60000 (94%)]\tLoss: 734.364746\n",
            "Train Epoch: 111 [57600/60000 (96%)]\tLoss: 739.580566\n",
            "Train Epoch: 111 [58880/60000 (98%)]\tLoss: 749.772766\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978113204240799\n",
            "\n",
            "Train Epoch: 112 [0/60000 (0%)]\tLoss: 742.071472\n",
            "Train Epoch: 112 [1280/60000 (2%)]\tLoss: 727.915894\n",
            "Train Epoch: 112 [2560/60000 (4%)]\tLoss: 722.621765\n",
            "Train Epoch: 112 [3840/60000 (6%)]\tLoss: 758.030457\n",
            "Train Epoch: 112 [5120/60000 (9%)]\tLoss: 731.124573\n",
            "Train Epoch: 112 [6400/60000 (11%)]\tLoss: 730.371399\n",
            "Train Epoch: 112 [7680/60000 (13%)]\tLoss: 746.849182\n",
            "Train Epoch: 112 [8960/60000 (15%)]\tLoss: 727.392151\n",
            "Train Epoch: 112 [10240/60000 (17%)]\tLoss: 719.946655\n",
            "Train Epoch: 112 [11520/60000 (19%)]\tLoss: 765.699951\n",
            "Train Epoch: 112 [12800/60000 (21%)]\tLoss: 736.049377\n",
            "Train Epoch: 112 [14080/60000 (23%)]\tLoss: 729.951050\n",
            "Train Epoch: 112 [15360/60000 (26%)]\tLoss: 720.046448\n",
            "Train Epoch: 112 [16640/60000 (28%)]\tLoss: 766.966980\n",
            "Train Epoch: 112 [17920/60000 (30%)]\tLoss: 730.675476\n",
            "Train Epoch: 112 [19200/60000 (32%)]\tLoss: 725.124878\n",
            "Train Epoch: 112 [20480/60000 (34%)]\tLoss: 726.131348\n",
            "Train Epoch: 112 [21760/60000 (36%)]\tLoss: 731.679443\n",
            "Train Epoch: 112 [23040/60000 (38%)]\tLoss: 729.771912\n",
            "Train Epoch: 112 [24320/60000 (41%)]\tLoss: 715.102112\n",
            "Train Epoch: 112 [25600/60000 (43%)]\tLoss: 740.311035\n",
            "Train Epoch: 112 [26880/60000 (45%)]\tLoss: 736.299255\n",
            "Train Epoch: 112 [28160/60000 (47%)]\tLoss: 752.134033\n",
            "Train Epoch: 112 [29440/60000 (49%)]\tLoss: 732.358337\n",
            "Train Epoch: 112 [30720/60000 (51%)]\tLoss: 719.579468\n",
            "Train Epoch: 112 [32000/60000 (53%)]\tLoss: 750.949280\n",
            "Train Epoch: 112 [33280/60000 (55%)]\tLoss: 745.281555\n",
            "Train Epoch: 112 [34560/60000 (58%)]\tLoss: 737.397278\n",
            "Train Epoch: 112 [35840/60000 (60%)]\tLoss: 743.055969\n",
            "Train Epoch: 112 [37120/60000 (62%)]\tLoss: 726.486389\n",
            "Train Epoch: 112 [38400/60000 (64%)]\tLoss: 726.670837\n",
            "Train Epoch: 112 [39680/60000 (66%)]\tLoss: 726.072937\n",
            "Train Epoch: 112 [40960/60000 (68%)]\tLoss: 712.617554\n",
            "Train Epoch: 112 [42240/60000 (70%)]\tLoss: 721.857910\n",
            "Train Epoch: 112 [43520/60000 (72%)]\tLoss: 744.407837\n",
            "Train Epoch: 112 [44800/60000 (75%)]\tLoss: 747.045837\n",
            "Train Epoch: 112 [46080/60000 (77%)]\tLoss: 751.132080\n",
            "Train Epoch: 112 [47360/60000 (79%)]\tLoss: 733.452148\n",
            "Train Epoch: 112 [48640/60000 (81%)]\tLoss: 744.073975\n",
            "Train Epoch: 112 [49920/60000 (83%)]\tLoss: 749.503296\n",
            "Train Epoch: 112 [51200/60000 (85%)]\tLoss: 740.483582\n",
            "Train Epoch: 112 [52480/60000 (87%)]\tLoss: 746.963806\n",
            "Train Epoch: 112 [53760/60000 (90%)]\tLoss: 733.645874\n",
            "Train Epoch: 112 [55040/60000 (92%)]\tLoss: 734.111816\n",
            "Train Epoch: 112 [56320/60000 (94%)]\tLoss: 741.119141\n",
            "Train Epoch: 112 [57600/60000 (96%)]\tLoss: 728.313965\n",
            "Train Epoch: 112 [58880/60000 (98%)]\tLoss: 741.239929\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784703850746155\n",
            "\n",
            "Train Epoch: 113 [0/60000 (0%)]\tLoss: 739.705627\n",
            "Train Epoch: 113 [1280/60000 (2%)]\tLoss: 742.079956\n",
            "Train Epoch: 113 [2560/60000 (4%)]\tLoss: 737.152710\n",
            "Train Epoch: 113 [3840/60000 (6%)]\tLoss: 741.361023\n",
            "Train Epoch: 113 [5120/60000 (9%)]\tLoss: 731.487549\n",
            "Train Epoch: 113 [6400/60000 (11%)]\tLoss: 738.314392\n",
            "Train Epoch: 113 [7680/60000 (13%)]\tLoss: 744.363647\n",
            "Train Epoch: 113 [8960/60000 (15%)]\tLoss: 708.158997\n",
            "Train Epoch: 113 [10240/60000 (17%)]\tLoss: 740.821960\n",
            "Train Epoch: 113 [11520/60000 (19%)]\tLoss: 730.083130\n",
            "Train Epoch: 113 [12800/60000 (21%)]\tLoss: 723.745239\n",
            "Train Epoch: 113 [14080/60000 (23%)]\tLoss: 737.619873\n",
            "Train Epoch: 113 [15360/60000 (26%)]\tLoss: 728.075806\n",
            "Train Epoch: 113 [16640/60000 (28%)]\tLoss: 741.070923\n",
            "Train Epoch: 113 [17920/60000 (30%)]\tLoss: 722.207825\n",
            "Train Epoch: 113 [19200/60000 (32%)]\tLoss: 725.478088\n",
            "Train Epoch: 113 [20480/60000 (34%)]\tLoss: 738.738342\n",
            "Train Epoch: 113 [21760/60000 (36%)]\tLoss: 720.777893\n",
            "Train Epoch: 113 [23040/60000 (38%)]\tLoss: 713.868225\n",
            "Train Epoch: 113 [24320/60000 (41%)]\tLoss: 748.635498\n",
            "Train Epoch: 113 [25600/60000 (43%)]\tLoss: 702.525330\n",
            "Train Epoch: 113 [26880/60000 (45%)]\tLoss: 732.282959\n",
            "Train Epoch: 113 [28160/60000 (47%)]\tLoss: 733.553955\n",
            "Train Epoch: 113 [29440/60000 (49%)]\tLoss: 748.791565\n",
            "Train Epoch: 113 [30720/60000 (51%)]\tLoss: 717.858154\n",
            "Train Epoch: 113 [32000/60000 (53%)]\tLoss: 750.378235\n",
            "Train Epoch: 113 [33280/60000 (55%)]\tLoss: 713.874146\n",
            "Train Epoch: 113 [34560/60000 (58%)]\tLoss: 742.200989\n",
            "Train Epoch: 113 [35840/60000 (60%)]\tLoss: 736.021362\n",
            "Train Epoch: 113 [37120/60000 (62%)]\tLoss: 717.259033\n",
            "Train Epoch: 113 [38400/60000 (64%)]\tLoss: 760.076904\n",
            "Train Epoch: 113 [39680/60000 (66%)]\tLoss: 743.395203\n",
            "Train Epoch: 113 [40960/60000 (68%)]\tLoss: 725.979614\n",
            "Train Epoch: 113 [42240/60000 (70%)]\tLoss: 739.293152\n",
            "Train Epoch: 113 [43520/60000 (72%)]\tLoss: 737.148438\n",
            "Train Epoch: 113 [44800/60000 (75%)]\tLoss: 728.035522\n",
            "Train Epoch: 113 [46080/60000 (77%)]\tLoss: 721.095947\n",
            "Train Epoch: 113 [47360/60000 (79%)]\tLoss: 744.714355\n",
            "Train Epoch: 113 [48640/60000 (81%)]\tLoss: 760.712158\n",
            "Train Epoch: 113 [49920/60000 (83%)]\tLoss: 713.297974\n",
            "Train Epoch: 113 [51200/60000 (85%)]\tLoss: 725.838867\n",
            "Train Epoch: 113 [52480/60000 (87%)]\tLoss: 748.462097\n",
            "Train Epoch: 113 [53760/60000 (90%)]\tLoss: 714.755859\n",
            "Train Epoch: 113 [55040/60000 (92%)]\tLoss: 756.894226\n",
            "Train Epoch: 113 [56320/60000 (94%)]\tLoss: 744.418701\n",
            "Train Epoch: 113 [57600/60000 (96%)]\tLoss: 738.093079\n",
            "Train Epoch: 113 [58880/60000 (98%)]\tLoss: 743.041077\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782263040542603\n",
            "\n",
            "Train Epoch: 114 [0/60000 (0%)]\tLoss: 745.485107\n",
            "Train Epoch: 114 [1280/60000 (2%)]\tLoss: 750.559814\n",
            "Train Epoch: 114 [2560/60000 (4%)]\tLoss: 725.035889\n",
            "Train Epoch: 114 [3840/60000 (6%)]\tLoss: 745.812988\n",
            "Train Epoch: 114 [5120/60000 (9%)]\tLoss: 750.987366\n",
            "Train Epoch: 114 [6400/60000 (11%)]\tLoss: 773.496033\n",
            "Train Epoch: 114 [7680/60000 (13%)]\tLoss: 706.979980\n",
            "Train Epoch: 114 [8960/60000 (15%)]\tLoss: 723.168152\n",
            "Train Epoch: 114 [10240/60000 (17%)]\tLoss: 708.474121\n",
            "Train Epoch: 114 [11520/60000 (19%)]\tLoss: 735.813354\n",
            "Train Epoch: 114 [12800/60000 (21%)]\tLoss: 720.585510\n",
            "Train Epoch: 114 [14080/60000 (23%)]\tLoss: 757.097290\n",
            "Train Epoch: 114 [15360/60000 (26%)]\tLoss: 721.223083\n",
            "Train Epoch: 114 [16640/60000 (28%)]\tLoss: 730.302124\n",
            "Train Epoch: 114 [17920/60000 (30%)]\tLoss: 762.722473\n",
            "Train Epoch: 114 [19200/60000 (32%)]\tLoss: 738.225708\n",
            "Train Epoch: 114 [20480/60000 (34%)]\tLoss: 750.538696\n",
            "Train Epoch: 114 [21760/60000 (36%)]\tLoss: 749.367859\n",
            "Train Epoch: 114 [23040/60000 (38%)]\tLoss: 730.550659\n",
            "Train Epoch: 114 [24320/60000 (41%)]\tLoss: 709.279602\n",
            "Train Epoch: 114 [25600/60000 (43%)]\tLoss: 757.480469\n",
            "Train Epoch: 114 [26880/60000 (45%)]\tLoss: 742.623596\n",
            "Train Epoch: 114 [28160/60000 (47%)]\tLoss: 762.082703\n",
            "Train Epoch: 114 [29440/60000 (49%)]\tLoss: 731.181824\n",
            "Train Epoch: 114 [30720/60000 (51%)]\tLoss: 743.444519\n",
            "Train Epoch: 114 [32000/60000 (53%)]\tLoss: 735.776306\n",
            "Train Epoch: 114 [33280/60000 (55%)]\tLoss: 761.197815\n",
            "Train Epoch: 114 [34560/60000 (58%)]\tLoss: 716.933960\n",
            "Train Epoch: 114 [35840/60000 (60%)]\tLoss: 703.067749\n",
            "Train Epoch: 114 [37120/60000 (62%)]\tLoss: 706.822754\n",
            "Train Epoch: 114 [38400/60000 (64%)]\tLoss: 765.491089\n",
            "Train Epoch: 114 [39680/60000 (66%)]\tLoss: 737.854492\n",
            "Train Epoch: 114 [40960/60000 (68%)]\tLoss: 752.811951\n",
            "Train Epoch: 114 [42240/60000 (70%)]\tLoss: 725.846558\n",
            "Train Epoch: 114 [43520/60000 (72%)]\tLoss: 752.853882\n",
            "Train Epoch: 114 [44800/60000 (75%)]\tLoss: 706.157043\n",
            "Train Epoch: 114 [46080/60000 (77%)]\tLoss: 744.768005\n",
            "Train Epoch: 114 [47360/60000 (79%)]\tLoss: 729.092773\n",
            "Train Epoch: 114 [48640/60000 (81%)]\tLoss: 729.978027\n",
            "Train Epoch: 114 [49920/60000 (83%)]\tLoss: 734.612793\n",
            "Train Epoch: 114 [51200/60000 (85%)]\tLoss: 739.265076\n",
            "Train Epoch: 114 [52480/60000 (87%)]\tLoss: 745.218018\n",
            "Train Epoch: 114 [53760/60000 (90%)]\tLoss: 739.096558\n",
            "Train Epoch: 114 [55040/60000 (92%)]\tLoss: 733.338196\n",
            "Train Epoch: 114 [56320/60000 (94%)]\tLoss: 726.464844\n",
            "Train Epoch: 114 [57600/60000 (96%)]\tLoss: 723.874207\n",
            "Train Epoch: 114 [58880/60000 (98%)]\tLoss: 739.478027\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785813987255096\n",
            "\n",
            "Train Epoch: 115 [0/60000 (0%)]\tLoss: 742.053833\n",
            "Train Epoch: 115 [1280/60000 (2%)]\tLoss: 744.517517\n",
            "Train Epoch: 115 [2560/60000 (4%)]\tLoss: 734.189087\n",
            "Train Epoch: 115 [3840/60000 (6%)]\tLoss: 754.052063\n",
            "Train Epoch: 115 [5120/60000 (9%)]\tLoss: 735.741150\n",
            "Train Epoch: 115 [6400/60000 (11%)]\tLoss: 742.368286\n",
            "Train Epoch: 115 [7680/60000 (13%)]\tLoss: 731.763123\n",
            "Train Epoch: 115 [8960/60000 (15%)]\tLoss: 730.062805\n",
            "Train Epoch: 115 [10240/60000 (17%)]\tLoss: 734.877747\n",
            "Train Epoch: 115 [11520/60000 (19%)]\tLoss: 746.048401\n",
            "Train Epoch: 115 [12800/60000 (21%)]\tLoss: 731.720520\n",
            "Train Epoch: 115 [14080/60000 (23%)]\tLoss: 745.590454\n",
            "Train Epoch: 115 [15360/60000 (26%)]\tLoss: 735.747620\n",
            "Train Epoch: 115 [16640/60000 (28%)]\tLoss: 747.233032\n",
            "Train Epoch: 115 [17920/60000 (30%)]\tLoss: 742.947205\n",
            "Train Epoch: 115 [19200/60000 (32%)]\tLoss: 741.519531\n",
            "Train Epoch: 115 [20480/60000 (34%)]\tLoss: 758.243774\n",
            "Train Epoch: 115 [21760/60000 (36%)]\tLoss: 783.630798\n",
            "Train Epoch: 115 [23040/60000 (38%)]\tLoss: 714.503601\n",
            "Train Epoch: 115 [24320/60000 (41%)]\tLoss: 747.381226\n",
            "Train Epoch: 115 [25600/60000 (43%)]\tLoss: 750.349182\n",
            "Train Epoch: 115 [26880/60000 (45%)]\tLoss: 748.201721\n",
            "Train Epoch: 115 [28160/60000 (47%)]\tLoss: 764.037476\n",
            "Train Epoch: 115 [29440/60000 (49%)]\tLoss: 734.375854\n",
            "Train Epoch: 115 [30720/60000 (51%)]\tLoss: 744.084595\n",
            "Train Epoch: 115 [32000/60000 (53%)]\tLoss: 749.338806\n",
            "Train Epoch: 115 [33280/60000 (55%)]\tLoss: 749.675842\n",
            "Train Epoch: 115 [34560/60000 (58%)]\tLoss: 735.394165\n",
            "Train Epoch: 115 [35840/60000 (60%)]\tLoss: 725.571838\n",
            "Train Epoch: 115 [37120/60000 (62%)]\tLoss: 733.216736\n",
            "Train Epoch: 115 [38400/60000 (64%)]\tLoss: 760.438354\n",
            "Train Epoch: 115 [39680/60000 (66%)]\tLoss: 739.215393\n",
            "Train Epoch: 115 [40960/60000 (68%)]\tLoss: 720.272095\n",
            "Train Epoch: 115 [42240/60000 (70%)]\tLoss: 772.156311\n",
            "Train Epoch: 115 [43520/60000 (72%)]\tLoss: 736.876343\n",
            "Train Epoch: 115 [44800/60000 (75%)]\tLoss: 727.635986\n",
            "Train Epoch: 115 [46080/60000 (77%)]\tLoss: 725.802612\n",
            "Train Epoch: 115 [47360/60000 (79%)]\tLoss: 758.037720\n",
            "Train Epoch: 115 [48640/60000 (81%)]\tLoss: 726.097473\n",
            "Train Epoch: 115 [49920/60000 (83%)]\tLoss: 721.978088\n",
            "Train Epoch: 115 [51200/60000 (85%)]\tLoss: 736.002014\n",
            "Train Epoch: 115 [52480/60000 (87%)]\tLoss: 737.650208\n",
            "Train Epoch: 115 [53760/60000 (90%)]\tLoss: 744.433228\n",
            "Train Epoch: 115 [55040/60000 (92%)]\tLoss: 730.810730\n",
            "Train Epoch: 115 [56320/60000 (94%)]\tLoss: 700.655334\n",
            "Train Epoch: 115 [57600/60000 (96%)]\tLoss: 734.858582\n",
            "Train Epoch: 115 [58880/60000 (98%)]\tLoss: 763.914978\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782529771327972\n",
            "\n",
            "Train Epoch: 116 [0/60000 (0%)]\tLoss: 732.550049\n",
            "Train Epoch: 116 [1280/60000 (2%)]\tLoss: 744.867737\n",
            "Train Epoch: 116 [2560/60000 (4%)]\tLoss: 760.224182\n",
            "Train Epoch: 116 [3840/60000 (6%)]\tLoss: 748.805115\n",
            "Train Epoch: 116 [5120/60000 (9%)]\tLoss: 737.546448\n",
            "Train Epoch: 116 [6400/60000 (11%)]\tLoss: 729.401367\n",
            "Train Epoch: 116 [7680/60000 (13%)]\tLoss: 743.918701\n",
            "Train Epoch: 116 [8960/60000 (15%)]\tLoss: 721.112732\n",
            "Train Epoch: 116 [10240/60000 (17%)]\tLoss: 733.823303\n",
            "Train Epoch: 116 [11520/60000 (19%)]\tLoss: 737.201477\n",
            "Train Epoch: 116 [12800/60000 (21%)]\tLoss: 746.340271\n",
            "Train Epoch: 116 [14080/60000 (23%)]\tLoss: 754.713440\n",
            "Train Epoch: 116 [15360/60000 (26%)]\tLoss: 725.481445\n",
            "Train Epoch: 116 [16640/60000 (28%)]\tLoss: 749.675171\n",
            "Train Epoch: 116 [17920/60000 (30%)]\tLoss: 762.587708\n",
            "Train Epoch: 116 [19200/60000 (32%)]\tLoss: 749.480469\n",
            "Train Epoch: 116 [20480/60000 (34%)]\tLoss: 716.290894\n",
            "Train Epoch: 116 [21760/60000 (36%)]\tLoss: 758.015015\n",
            "Train Epoch: 116 [23040/60000 (38%)]\tLoss: 734.392029\n",
            "Train Epoch: 116 [24320/60000 (41%)]\tLoss: 704.437256\n",
            "Train Epoch: 116 [25600/60000 (43%)]\tLoss: 763.579102\n",
            "Train Epoch: 116 [26880/60000 (45%)]\tLoss: 715.777527\n",
            "Train Epoch: 116 [28160/60000 (47%)]\tLoss: 731.943115\n",
            "Train Epoch: 116 [29440/60000 (49%)]\tLoss: 759.132568\n",
            "Train Epoch: 116 [30720/60000 (51%)]\tLoss: 726.054932\n",
            "Train Epoch: 116 [32000/60000 (53%)]\tLoss: 739.496643\n",
            "Train Epoch: 116 [33280/60000 (55%)]\tLoss: 740.719543\n",
            "Train Epoch: 116 [34560/60000 (58%)]\tLoss: 720.023926\n",
            "Train Epoch: 116 [35840/60000 (60%)]\tLoss: 711.663025\n",
            "Train Epoch: 116 [37120/60000 (62%)]\tLoss: 750.180542\n",
            "Train Epoch: 116 [38400/60000 (64%)]\tLoss: 729.274597\n",
            "Train Epoch: 116 [39680/60000 (66%)]\tLoss: 722.167847\n",
            "Train Epoch: 116 [40960/60000 (68%)]\tLoss: 725.296387\n",
            "Train Epoch: 116 [42240/60000 (70%)]\tLoss: 728.129211\n",
            "Train Epoch: 116 [43520/60000 (72%)]\tLoss: 705.901978\n",
            "Train Epoch: 116 [44800/60000 (75%)]\tLoss: 731.156738\n",
            "Train Epoch: 116 [46080/60000 (77%)]\tLoss: 727.050293\n",
            "Train Epoch: 116 [47360/60000 (79%)]\tLoss: 750.489746\n",
            "Train Epoch: 116 [48640/60000 (81%)]\tLoss: 779.843933\n",
            "Train Epoch: 116 [49920/60000 (83%)]\tLoss: 733.592407\n",
            "Train Epoch: 116 [51200/60000 (85%)]\tLoss: 734.580444\n",
            "Train Epoch: 116 [52480/60000 (87%)]\tLoss: 735.668823\n",
            "Train Epoch: 116 [53760/60000 (90%)]\tLoss: 755.510864\n",
            "Train Epoch: 116 [55040/60000 (92%)]\tLoss: 734.147522\n",
            "Train Epoch: 116 [56320/60000 (94%)]\tLoss: 736.234924\n",
            "Train Epoch: 116 [57600/60000 (96%)]\tLoss: 720.737732\n",
            "Train Epoch: 116 [58880/60000 (98%)]\tLoss: 732.012451\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784633815288544\n",
            "\n",
            "Train Epoch: 117 [0/60000 (0%)]\tLoss: 732.750305\n",
            "Train Epoch: 117 [1280/60000 (2%)]\tLoss: 716.935913\n",
            "Train Epoch: 117 [2560/60000 (4%)]\tLoss: 758.247681\n",
            "Train Epoch: 117 [3840/60000 (6%)]\tLoss: 745.124207\n",
            "Train Epoch: 117 [5120/60000 (9%)]\tLoss: 739.072998\n",
            "Train Epoch: 117 [6400/60000 (11%)]\tLoss: 741.758423\n",
            "Train Epoch: 117 [7680/60000 (13%)]\tLoss: 740.733459\n",
            "Train Epoch: 117 [8960/60000 (15%)]\tLoss: 768.947083\n",
            "Train Epoch: 117 [10240/60000 (17%)]\tLoss: 736.112244\n",
            "Train Epoch: 117 [11520/60000 (19%)]\tLoss: 740.255249\n",
            "Train Epoch: 117 [12800/60000 (21%)]\tLoss: 736.745667\n",
            "Train Epoch: 117 [14080/60000 (23%)]\tLoss: 769.439819\n",
            "Train Epoch: 117 [15360/60000 (26%)]\tLoss: 735.495239\n",
            "Train Epoch: 117 [16640/60000 (28%)]\tLoss: 723.494019\n",
            "Train Epoch: 117 [17920/60000 (30%)]\tLoss: 760.288147\n",
            "Train Epoch: 117 [19200/60000 (32%)]\tLoss: 739.988281\n",
            "Train Epoch: 117 [20480/60000 (34%)]\tLoss: 755.400635\n",
            "Train Epoch: 117 [21760/60000 (36%)]\tLoss: 754.427551\n",
            "Train Epoch: 117 [23040/60000 (38%)]\tLoss: 753.257629\n",
            "Train Epoch: 117 [24320/60000 (41%)]\tLoss: 728.796570\n",
            "Train Epoch: 117 [25600/60000 (43%)]\tLoss: 753.422546\n",
            "Train Epoch: 117 [26880/60000 (45%)]\tLoss: 744.756165\n",
            "Train Epoch: 117 [28160/60000 (47%)]\tLoss: 757.198547\n",
            "Train Epoch: 117 [29440/60000 (49%)]\tLoss: 736.630981\n",
            "Train Epoch: 117 [30720/60000 (51%)]\tLoss: 746.097412\n",
            "Train Epoch: 117 [32000/60000 (53%)]\tLoss: 727.643372\n",
            "Train Epoch: 117 [33280/60000 (55%)]\tLoss: 750.157776\n",
            "Train Epoch: 117 [34560/60000 (58%)]\tLoss: 718.548767\n",
            "Train Epoch: 117 [35840/60000 (60%)]\tLoss: 746.982544\n",
            "Train Epoch: 117 [37120/60000 (62%)]\tLoss: 764.206299\n",
            "Train Epoch: 117 [38400/60000 (64%)]\tLoss: 712.602600\n",
            "Train Epoch: 117 [39680/60000 (66%)]\tLoss: 729.663696\n",
            "Train Epoch: 117 [40960/60000 (68%)]\tLoss: 750.867981\n",
            "Train Epoch: 117 [42240/60000 (70%)]\tLoss: 713.126770\n",
            "Train Epoch: 117 [43520/60000 (72%)]\tLoss: 767.080017\n",
            "Train Epoch: 117 [44800/60000 (75%)]\tLoss: 747.183533\n",
            "Train Epoch: 117 [46080/60000 (77%)]\tLoss: 716.143982\n",
            "Train Epoch: 117 [47360/60000 (79%)]\tLoss: 742.198425\n",
            "Train Epoch: 117 [48640/60000 (81%)]\tLoss: 736.814636\n",
            "Train Epoch: 117 [49920/60000 (83%)]\tLoss: 726.088745\n",
            "Train Epoch: 117 [51200/60000 (85%)]\tLoss: 746.835205\n",
            "Train Epoch: 117 [52480/60000 (87%)]\tLoss: 738.585327\n",
            "Train Epoch: 117 [53760/60000 (90%)]\tLoss: 727.641357\n",
            "Train Epoch: 117 [55040/60000 (92%)]\tLoss: 746.460815\n",
            "Train Epoch: 117 [56320/60000 (94%)]\tLoss: 736.927734\n",
            "Train Epoch: 117 [57600/60000 (96%)]\tLoss: 748.602600\n",
            "Train Epoch: 117 [58880/60000 (98%)]\tLoss: 730.568298\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978786140680313\n",
            "\n",
            "Train Epoch: 118 [0/60000 (0%)]\tLoss: 724.142578\n",
            "Train Epoch: 118 [1280/60000 (2%)]\tLoss: 718.285583\n",
            "Train Epoch: 118 [2560/60000 (4%)]\tLoss: 747.900269\n",
            "Train Epoch: 118 [3840/60000 (6%)]\tLoss: 753.500916\n",
            "Train Epoch: 118 [5120/60000 (9%)]\tLoss: 727.874023\n",
            "Train Epoch: 118 [6400/60000 (11%)]\tLoss: 735.882874\n",
            "Train Epoch: 118 [7680/60000 (13%)]\tLoss: 708.162354\n",
            "Train Epoch: 118 [8960/60000 (15%)]\tLoss: 741.844482\n",
            "Train Epoch: 118 [10240/60000 (17%)]\tLoss: 719.728882\n",
            "Train Epoch: 118 [11520/60000 (19%)]\tLoss: 743.884399\n",
            "Train Epoch: 118 [12800/60000 (21%)]\tLoss: 747.226746\n",
            "Train Epoch: 118 [14080/60000 (23%)]\tLoss: 742.246338\n",
            "Train Epoch: 118 [15360/60000 (26%)]\tLoss: 765.937744\n",
            "Train Epoch: 118 [16640/60000 (28%)]\tLoss: 758.370117\n",
            "Train Epoch: 118 [17920/60000 (30%)]\tLoss: 739.680481\n",
            "Train Epoch: 118 [19200/60000 (32%)]\tLoss: 714.276917\n",
            "Train Epoch: 118 [20480/60000 (34%)]\tLoss: 739.015930\n",
            "Train Epoch: 118 [21760/60000 (36%)]\tLoss: 732.725830\n",
            "Train Epoch: 118 [23040/60000 (38%)]\tLoss: 725.907043\n",
            "Train Epoch: 118 [24320/60000 (41%)]\tLoss: 737.673035\n",
            "Train Epoch: 118 [25600/60000 (43%)]\tLoss: 751.313599\n",
            "Train Epoch: 118 [26880/60000 (45%)]\tLoss: 728.945801\n",
            "Train Epoch: 118 [28160/60000 (47%)]\tLoss: 749.386353\n",
            "Train Epoch: 118 [29440/60000 (49%)]\tLoss: 728.103271\n",
            "Train Epoch: 118 [30720/60000 (51%)]\tLoss: 742.735046\n",
            "Train Epoch: 118 [32000/60000 (53%)]\tLoss: 734.545227\n",
            "Train Epoch: 118 [33280/60000 (55%)]\tLoss: 738.822876\n",
            "Train Epoch: 118 [34560/60000 (58%)]\tLoss: 721.737976\n",
            "Train Epoch: 118 [35840/60000 (60%)]\tLoss: 749.210876\n",
            "Train Epoch: 118 [37120/60000 (62%)]\tLoss: 708.196472\n",
            "Train Epoch: 118 [38400/60000 (64%)]\tLoss: 755.204651\n",
            "Train Epoch: 118 [39680/60000 (66%)]\tLoss: 755.809753\n",
            "Train Epoch: 118 [40960/60000 (68%)]\tLoss: 737.352417\n",
            "Train Epoch: 118 [42240/60000 (70%)]\tLoss: 724.055481\n",
            "Train Epoch: 118 [43520/60000 (72%)]\tLoss: 726.297546\n",
            "Train Epoch: 118 [44800/60000 (75%)]\tLoss: 753.113770\n",
            "Train Epoch: 118 [46080/60000 (77%)]\tLoss: 738.655823\n",
            "Train Epoch: 118 [47360/60000 (79%)]\tLoss: 735.613220\n",
            "Train Epoch: 118 [48640/60000 (81%)]\tLoss: 742.629395\n",
            "Train Epoch: 118 [49920/60000 (83%)]\tLoss: 726.908081\n",
            "Train Epoch: 118 [51200/60000 (85%)]\tLoss: 709.505859\n",
            "Train Epoch: 118 [52480/60000 (87%)]\tLoss: 748.972778\n",
            "Train Epoch: 118 [53760/60000 (90%)]\tLoss: 722.718689\n",
            "Train Epoch: 118 [55040/60000 (92%)]\tLoss: 714.471252\n",
            "Train Epoch: 118 [56320/60000 (94%)]\tLoss: 743.036255\n",
            "Train Epoch: 118 [57600/60000 (96%)]\tLoss: 746.697754\n",
            "Train Epoch: 118 [58880/60000 (98%)]\tLoss: 721.610840\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782918691635132\n",
            "\n",
            "Train Epoch: 119 [0/60000 (0%)]\tLoss: 730.389648\n",
            "Train Epoch: 119 [1280/60000 (2%)]\tLoss: 733.337524\n",
            "Train Epoch: 119 [2560/60000 (4%)]\tLoss: 729.494080\n",
            "Train Epoch: 119 [3840/60000 (6%)]\tLoss: 713.672852\n",
            "Train Epoch: 119 [5120/60000 (9%)]\tLoss: 737.094604\n",
            "Train Epoch: 119 [6400/60000 (11%)]\tLoss: 732.157776\n",
            "Train Epoch: 119 [7680/60000 (13%)]\tLoss: 731.199402\n",
            "Train Epoch: 119 [8960/60000 (15%)]\tLoss: 749.439087\n",
            "Train Epoch: 119 [10240/60000 (17%)]\tLoss: 727.231812\n",
            "Train Epoch: 119 [11520/60000 (19%)]\tLoss: 758.076599\n",
            "Train Epoch: 119 [12800/60000 (21%)]\tLoss: 742.617615\n",
            "Train Epoch: 119 [14080/60000 (23%)]\tLoss: 741.692139\n",
            "Train Epoch: 119 [15360/60000 (26%)]\tLoss: 729.538025\n",
            "Train Epoch: 119 [16640/60000 (28%)]\tLoss: 733.958679\n",
            "Train Epoch: 119 [17920/60000 (30%)]\tLoss: 728.912292\n",
            "Train Epoch: 119 [19200/60000 (32%)]\tLoss: 720.565125\n",
            "Train Epoch: 119 [20480/60000 (34%)]\tLoss: 743.615723\n",
            "Train Epoch: 119 [21760/60000 (36%)]\tLoss: 749.369446\n",
            "Train Epoch: 119 [23040/60000 (38%)]\tLoss: 772.012878\n",
            "Train Epoch: 119 [24320/60000 (41%)]\tLoss: 712.688293\n",
            "Train Epoch: 119 [25600/60000 (43%)]\tLoss: 729.006042\n",
            "Train Epoch: 119 [26880/60000 (45%)]\tLoss: 751.087891\n",
            "Train Epoch: 119 [28160/60000 (47%)]\tLoss: 719.105957\n",
            "Train Epoch: 119 [29440/60000 (49%)]\tLoss: 740.262085\n",
            "Train Epoch: 119 [30720/60000 (51%)]\tLoss: 740.801025\n",
            "Train Epoch: 119 [32000/60000 (53%)]\tLoss: 750.738220\n",
            "Train Epoch: 119 [33280/60000 (55%)]\tLoss: 724.440002\n",
            "Train Epoch: 119 [34560/60000 (58%)]\tLoss: 731.170532\n",
            "Train Epoch: 119 [35840/60000 (60%)]\tLoss: 741.405212\n",
            "Train Epoch: 119 [37120/60000 (62%)]\tLoss: 735.015991\n",
            "Train Epoch: 119 [38400/60000 (64%)]\tLoss: 737.574524\n",
            "Train Epoch: 119 [39680/60000 (66%)]\tLoss: 742.616699\n",
            "Train Epoch: 119 [40960/60000 (68%)]\tLoss: 711.745972\n",
            "Train Epoch: 119 [42240/60000 (70%)]\tLoss: 731.624207\n",
            "Train Epoch: 119 [43520/60000 (72%)]\tLoss: 735.582581\n",
            "Train Epoch: 119 [44800/60000 (75%)]\tLoss: 735.689453\n",
            "Train Epoch: 119 [46080/60000 (77%)]\tLoss: 764.992859\n",
            "Train Epoch: 119 [47360/60000 (79%)]\tLoss: 741.385071\n",
            "Train Epoch: 119 [48640/60000 (81%)]\tLoss: 717.639343\n",
            "Train Epoch: 119 [49920/60000 (83%)]\tLoss: 748.408569\n",
            "Train Epoch: 119 [51200/60000 (85%)]\tLoss: 738.091675\n",
            "Train Epoch: 119 [52480/60000 (87%)]\tLoss: 768.925110\n",
            "Train Epoch: 119 [53760/60000 (90%)]\tLoss: 738.195984\n",
            "Train Epoch: 119 [55040/60000 (92%)]\tLoss: 753.473022\n",
            "Train Epoch: 119 [56320/60000 (94%)]\tLoss: 758.278809\n",
            "Train Epoch: 119 [57600/60000 (96%)]\tLoss: 751.364075\n",
            "Train Epoch: 119 [58880/60000 (98%)]\tLoss: 759.665771\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781994819641113\n",
            "\n",
            "Train Epoch: 120 [0/60000 (0%)]\tLoss: 737.801392\n",
            "Train Epoch: 120 [1280/60000 (2%)]\tLoss: 723.466492\n",
            "Train Epoch: 120 [2560/60000 (4%)]\tLoss: 735.388245\n",
            "Train Epoch: 120 [3840/60000 (6%)]\tLoss: 715.589722\n",
            "Train Epoch: 120 [5120/60000 (9%)]\tLoss: 726.649536\n",
            "Train Epoch: 120 [6400/60000 (11%)]\tLoss: 743.217896\n",
            "Train Epoch: 120 [7680/60000 (13%)]\tLoss: 730.945312\n",
            "Train Epoch: 120 [8960/60000 (15%)]\tLoss: 748.024353\n",
            "Train Epoch: 120 [10240/60000 (17%)]\tLoss: 723.389221\n",
            "Train Epoch: 120 [11520/60000 (19%)]\tLoss: 738.680298\n",
            "Train Epoch: 120 [12800/60000 (21%)]\tLoss: 720.376953\n",
            "Train Epoch: 120 [14080/60000 (23%)]\tLoss: 725.481323\n",
            "Train Epoch: 120 [15360/60000 (26%)]\tLoss: 740.605591\n",
            "Train Epoch: 120 [16640/60000 (28%)]\tLoss: 730.175964\n",
            "Train Epoch: 120 [17920/60000 (30%)]\tLoss: 742.233643\n",
            "Train Epoch: 120 [19200/60000 (32%)]\tLoss: 736.524475\n",
            "Train Epoch: 120 [20480/60000 (34%)]\tLoss: 769.348267\n",
            "Train Epoch: 120 [21760/60000 (36%)]\tLoss: 753.457458\n",
            "Train Epoch: 120 [23040/60000 (38%)]\tLoss: 722.659302\n",
            "Train Epoch: 120 [24320/60000 (41%)]\tLoss: 743.905884\n",
            "Train Epoch: 120 [25600/60000 (43%)]\tLoss: 726.395081\n",
            "Train Epoch: 120 [26880/60000 (45%)]\tLoss: 741.481445\n",
            "Train Epoch: 120 [28160/60000 (47%)]\tLoss: 712.367554\n",
            "Train Epoch: 120 [29440/60000 (49%)]\tLoss: 711.864807\n",
            "Train Epoch: 120 [30720/60000 (51%)]\tLoss: 719.348999\n",
            "Train Epoch: 120 [32000/60000 (53%)]\tLoss: 742.314819\n",
            "Train Epoch: 120 [33280/60000 (55%)]\tLoss: 742.011353\n",
            "Train Epoch: 120 [34560/60000 (58%)]\tLoss: 743.604919\n",
            "Train Epoch: 120 [35840/60000 (60%)]\tLoss: 731.836487\n",
            "Train Epoch: 120 [37120/60000 (62%)]\tLoss: 718.217163\n",
            "Train Epoch: 120 [38400/60000 (64%)]\tLoss: 753.010254\n",
            "Train Epoch: 120 [39680/60000 (66%)]\tLoss: 754.459045\n",
            "Train Epoch: 120 [40960/60000 (68%)]\tLoss: 749.257629\n",
            "Train Epoch: 120 [42240/60000 (70%)]\tLoss: 750.731140\n",
            "Train Epoch: 120 [43520/60000 (72%)]\tLoss: 715.127625\n",
            "Train Epoch: 120 [44800/60000 (75%)]\tLoss: 730.769226\n",
            "Train Epoch: 120 [46080/60000 (77%)]\tLoss: 734.505554\n",
            "Train Epoch: 120 [47360/60000 (79%)]\tLoss: 747.656067\n",
            "Train Epoch: 120 [48640/60000 (81%)]\tLoss: 748.959534\n",
            "Train Epoch: 120 [49920/60000 (83%)]\tLoss: 713.335632\n",
            "Train Epoch: 120 [51200/60000 (85%)]\tLoss: 733.708496\n",
            "Train Epoch: 120 [52480/60000 (87%)]\tLoss: 747.051819\n",
            "Train Epoch: 120 [53760/60000 (90%)]\tLoss: 738.156433\n",
            "Train Epoch: 120 [55040/60000 (92%)]\tLoss: 731.093323\n",
            "Train Epoch: 120 [56320/60000 (94%)]\tLoss: 718.218079\n",
            "Train Epoch: 120 [57600/60000 (96%)]\tLoss: 711.918945\n",
            "Train Epoch: 120 [58880/60000 (98%)]\tLoss: 724.767517\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978667974472046\n",
            "\n",
            "Train Epoch: 121 [0/60000 (0%)]\tLoss: 733.550720\n",
            "Train Epoch: 121 [1280/60000 (2%)]\tLoss: 740.517212\n",
            "Train Epoch: 121 [2560/60000 (4%)]\tLoss: 762.494812\n",
            "Train Epoch: 121 [3840/60000 (6%)]\tLoss: 732.659668\n",
            "Train Epoch: 121 [5120/60000 (9%)]\tLoss: 748.398071\n",
            "Train Epoch: 121 [6400/60000 (11%)]\tLoss: 727.126343\n",
            "Train Epoch: 121 [7680/60000 (13%)]\tLoss: 716.128540\n",
            "Train Epoch: 121 [8960/60000 (15%)]\tLoss: 719.478149\n",
            "Train Epoch: 121 [10240/60000 (17%)]\tLoss: 740.073853\n",
            "Train Epoch: 121 [11520/60000 (19%)]\tLoss: 775.024780\n",
            "Train Epoch: 121 [12800/60000 (21%)]\tLoss: 714.662781\n",
            "Train Epoch: 121 [14080/60000 (23%)]\tLoss: 725.920898\n",
            "Train Epoch: 121 [15360/60000 (26%)]\tLoss: 728.061157\n",
            "Train Epoch: 121 [16640/60000 (28%)]\tLoss: 755.922852\n",
            "Train Epoch: 121 [17920/60000 (30%)]\tLoss: 775.077820\n",
            "Train Epoch: 121 [19200/60000 (32%)]\tLoss: 747.852722\n",
            "Train Epoch: 121 [20480/60000 (34%)]\tLoss: 719.163940\n",
            "Train Epoch: 121 [21760/60000 (36%)]\tLoss: 738.834839\n",
            "Train Epoch: 121 [23040/60000 (38%)]\tLoss: 723.261780\n",
            "Train Epoch: 121 [24320/60000 (41%)]\tLoss: 712.508789\n",
            "Train Epoch: 121 [25600/60000 (43%)]\tLoss: 732.353394\n",
            "Train Epoch: 121 [26880/60000 (45%)]\tLoss: 743.162964\n",
            "Train Epoch: 121 [28160/60000 (47%)]\tLoss: 735.086548\n",
            "Train Epoch: 121 [29440/60000 (49%)]\tLoss: 731.119812\n",
            "Train Epoch: 121 [30720/60000 (51%)]\tLoss: 752.272156\n",
            "Train Epoch: 121 [32000/60000 (53%)]\tLoss: 734.624634\n",
            "Train Epoch: 121 [33280/60000 (55%)]\tLoss: 728.677246\n",
            "Train Epoch: 121 [34560/60000 (58%)]\tLoss: 721.192993\n",
            "Train Epoch: 121 [35840/60000 (60%)]\tLoss: 749.441650\n",
            "Train Epoch: 121 [37120/60000 (62%)]\tLoss: 752.351868\n",
            "Train Epoch: 121 [38400/60000 (64%)]\tLoss: 725.722595\n",
            "Train Epoch: 121 [39680/60000 (66%)]\tLoss: 725.850159\n",
            "Train Epoch: 121 [40960/60000 (68%)]\tLoss: 749.424438\n",
            "Train Epoch: 121 [42240/60000 (70%)]\tLoss: 762.684570\n",
            "Train Epoch: 121 [43520/60000 (72%)]\tLoss: 744.316650\n",
            "Train Epoch: 121 [44800/60000 (75%)]\tLoss: 753.200867\n",
            "Train Epoch: 121 [46080/60000 (77%)]\tLoss: 739.678040\n",
            "Train Epoch: 121 [47360/60000 (79%)]\tLoss: 720.615723\n",
            "Train Epoch: 121 [48640/60000 (81%)]\tLoss: 739.708923\n",
            "Train Epoch: 121 [49920/60000 (83%)]\tLoss: 733.817993\n",
            "Train Epoch: 121 [51200/60000 (85%)]\tLoss: 728.954651\n",
            "Train Epoch: 121 [52480/60000 (87%)]\tLoss: 756.243103\n",
            "Train Epoch: 121 [53760/60000 (90%)]\tLoss: 727.610718\n",
            "Train Epoch: 121 [55040/60000 (92%)]\tLoss: 746.558411\n",
            "Train Epoch: 121 [56320/60000 (94%)]\tLoss: 734.700989\n",
            "Train Epoch: 121 [57600/60000 (96%)]\tLoss: 736.613525\n",
            "Train Epoch: 121 [58880/60000 (98%)]\tLoss: 727.146973\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781459867954254\n",
            "\n",
            "Train Epoch: 122 [0/60000 (0%)]\tLoss: 720.231384\n",
            "Train Epoch: 122 [1280/60000 (2%)]\tLoss: 721.937744\n",
            "Train Epoch: 122 [2560/60000 (4%)]\tLoss: 746.364746\n",
            "Train Epoch: 122 [3840/60000 (6%)]\tLoss: 752.443909\n",
            "Train Epoch: 122 [5120/60000 (9%)]\tLoss: 736.495178\n",
            "Train Epoch: 122 [6400/60000 (11%)]\tLoss: 709.720886\n",
            "Train Epoch: 122 [7680/60000 (13%)]\tLoss: 769.215393\n",
            "Train Epoch: 122 [8960/60000 (15%)]\tLoss: 761.141846\n",
            "Train Epoch: 122 [10240/60000 (17%)]\tLoss: 763.743103\n",
            "Train Epoch: 122 [11520/60000 (19%)]\tLoss: 723.559875\n",
            "Train Epoch: 122 [12800/60000 (21%)]\tLoss: 739.227417\n",
            "Train Epoch: 122 [14080/60000 (23%)]\tLoss: 733.146057\n",
            "Train Epoch: 122 [15360/60000 (26%)]\tLoss: 757.096069\n",
            "Train Epoch: 122 [16640/60000 (28%)]\tLoss: 748.950378\n",
            "Train Epoch: 122 [17920/60000 (30%)]\tLoss: 749.406616\n",
            "Train Epoch: 122 [19200/60000 (32%)]\tLoss: 719.688354\n",
            "Train Epoch: 122 [20480/60000 (34%)]\tLoss: 727.593384\n",
            "Train Epoch: 122 [21760/60000 (36%)]\tLoss: 713.270935\n",
            "Train Epoch: 122 [23040/60000 (38%)]\tLoss: 744.932251\n",
            "Train Epoch: 122 [24320/60000 (41%)]\tLoss: 747.370544\n",
            "Train Epoch: 122 [25600/60000 (43%)]\tLoss: 751.189819\n",
            "Train Epoch: 122 [26880/60000 (45%)]\tLoss: 722.129395\n",
            "Train Epoch: 122 [28160/60000 (47%)]\tLoss: 721.798889\n",
            "Train Epoch: 122 [29440/60000 (49%)]\tLoss: 735.885376\n",
            "Train Epoch: 122 [30720/60000 (51%)]\tLoss: 737.429260\n",
            "Train Epoch: 122 [32000/60000 (53%)]\tLoss: 731.956421\n",
            "Train Epoch: 122 [33280/60000 (55%)]\tLoss: 741.703186\n",
            "Train Epoch: 122 [34560/60000 (58%)]\tLoss: 721.204285\n",
            "Train Epoch: 122 [35840/60000 (60%)]\tLoss: 741.346375\n",
            "Train Epoch: 122 [37120/60000 (62%)]\tLoss: 718.969604\n",
            "Train Epoch: 122 [38400/60000 (64%)]\tLoss: 734.220947\n",
            "Train Epoch: 122 [39680/60000 (66%)]\tLoss: 734.186707\n",
            "Train Epoch: 122 [40960/60000 (68%)]\tLoss: 755.053040\n",
            "Train Epoch: 122 [42240/60000 (70%)]\tLoss: 729.680908\n",
            "Train Epoch: 122 [43520/60000 (72%)]\tLoss: 751.322205\n",
            "Train Epoch: 122 [44800/60000 (75%)]\tLoss: 727.988770\n",
            "Train Epoch: 122 [46080/60000 (77%)]\tLoss: 767.536011\n",
            "Train Epoch: 122 [47360/60000 (79%)]\tLoss: 744.140137\n",
            "Train Epoch: 122 [48640/60000 (81%)]\tLoss: 740.245972\n",
            "Train Epoch: 122 [49920/60000 (83%)]\tLoss: 733.961182\n",
            "Train Epoch: 122 [51200/60000 (85%)]\tLoss: 737.320618\n",
            "Train Epoch: 122 [52480/60000 (87%)]\tLoss: 726.490845\n",
            "Train Epoch: 122 [53760/60000 (90%)]\tLoss: 731.264954\n",
            "Train Epoch: 122 [55040/60000 (92%)]\tLoss: 729.467468\n",
            "Train Epoch: 122 [56320/60000 (94%)]\tLoss: 739.934143\n",
            "Train Epoch: 122 [57600/60000 (96%)]\tLoss: 729.299011\n",
            "Train Epoch: 122 [58880/60000 (98%)]\tLoss: 723.943115\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786402583122253\n",
            "\n",
            "Train Epoch: 123 [0/60000 (0%)]\tLoss: 770.111633\n",
            "Train Epoch: 123 [1280/60000 (2%)]\tLoss: 723.183838\n",
            "Train Epoch: 123 [2560/60000 (4%)]\tLoss: 744.311340\n",
            "Train Epoch: 123 [3840/60000 (6%)]\tLoss: 725.499695\n",
            "Train Epoch: 123 [5120/60000 (9%)]\tLoss: 736.783508\n",
            "Train Epoch: 123 [6400/60000 (11%)]\tLoss: 740.912415\n",
            "Train Epoch: 123 [7680/60000 (13%)]\tLoss: 733.950439\n",
            "Train Epoch: 123 [8960/60000 (15%)]\tLoss: 750.083069\n",
            "Train Epoch: 123 [10240/60000 (17%)]\tLoss: 743.975769\n",
            "Train Epoch: 123 [11520/60000 (19%)]\tLoss: 732.393921\n",
            "Train Epoch: 123 [12800/60000 (21%)]\tLoss: 716.902649\n",
            "Train Epoch: 123 [14080/60000 (23%)]\tLoss: 750.030762\n",
            "Train Epoch: 123 [15360/60000 (26%)]\tLoss: 726.069885\n",
            "Train Epoch: 123 [16640/60000 (28%)]\tLoss: 741.300781\n",
            "Train Epoch: 123 [17920/60000 (30%)]\tLoss: 744.804382\n",
            "Train Epoch: 123 [19200/60000 (32%)]\tLoss: 728.513733\n",
            "Train Epoch: 123 [20480/60000 (34%)]\tLoss: 718.835327\n",
            "Train Epoch: 123 [21760/60000 (36%)]\tLoss: 746.124146\n",
            "Train Epoch: 123 [23040/60000 (38%)]\tLoss: 777.066528\n",
            "Train Epoch: 123 [24320/60000 (41%)]\tLoss: 714.640259\n",
            "Train Epoch: 123 [25600/60000 (43%)]\tLoss: 745.286926\n",
            "Train Epoch: 123 [26880/60000 (45%)]\tLoss: 749.504211\n",
            "Train Epoch: 123 [28160/60000 (47%)]\tLoss: 750.594727\n",
            "Train Epoch: 123 [29440/60000 (49%)]\tLoss: 742.434570\n",
            "Train Epoch: 123 [30720/60000 (51%)]\tLoss: 716.806152\n",
            "Train Epoch: 123 [32000/60000 (53%)]\tLoss: 741.878540\n",
            "Train Epoch: 123 [33280/60000 (55%)]\tLoss: 755.509766\n",
            "Train Epoch: 123 [34560/60000 (58%)]\tLoss: 727.568665\n",
            "Train Epoch: 123 [35840/60000 (60%)]\tLoss: 732.724060\n",
            "Train Epoch: 123 [37120/60000 (62%)]\tLoss: 709.151611\n",
            "Train Epoch: 123 [38400/60000 (64%)]\tLoss: 762.172607\n",
            "Train Epoch: 123 [39680/60000 (66%)]\tLoss: 758.667236\n",
            "Train Epoch: 123 [40960/60000 (68%)]\tLoss: 728.394348\n",
            "Train Epoch: 123 [42240/60000 (70%)]\tLoss: 728.245422\n",
            "Train Epoch: 123 [43520/60000 (72%)]\tLoss: 748.012268\n",
            "Train Epoch: 123 [44800/60000 (75%)]\tLoss: 741.691956\n",
            "Train Epoch: 123 [46080/60000 (77%)]\tLoss: 733.438110\n",
            "Train Epoch: 123 [47360/60000 (79%)]\tLoss: 744.753296\n",
            "Train Epoch: 123 [48640/60000 (81%)]\tLoss: 716.999573\n",
            "Train Epoch: 123 [49920/60000 (83%)]\tLoss: 767.983582\n",
            "Train Epoch: 123 [51200/60000 (85%)]\tLoss: 746.095276\n",
            "Train Epoch: 123 [52480/60000 (87%)]\tLoss: 742.186401\n",
            "Train Epoch: 123 [53760/60000 (90%)]\tLoss: 741.721741\n",
            "Train Epoch: 123 [55040/60000 (92%)]\tLoss: 747.871582\n",
            "Train Epoch: 123 [56320/60000 (94%)]\tLoss: 731.949524\n",
            "Train Epoch: 123 [57600/60000 (96%)]\tLoss: 724.875732\n",
            "Train Epoch: 123 [58880/60000 (98%)]\tLoss: 736.769165\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978510618209839\n",
            "\n",
            "Train Epoch: 124 [0/60000 (0%)]\tLoss: 729.581604\n",
            "Train Epoch: 124 [1280/60000 (2%)]\tLoss: 745.378296\n",
            "Train Epoch: 124 [2560/60000 (4%)]\tLoss: 748.631531\n",
            "Train Epoch: 124 [3840/60000 (6%)]\tLoss: 712.210266\n",
            "Train Epoch: 124 [5120/60000 (9%)]\tLoss: 739.830200\n",
            "Train Epoch: 124 [6400/60000 (11%)]\tLoss: 735.148682\n",
            "Train Epoch: 124 [7680/60000 (13%)]\tLoss: 726.877625\n",
            "Train Epoch: 124 [8960/60000 (15%)]\tLoss: 701.735291\n",
            "Train Epoch: 124 [10240/60000 (17%)]\tLoss: 734.434326\n",
            "Train Epoch: 124 [11520/60000 (19%)]\tLoss: 724.810425\n",
            "Train Epoch: 124 [12800/60000 (21%)]\tLoss: 715.983948\n",
            "Train Epoch: 124 [14080/60000 (23%)]\tLoss: 756.675537\n",
            "Train Epoch: 124 [15360/60000 (26%)]\tLoss: 747.018066\n",
            "Train Epoch: 124 [16640/60000 (28%)]\tLoss: 756.934265\n",
            "Train Epoch: 124 [17920/60000 (30%)]\tLoss: 692.452087\n",
            "Train Epoch: 124 [19200/60000 (32%)]\tLoss: 753.265869\n",
            "Train Epoch: 124 [20480/60000 (34%)]\tLoss: 735.678894\n",
            "Train Epoch: 124 [21760/60000 (36%)]\tLoss: 742.833984\n",
            "Train Epoch: 124 [23040/60000 (38%)]\tLoss: 727.738098\n",
            "Train Epoch: 124 [24320/60000 (41%)]\tLoss: 764.924377\n",
            "Train Epoch: 124 [25600/60000 (43%)]\tLoss: 723.869995\n",
            "Train Epoch: 124 [26880/60000 (45%)]\tLoss: 727.636414\n",
            "Train Epoch: 124 [28160/60000 (47%)]\tLoss: 740.716797\n",
            "Train Epoch: 124 [29440/60000 (49%)]\tLoss: 739.467651\n",
            "Train Epoch: 124 [30720/60000 (51%)]\tLoss: 749.991272\n",
            "Train Epoch: 124 [32000/60000 (53%)]\tLoss: 728.823242\n",
            "Train Epoch: 124 [33280/60000 (55%)]\tLoss: 720.490540\n",
            "Train Epoch: 124 [34560/60000 (58%)]\tLoss: 746.137329\n",
            "Train Epoch: 124 [35840/60000 (60%)]\tLoss: 731.100037\n",
            "Train Epoch: 124 [37120/60000 (62%)]\tLoss: 754.246399\n",
            "Train Epoch: 124 [38400/60000 (64%)]\tLoss: 743.567688\n",
            "Train Epoch: 124 [39680/60000 (66%)]\tLoss: 721.928833\n",
            "Train Epoch: 124 [40960/60000 (68%)]\tLoss: 750.901672\n",
            "Train Epoch: 124 [42240/60000 (70%)]\tLoss: 719.316895\n",
            "Train Epoch: 124 [43520/60000 (72%)]\tLoss: 718.752380\n",
            "Train Epoch: 124 [44800/60000 (75%)]\tLoss: 741.459717\n",
            "Train Epoch: 124 [46080/60000 (77%)]\tLoss: 753.268738\n",
            "Train Epoch: 124 [47360/60000 (79%)]\tLoss: 751.556580\n",
            "Train Epoch: 124 [48640/60000 (81%)]\tLoss: 694.880371\n",
            "Train Epoch: 124 [49920/60000 (83%)]\tLoss: 728.287903\n",
            "Train Epoch: 124 [51200/60000 (85%)]\tLoss: 742.391235\n",
            "Train Epoch: 124 [52480/60000 (87%)]\tLoss: 728.776550\n",
            "Train Epoch: 124 [53760/60000 (90%)]\tLoss: 735.768311\n",
            "Train Epoch: 124 [55040/60000 (92%)]\tLoss: 724.665039\n",
            "Train Epoch: 124 [56320/60000 (94%)]\tLoss: 763.075012\n",
            "Train Epoch: 124 [57600/60000 (96%)]\tLoss: 724.937317\n",
            "Train Epoch: 124 [58880/60000 (98%)]\tLoss: 732.080322\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783569872379303\n",
            "\n",
            "Train Epoch: 125 [0/60000 (0%)]\tLoss: 745.088074\n",
            "Train Epoch: 125 [1280/60000 (2%)]\tLoss: 749.070251\n",
            "Train Epoch: 125 [2560/60000 (4%)]\tLoss: 731.216980\n",
            "Train Epoch: 125 [3840/60000 (6%)]\tLoss: 724.612305\n",
            "Train Epoch: 125 [5120/60000 (9%)]\tLoss: 745.071167\n",
            "Train Epoch: 125 [6400/60000 (11%)]\tLoss: 754.511047\n",
            "Train Epoch: 125 [7680/60000 (13%)]\tLoss: 733.193054\n",
            "Train Epoch: 125 [8960/60000 (15%)]\tLoss: 712.046082\n",
            "Train Epoch: 125 [10240/60000 (17%)]\tLoss: 737.764587\n",
            "Train Epoch: 125 [11520/60000 (19%)]\tLoss: 755.422729\n",
            "Train Epoch: 125 [12800/60000 (21%)]\tLoss: 749.913574\n",
            "Train Epoch: 125 [14080/60000 (23%)]\tLoss: 740.960327\n",
            "Train Epoch: 125 [15360/60000 (26%)]\tLoss: 738.378906\n",
            "Train Epoch: 125 [16640/60000 (28%)]\tLoss: 721.483398\n",
            "Train Epoch: 125 [17920/60000 (30%)]\tLoss: 743.558044\n",
            "Train Epoch: 125 [19200/60000 (32%)]\tLoss: 728.644836\n",
            "Train Epoch: 125 [20480/60000 (34%)]\tLoss: 749.003540\n",
            "Train Epoch: 125 [21760/60000 (36%)]\tLoss: 745.663330\n",
            "Train Epoch: 125 [23040/60000 (38%)]\tLoss: 740.251038\n",
            "Train Epoch: 125 [24320/60000 (41%)]\tLoss: 732.386230\n",
            "Train Epoch: 125 [25600/60000 (43%)]\tLoss: 737.568237\n",
            "Train Epoch: 125 [26880/60000 (45%)]\tLoss: 715.068481\n",
            "Train Epoch: 125 [28160/60000 (47%)]\tLoss: 734.422546\n",
            "Train Epoch: 125 [29440/60000 (49%)]\tLoss: 721.102539\n",
            "Train Epoch: 125 [30720/60000 (51%)]\tLoss: 732.591003\n",
            "Train Epoch: 125 [32000/60000 (53%)]\tLoss: 750.338379\n",
            "Train Epoch: 125 [33280/60000 (55%)]\tLoss: 725.138977\n",
            "Train Epoch: 125 [34560/60000 (58%)]\tLoss: 719.629150\n",
            "Train Epoch: 125 [35840/60000 (60%)]\tLoss: 762.490845\n",
            "Train Epoch: 125 [37120/60000 (62%)]\tLoss: 723.044861\n",
            "Train Epoch: 125 [38400/60000 (64%)]\tLoss: 724.446716\n",
            "Train Epoch: 125 [39680/60000 (66%)]\tLoss: 758.044434\n",
            "Train Epoch: 125 [40960/60000 (68%)]\tLoss: 706.909973\n",
            "Train Epoch: 125 [42240/60000 (70%)]\tLoss: 748.505737\n",
            "Train Epoch: 125 [43520/60000 (72%)]\tLoss: 733.532837\n",
            "Train Epoch: 125 [44800/60000 (75%)]\tLoss: 720.653809\n",
            "Train Epoch: 125 [46080/60000 (77%)]\tLoss: 746.093933\n",
            "Train Epoch: 125 [47360/60000 (79%)]\tLoss: 737.458374\n",
            "Train Epoch: 125 [48640/60000 (81%)]\tLoss: 727.608948\n",
            "Train Epoch: 125 [49920/60000 (83%)]\tLoss: 729.331787\n",
            "Train Epoch: 125 [51200/60000 (85%)]\tLoss: 742.354431\n",
            "Train Epoch: 125 [52480/60000 (87%)]\tLoss: 743.205017\n",
            "Train Epoch: 125 [53760/60000 (90%)]\tLoss: 752.111755\n",
            "Train Epoch: 125 [55040/60000 (92%)]\tLoss: 751.537598\n",
            "Train Epoch: 125 [56320/60000 (94%)]\tLoss: 743.001648\n",
            "Train Epoch: 125 [57600/60000 (96%)]\tLoss: 720.274780\n",
            "Train Epoch: 125 [58880/60000 (98%)]\tLoss: 724.477356\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781199097633362\n",
            "\n",
            "Train Epoch: 126 [0/60000 (0%)]\tLoss: 726.930725\n",
            "Train Epoch: 126 [1280/60000 (2%)]\tLoss: 726.715515\n",
            "Train Epoch: 126 [2560/60000 (4%)]\tLoss: 704.319153\n",
            "Train Epoch: 126 [3840/60000 (6%)]\tLoss: 717.114563\n",
            "Train Epoch: 126 [5120/60000 (9%)]\tLoss: 761.168457\n",
            "Train Epoch: 126 [6400/60000 (11%)]\tLoss: 752.016602\n",
            "Train Epoch: 126 [7680/60000 (13%)]\tLoss: 734.419678\n",
            "Train Epoch: 126 [8960/60000 (15%)]\tLoss: 746.510925\n",
            "Train Epoch: 126 [10240/60000 (17%)]\tLoss: 749.721375\n",
            "Train Epoch: 126 [11520/60000 (19%)]\tLoss: 733.596558\n",
            "Train Epoch: 126 [12800/60000 (21%)]\tLoss: 726.085632\n",
            "Train Epoch: 126 [14080/60000 (23%)]\tLoss: 722.846497\n",
            "Train Epoch: 126 [15360/60000 (26%)]\tLoss: 746.744263\n",
            "Train Epoch: 126 [16640/60000 (28%)]\tLoss: 739.657471\n",
            "Train Epoch: 126 [17920/60000 (30%)]\tLoss: 695.638733\n",
            "Train Epoch: 126 [19200/60000 (32%)]\tLoss: 734.188049\n",
            "Train Epoch: 126 [20480/60000 (34%)]\tLoss: 711.735718\n",
            "Train Epoch: 126 [21760/60000 (36%)]\tLoss: 724.837585\n",
            "Train Epoch: 126 [23040/60000 (38%)]\tLoss: 740.055969\n",
            "Train Epoch: 126 [24320/60000 (41%)]\tLoss: 724.711914\n",
            "Train Epoch: 126 [25600/60000 (43%)]\tLoss: 740.094177\n",
            "Train Epoch: 126 [26880/60000 (45%)]\tLoss: 738.991089\n",
            "Train Epoch: 126 [28160/60000 (47%)]\tLoss: 737.133301\n",
            "Train Epoch: 126 [29440/60000 (49%)]\tLoss: 750.048279\n",
            "Train Epoch: 126 [30720/60000 (51%)]\tLoss: 743.006836\n",
            "Train Epoch: 126 [32000/60000 (53%)]\tLoss: 743.200989\n",
            "Train Epoch: 126 [33280/60000 (55%)]\tLoss: 721.396729\n",
            "Train Epoch: 126 [34560/60000 (58%)]\tLoss: 724.011658\n",
            "Train Epoch: 126 [35840/60000 (60%)]\tLoss: 719.307190\n",
            "Train Epoch: 126 [37120/60000 (62%)]\tLoss: 744.994995\n",
            "Train Epoch: 126 [38400/60000 (64%)]\tLoss: 731.134460\n",
            "Train Epoch: 126 [39680/60000 (66%)]\tLoss: 735.876404\n",
            "Train Epoch: 126 [40960/60000 (68%)]\tLoss: 724.270386\n",
            "Train Epoch: 126 [42240/60000 (70%)]\tLoss: 752.717834\n",
            "Train Epoch: 126 [43520/60000 (72%)]\tLoss: 728.315979\n",
            "Train Epoch: 126 [44800/60000 (75%)]\tLoss: 725.708130\n",
            "Train Epoch: 126 [46080/60000 (77%)]\tLoss: 691.870850\n",
            "Train Epoch: 126 [47360/60000 (79%)]\tLoss: 739.103027\n",
            "Train Epoch: 126 [48640/60000 (81%)]\tLoss: 727.564392\n",
            "Train Epoch: 126 [49920/60000 (83%)]\tLoss: 738.673462\n",
            "Train Epoch: 126 [51200/60000 (85%)]\tLoss: 726.686646\n",
            "Train Epoch: 126 [52480/60000 (87%)]\tLoss: 720.570862\n",
            "Train Epoch: 126 [53760/60000 (90%)]\tLoss: 730.462341\n",
            "Train Epoch: 126 [55040/60000 (92%)]\tLoss: 727.793396\n",
            "Train Epoch: 126 [56320/60000 (94%)]\tLoss: 745.332886\n",
            "Train Epoch: 126 [57600/60000 (96%)]\tLoss: 729.897034\n",
            "Train Epoch: 126 [58880/60000 (98%)]\tLoss: 762.354736\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784040749073029\n",
            "\n",
            "Train Epoch: 127 [0/60000 (0%)]\tLoss: 750.558838\n",
            "Train Epoch: 127 [1280/60000 (2%)]\tLoss: 727.065796\n",
            "Train Epoch: 127 [2560/60000 (4%)]\tLoss: 728.745972\n",
            "Train Epoch: 127 [3840/60000 (6%)]\tLoss: 719.930786\n",
            "Train Epoch: 127 [5120/60000 (9%)]\tLoss: 753.359924\n",
            "Train Epoch: 127 [6400/60000 (11%)]\tLoss: 746.587097\n",
            "Train Epoch: 127 [7680/60000 (13%)]\tLoss: 738.185181\n",
            "Train Epoch: 127 [8960/60000 (15%)]\tLoss: 747.587830\n",
            "Train Epoch: 127 [10240/60000 (17%)]\tLoss: 753.219116\n",
            "Train Epoch: 127 [11520/60000 (19%)]\tLoss: 738.178772\n",
            "Train Epoch: 127 [12800/60000 (21%)]\tLoss: 718.549500\n",
            "Train Epoch: 127 [14080/60000 (23%)]\tLoss: 730.071045\n",
            "Train Epoch: 127 [15360/60000 (26%)]\tLoss: 709.421997\n",
            "Train Epoch: 127 [16640/60000 (28%)]\tLoss: 732.298218\n",
            "Train Epoch: 127 [17920/60000 (30%)]\tLoss: 748.097839\n",
            "Train Epoch: 127 [19200/60000 (32%)]\tLoss: 730.612793\n",
            "Train Epoch: 127 [20480/60000 (34%)]\tLoss: 737.044800\n",
            "Train Epoch: 127 [21760/60000 (36%)]\tLoss: 743.048218\n",
            "Train Epoch: 127 [23040/60000 (38%)]\tLoss: 720.985474\n",
            "Train Epoch: 127 [24320/60000 (41%)]\tLoss: 757.926697\n",
            "Train Epoch: 127 [25600/60000 (43%)]\tLoss: 738.167236\n",
            "Train Epoch: 127 [26880/60000 (45%)]\tLoss: 770.908691\n",
            "Train Epoch: 127 [28160/60000 (47%)]\tLoss: 731.064087\n",
            "Train Epoch: 127 [29440/60000 (49%)]\tLoss: 741.600586\n",
            "Train Epoch: 127 [30720/60000 (51%)]\tLoss: 722.404663\n",
            "Train Epoch: 127 [32000/60000 (53%)]\tLoss: 744.486206\n",
            "Train Epoch: 127 [33280/60000 (55%)]\tLoss: 729.218567\n",
            "Train Epoch: 127 [34560/60000 (58%)]\tLoss: 732.630371\n",
            "Train Epoch: 127 [35840/60000 (60%)]\tLoss: 737.168457\n",
            "Train Epoch: 127 [37120/60000 (62%)]\tLoss: 724.622192\n",
            "Train Epoch: 127 [38400/60000 (64%)]\tLoss: 735.046936\n",
            "Train Epoch: 127 [39680/60000 (66%)]\tLoss: 750.609802\n",
            "Train Epoch: 127 [40960/60000 (68%)]\tLoss: 721.435730\n",
            "Train Epoch: 127 [42240/60000 (70%)]\tLoss: 725.882996\n",
            "Train Epoch: 127 [43520/60000 (72%)]\tLoss: 737.446838\n",
            "Train Epoch: 127 [44800/60000 (75%)]\tLoss: 742.447754\n",
            "Train Epoch: 127 [46080/60000 (77%)]\tLoss: 722.836914\n",
            "Train Epoch: 127 [47360/60000 (79%)]\tLoss: 740.922913\n",
            "Train Epoch: 127 [48640/60000 (81%)]\tLoss: 721.597595\n",
            "Train Epoch: 127 [49920/60000 (83%)]\tLoss: 731.943420\n",
            "Train Epoch: 127 [51200/60000 (85%)]\tLoss: 718.921997\n",
            "Train Epoch: 127 [52480/60000 (87%)]\tLoss: 774.448608\n",
            "Train Epoch: 127 [53760/60000 (90%)]\tLoss: 746.680420\n",
            "Train Epoch: 127 [55040/60000 (92%)]\tLoss: 710.872742\n",
            "Train Epoch: 127 [56320/60000 (94%)]\tLoss: 705.910339\n",
            "Train Epoch: 127 [57600/60000 (96%)]\tLoss: 745.280457\n",
            "Train Epoch: 127 [58880/60000 (98%)]\tLoss: 724.497375\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782252609729767\n",
            "\n",
            "Train Epoch: 128 [0/60000 (0%)]\tLoss: 754.034973\n",
            "Train Epoch: 128 [1280/60000 (2%)]\tLoss: 747.094788\n",
            "Train Epoch: 128 [2560/60000 (4%)]\tLoss: 755.021484\n",
            "Train Epoch: 128 [3840/60000 (6%)]\tLoss: 730.626953\n",
            "Train Epoch: 128 [5120/60000 (9%)]\tLoss: 746.901367\n",
            "Train Epoch: 128 [6400/60000 (11%)]\tLoss: 727.609131\n",
            "Train Epoch: 128 [7680/60000 (13%)]\tLoss: 752.811218\n",
            "Train Epoch: 128 [8960/60000 (15%)]\tLoss: 722.116760\n",
            "Train Epoch: 128 [10240/60000 (17%)]\tLoss: 734.268738\n",
            "Train Epoch: 128 [11520/60000 (19%)]\tLoss: 739.659119\n",
            "Train Epoch: 128 [12800/60000 (21%)]\tLoss: 740.921631\n",
            "Train Epoch: 128 [14080/60000 (23%)]\tLoss: 746.687073\n",
            "Train Epoch: 128 [15360/60000 (26%)]\tLoss: 725.506042\n",
            "Train Epoch: 128 [16640/60000 (28%)]\tLoss: 718.000916\n",
            "Train Epoch: 128 [17920/60000 (30%)]\tLoss: 725.322266\n",
            "Train Epoch: 128 [19200/60000 (32%)]\tLoss: 716.911072\n",
            "Train Epoch: 128 [20480/60000 (34%)]\tLoss: 730.507202\n",
            "Train Epoch: 128 [21760/60000 (36%)]\tLoss: 756.085205\n",
            "Train Epoch: 128 [23040/60000 (38%)]\tLoss: 757.361023\n",
            "Train Epoch: 128 [24320/60000 (41%)]\tLoss: 747.688293\n",
            "Train Epoch: 128 [25600/60000 (43%)]\tLoss: 730.201233\n",
            "Train Epoch: 128 [26880/60000 (45%)]\tLoss: 745.101685\n",
            "Train Epoch: 128 [28160/60000 (47%)]\tLoss: 724.735596\n",
            "Train Epoch: 128 [29440/60000 (49%)]\tLoss: 726.754700\n",
            "Train Epoch: 128 [30720/60000 (51%)]\tLoss: 713.940430\n",
            "Train Epoch: 128 [32000/60000 (53%)]\tLoss: 749.168518\n",
            "Train Epoch: 128 [33280/60000 (55%)]\tLoss: 741.482300\n",
            "Train Epoch: 128 [34560/60000 (58%)]\tLoss: 759.515381\n",
            "Train Epoch: 128 [35840/60000 (60%)]\tLoss: 738.555237\n",
            "Train Epoch: 128 [37120/60000 (62%)]\tLoss: 755.867676\n",
            "Train Epoch: 128 [38400/60000 (64%)]\tLoss: 726.203247\n",
            "Train Epoch: 128 [39680/60000 (66%)]\tLoss: 745.084106\n",
            "Train Epoch: 128 [40960/60000 (68%)]\tLoss: 727.370483\n",
            "Train Epoch: 128 [42240/60000 (70%)]\tLoss: 747.922974\n",
            "Train Epoch: 128 [43520/60000 (72%)]\tLoss: 735.601746\n",
            "Train Epoch: 128 [44800/60000 (75%)]\tLoss: 741.750916\n",
            "Train Epoch: 128 [46080/60000 (77%)]\tLoss: 716.233887\n",
            "Train Epoch: 128 [47360/60000 (79%)]\tLoss: 751.966309\n",
            "Train Epoch: 128 [48640/60000 (81%)]\tLoss: 722.170288\n",
            "Train Epoch: 128 [49920/60000 (83%)]\tLoss: 755.384460\n",
            "Train Epoch: 128 [51200/60000 (85%)]\tLoss: 753.884766\n",
            "Train Epoch: 128 [52480/60000 (87%)]\tLoss: 741.899963\n",
            "Train Epoch: 128 [53760/60000 (90%)]\tLoss: 702.405640\n",
            "Train Epoch: 128 [55040/60000 (92%)]\tLoss: 723.754456\n",
            "Train Epoch: 128 [56320/60000 (94%)]\tLoss: 725.695984\n",
            "Train Epoch: 128 [57600/60000 (96%)]\tLoss: 730.994873\n",
            "Train Epoch: 128 [58880/60000 (98%)]\tLoss: 732.053345\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781579077243805\n",
            "\n",
            "Train Epoch: 129 [0/60000 (0%)]\tLoss: 718.317017\n",
            "Train Epoch: 129 [1280/60000 (2%)]\tLoss: 734.942444\n",
            "Train Epoch: 129 [2560/60000 (4%)]\tLoss: 720.849915\n",
            "Train Epoch: 129 [3840/60000 (6%)]\tLoss: 732.031799\n",
            "Train Epoch: 129 [5120/60000 (9%)]\tLoss: 725.146973\n",
            "Train Epoch: 129 [6400/60000 (11%)]\tLoss: 729.534180\n",
            "Train Epoch: 129 [7680/60000 (13%)]\tLoss: 732.265137\n",
            "Train Epoch: 129 [8960/60000 (15%)]\tLoss: 735.087341\n",
            "Train Epoch: 129 [10240/60000 (17%)]\tLoss: 741.107422\n",
            "Train Epoch: 129 [11520/60000 (19%)]\tLoss: 755.576904\n",
            "Train Epoch: 129 [12800/60000 (21%)]\tLoss: 739.448425\n",
            "Train Epoch: 129 [14080/60000 (23%)]\tLoss: 724.325439\n",
            "Train Epoch: 129 [15360/60000 (26%)]\tLoss: 711.615479\n",
            "Train Epoch: 129 [16640/60000 (28%)]\tLoss: 728.086609\n",
            "Train Epoch: 129 [17920/60000 (30%)]\tLoss: 740.370544\n",
            "Train Epoch: 129 [19200/60000 (32%)]\tLoss: 746.604187\n",
            "Train Epoch: 129 [20480/60000 (34%)]\tLoss: 738.879944\n",
            "Train Epoch: 129 [21760/60000 (36%)]\tLoss: 707.399841\n",
            "Train Epoch: 129 [23040/60000 (38%)]\tLoss: 753.326660\n",
            "Train Epoch: 129 [24320/60000 (41%)]\tLoss: 727.850220\n",
            "Train Epoch: 129 [25600/60000 (43%)]\tLoss: 732.459351\n",
            "Train Epoch: 129 [26880/60000 (45%)]\tLoss: 747.894775\n",
            "Train Epoch: 129 [28160/60000 (47%)]\tLoss: 746.053589\n",
            "Train Epoch: 129 [29440/60000 (49%)]\tLoss: 771.146484\n",
            "Train Epoch: 129 [30720/60000 (51%)]\tLoss: 728.893433\n",
            "Train Epoch: 129 [32000/60000 (53%)]\tLoss: 742.978088\n",
            "Train Epoch: 129 [33280/60000 (55%)]\tLoss: 722.772095\n",
            "Train Epoch: 129 [34560/60000 (58%)]\tLoss: 728.299988\n",
            "Train Epoch: 129 [35840/60000 (60%)]\tLoss: 737.640564\n",
            "Train Epoch: 129 [37120/60000 (62%)]\tLoss: 747.576416\n",
            "Train Epoch: 129 [38400/60000 (64%)]\tLoss: 700.315430\n",
            "Train Epoch: 129 [39680/60000 (66%)]\tLoss: 768.963684\n",
            "Train Epoch: 129 [40960/60000 (68%)]\tLoss: 710.310425\n",
            "Train Epoch: 129 [42240/60000 (70%)]\tLoss: 746.268066\n",
            "Train Epoch: 129 [43520/60000 (72%)]\tLoss: 738.560852\n",
            "Train Epoch: 129 [44800/60000 (75%)]\tLoss: 723.611389\n",
            "Train Epoch: 129 [46080/60000 (77%)]\tLoss: 759.636963\n",
            "Train Epoch: 129 [47360/60000 (79%)]\tLoss: 738.750305\n",
            "Train Epoch: 129 [48640/60000 (81%)]\tLoss: 737.521362\n",
            "Train Epoch: 129 [49920/60000 (83%)]\tLoss: 716.070923\n",
            "Train Epoch: 129 [51200/60000 (85%)]\tLoss: 729.684082\n",
            "Train Epoch: 129 [52480/60000 (87%)]\tLoss: 734.076355\n",
            "Train Epoch: 129 [53760/60000 (90%)]\tLoss: 727.118347\n",
            "Train Epoch: 129 [55040/60000 (92%)]\tLoss: 734.772339\n",
            "Train Epoch: 129 [56320/60000 (94%)]\tLoss: 741.136230\n",
            "Train Epoch: 129 [57600/60000 (96%)]\tLoss: 743.596069\n",
            "Train Epoch: 129 [58880/60000 (98%)]\tLoss: 733.326538\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782748818397522\n",
            "\n",
            "Train Epoch: 130 [0/60000 (0%)]\tLoss: 723.724487\n",
            "Train Epoch: 130 [1280/60000 (2%)]\tLoss: 765.417419\n",
            "Train Epoch: 130 [2560/60000 (4%)]\tLoss: 760.222290\n",
            "Train Epoch: 130 [3840/60000 (6%)]\tLoss: 756.382385\n",
            "Train Epoch: 130 [5120/60000 (9%)]\tLoss: 747.026855\n",
            "Train Epoch: 130 [6400/60000 (11%)]\tLoss: 730.361328\n",
            "Train Epoch: 130 [7680/60000 (13%)]\tLoss: 761.577209\n",
            "Train Epoch: 130 [8960/60000 (15%)]\tLoss: 747.434753\n",
            "Train Epoch: 130 [10240/60000 (17%)]\tLoss: 719.463684\n",
            "Train Epoch: 130 [11520/60000 (19%)]\tLoss: 736.115173\n",
            "Train Epoch: 130 [12800/60000 (21%)]\tLoss: 728.141418\n",
            "Train Epoch: 130 [14080/60000 (23%)]\tLoss: 746.450562\n",
            "Train Epoch: 130 [15360/60000 (26%)]\tLoss: 752.466492\n",
            "Train Epoch: 130 [16640/60000 (28%)]\tLoss: 726.376831\n",
            "Train Epoch: 130 [17920/60000 (30%)]\tLoss: 757.253174\n",
            "Train Epoch: 130 [19200/60000 (32%)]\tLoss: 736.817261\n",
            "Train Epoch: 130 [20480/60000 (34%)]\tLoss: 733.539856\n",
            "Train Epoch: 130 [21760/60000 (36%)]\tLoss: 742.775146\n",
            "Train Epoch: 130 [23040/60000 (38%)]\tLoss: 734.272278\n",
            "Train Epoch: 130 [24320/60000 (41%)]\tLoss: 717.888123\n",
            "Train Epoch: 130 [25600/60000 (43%)]\tLoss: 727.525452\n",
            "Train Epoch: 130 [26880/60000 (45%)]\tLoss: 738.803406\n",
            "Train Epoch: 130 [28160/60000 (47%)]\tLoss: 748.000671\n",
            "Train Epoch: 130 [29440/60000 (49%)]\tLoss: 741.751587\n",
            "Train Epoch: 130 [30720/60000 (51%)]\tLoss: 722.341675\n",
            "Train Epoch: 130 [32000/60000 (53%)]\tLoss: 738.819153\n",
            "Train Epoch: 130 [33280/60000 (55%)]\tLoss: 757.195740\n",
            "Train Epoch: 130 [34560/60000 (58%)]\tLoss: 741.921570\n",
            "Train Epoch: 130 [35840/60000 (60%)]\tLoss: 721.892639\n",
            "Train Epoch: 130 [37120/60000 (62%)]\tLoss: 726.783447\n",
            "Train Epoch: 130 [38400/60000 (64%)]\tLoss: 741.038879\n",
            "Train Epoch: 130 [39680/60000 (66%)]\tLoss: 725.814148\n",
            "Train Epoch: 130 [40960/60000 (68%)]\tLoss: 716.980286\n",
            "Train Epoch: 130 [42240/60000 (70%)]\tLoss: 743.354004\n",
            "Train Epoch: 130 [43520/60000 (72%)]\tLoss: 727.986511\n",
            "Train Epoch: 130 [44800/60000 (75%)]\tLoss: 748.365601\n",
            "Train Epoch: 130 [46080/60000 (77%)]\tLoss: 757.689270\n",
            "Train Epoch: 130 [47360/60000 (79%)]\tLoss: 747.155457\n",
            "Train Epoch: 130 [48640/60000 (81%)]\tLoss: 731.226196\n",
            "Train Epoch: 130 [49920/60000 (83%)]\tLoss: 741.922485\n",
            "Train Epoch: 130 [51200/60000 (85%)]\tLoss: 728.882446\n",
            "Train Epoch: 130 [52480/60000 (87%)]\tLoss: 737.676392\n",
            "Train Epoch: 130 [53760/60000 (90%)]\tLoss: 713.999207\n",
            "Train Epoch: 130 [55040/60000 (92%)]\tLoss: 759.086731\n",
            "Train Epoch: 130 [56320/60000 (94%)]\tLoss: 756.339844\n",
            "Train Epoch: 130 [57600/60000 (96%)]\tLoss: 733.564819\n",
            "Train Epoch: 130 [58880/60000 (98%)]\tLoss: 749.769165\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784609973430634\n",
            "\n",
            "Train Epoch: 131 [0/60000 (0%)]\tLoss: 738.799988\n",
            "Train Epoch: 131 [1280/60000 (2%)]\tLoss: 738.289551\n",
            "Train Epoch: 131 [2560/60000 (4%)]\tLoss: 736.564575\n",
            "Train Epoch: 131 [3840/60000 (6%)]\tLoss: 725.281433\n",
            "Train Epoch: 131 [5120/60000 (9%)]\tLoss: 727.157532\n",
            "Train Epoch: 131 [6400/60000 (11%)]\tLoss: 732.829285\n",
            "Train Epoch: 131 [7680/60000 (13%)]\tLoss: 722.579346\n",
            "Train Epoch: 131 [8960/60000 (15%)]\tLoss: 740.483826\n",
            "Train Epoch: 131 [10240/60000 (17%)]\tLoss: 740.486938\n",
            "Train Epoch: 131 [11520/60000 (19%)]\tLoss: 732.080566\n",
            "Train Epoch: 131 [12800/60000 (21%)]\tLoss: 751.290344\n",
            "Train Epoch: 131 [14080/60000 (23%)]\tLoss: 753.644775\n",
            "Train Epoch: 131 [15360/60000 (26%)]\tLoss: 715.371094\n",
            "Train Epoch: 131 [16640/60000 (28%)]\tLoss: 724.057251\n",
            "Train Epoch: 131 [17920/60000 (30%)]\tLoss: 740.112183\n",
            "Train Epoch: 131 [19200/60000 (32%)]\tLoss: 730.670532\n",
            "Train Epoch: 131 [20480/60000 (34%)]\tLoss: 705.673218\n",
            "Train Epoch: 131 [21760/60000 (36%)]\tLoss: 728.415466\n",
            "Train Epoch: 131 [23040/60000 (38%)]\tLoss: 772.095947\n",
            "Train Epoch: 131 [24320/60000 (41%)]\tLoss: 740.676453\n",
            "Train Epoch: 131 [25600/60000 (43%)]\tLoss: 730.261719\n",
            "Train Epoch: 131 [26880/60000 (45%)]\tLoss: 744.645996\n",
            "Train Epoch: 131 [28160/60000 (47%)]\tLoss: 759.519958\n",
            "Train Epoch: 131 [29440/60000 (49%)]\tLoss: 736.252686\n",
            "Train Epoch: 131 [30720/60000 (51%)]\tLoss: 730.155701\n",
            "Train Epoch: 131 [32000/60000 (53%)]\tLoss: 716.078125\n",
            "Train Epoch: 131 [33280/60000 (55%)]\tLoss: 725.232910\n",
            "Train Epoch: 131 [34560/60000 (58%)]\tLoss: 721.304077\n",
            "Train Epoch: 131 [35840/60000 (60%)]\tLoss: 726.803589\n",
            "Train Epoch: 131 [37120/60000 (62%)]\tLoss: 750.511353\n",
            "Train Epoch: 131 [38400/60000 (64%)]\tLoss: 722.396179\n",
            "Train Epoch: 131 [39680/60000 (66%)]\tLoss: 725.914978\n",
            "Train Epoch: 131 [40960/60000 (68%)]\tLoss: 736.635010\n",
            "Train Epoch: 131 [42240/60000 (70%)]\tLoss: 759.169556\n",
            "Train Epoch: 131 [43520/60000 (72%)]\tLoss: 739.022339\n",
            "Train Epoch: 131 [44800/60000 (75%)]\tLoss: 771.093628\n",
            "Train Epoch: 131 [46080/60000 (77%)]\tLoss: 735.792297\n",
            "Train Epoch: 131 [47360/60000 (79%)]\tLoss: 738.533569\n",
            "Train Epoch: 131 [48640/60000 (81%)]\tLoss: 741.236389\n",
            "Train Epoch: 131 [49920/60000 (83%)]\tLoss: 757.054504\n",
            "Train Epoch: 131 [51200/60000 (85%)]\tLoss: 719.344543\n",
            "Train Epoch: 131 [52480/60000 (87%)]\tLoss: 741.182007\n",
            "Train Epoch: 131 [53760/60000 (90%)]\tLoss: 735.204773\n",
            "Train Epoch: 131 [55040/60000 (92%)]\tLoss: 716.303650\n",
            "Train Epoch: 131 [56320/60000 (94%)]\tLoss: 765.647583\n",
            "Train Epoch: 131 [57600/60000 (96%)]\tLoss: 715.241455\n",
            "Train Epoch: 131 [58880/60000 (98%)]\tLoss: 752.994446\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783708453178406\n",
            "\n",
            "Train Epoch: 132 [0/60000 (0%)]\tLoss: 737.363586\n",
            "Train Epoch: 132 [1280/60000 (2%)]\tLoss: 722.326233\n",
            "Train Epoch: 132 [2560/60000 (4%)]\tLoss: 707.791687\n",
            "Train Epoch: 132 [3840/60000 (6%)]\tLoss: 748.349976\n",
            "Train Epoch: 132 [5120/60000 (9%)]\tLoss: 708.055786\n",
            "Train Epoch: 132 [6400/60000 (11%)]\tLoss: 733.097595\n",
            "Train Epoch: 132 [7680/60000 (13%)]\tLoss: 731.576233\n",
            "Train Epoch: 132 [8960/60000 (15%)]\tLoss: 779.516663\n",
            "Train Epoch: 132 [10240/60000 (17%)]\tLoss: 740.091003\n",
            "Train Epoch: 132 [11520/60000 (19%)]\tLoss: 704.059570\n",
            "Train Epoch: 132 [12800/60000 (21%)]\tLoss: 724.288574\n",
            "Train Epoch: 132 [14080/60000 (23%)]\tLoss: 737.754639\n",
            "Train Epoch: 132 [15360/60000 (26%)]\tLoss: 727.920654\n",
            "Train Epoch: 132 [16640/60000 (28%)]\tLoss: 748.690674\n",
            "Train Epoch: 132 [17920/60000 (30%)]\tLoss: 744.385925\n",
            "Train Epoch: 132 [19200/60000 (32%)]\tLoss: 756.922180\n",
            "Train Epoch: 132 [20480/60000 (34%)]\tLoss: 720.530151\n",
            "Train Epoch: 132 [21760/60000 (36%)]\tLoss: 730.502991\n",
            "Train Epoch: 132 [23040/60000 (38%)]\tLoss: 746.718933\n",
            "Train Epoch: 132 [24320/60000 (41%)]\tLoss: 756.297729\n",
            "Train Epoch: 132 [25600/60000 (43%)]\tLoss: 743.637939\n",
            "Train Epoch: 132 [26880/60000 (45%)]\tLoss: 743.841553\n",
            "Train Epoch: 132 [28160/60000 (47%)]\tLoss: 731.990784\n",
            "Train Epoch: 132 [29440/60000 (49%)]\tLoss: 721.762024\n",
            "Train Epoch: 132 [30720/60000 (51%)]\tLoss: 746.457703\n",
            "Train Epoch: 132 [32000/60000 (53%)]\tLoss: 710.695984\n",
            "Train Epoch: 132 [33280/60000 (55%)]\tLoss: 731.571899\n",
            "Train Epoch: 132 [34560/60000 (58%)]\tLoss: 730.904785\n",
            "Train Epoch: 132 [35840/60000 (60%)]\tLoss: 737.938232\n",
            "Train Epoch: 132 [37120/60000 (62%)]\tLoss: 732.370544\n",
            "Train Epoch: 132 [38400/60000 (64%)]\tLoss: 751.354858\n",
            "Train Epoch: 132 [39680/60000 (66%)]\tLoss: 748.180725\n",
            "Train Epoch: 132 [40960/60000 (68%)]\tLoss: 734.626038\n",
            "Train Epoch: 132 [42240/60000 (70%)]\tLoss: 740.927063\n",
            "Train Epoch: 132 [43520/60000 (72%)]\tLoss: 742.883728\n",
            "Train Epoch: 132 [44800/60000 (75%)]\tLoss: 733.144043\n",
            "Train Epoch: 132 [46080/60000 (77%)]\tLoss: 744.060181\n",
            "Train Epoch: 132 [47360/60000 (79%)]\tLoss: 758.758057\n",
            "Train Epoch: 132 [48640/60000 (81%)]\tLoss: 730.762146\n",
            "Train Epoch: 132 [49920/60000 (83%)]\tLoss: 744.083679\n",
            "Train Epoch: 132 [51200/60000 (85%)]\tLoss: 720.762268\n",
            "Train Epoch: 132 [52480/60000 (87%)]\tLoss: 742.574890\n",
            "Train Epoch: 132 [53760/60000 (90%)]\tLoss: 766.284973\n",
            "Train Epoch: 132 [55040/60000 (92%)]\tLoss: 738.682312\n",
            "Train Epoch: 132 [56320/60000 (94%)]\tLoss: 751.469177\n",
            "Train Epoch: 132 [57600/60000 (96%)]\tLoss: 735.848572\n",
            "Train Epoch: 132 [58880/60000 (98%)]\tLoss: 745.046143\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978173851966858\n",
            "\n",
            "Train Epoch: 133 [0/60000 (0%)]\tLoss: 711.068054\n",
            "Train Epoch: 133 [1280/60000 (2%)]\tLoss: 730.873352\n",
            "Train Epoch: 133 [2560/60000 (4%)]\tLoss: 729.920898\n",
            "Train Epoch: 133 [3840/60000 (6%)]\tLoss: 749.695374\n",
            "Train Epoch: 133 [5120/60000 (9%)]\tLoss: 733.436584\n",
            "Train Epoch: 133 [6400/60000 (11%)]\tLoss: 750.965515\n",
            "Train Epoch: 133 [7680/60000 (13%)]\tLoss: 732.845703\n",
            "Train Epoch: 133 [8960/60000 (15%)]\tLoss: 724.307129\n",
            "Train Epoch: 133 [10240/60000 (17%)]\tLoss: 715.979065\n",
            "Train Epoch: 133 [11520/60000 (19%)]\tLoss: 728.929138\n",
            "Train Epoch: 133 [12800/60000 (21%)]\tLoss: 736.752930\n",
            "Train Epoch: 133 [14080/60000 (23%)]\tLoss: 754.903381\n",
            "Train Epoch: 133 [15360/60000 (26%)]\tLoss: 743.757812\n",
            "Train Epoch: 133 [16640/60000 (28%)]\tLoss: 735.398193\n",
            "Train Epoch: 133 [17920/60000 (30%)]\tLoss: 732.466736\n",
            "Train Epoch: 133 [19200/60000 (32%)]\tLoss: 731.335449\n",
            "Train Epoch: 133 [20480/60000 (34%)]\tLoss: 737.780273\n",
            "Train Epoch: 133 [21760/60000 (36%)]\tLoss: 739.095215\n",
            "Train Epoch: 133 [23040/60000 (38%)]\tLoss: 734.912231\n",
            "Train Epoch: 133 [24320/60000 (41%)]\tLoss: 722.387817\n",
            "Train Epoch: 133 [25600/60000 (43%)]\tLoss: 735.071350\n",
            "Train Epoch: 133 [26880/60000 (45%)]\tLoss: 738.587463\n",
            "Train Epoch: 133 [28160/60000 (47%)]\tLoss: 737.839478\n",
            "Train Epoch: 133 [29440/60000 (49%)]\tLoss: 764.518250\n",
            "Train Epoch: 133 [30720/60000 (51%)]\tLoss: 756.479675\n",
            "Train Epoch: 133 [32000/60000 (53%)]\tLoss: 723.467957\n",
            "Train Epoch: 133 [33280/60000 (55%)]\tLoss: 724.768066\n",
            "Train Epoch: 133 [34560/60000 (58%)]\tLoss: 745.205750\n",
            "Train Epoch: 133 [35840/60000 (60%)]\tLoss: 750.405762\n",
            "Train Epoch: 133 [37120/60000 (62%)]\tLoss: 717.096130\n",
            "Train Epoch: 133 [38400/60000 (64%)]\tLoss: 745.769958\n",
            "Train Epoch: 133 [39680/60000 (66%)]\tLoss: 742.651672\n",
            "Train Epoch: 133 [40960/60000 (68%)]\tLoss: 730.993774\n",
            "Train Epoch: 133 [42240/60000 (70%)]\tLoss: 736.988342\n",
            "Train Epoch: 133 [43520/60000 (72%)]\tLoss: 745.841003\n",
            "Train Epoch: 133 [44800/60000 (75%)]\tLoss: 731.380554\n",
            "Train Epoch: 133 [46080/60000 (77%)]\tLoss: 727.477783\n",
            "Train Epoch: 133 [47360/60000 (79%)]\tLoss: 741.721924\n",
            "Train Epoch: 133 [48640/60000 (81%)]\tLoss: 749.398499\n",
            "Train Epoch: 133 [49920/60000 (83%)]\tLoss: 771.791199\n",
            "Train Epoch: 133 [51200/60000 (85%)]\tLoss: 740.454895\n",
            "Train Epoch: 133 [52480/60000 (87%)]\tLoss: 727.432068\n",
            "Train Epoch: 133 [53760/60000 (90%)]\tLoss: 727.178162\n",
            "Train Epoch: 133 [55040/60000 (92%)]\tLoss: 741.808411\n",
            "Train Epoch: 133 [56320/60000 (94%)]\tLoss: 734.293518\n",
            "Train Epoch: 133 [57600/60000 (96%)]\tLoss: 757.359863\n",
            "Train Epoch: 133 [58880/60000 (98%)]\tLoss: 768.353516\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783858954906464\n",
            "\n",
            "Train Epoch: 134 [0/60000 (0%)]\tLoss: 725.384094\n",
            "Train Epoch: 134 [1280/60000 (2%)]\tLoss: 744.806335\n",
            "Train Epoch: 134 [2560/60000 (4%)]\tLoss: 741.550293\n",
            "Train Epoch: 134 [3840/60000 (6%)]\tLoss: 717.337708\n",
            "Train Epoch: 134 [5120/60000 (9%)]\tLoss: 739.940796\n",
            "Train Epoch: 134 [6400/60000 (11%)]\tLoss: 745.630371\n",
            "Train Epoch: 134 [7680/60000 (13%)]\tLoss: 722.620239\n",
            "Train Epoch: 134 [8960/60000 (15%)]\tLoss: 746.126892\n",
            "Train Epoch: 134 [10240/60000 (17%)]\tLoss: 749.709656\n",
            "Train Epoch: 134 [11520/60000 (19%)]\tLoss: 736.560730\n",
            "Train Epoch: 134 [12800/60000 (21%)]\tLoss: 721.255798\n",
            "Train Epoch: 134 [14080/60000 (23%)]\tLoss: 719.585022\n",
            "Train Epoch: 134 [15360/60000 (26%)]\tLoss: 746.744507\n",
            "Train Epoch: 134 [16640/60000 (28%)]\tLoss: 758.948547\n",
            "Train Epoch: 134 [17920/60000 (30%)]\tLoss: 733.833008\n",
            "Train Epoch: 134 [19200/60000 (32%)]\tLoss: 704.671997\n",
            "Train Epoch: 134 [20480/60000 (34%)]\tLoss: 731.802917\n",
            "Train Epoch: 134 [21760/60000 (36%)]\tLoss: 728.691528\n",
            "Train Epoch: 134 [23040/60000 (38%)]\tLoss: 747.182800\n",
            "Train Epoch: 134 [24320/60000 (41%)]\tLoss: 752.541382\n",
            "Train Epoch: 134 [25600/60000 (43%)]\tLoss: 763.669617\n",
            "Train Epoch: 134 [26880/60000 (45%)]\tLoss: 739.120483\n",
            "Train Epoch: 134 [28160/60000 (47%)]\tLoss: 728.300720\n",
            "Train Epoch: 134 [29440/60000 (49%)]\tLoss: 742.799683\n",
            "Train Epoch: 134 [30720/60000 (51%)]\tLoss: 748.035400\n",
            "Train Epoch: 134 [32000/60000 (53%)]\tLoss: 723.647034\n",
            "Train Epoch: 134 [33280/60000 (55%)]\tLoss: 744.459900\n",
            "Train Epoch: 134 [34560/60000 (58%)]\tLoss: 768.146973\n",
            "Train Epoch: 134 [35840/60000 (60%)]\tLoss: 749.890747\n",
            "Train Epoch: 134 [37120/60000 (62%)]\tLoss: 738.537842\n",
            "Train Epoch: 134 [38400/60000 (64%)]\tLoss: 744.957764\n",
            "Train Epoch: 134 [39680/60000 (66%)]\tLoss: 715.954773\n",
            "Train Epoch: 134 [40960/60000 (68%)]\tLoss: 723.326904\n",
            "Train Epoch: 134 [42240/60000 (70%)]\tLoss: 717.845520\n",
            "Train Epoch: 134 [43520/60000 (72%)]\tLoss: 735.347168\n",
            "Train Epoch: 134 [44800/60000 (75%)]\tLoss: 730.021301\n",
            "Train Epoch: 134 [46080/60000 (77%)]\tLoss: 720.237549\n",
            "Train Epoch: 134 [47360/60000 (79%)]\tLoss: 721.184204\n",
            "Train Epoch: 134 [48640/60000 (81%)]\tLoss: 716.091431\n",
            "Train Epoch: 134 [49920/60000 (83%)]\tLoss: 733.417664\n",
            "Train Epoch: 134 [51200/60000 (85%)]\tLoss: 737.905640\n",
            "Train Epoch: 134 [52480/60000 (87%)]\tLoss: 742.804443\n",
            "Train Epoch: 134 [53760/60000 (90%)]\tLoss: 720.467285\n",
            "Train Epoch: 134 [55040/60000 (92%)]\tLoss: 722.354492\n",
            "Train Epoch: 134 [56320/60000 (94%)]\tLoss: 707.409058\n",
            "Train Epoch: 134 [57600/60000 (96%)]\tLoss: 714.725342\n",
            "Train Epoch: 134 [58880/60000 (98%)]\tLoss: 695.550171\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786864519119263\n",
            "\n",
            "Train Epoch: 135 [0/60000 (0%)]\tLoss: 725.603943\n",
            "Train Epoch: 135 [1280/60000 (2%)]\tLoss: 741.603577\n",
            "Train Epoch: 135 [2560/60000 (4%)]\tLoss: 751.675110\n",
            "Train Epoch: 135 [3840/60000 (6%)]\tLoss: 728.333740\n",
            "Train Epoch: 135 [5120/60000 (9%)]\tLoss: 710.718628\n",
            "Train Epoch: 135 [6400/60000 (11%)]\tLoss: 746.587036\n",
            "Train Epoch: 135 [7680/60000 (13%)]\tLoss: 745.505859\n",
            "Train Epoch: 135 [8960/60000 (15%)]\tLoss: 714.569763\n",
            "Train Epoch: 135 [10240/60000 (17%)]\tLoss: 731.049561\n",
            "Train Epoch: 135 [11520/60000 (19%)]\tLoss: 736.240173\n",
            "Train Epoch: 135 [12800/60000 (21%)]\tLoss: 749.920044\n",
            "Train Epoch: 135 [14080/60000 (23%)]\tLoss: 717.187439\n",
            "Train Epoch: 135 [15360/60000 (26%)]\tLoss: 740.146973\n",
            "Train Epoch: 135 [16640/60000 (28%)]\tLoss: 747.643311\n",
            "Train Epoch: 135 [17920/60000 (30%)]\tLoss: 734.842896\n",
            "Train Epoch: 135 [19200/60000 (32%)]\tLoss: 741.861816\n",
            "Train Epoch: 135 [20480/60000 (34%)]\tLoss: 732.496155\n",
            "Train Epoch: 135 [21760/60000 (36%)]\tLoss: 736.729492\n",
            "Train Epoch: 135 [23040/60000 (38%)]\tLoss: 708.191345\n",
            "Train Epoch: 135 [24320/60000 (41%)]\tLoss: 753.088074\n",
            "Train Epoch: 135 [25600/60000 (43%)]\tLoss: 725.020752\n",
            "Train Epoch: 135 [26880/60000 (45%)]\tLoss: 755.311218\n",
            "Train Epoch: 135 [28160/60000 (47%)]\tLoss: 734.413818\n",
            "Train Epoch: 135 [29440/60000 (49%)]\tLoss: 727.803711\n",
            "Train Epoch: 135 [30720/60000 (51%)]\tLoss: 736.275696\n",
            "Train Epoch: 135 [32000/60000 (53%)]\tLoss: 746.736572\n",
            "Train Epoch: 135 [33280/60000 (55%)]\tLoss: 738.616394\n",
            "Train Epoch: 135 [34560/60000 (58%)]\tLoss: 738.742126\n",
            "Train Epoch: 135 [35840/60000 (60%)]\tLoss: 725.092346\n",
            "Train Epoch: 135 [37120/60000 (62%)]\tLoss: 768.047363\n",
            "Train Epoch: 135 [38400/60000 (64%)]\tLoss: 736.814209\n",
            "Train Epoch: 135 [39680/60000 (66%)]\tLoss: 744.659973\n",
            "Train Epoch: 135 [40960/60000 (68%)]\tLoss: 727.079285\n",
            "Train Epoch: 135 [42240/60000 (70%)]\tLoss: 730.107300\n",
            "Train Epoch: 135 [43520/60000 (72%)]\tLoss: 710.412170\n",
            "Train Epoch: 135 [44800/60000 (75%)]\tLoss: 725.740540\n",
            "Train Epoch: 135 [46080/60000 (77%)]\tLoss: 737.378845\n",
            "Train Epoch: 135 [47360/60000 (79%)]\tLoss: 708.823547\n",
            "Train Epoch: 135 [48640/60000 (81%)]\tLoss: 738.578735\n",
            "Train Epoch: 135 [49920/60000 (83%)]\tLoss: 729.410767\n",
            "Train Epoch: 135 [51200/60000 (85%)]\tLoss: 717.260254\n",
            "Train Epoch: 135 [52480/60000 (87%)]\tLoss: 750.464905\n",
            "Train Epoch: 135 [53760/60000 (90%)]\tLoss: 716.898621\n",
            "Train Epoch: 135 [55040/60000 (92%)]\tLoss: 712.416687\n",
            "Train Epoch: 135 [56320/60000 (94%)]\tLoss: 748.480286\n",
            "Train Epoch: 135 [57600/60000 (96%)]\tLoss: 740.090515\n",
            "Train Epoch: 135 [58880/60000 (98%)]\tLoss: 745.303284\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784368574619293\n",
            "\n",
            "Train Epoch: 136 [0/60000 (0%)]\tLoss: 732.912720\n",
            "Train Epoch: 136 [1280/60000 (2%)]\tLoss: 725.849670\n",
            "Train Epoch: 136 [2560/60000 (4%)]\tLoss: 744.139587\n",
            "Train Epoch: 136 [3840/60000 (6%)]\tLoss: 738.475769\n",
            "Train Epoch: 136 [5120/60000 (9%)]\tLoss: 762.373901\n",
            "Train Epoch: 136 [6400/60000 (11%)]\tLoss: 722.776855\n",
            "Train Epoch: 136 [7680/60000 (13%)]\tLoss: 772.108093\n",
            "Train Epoch: 136 [8960/60000 (15%)]\tLoss: 719.097107\n",
            "Train Epoch: 136 [10240/60000 (17%)]\tLoss: 720.927917\n",
            "Train Epoch: 136 [11520/60000 (19%)]\tLoss: 734.262756\n",
            "Train Epoch: 136 [12800/60000 (21%)]\tLoss: 734.419556\n",
            "Train Epoch: 136 [14080/60000 (23%)]\tLoss: 730.454346\n",
            "Train Epoch: 136 [15360/60000 (26%)]\tLoss: 763.094788\n",
            "Train Epoch: 136 [16640/60000 (28%)]\tLoss: 713.156189\n",
            "Train Epoch: 136 [17920/60000 (30%)]\tLoss: 704.729919\n",
            "Train Epoch: 136 [19200/60000 (32%)]\tLoss: 761.255859\n",
            "Train Epoch: 136 [20480/60000 (34%)]\tLoss: 738.847656\n",
            "Train Epoch: 136 [21760/60000 (36%)]\tLoss: 747.339050\n",
            "Train Epoch: 136 [23040/60000 (38%)]\tLoss: 732.805359\n",
            "Train Epoch: 136 [24320/60000 (41%)]\tLoss: 760.711609\n",
            "Train Epoch: 136 [25600/60000 (43%)]\tLoss: 724.533813\n",
            "Train Epoch: 136 [26880/60000 (45%)]\tLoss: 704.708191\n",
            "Train Epoch: 136 [28160/60000 (47%)]\tLoss: 755.583435\n",
            "Train Epoch: 136 [29440/60000 (49%)]\tLoss: 732.947937\n",
            "Train Epoch: 136 [30720/60000 (51%)]\tLoss: 712.712463\n",
            "Train Epoch: 136 [32000/60000 (53%)]\tLoss: 726.582031\n",
            "Train Epoch: 136 [33280/60000 (55%)]\tLoss: 734.579590\n",
            "Train Epoch: 136 [34560/60000 (58%)]\tLoss: 714.826233\n",
            "Train Epoch: 136 [35840/60000 (60%)]\tLoss: 751.571777\n",
            "Train Epoch: 136 [37120/60000 (62%)]\tLoss: 711.484497\n",
            "Train Epoch: 136 [38400/60000 (64%)]\tLoss: 731.800964\n",
            "Train Epoch: 136 [39680/60000 (66%)]\tLoss: 739.641846\n",
            "Train Epoch: 136 [40960/60000 (68%)]\tLoss: 732.542786\n",
            "Train Epoch: 136 [42240/60000 (70%)]\tLoss: 734.344604\n",
            "Train Epoch: 136 [43520/60000 (72%)]\tLoss: 753.544373\n",
            "Train Epoch: 136 [44800/60000 (75%)]\tLoss: 747.554382\n",
            "Train Epoch: 136 [46080/60000 (77%)]\tLoss: 755.420715\n",
            "Train Epoch: 136 [47360/60000 (79%)]\tLoss: 737.905151\n",
            "Train Epoch: 136 [48640/60000 (81%)]\tLoss: 705.571106\n",
            "Train Epoch: 136 [49920/60000 (83%)]\tLoss: 720.423706\n",
            "Train Epoch: 136 [51200/60000 (85%)]\tLoss: 740.526733\n",
            "Train Epoch: 136 [52480/60000 (87%)]\tLoss: 732.420593\n",
            "Train Epoch: 136 [53760/60000 (90%)]\tLoss: 742.672363\n",
            "Train Epoch: 136 [55040/60000 (92%)]\tLoss: 731.701782\n",
            "Train Epoch: 136 [56320/60000 (94%)]\tLoss: 749.924072\n",
            "Train Epoch: 136 [57600/60000 (96%)]\tLoss: 743.503296\n",
            "Train Epoch: 136 [58880/60000 (98%)]\tLoss: 725.119751\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783549010753632\n",
            "\n",
            "Train Epoch: 137 [0/60000 (0%)]\tLoss: 752.256836\n",
            "Train Epoch: 137 [1280/60000 (2%)]\tLoss: 715.787598\n",
            "Train Epoch: 137 [2560/60000 (4%)]\tLoss: 740.288635\n",
            "Train Epoch: 137 [3840/60000 (6%)]\tLoss: 747.017639\n",
            "Train Epoch: 137 [5120/60000 (9%)]\tLoss: 726.733459\n",
            "Train Epoch: 137 [6400/60000 (11%)]\tLoss: 733.113037\n",
            "Train Epoch: 137 [7680/60000 (13%)]\tLoss: 717.032837\n",
            "Train Epoch: 137 [8960/60000 (15%)]\tLoss: 766.690308\n",
            "Train Epoch: 137 [10240/60000 (17%)]\tLoss: 720.624023\n",
            "Train Epoch: 137 [11520/60000 (19%)]\tLoss: 746.233826\n",
            "Train Epoch: 137 [12800/60000 (21%)]\tLoss: 734.223633\n",
            "Train Epoch: 137 [14080/60000 (23%)]\tLoss: 726.512451\n",
            "Train Epoch: 137 [15360/60000 (26%)]\tLoss: 743.652039\n",
            "Train Epoch: 137 [16640/60000 (28%)]\tLoss: 735.041626\n",
            "Train Epoch: 137 [17920/60000 (30%)]\tLoss: 741.074280\n",
            "Train Epoch: 137 [19200/60000 (32%)]\tLoss: 722.592407\n",
            "Train Epoch: 137 [20480/60000 (34%)]\tLoss: 753.427856\n",
            "Train Epoch: 137 [21760/60000 (36%)]\tLoss: 722.015747\n",
            "Train Epoch: 137 [23040/60000 (38%)]\tLoss: 725.967834\n",
            "Train Epoch: 137 [24320/60000 (41%)]\tLoss: 727.622803\n",
            "Train Epoch: 137 [25600/60000 (43%)]\tLoss: 729.482605\n",
            "Train Epoch: 137 [26880/60000 (45%)]\tLoss: 714.716309\n",
            "Train Epoch: 137 [28160/60000 (47%)]\tLoss: 752.085754\n",
            "Train Epoch: 137 [29440/60000 (49%)]\tLoss: 758.885193\n",
            "Train Epoch: 137 [30720/60000 (51%)]\tLoss: 736.661743\n",
            "Train Epoch: 137 [32000/60000 (53%)]\tLoss: 737.180481\n",
            "Train Epoch: 137 [33280/60000 (55%)]\tLoss: 742.178650\n",
            "Train Epoch: 137 [34560/60000 (58%)]\tLoss: 745.414062\n",
            "Train Epoch: 137 [35840/60000 (60%)]\tLoss: 717.557800\n",
            "Train Epoch: 137 [37120/60000 (62%)]\tLoss: 747.751953\n",
            "Train Epoch: 137 [38400/60000 (64%)]\tLoss: 731.721802\n",
            "Train Epoch: 137 [39680/60000 (66%)]\tLoss: 744.152222\n",
            "Train Epoch: 137 [40960/60000 (68%)]\tLoss: 741.212769\n",
            "Train Epoch: 137 [42240/60000 (70%)]\tLoss: 716.472839\n",
            "Train Epoch: 137 [43520/60000 (72%)]\tLoss: 746.577881\n",
            "Train Epoch: 137 [44800/60000 (75%)]\tLoss: 736.250854\n",
            "Train Epoch: 137 [46080/60000 (77%)]\tLoss: 725.310425\n",
            "Train Epoch: 137 [47360/60000 (79%)]\tLoss: 720.271545\n",
            "Train Epoch: 137 [48640/60000 (81%)]\tLoss: 736.056824\n",
            "Train Epoch: 137 [49920/60000 (83%)]\tLoss: 732.976440\n",
            "Train Epoch: 137 [51200/60000 (85%)]\tLoss: 745.708862\n",
            "Train Epoch: 137 [52480/60000 (87%)]\tLoss: 724.195557\n",
            "Train Epoch: 137 [53760/60000 (90%)]\tLoss: 752.769775\n",
            "Train Epoch: 137 [55040/60000 (92%)]\tLoss: 716.137268\n",
            "Train Epoch: 137 [56320/60000 (94%)]\tLoss: 749.938843\n",
            "Train Epoch: 137 [57600/60000 (96%)]\tLoss: 724.589783\n",
            "Train Epoch: 137 [58880/60000 (98%)]\tLoss: 732.552002\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783414900302887\n",
            "\n",
            "Train Epoch: 138 [0/60000 (0%)]\tLoss: 717.278503\n",
            "Train Epoch: 138 [1280/60000 (2%)]\tLoss: 722.945862\n",
            "Train Epoch: 138 [2560/60000 (4%)]\tLoss: 736.583801\n",
            "Train Epoch: 138 [3840/60000 (6%)]\tLoss: 757.600037\n",
            "Train Epoch: 138 [5120/60000 (9%)]\tLoss: 731.640320\n",
            "Train Epoch: 138 [6400/60000 (11%)]\tLoss: 740.265747\n",
            "Train Epoch: 138 [7680/60000 (13%)]\tLoss: 727.919922\n",
            "Train Epoch: 138 [8960/60000 (15%)]\tLoss: 724.834106\n",
            "Train Epoch: 138 [10240/60000 (17%)]\tLoss: 759.769348\n",
            "Train Epoch: 138 [11520/60000 (19%)]\tLoss: 717.200134\n",
            "Train Epoch: 138 [12800/60000 (21%)]\tLoss: 728.760620\n",
            "Train Epoch: 138 [14080/60000 (23%)]\tLoss: 748.871765\n",
            "Train Epoch: 138 [15360/60000 (26%)]\tLoss: 750.665283\n",
            "Train Epoch: 138 [16640/60000 (28%)]\tLoss: 731.877686\n",
            "Train Epoch: 138 [17920/60000 (30%)]\tLoss: 755.026855\n",
            "Train Epoch: 138 [19200/60000 (32%)]\tLoss: 755.423523\n",
            "Train Epoch: 138 [20480/60000 (34%)]\tLoss: 749.241089\n",
            "Train Epoch: 138 [21760/60000 (36%)]\tLoss: 729.021484\n",
            "Train Epoch: 138 [23040/60000 (38%)]\tLoss: 705.554016\n",
            "Train Epoch: 138 [24320/60000 (41%)]\tLoss: 716.389099\n",
            "Train Epoch: 138 [25600/60000 (43%)]\tLoss: 734.186462\n",
            "Train Epoch: 138 [26880/60000 (45%)]\tLoss: 718.920044\n",
            "Train Epoch: 138 [28160/60000 (47%)]\tLoss: 743.677185\n",
            "Train Epoch: 138 [29440/60000 (49%)]\tLoss: 727.356323\n",
            "Train Epoch: 138 [30720/60000 (51%)]\tLoss: 739.168457\n",
            "Train Epoch: 138 [32000/60000 (53%)]\tLoss: 758.402588\n",
            "Train Epoch: 138 [33280/60000 (55%)]\tLoss: 747.293396\n",
            "Train Epoch: 138 [34560/60000 (58%)]\tLoss: 720.584167\n",
            "Train Epoch: 138 [35840/60000 (60%)]\tLoss: 749.925598\n",
            "Train Epoch: 138 [37120/60000 (62%)]\tLoss: 726.856506\n",
            "Train Epoch: 138 [38400/60000 (64%)]\tLoss: 740.491455\n",
            "Train Epoch: 138 [39680/60000 (66%)]\tLoss: 740.478210\n",
            "Train Epoch: 138 [40960/60000 (68%)]\tLoss: 753.869873\n",
            "Train Epoch: 138 [42240/60000 (70%)]\tLoss: 734.624878\n",
            "Train Epoch: 138 [43520/60000 (72%)]\tLoss: 727.499207\n",
            "Train Epoch: 138 [44800/60000 (75%)]\tLoss: 718.249512\n",
            "Train Epoch: 138 [46080/60000 (77%)]\tLoss: 731.566956\n",
            "Train Epoch: 138 [47360/60000 (79%)]\tLoss: 748.373230\n",
            "Train Epoch: 138 [48640/60000 (81%)]\tLoss: 735.855530\n",
            "Train Epoch: 138 [49920/60000 (83%)]\tLoss: 747.629883\n",
            "Train Epoch: 138 [51200/60000 (85%)]\tLoss: 727.807434\n",
            "Train Epoch: 138 [52480/60000 (87%)]\tLoss: 748.425110\n",
            "Train Epoch: 138 [53760/60000 (90%)]\tLoss: 737.101318\n",
            "Train Epoch: 138 [55040/60000 (92%)]\tLoss: 735.886292\n",
            "Train Epoch: 138 [56320/60000 (94%)]\tLoss: 721.866150\n",
            "Train Epoch: 138 [57600/60000 (96%)]\tLoss: 721.879272\n",
            "Train Epoch: 138 [58880/60000 (98%)]\tLoss: 733.569458\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781042635440826\n",
            "\n",
            "Train Epoch: 139 [0/60000 (0%)]\tLoss: 735.642273\n",
            "Train Epoch: 139 [1280/60000 (2%)]\tLoss: 763.064819\n",
            "Train Epoch: 139 [2560/60000 (4%)]\tLoss: 756.313477\n",
            "Train Epoch: 139 [3840/60000 (6%)]\tLoss: 719.109253\n",
            "Train Epoch: 139 [5120/60000 (9%)]\tLoss: 717.573303\n",
            "Train Epoch: 139 [6400/60000 (11%)]\tLoss: 746.629761\n",
            "Train Epoch: 139 [7680/60000 (13%)]\tLoss: 756.277283\n",
            "Train Epoch: 139 [8960/60000 (15%)]\tLoss: 715.547974\n",
            "Train Epoch: 139 [10240/60000 (17%)]\tLoss: 726.617065\n",
            "Train Epoch: 139 [11520/60000 (19%)]\tLoss: 755.097229\n",
            "Train Epoch: 139 [12800/60000 (21%)]\tLoss: 737.659119\n",
            "Train Epoch: 139 [14080/60000 (23%)]\tLoss: 766.425964\n",
            "Train Epoch: 139 [15360/60000 (26%)]\tLoss: 754.979492\n",
            "Train Epoch: 139 [16640/60000 (28%)]\tLoss: 745.469299\n",
            "Train Epoch: 139 [17920/60000 (30%)]\tLoss: 731.860718\n",
            "Train Epoch: 139 [19200/60000 (32%)]\tLoss: 725.538574\n",
            "Train Epoch: 139 [20480/60000 (34%)]\tLoss: 728.070740\n",
            "Train Epoch: 139 [21760/60000 (36%)]\tLoss: 733.132751\n",
            "Train Epoch: 139 [23040/60000 (38%)]\tLoss: 743.790588\n",
            "Train Epoch: 139 [24320/60000 (41%)]\tLoss: 715.380554\n",
            "Train Epoch: 139 [25600/60000 (43%)]\tLoss: 735.899231\n",
            "Train Epoch: 139 [26880/60000 (45%)]\tLoss: 737.926636\n",
            "Train Epoch: 139 [28160/60000 (47%)]\tLoss: 717.920532\n",
            "Train Epoch: 139 [29440/60000 (49%)]\tLoss: 747.311035\n",
            "Train Epoch: 139 [30720/60000 (51%)]\tLoss: 750.352600\n",
            "Train Epoch: 139 [32000/60000 (53%)]\tLoss: 736.636719\n",
            "Train Epoch: 139 [33280/60000 (55%)]\tLoss: 731.360840\n",
            "Train Epoch: 139 [34560/60000 (58%)]\tLoss: 722.353882\n",
            "Train Epoch: 139 [35840/60000 (60%)]\tLoss: 727.495361\n",
            "Train Epoch: 139 [37120/60000 (62%)]\tLoss: 738.417480\n",
            "Train Epoch: 139 [38400/60000 (64%)]\tLoss: 738.922119\n",
            "Train Epoch: 139 [39680/60000 (66%)]\tLoss: 713.811218\n",
            "Train Epoch: 139 [40960/60000 (68%)]\tLoss: 721.565674\n",
            "Train Epoch: 139 [42240/60000 (70%)]\tLoss: 724.499207\n",
            "Train Epoch: 139 [43520/60000 (72%)]\tLoss: 726.271790\n",
            "Train Epoch: 139 [44800/60000 (75%)]\tLoss: 720.689697\n",
            "Train Epoch: 139 [46080/60000 (77%)]\tLoss: 747.827576\n",
            "Train Epoch: 139 [47360/60000 (79%)]\tLoss: 732.131470\n",
            "Train Epoch: 139 [48640/60000 (81%)]\tLoss: 746.757263\n",
            "Train Epoch: 139 [49920/60000 (83%)]\tLoss: 729.338196\n",
            "Train Epoch: 139 [51200/60000 (85%)]\tLoss: 732.468201\n",
            "Train Epoch: 139 [52480/60000 (87%)]\tLoss: 743.027649\n",
            "Train Epoch: 139 [53760/60000 (90%)]\tLoss: 735.467651\n",
            "Train Epoch: 139 [55040/60000 (92%)]\tLoss: 744.019897\n",
            "Train Epoch: 139 [56320/60000 (94%)]\tLoss: 724.736023\n",
            "Train Epoch: 139 [57600/60000 (96%)]\tLoss: 731.666931\n",
            "Train Epoch: 139 [58880/60000 (98%)]\tLoss: 729.020203\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784937798976898\n",
            "\n",
            "Train Epoch: 140 [0/60000 (0%)]\tLoss: 724.296204\n",
            "Train Epoch: 140 [1280/60000 (2%)]\tLoss: 735.587830\n",
            "Train Epoch: 140 [2560/60000 (4%)]\tLoss: 738.400513\n",
            "Train Epoch: 140 [3840/60000 (6%)]\tLoss: 717.237000\n",
            "Train Epoch: 140 [5120/60000 (9%)]\tLoss: 732.171082\n",
            "Train Epoch: 140 [6400/60000 (11%)]\tLoss: 741.645386\n",
            "Train Epoch: 140 [7680/60000 (13%)]\tLoss: 735.700500\n",
            "Train Epoch: 140 [8960/60000 (15%)]\tLoss: 749.725098\n",
            "Train Epoch: 140 [10240/60000 (17%)]\tLoss: 731.435364\n",
            "Train Epoch: 140 [11520/60000 (19%)]\tLoss: 722.857239\n",
            "Train Epoch: 140 [12800/60000 (21%)]\tLoss: 761.548706\n",
            "Train Epoch: 140 [14080/60000 (23%)]\tLoss: 709.056641\n",
            "Train Epoch: 140 [15360/60000 (26%)]\tLoss: 717.834167\n",
            "Train Epoch: 140 [16640/60000 (28%)]\tLoss: 727.136536\n",
            "Train Epoch: 140 [17920/60000 (30%)]\tLoss: 749.362305\n",
            "Train Epoch: 140 [19200/60000 (32%)]\tLoss: 727.738770\n",
            "Train Epoch: 140 [20480/60000 (34%)]\tLoss: 746.348083\n",
            "Train Epoch: 140 [21760/60000 (36%)]\tLoss: 699.370972\n",
            "Train Epoch: 140 [23040/60000 (38%)]\tLoss: 746.619629\n",
            "Train Epoch: 140 [24320/60000 (41%)]\tLoss: 732.214355\n",
            "Train Epoch: 140 [25600/60000 (43%)]\tLoss: 740.620117\n",
            "Train Epoch: 140 [26880/60000 (45%)]\tLoss: 736.356384\n",
            "Train Epoch: 140 [28160/60000 (47%)]\tLoss: 736.365967\n",
            "Train Epoch: 140 [29440/60000 (49%)]\tLoss: 730.865662\n",
            "Train Epoch: 140 [30720/60000 (51%)]\tLoss: 731.667480\n",
            "Train Epoch: 140 [32000/60000 (53%)]\tLoss: 723.317627\n",
            "Train Epoch: 140 [33280/60000 (55%)]\tLoss: 740.832886\n",
            "Train Epoch: 140 [34560/60000 (58%)]\tLoss: 733.039856\n",
            "Train Epoch: 140 [35840/60000 (60%)]\tLoss: 736.179810\n",
            "Train Epoch: 140 [37120/60000 (62%)]\tLoss: 727.193176\n",
            "Train Epoch: 140 [38400/60000 (64%)]\tLoss: 715.284180\n",
            "Train Epoch: 140 [39680/60000 (66%)]\tLoss: 721.342468\n",
            "Train Epoch: 140 [40960/60000 (68%)]\tLoss: 711.594604\n",
            "Train Epoch: 140 [42240/60000 (70%)]\tLoss: 747.235352\n",
            "Train Epoch: 140 [43520/60000 (72%)]\tLoss: 744.597595\n",
            "Train Epoch: 140 [44800/60000 (75%)]\tLoss: 731.973511\n",
            "Train Epoch: 140 [46080/60000 (77%)]\tLoss: 750.024902\n",
            "Train Epoch: 140 [47360/60000 (79%)]\tLoss: 736.141846\n",
            "Train Epoch: 140 [48640/60000 (81%)]\tLoss: 719.512817\n",
            "Train Epoch: 140 [49920/60000 (83%)]\tLoss: 742.559570\n",
            "Train Epoch: 140 [51200/60000 (85%)]\tLoss: 719.750000\n",
            "Train Epoch: 140 [52480/60000 (87%)]\tLoss: 751.003540\n",
            "Train Epoch: 140 [53760/60000 (90%)]\tLoss: 734.510681\n",
            "Train Epoch: 140 [55040/60000 (92%)]\tLoss: 744.834656\n",
            "Train Epoch: 140 [56320/60000 (94%)]\tLoss: 734.425171\n",
            "Train Epoch: 140 [57600/60000 (96%)]\tLoss: 752.157532\n",
            "Train Epoch: 140 [58880/60000 (98%)]\tLoss: 751.468018\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978348046541214\n",
            "\n",
            "Train Epoch: 141 [0/60000 (0%)]\tLoss: 758.647339\n",
            "Train Epoch: 141 [1280/60000 (2%)]\tLoss: 729.931152\n",
            "Train Epoch: 141 [2560/60000 (4%)]\tLoss: 729.961853\n",
            "Train Epoch: 141 [3840/60000 (6%)]\tLoss: 755.279053\n",
            "Train Epoch: 141 [5120/60000 (9%)]\tLoss: 728.558533\n",
            "Train Epoch: 141 [6400/60000 (11%)]\tLoss: 746.315002\n",
            "Train Epoch: 141 [7680/60000 (13%)]\tLoss: 723.318542\n",
            "Train Epoch: 141 [8960/60000 (15%)]\tLoss: 749.315613\n",
            "Train Epoch: 141 [10240/60000 (17%)]\tLoss: 749.170410\n",
            "Train Epoch: 141 [11520/60000 (19%)]\tLoss: 736.422424\n",
            "Train Epoch: 141 [12800/60000 (21%)]\tLoss: 737.514099\n",
            "Train Epoch: 141 [14080/60000 (23%)]\tLoss: 729.893127\n",
            "Train Epoch: 141 [15360/60000 (26%)]\tLoss: 719.532593\n",
            "Train Epoch: 141 [16640/60000 (28%)]\tLoss: 719.959106\n",
            "Train Epoch: 141 [17920/60000 (30%)]\tLoss: 723.793457\n",
            "Train Epoch: 141 [19200/60000 (32%)]\tLoss: 748.110718\n",
            "Train Epoch: 141 [20480/60000 (34%)]\tLoss: 727.289246\n",
            "Train Epoch: 141 [21760/60000 (36%)]\tLoss: 757.808044\n",
            "Train Epoch: 141 [23040/60000 (38%)]\tLoss: 726.446228\n",
            "Train Epoch: 141 [24320/60000 (41%)]\tLoss: 714.226257\n",
            "Train Epoch: 141 [25600/60000 (43%)]\tLoss: 737.450745\n",
            "Train Epoch: 141 [26880/60000 (45%)]\tLoss: 762.802612\n",
            "Train Epoch: 141 [28160/60000 (47%)]\tLoss: 740.264648\n",
            "Train Epoch: 141 [29440/60000 (49%)]\tLoss: 713.674927\n",
            "Train Epoch: 141 [30720/60000 (51%)]\tLoss: 745.013245\n",
            "Train Epoch: 141 [32000/60000 (53%)]\tLoss: 729.079163\n",
            "Train Epoch: 141 [33280/60000 (55%)]\tLoss: 733.786377\n",
            "Train Epoch: 141 [34560/60000 (58%)]\tLoss: 727.228699\n",
            "Train Epoch: 141 [35840/60000 (60%)]\tLoss: 764.137390\n",
            "Train Epoch: 141 [37120/60000 (62%)]\tLoss: 739.077209\n",
            "Train Epoch: 141 [38400/60000 (64%)]\tLoss: 739.438171\n",
            "Train Epoch: 141 [39680/60000 (66%)]\tLoss: 743.037964\n",
            "Train Epoch: 141 [40960/60000 (68%)]\tLoss: 722.806458\n",
            "Train Epoch: 141 [42240/60000 (70%)]\tLoss: 759.900696\n",
            "Train Epoch: 141 [43520/60000 (72%)]\tLoss: 714.342468\n",
            "Train Epoch: 141 [44800/60000 (75%)]\tLoss: 722.941040\n",
            "Train Epoch: 141 [46080/60000 (77%)]\tLoss: 728.277466\n",
            "Train Epoch: 141 [47360/60000 (79%)]\tLoss: 741.786621\n",
            "Train Epoch: 141 [48640/60000 (81%)]\tLoss: 739.413818\n",
            "Train Epoch: 141 [49920/60000 (83%)]\tLoss: 710.993469\n",
            "Train Epoch: 141 [51200/60000 (85%)]\tLoss: 732.087585\n",
            "Train Epoch: 141 [52480/60000 (87%)]\tLoss: 737.838867\n",
            "Train Epoch: 141 [53760/60000 (90%)]\tLoss: 736.112305\n",
            "Train Epoch: 141 [55040/60000 (92%)]\tLoss: 736.280640\n",
            "Train Epoch: 141 [56320/60000 (94%)]\tLoss: 737.236450\n",
            "Train Epoch: 141 [57600/60000 (96%)]\tLoss: 758.948364\n",
            "Train Epoch: 141 [58880/60000 (98%)]\tLoss: 722.237915\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785809516906738\n",
            "\n",
            "Train Epoch: 142 [0/60000 (0%)]\tLoss: 736.775452\n",
            "Train Epoch: 142 [1280/60000 (2%)]\tLoss: 736.070374\n",
            "Train Epoch: 142 [2560/60000 (4%)]\tLoss: 741.247009\n",
            "Train Epoch: 142 [3840/60000 (6%)]\tLoss: 731.485413\n",
            "Train Epoch: 142 [5120/60000 (9%)]\tLoss: 752.458130\n",
            "Train Epoch: 142 [6400/60000 (11%)]\tLoss: 744.127930\n",
            "Train Epoch: 142 [7680/60000 (13%)]\tLoss: 733.165100\n",
            "Train Epoch: 142 [8960/60000 (15%)]\tLoss: 764.804993\n",
            "Train Epoch: 142 [10240/60000 (17%)]\tLoss: 710.028381\n",
            "Train Epoch: 142 [11520/60000 (19%)]\tLoss: 752.203918\n",
            "Train Epoch: 142 [12800/60000 (21%)]\tLoss: 748.209351\n",
            "Train Epoch: 142 [14080/60000 (23%)]\tLoss: 715.179749\n",
            "Train Epoch: 142 [15360/60000 (26%)]\tLoss: 737.868713\n",
            "Train Epoch: 142 [16640/60000 (28%)]\tLoss: 710.604614\n",
            "Train Epoch: 142 [17920/60000 (30%)]\tLoss: 733.595337\n",
            "Train Epoch: 142 [19200/60000 (32%)]\tLoss: 729.236572\n",
            "Train Epoch: 142 [20480/60000 (34%)]\tLoss: 751.465820\n",
            "Train Epoch: 142 [21760/60000 (36%)]\tLoss: 731.902466\n",
            "Train Epoch: 142 [23040/60000 (38%)]\tLoss: 738.521423\n",
            "Train Epoch: 142 [24320/60000 (41%)]\tLoss: 738.017883\n",
            "Train Epoch: 142 [25600/60000 (43%)]\tLoss: 743.624634\n",
            "Train Epoch: 142 [26880/60000 (45%)]\tLoss: 742.453247\n",
            "Train Epoch: 142 [28160/60000 (47%)]\tLoss: 752.219666\n",
            "Train Epoch: 142 [29440/60000 (49%)]\tLoss: 744.035950\n",
            "Train Epoch: 142 [30720/60000 (51%)]\tLoss: 739.088928\n",
            "Train Epoch: 142 [32000/60000 (53%)]\tLoss: 741.690857\n",
            "Train Epoch: 142 [33280/60000 (55%)]\tLoss: 726.658142\n",
            "Train Epoch: 142 [34560/60000 (58%)]\tLoss: 748.242554\n",
            "Train Epoch: 142 [35840/60000 (60%)]\tLoss: 751.166504\n",
            "Train Epoch: 142 [37120/60000 (62%)]\tLoss: 761.954895\n",
            "Train Epoch: 142 [38400/60000 (64%)]\tLoss: 743.894470\n",
            "Train Epoch: 142 [39680/60000 (66%)]\tLoss: 729.315674\n",
            "Train Epoch: 142 [40960/60000 (68%)]\tLoss: 726.495239\n",
            "Train Epoch: 142 [42240/60000 (70%)]\tLoss: 736.156189\n",
            "Train Epoch: 142 [43520/60000 (72%)]\tLoss: 753.855591\n",
            "Train Epoch: 142 [44800/60000 (75%)]\tLoss: 728.087158\n",
            "Train Epoch: 142 [46080/60000 (77%)]\tLoss: 751.057556\n",
            "Train Epoch: 142 [47360/60000 (79%)]\tLoss: 719.736572\n",
            "Train Epoch: 142 [48640/60000 (81%)]\tLoss: 730.660400\n",
            "Train Epoch: 142 [49920/60000 (83%)]\tLoss: 731.777649\n",
            "Train Epoch: 142 [51200/60000 (85%)]\tLoss: 748.449524\n",
            "Train Epoch: 142 [52480/60000 (87%)]\tLoss: 723.283875\n",
            "Train Epoch: 142 [53760/60000 (90%)]\tLoss: 760.555481\n",
            "Train Epoch: 142 [55040/60000 (92%)]\tLoss: 730.329834\n",
            "Train Epoch: 142 [56320/60000 (94%)]\tLoss: 711.089661\n",
            "Train Epoch: 142 [57600/60000 (96%)]\tLoss: 716.994446\n",
            "Train Epoch: 142 [58880/60000 (98%)]\tLoss: 753.544983\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784799218177795\n",
            "\n",
            "Train Epoch: 143 [0/60000 (0%)]\tLoss: 728.746338\n",
            "Train Epoch: 143 [1280/60000 (2%)]\tLoss: 730.277893\n",
            "Train Epoch: 143 [2560/60000 (4%)]\tLoss: 746.059753\n",
            "Train Epoch: 143 [3840/60000 (6%)]\tLoss: 742.892273\n",
            "Train Epoch: 143 [5120/60000 (9%)]\tLoss: 744.459961\n",
            "Train Epoch: 143 [6400/60000 (11%)]\tLoss: 724.120178\n",
            "Train Epoch: 143 [7680/60000 (13%)]\tLoss: 749.453613\n",
            "Train Epoch: 143 [8960/60000 (15%)]\tLoss: 735.174988\n",
            "Train Epoch: 143 [10240/60000 (17%)]\tLoss: 740.127625\n",
            "Train Epoch: 143 [11520/60000 (19%)]\tLoss: 753.427490\n",
            "Train Epoch: 143 [12800/60000 (21%)]\tLoss: 739.697144\n",
            "Train Epoch: 143 [14080/60000 (23%)]\tLoss: 757.825134\n",
            "Train Epoch: 143 [15360/60000 (26%)]\tLoss: 718.152893\n",
            "Train Epoch: 143 [16640/60000 (28%)]\tLoss: 732.413147\n",
            "Train Epoch: 143 [17920/60000 (30%)]\tLoss: 756.395752\n",
            "Train Epoch: 143 [19200/60000 (32%)]\tLoss: 723.380676\n",
            "Train Epoch: 143 [20480/60000 (34%)]\tLoss: 729.044556\n",
            "Train Epoch: 143 [21760/60000 (36%)]\tLoss: 736.262756\n",
            "Train Epoch: 143 [23040/60000 (38%)]\tLoss: 732.249695\n",
            "Train Epoch: 143 [24320/60000 (41%)]\tLoss: 733.718872\n",
            "Train Epoch: 143 [25600/60000 (43%)]\tLoss: 737.329651\n",
            "Train Epoch: 143 [26880/60000 (45%)]\tLoss: 725.959167\n",
            "Train Epoch: 143 [28160/60000 (47%)]\tLoss: 714.137634\n",
            "Train Epoch: 143 [29440/60000 (49%)]\tLoss: 735.792725\n",
            "Train Epoch: 143 [30720/60000 (51%)]\tLoss: 728.648682\n",
            "Train Epoch: 143 [32000/60000 (53%)]\tLoss: 740.515076\n",
            "Train Epoch: 143 [33280/60000 (55%)]\tLoss: 738.938477\n",
            "Train Epoch: 143 [34560/60000 (58%)]\tLoss: 733.539185\n",
            "Train Epoch: 143 [35840/60000 (60%)]\tLoss: 727.881042\n",
            "Train Epoch: 143 [37120/60000 (62%)]\tLoss: 752.487854\n",
            "Train Epoch: 143 [38400/60000 (64%)]\tLoss: 747.133728\n",
            "Train Epoch: 143 [39680/60000 (66%)]\tLoss: 745.691101\n",
            "Train Epoch: 143 [40960/60000 (68%)]\tLoss: 726.363159\n",
            "Train Epoch: 143 [42240/60000 (70%)]\tLoss: 738.764099\n",
            "Train Epoch: 143 [43520/60000 (72%)]\tLoss: 723.135254\n",
            "Train Epoch: 143 [44800/60000 (75%)]\tLoss: 719.929321\n",
            "Train Epoch: 143 [46080/60000 (77%)]\tLoss: 728.686035\n",
            "Train Epoch: 143 [47360/60000 (79%)]\tLoss: 749.393372\n",
            "Train Epoch: 143 [48640/60000 (81%)]\tLoss: 722.491699\n",
            "Train Epoch: 143 [49920/60000 (83%)]\tLoss: 754.206604\n",
            "Train Epoch: 143 [51200/60000 (85%)]\tLoss: 722.340332\n",
            "Train Epoch: 143 [52480/60000 (87%)]\tLoss: 728.303101\n",
            "Train Epoch: 143 [53760/60000 (90%)]\tLoss: 739.213989\n",
            "Train Epoch: 143 [55040/60000 (92%)]\tLoss: 723.732544\n",
            "Train Epoch: 143 [56320/60000 (94%)]\tLoss: 752.034302\n",
            "Train Epoch: 143 [57600/60000 (96%)]\tLoss: 749.000122\n",
            "Train Epoch: 143 [58880/60000 (98%)]\tLoss: 733.650696\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785946607589722\n",
            "\n",
            "Train Epoch: 144 [0/60000 (0%)]\tLoss: 733.840149\n",
            "Train Epoch: 144 [1280/60000 (2%)]\tLoss: 754.942200\n",
            "Train Epoch: 144 [2560/60000 (4%)]\tLoss: 729.217834\n",
            "Train Epoch: 144 [3840/60000 (6%)]\tLoss: 730.373840\n",
            "Train Epoch: 144 [5120/60000 (9%)]\tLoss: 747.900818\n",
            "Train Epoch: 144 [6400/60000 (11%)]\tLoss: 739.554382\n",
            "Train Epoch: 144 [7680/60000 (13%)]\tLoss: 731.461731\n",
            "Train Epoch: 144 [8960/60000 (15%)]\tLoss: 715.396362\n",
            "Train Epoch: 144 [10240/60000 (17%)]\tLoss: 748.174011\n",
            "Train Epoch: 144 [11520/60000 (19%)]\tLoss: 742.368835\n",
            "Train Epoch: 144 [12800/60000 (21%)]\tLoss: 743.289429\n",
            "Train Epoch: 144 [14080/60000 (23%)]\tLoss: 744.691467\n",
            "Train Epoch: 144 [15360/60000 (26%)]\tLoss: 724.427246\n",
            "Train Epoch: 144 [16640/60000 (28%)]\tLoss: 737.235596\n",
            "Train Epoch: 144 [17920/60000 (30%)]\tLoss: 753.102051\n",
            "Train Epoch: 144 [19200/60000 (32%)]\tLoss: 744.462280\n",
            "Train Epoch: 144 [20480/60000 (34%)]\tLoss: 727.713928\n",
            "Train Epoch: 144 [21760/60000 (36%)]\tLoss: 742.129700\n",
            "Train Epoch: 144 [23040/60000 (38%)]\tLoss: 726.982056\n",
            "Train Epoch: 144 [24320/60000 (41%)]\tLoss: 742.435120\n",
            "Train Epoch: 144 [25600/60000 (43%)]\tLoss: 737.880127\n",
            "Train Epoch: 144 [26880/60000 (45%)]\tLoss: 737.211060\n",
            "Train Epoch: 144 [28160/60000 (47%)]\tLoss: 712.122192\n",
            "Train Epoch: 144 [29440/60000 (49%)]\tLoss: 713.523621\n",
            "Train Epoch: 144 [30720/60000 (51%)]\tLoss: 715.319214\n",
            "Train Epoch: 144 [32000/60000 (53%)]\tLoss: 724.717041\n",
            "Train Epoch: 144 [33280/60000 (55%)]\tLoss: 740.027649\n",
            "Train Epoch: 144 [34560/60000 (58%)]\tLoss: 736.809204\n",
            "Train Epoch: 144 [35840/60000 (60%)]\tLoss: 758.125732\n",
            "Train Epoch: 144 [37120/60000 (62%)]\tLoss: 741.614441\n",
            "Train Epoch: 144 [38400/60000 (64%)]\tLoss: 697.779175\n",
            "Train Epoch: 144 [39680/60000 (66%)]\tLoss: 726.100769\n",
            "Train Epoch: 144 [40960/60000 (68%)]\tLoss: 740.627502\n",
            "Train Epoch: 144 [42240/60000 (70%)]\tLoss: 713.990601\n",
            "Train Epoch: 144 [43520/60000 (72%)]\tLoss: 767.871582\n",
            "Train Epoch: 144 [44800/60000 (75%)]\tLoss: 739.939575\n",
            "Train Epoch: 144 [46080/60000 (77%)]\tLoss: 735.512939\n",
            "Train Epoch: 144 [47360/60000 (79%)]\tLoss: 721.946289\n",
            "Train Epoch: 144 [48640/60000 (81%)]\tLoss: 703.162292\n",
            "Train Epoch: 144 [49920/60000 (83%)]\tLoss: 724.857544\n",
            "Train Epoch: 144 [51200/60000 (85%)]\tLoss: 739.498535\n",
            "Train Epoch: 144 [52480/60000 (87%)]\tLoss: 753.875061\n",
            "Train Epoch: 144 [53760/60000 (90%)]\tLoss: 743.054382\n",
            "Train Epoch: 144 [55040/60000 (92%)]\tLoss: 736.718018\n",
            "Train Epoch: 144 [56320/60000 (94%)]\tLoss: 757.766541\n",
            "Train Epoch: 144 [57600/60000 (96%)]\tLoss: 730.111206\n",
            "Train Epoch: 144 [58880/60000 (98%)]\tLoss: 758.692383\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978653371334076\n",
            "\n",
            "Train Epoch: 145 [0/60000 (0%)]\tLoss: 733.634583\n",
            "Train Epoch: 145 [1280/60000 (2%)]\tLoss: 723.837769\n",
            "Train Epoch: 145 [2560/60000 (4%)]\tLoss: 711.680847\n",
            "Train Epoch: 145 [3840/60000 (6%)]\tLoss: 765.169495\n",
            "Train Epoch: 145 [5120/60000 (9%)]\tLoss: 717.487488\n",
            "Train Epoch: 145 [6400/60000 (11%)]\tLoss: 751.369324\n",
            "Train Epoch: 145 [7680/60000 (13%)]\tLoss: 723.930237\n",
            "Train Epoch: 145 [8960/60000 (15%)]\tLoss: 714.227600\n",
            "Train Epoch: 145 [10240/60000 (17%)]\tLoss: 744.437012\n",
            "Train Epoch: 145 [11520/60000 (19%)]\tLoss: 736.284058\n",
            "Train Epoch: 145 [12800/60000 (21%)]\tLoss: 747.822571\n",
            "Train Epoch: 145 [14080/60000 (23%)]\tLoss: 723.259216\n",
            "Train Epoch: 145 [15360/60000 (26%)]\tLoss: 748.076599\n",
            "Train Epoch: 145 [16640/60000 (28%)]\tLoss: 762.692383\n",
            "Train Epoch: 145 [17920/60000 (30%)]\tLoss: 741.813721\n",
            "Train Epoch: 145 [19200/60000 (32%)]\tLoss: 726.608093\n",
            "Train Epoch: 145 [20480/60000 (34%)]\tLoss: 732.861816\n",
            "Train Epoch: 145 [21760/60000 (36%)]\tLoss: 736.228333\n",
            "Train Epoch: 145 [23040/60000 (38%)]\tLoss: 737.006592\n",
            "Train Epoch: 145 [24320/60000 (41%)]\tLoss: 716.835815\n",
            "Train Epoch: 145 [25600/60000 (43%)]\tLoss: 730.661499\n",
            "Train Epoch: 145 [26880/60000 (45%)]\tLoss: 740.375305\n",
            "Train Epoch: 145 [28160/60000 (47%)]\tLoss: 766.561157\n",
            "Train Epoch: 145 [29440/60000 (49%)]\tLoss: 722.836609\n",
            "Train Epoch: 145 [30720/60000 (51%)]\tLoss: 741.494263\n",
            "Train Epoch: 145 [32000/60000 (53%)]\tLoss: 732.984192\n",
            "Train Epoch: 145 [33280/60000 (55%)]\tLoss: 765.963379\n",
            "Train Epoch: 145 [34560/60000 (58%)]\tLoss: 732.293091\n",
            "Train Epoch: 145 [35840/60000 (60%)]\tLoss: 751.638794\n",
            "Train Epoch: 145 [37120/60000 (62%)]\tLoss: 739.586853\n",
            "Train Epoch: 145 [38400/60000 (64%)]\tLoss: 744.908142\n",
            "Train Epoch: 145 [39680/60000 (66%)]\tLoss: 759.046204\n",
            "Train Epoch: 145 [40960/60000 (68%)]\tLoss: 744.298950\n",
            "Train Epoch: 145 [42240/60000 (70%)]\tLoss: 739.513489\n",
            "Train Epoch: 145 [43520/60000 (72%)]\tLoss: 744.046204\n",
            "Train Epoch: 145 [44800/60000 (75%)]\tLoss: 736.468140\n",
            "Train Epoch: 145 [46080/60000 (77%)]\tLoss: 737.994385\n",
            "Train Epoch: 145 [47360/60000 (79%)]\tLoss: 712.812439\n",
            "Train Epoch: 145 [48640/60000 (81%)]\tLoss: 748.073242\n",
            "Train Epoch: 145 [49920/60000 (83%)]\tLoss: 744.148621\n",
            "Train Epoch: 145 [51200/60000 (85%)]\tLoss: 739.144836\n",
            "Train Epoch: 145 [52480/60000 (87%)]\tLoss: 716.872314\n",
            "Train Epoch: 145 [53760/60000 (90%)]\tLoss: 725.404175\n",
            "Train Epoch: 145 [55040/60000 (92%)]\tLoss: 766.639648\n",
            "Train Epoch: 145 [56320/60000 (94%)]\tLoss: 740.656128\n",
            "Train Epoch: 145 [57600/60000 (96%)]\tLoss: 740.247864\n",
            "Train Epoch: 145 [58880/60000 (98%)]\tLoss: 745.146240\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782491028308868\n",
            "\n",
            "Train Epoch: 146 [0/60000 (0%)]\tLoss: 720.953918\n",
            "Train Epoch: 146 [1280/60000 (2%)]\tLoss: 742.485596\n",
            "Train Epoch: 146 [2560/60000 (4%)]\tLoss: 764.468079\n",
            "Train Epoch: 146 [3840/60000 (6%)]\tLoss: 727.580200\n",
            "Train Epoch: 146 [5120/60000 (9%)]\tLoss: 734.650085\n",
            "Train Epoch: 146 [6400/60000 (11%)]\tLoss: 718.369629\n",
            "Train Epoch: 146 [7680/60000 (13%)]\tLoss: 747.545471\n",
            "Train Epoch: 146 [8960/60000 (15%)]\tLoss: 710.126831\n",
            "Train Epoch: 146 [10240/60000 (17%)]\tLoss: 725.871460\n",
            "Train Epoch: 146 [11520/60000 (19%)]\tLoss: 736.238831\n",
            "Train Epoch: 146 [12800/60000 (21%)]\tLoss: 725.140015\n",
            "Train Epoch: 146 [14080/60000 (23%)]\tLoss: 752.619873\n",
            "Train Epoch: 146 [15360/60000 (26%)]\tLoss: 753.479553\n",
            "Train Epoch: 146 [16640/60000 (28%)]\tLoss: 734.698242\n",
            "Train Epoch: 146 [17920/60000 (30%)]\tLoss: 745.874878\n",
            "Train Epoch: 146 [19200/60000 (32%)]\tLoss: 698.802856\n",
            "Train Epoch: 146 [20480/60000 (34%)]\tLoss: 759.578247\n",
            "Train Epoch: 146 [21760/60000 (36%)]\tLoss: 741.554382\n",
            "Train Epoch: 146 [23040/60000 (38%)]\tLoss: 707.637695\n",
            "Train Epoch: 146 [24320/60000 (41%)]\tLoss: 734.690918\n",
            "Train Epoch: 146 [25600/60000 (43%)]\tLoss: 733.781982\n",
            "Train Epoch: 146 [26880/60000 (45%)]\tLoss: 721.719666\n",
            "Train Epoch: 146 [28160/60000 (47%)]\tLoss: 718.740173\n",
            "Train Epoch: 146 [29440/60000 (49%)]\tLoss: 722.069824\n",
            "Train Epoch: 146 [30720/60000 (51%)]\tLoss: 724.508850\n",
            "Train Epoch: 146 [32000/60000 (53%)]\tLoss: 723.452454\n",
            "Train Epoch: 146 [33280/60000 (55%)]\tLoss: 729.504456\n",
            "Train Epoch: 146 [34560/60000 (58%)]\tLoss: 726.934875\n",
            "Train Epoch: 146 [35840/60000 (60%)]\tLoss: 722.223328\n",
            "Train Epoch: 146 [37120/60000 (62%)]\tLoss: 734.318665\n",
            "Train Epoch: 146 [38400/60000 (64%)]\tLoss: 732.755371\n",
            "Train Epoch: 146 [39680/60000 (66%)]\tLoss: 706.077026\n",
            "Train Epoch: 146 [40960/60000 (68%)]\tLoss: 732.765320\n",
            "Train Epoch: 146 [42240/60000 (70%)]\tLoss: 731.967712\n",
            "Train Epoch: 146 [43520/60000 (72%)]\tLoss: 714.946045\n",
            "Train Epoch: 146 [44800/60000 (75%)]\tLoss: 739.211426\n",
            "Train Epoch: 146 [46080/60000 (77%)]\tLoss: 732.236328\n",
            "Train Epoch: 146 [47360/60000 (79%)]\tLoss: 736.087219\n",
            "Train Epoch: 146 [48640/60000 (81%)]\tLoss: 708.630249\n",
            "Train Epoch: 146 [49920/60000 (83%)]\tLoss: 741.098267\n",
            "Train Epoch: 146 [51200/60000 (85%)]\tLoss: 730.584290\n",
            "Train Epoch: 146 [52480/60000 (87%)]\tLoss: 736.589539\n",
            "Train Epoch: 146 [53760/60000 (90%)]\tLoss: 750.653015\n",
            "Train Epoch: 146 [55040/60000 (92%)]\tLoss: 754.708740\n",
            "Train Epoch: 146 [56320/60000 (94%)]\tLoss: 755.844604\n",
            "Train Epoch: 146 [57600/60000 (96%)]\tLoss: 719.495117\n",
            "Train Epoch: 146 [58880/60000 (98%)]\tLoss: 739.024414\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784346222877502\n",
            "\n",
            "Train Epoch: 147 [0/60000 (0%)]\tLoss: 724.015076\n",
            "Train Epoch: 147 [1280/60000 (2%)]\tLoss: 731.995300\n",
            "Train Epoch: 147 [2560/60000 (4%)]\tLoss: 724.108215\n",
            "Train Epoch: 147 [3840/60000 (6%)]\tLoss: 713.629761\n",
            "Train Epoch: 147 [5120/60000 (9%)]\tLoss: 765.774231\n",
            "Train Epoch: 147 [6400/60000 (11%)]\tLoss: 740.723206\n",
            "Train Epoch: 147 [7680/60000 (13%)]\tLoss: 725.312622\n",
            "Train Epoch: 147 [8960/60000 (15%)]\tLoss: 712.165161\n",
            "Train Epoch: 147 [10240/60000 (17%)]\tLoss: 729.274475\n",
            "Train Epoch: 147 [11520/60000 (19%)]\tLoss: 743.522095\n",
            "Train Epoch: 147 [12800/60000 (21%)]\tLoss: 743.609009\n",
            "Train Epoch: 147 [14080/60000 (23%)]\tLoss: 756.123596\n",
            "Train Epoch: 147 [15360/60000 (26%)]\tLoss: 737.807190\n",
            "Train Epoch: 147 [16640/60000 (28%)]\tLoss: 764.327942\n",
            "Train Epoch: 147 [17920/60000 (30%)]\tLoss: 755.134766\n",
            "Train Epoch: 147 [19200/60000 (32%)]\tLoss: 745.538330\n",
            "Train Epoch: 147 [20480/60000 (34%)]\tLoss: 722.503479\n",
            "Train Epoch: 147 [21760/60000 (36%)]\tLoss: 739.959656\n",
            "Train Epoch: 147 [23040/60000 (38%)]\tLoss: 743.786194\n",
            "Train Epoch: 147 [24320/60000 (41%)]\tLoss: 702.226624\n",
            "Train Epoch: 147 [25600/60000 (43%)]\tLoss: 724.248108\n",
            "Train Epoch: 147 [26880/60000 (45%)]\tLoss: 742.763123\n",
            "Train Epoch: 147 [28160/60000 (47%)]\tLoss: 727.155823\n",
            "Train Epoch: 147 [29440/60000 (49%)]\tLoss: 749.673706\n",
            "Train Epoch: 147 [30720/60000 (51%)]\tLoss: 751.121155\n",
            "Train Epoch: 147 [32000/60000 (53%)]\tLoss: 724.498718\n",
            "Train Epoch: 147 [33280/60000 (55%)]\tLoss: 740.562805\n",
            "Train Epoch: 147 [34560/60000 (58%)]\tLoss: 762.065491\n",
            "Train Epoch: 147 [35840/60000 (60%)]\tLoss: 723.038452\n",
            "Train Epoch: 147 [37120/60000 (62%)]\tLoss: 748.477356\n",
            "Train Epoch: 147 [38400/60000 (64%)]\tLoss: 729.985657\n",
            "Train Epoch: 147 [39680/60000 (66%)]\tLoss: 715.286865\n",
            "Train Epoch: 147 [40960/60000 (68%)]\tLoss: 739.892822\n",
            "Train Epoch: 147 [42240/60000 (70%)]\tLoss: 721.215210\n",
            "Train Epoch: 147 [43520/60000 (72%)]\tLoss: 731.500427\n",
            "Train Epoch: 147 [44800/60000 (75%)]\tLoss: 749.880981\n",
            "Train Epoch: 147 [46080/60000 (77%)]\tLoss: 744.001831\n",
            "Train Epoch: 147 [47360/60000 (79%)]\tLoss: 736.969666\n",
            "Train Epoch: 147 [48640/60000 (81%)]\tLoss: 749.376953\n",
            "Train Epoch: 147 [49920/60000 (83%)]\tLoss: 751.142151\n",
            "Train Epoch: 147 [51200/60000 (85%)]\tLoss: 732.226440\n",
            "Train Epoch: 147 [52480/60000 (87%)]\tLoss: 742.734375\n",
            "Train Epoch: 147 [53760/60000 (90%)]\tLoss: 747.856445\n",
            "Train Epoch: 147 [55040/60000 (92%)]\tLoss: 751.386169\n",
            "Train Epoch: 147 [56320/60000 (94%)]\tLoss: 742.570312\n",
            "Train Epoch: 147 [57600/60000 (96%)]\tLoss: 748.144348\n",
            "Train Epoch: 147 [58880/60000 (98%)]\tLoss: 758.648132\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784143567085266\n",
            "\n",
            "Train Epoch: 148 [0/60000 (0%)]\tLoss: 742.595337\n",
            "Train Epoch: 148 [1280/60000 (2%)]\tLoss: 732.284119\n",
            "Train Epoch: 148 [2560/60000 (4%)]\tLoss: 722.472595\n",
            "Train Epoch: 148 [3840/60000 (6%)]\tLoss: 732.797913\n",
            "Train Epoch: 148 [5120/60000 (9%)]\tLoss: 725.790405\n",
            "Train Epoch: 148 [6400/60000 (11%)]\tLoss: 744.858032\n",
            "Train Epoch: 148 [7680/60000 (13%)]\tLoss: 755.503906\n",
            "Train Epoch: 148 [8960/60000 (15%)]\tLoss: 729.030701\n",
            "Train Epoch: 148 [10240/60000 (17%)]\tLoss: 741.763184\n",
            "Train Epoch: 148 [11520/60000 (19%)]\tLoss: 766.789429\n",
            "Train Epoch: 148 [12800/60000 (21%)]\tLoss: 735.237183\n",
            "Train Epoch: 148 [14080/60000 (23%)]\tLoss: 737.074463\n",
            "Train Epoch: 148 [15360/60000 (26%)]\tLoss: 754.309448\n",
            "Train Epoch: 148 [16640/60000 (28%)]\tLoss: 745.748596\n",
            "Train Epoch: 148 [17920/60000 (30%)]\tLoss: 725.490051\n",
            "Train Epoch: 148 [19200/60000 (32%)]\tLoss: 741.114014\n",
            "Train Epoch: 148 [20480/60000 (34%)]\tLoss: 716.348816\n",
            "Train Epoch: 148 [21760/60000 (36%)]\tLoss: 741.407959\n",
            "Train Epoch: 148 [23040/60000 (38%)]\tLoss: 743.834656\n",
            "Train Epoch: 148 [24320/60000 (41%)]\tLoss: 746.717468\n",
            "Train Epoch: 148 [25600/60000 (43%)]\tLoss: 740.747131\n",
            "Train Epoch: 148 [26880/60000 (45%)]\tLoss: 722.781616\n",
            "Train Epoch: 148 [28160/60000 (47%)]\tLoss: 726.488159\n",
            "Train Epoch: 148 [29440/60000 (49%)]\tLoss: 725.273682\n",
            "Train Epoch: 148 [30720/60000 (51%)]\tLoss: 752.038513\n",
            "Train Epoch: 148 [32000/60000 (53%)]\tLoss: 732.301453\n",
            "Train Epoch: 148 [33280/60000 (55%)]\tLoss: 732.539551\n",
            "Train Epoch: 148 [34560/60000 (58%)]\tLoss: 721.316711\n",
            "Train Epoch: 148 [35840/60000 (60%)]\tLoss: 717.364014\n",
            "Train Epoch: 148 [37120/60000 (62%)]\tLoss: 731.457397\n",
            "Train Epoch: 148 [38400/60000 (64%)]\tLoss: 726.161072\n",
            "Train Epoch: 148 [39680/60000 (66%)]\tLoss: 734.153870\n",
            "Train Epoch: 148 [40960/60000 (68%)]\tLoss: 733.972290\n",
            "Train Epoch: 148 [42240/60000 (70%)]\tLoss: 700.198792\n",
            "Train Epoch: 148 [43520/60000 (72%)]\tLoss: 744.111755\n",
            "Train Epoch: 148 [44800/60000 (75%)]\tLoss: 723.696106\n",
            "Train Epoch: 148 [46080/60000 (77%)]\tLoss: 731.297607\n",
            "Train Epoch: 148 [47360/60000 (79%)]\tLoss: 750.912903\n",
            "Train Epoch: 148 [48640/60000 (81%)]\tLoss: 746.897339\n",
            "Train Epoch: 148 [49920/60000 (83%)]\tLoss: 730.728027\n",
            "Train Epoch: 148 [51200/60000 (85%)]\tLoss: 739.230042\n",
            "Train Epoch: 148 [52480/60000 (87%)]\tLoss: 750.341125\n",
            "Train Epoch: 148 [53760/60000 (90%)]\tLoss: 720.403931\n",
            "Train Epoch: 148 [55040/60000 (92%)]\tLoss: 733.806824\n",
            "Train Epoch: 148 [56320/60000 (94%)]\tLoss: 737.108643\n",
            "Train Epoch: 148 [57600/60000 (96%)]\tLoss: 752.900330\n",
            "Train Epoch: 148 [58880/60000 (98%)]\tLoss: 765.236206\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787651300430298\n",
            "\n",
            "Train Epoch: 149 [0/60000 (0%)]\tLoss: 714.677673\n",
            "Train Epoch: 149 [1280/60000 (2%)]\tLoss: 739.288696\n",
            "Train Epoch: 149 [2560/60000 (4%)]\tLoss: 757.924194\n",
            "Train Epoch: 149 [3840/60000 (6%)]\tLoss: 735.560364\n",
            "Train Epoch: 149 [5120/60000 (9%)]\tLoss: 723.642944\n",
            "Train Epoch: 149 [6400/60000 (11%)]\tLoss: 766.334473\n",
            "Train Epoch: 149 [7680/60000 (13%)]\tLoss: 744.879578\n",
            "Train Epoch: 149 [8960/60000 (15%)]\tLoss: 734.954712\n",
            "Train Epoch: 149 [10240/60000 (17%)]\tLoss: 751.927612\n",
            "Train Epoch: 149 [11520/60000 (19%)]\tLoss: 733.451355\n",
            "Train Epoch: 149 [12800/60000 (21%)]\tLoss: 737.433411\n",
            "Train Epoch: 149 [14080/60000 (23%)]\tLoss: 733.029846\n",
            "Train Epoch: 149 [15360/60000 (26%)]\tLoss: 723.804688\n",
            "Train Epoch: 149 [16640/60000 (28%)]\tLoss: 762.306946\n",
            "Train Epoch: 149 [17920/60000 (30%)]\tLoss: 754.452148\n",
            "Train Epoch: 149 [19200/60000 (32%)]\tLoss: 718.595215\n",
            "Train Epoch: 149 [20480/60000 (34%)]\tLoss: 754.017517\n",
            "Train Epoch: 149 [21760/60000 (36%)]\tLoss: 730.661987\n",
            "Train Epoch: 149 [23040/60000 (38%)]\tLoss: 730.061035\n",
            "Train Epoch: 149 [24320/60000 (41%)]\tLoss: 709.570923\n",
            "Train Epoch: 149 [25600/60000 (43%)]\tLoss: 723.793701\n",
            "Train Epoch: 149 [26880/60000 (45%)]\tLoss: 721.703491\n",
            "Train Epoch: 149 [28160/60000 (47%)]\tLoss: 740.779114\n",
            "Train Epoch: 149 [29440/60000 (49%)]\tLoss: 766.680786\n",
            "Train Epoch: 149 [30720/60000 (51%)]\tLoss: 740.319702\n",
            "Train Epoch: 149 [32000/60000 (53%)]\tLoss: 727.118347\n",
            "Train Epoch: 149 [33280/60000 (55%)]\tLoss: 743.854858\n",
            "Train Epoch: 149 [34560/60000 (58%)]\tLoss: 752.059875\n",
            "Train Epoch: 149 [35840/60000 (60%)]\tLoss: 741.362488\n",
            "Train Epoch: 149 [37120/60000 (62%)]\tLoss: 730.914856\n",
            "Train Epoch: 149 [38400/60000 (64%)]\tLoss: 768.483887\n",
            "Train Epoch: 149 [39680/60000 (66%)]\tLoss: 721.948364\n",
            "Train Epoch: 149 [40960/60000 (68%)]\tLoss: 740.631714\n",
            "Train Epoch: 149 [42240/60000 (70%)]\tLoss: 740.986389\n",
            "Train Epoch: 149 [43520/60000 (72%)]\tLoss: 741.175232\n",
            "Train Epoch: 149 [44800/60000 (75%)]\tLoss: 732.460693\n",
            "Train Epoch: 149 [46080/60000 (77%)]\tLoss: 727.798706\n",
            "Train Epoch: 149 [47360/60000 (79%)]\tLoss: 714.226929\n",
            "Train Epoch: 149 [48640/60000 (81%)]\tLoss: 734.580444\n",
            "Train Epoch: 149 [49920/60000 (83%)]\tLoss: 736.422485\n",
            "Train Epoch: 149 [51200/60000 (85%)]\tLoss: 723.341248\n",
            "Train Epoch: 149 [52480/60000 (87%)]\tLoss: 727.986755\n",
            "Train Epoch: 149 [53760/60000 (90%)]\tLoss: 747.104004\n",
            "Train Epoch: 149 [55040/60000 (92%)]\tLoss: 742.818298\n",
            "Train Epoch: 149 [56320/60000 (94%)]\tLoss: 718.201111\n",
            "Train Epoch: 149 [57600/60000 (96%)]\tLoss: 735.765930\n",
            "Train Epoch: 149 [58880/60000 (98%)]\tLoss: 755.450256\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786439836025238\n",
            "\n",
            "Train Epoch: 150 [0/60000 (0%)]\tLoss: 746.702515\n",
            "Train Epoch: 150 [1280/60000 (2%)]\tLoss: 737.712158\n",
            "Train Epoch: 150 [2560/60000 (4%)]\tLoss: 725.100098\n",
            "Train Epoch: 150 [3840/60000 (6%)]\tLoss: 764.177124\n",
            "Train Epoch: 150 [5120/60000 (9%)]\tLoss: 702.837463\n",
            "Train Epoch: 150 [6400/60000 (11%)]\tLoss: 733.624756\n",
            "Train Epoch: 150 [7680/60000 (13%)]\tLoss: 737.165100\n",
            "Train Epoch: 150 [8960/60000 (15%)]\tLoss: 732.394836\n",
            "Train Epoch: 150 [10240/60000 (17%)]\tLoss: 756.268982\n",
            "Train Epoch: 150 [11520/60000 (19%)]\tLoss: 738.167114\n",
            "Train Epoch: 150 [12800/60000 (21%)]\tLoss: 723.828308\n",
            "Train Epoch: 150 [14080/60000 (23%)]\tLoss: 742.321777\n",
            "Train Epoch: 150 [15360/60000 (26%)]\tLoss: 748.404663\n",
            "Train Epoch: 150 [16640/60000 (28%)]\tLoss: 730.751587\n",
            "Train Epoch: 150 [17920/60000 (30%)]\tLoss: 728.524719\n",
            "Train Epoch: 150 [19200/60000 (32%)]\tLoss: 741.152039\n",
            "Train Epoch: 150 [20480/60000 (34%)]\tLoss: 736.578186\n",
            "Train Epoch: 150 [21760/60000 (36%)]\tLoss: 730.677979\n",
            "Train Epoch: 150 [23040/60000 (38%)]\tLoss: 721.135559\n",
            "Train Epoch: 150 [24320/60000 (41%)]\tLoss: 735.485840\n",
            "Train Epoch: 150 [25600/60000 (43%)]\tLoss: 739.715942\n",
            "Train Epoch: 150 [26880/60000 (45%)]\tLoss: 756.277588\n",
            "Train Epoch: 150 [28160/60000 (47%)]\tLoss: 728.011841\n",
            "Train Epoch: 150 [29440/60000 (49%)]\tLoss: 724.700745\n",
            "Train Epoch: 150 [30720/60000 (51%)]\tLoss: 736.708862\n",
            "Train Epoch: 150 [32000/60000 (53%)]\tLoss: 732.707214\n",
            "Train Epoch: 150 [33280/60000 (55%)]\tLoss: 721.628784\n",
            "Train Epoch: 150 [34560/60000 (58%)]\tLoss: 737.987488\n",
            "Train Epoch: 150 [35840/60000 (60%)]\tLoss: 747.659180\n",
            "Train Epoch: 150 [37120/60000 (62%)]\tLoss: 714.715027\n",
            "Train Epoch: 150 [38400/60000 (64%)]\tLoss: 740.383423\n",
            "Train Epoch: 150 [39680/60000 (66%)]\tLoss: 717.048584\n",
            "Train Epoch: 150 [40960/60000 (68%)]\tLoss: 724.625305\n",
            "Train Epoch: 150 [42240/60000 (70%)]\tLoss: 712.660278\n",
            "Train Epoch: 150 [43520/60000 (72%)]\tLoss: 727.969543\n",
            "Train Epoch: 150 [44800/60000 (75%)]\tLoss: 727.958740\n",
            "Train Epoch: 150 [46080/60000 (77%)]\tLoss: 725.309570\n",
            "Train Epoch: 150 [47360/60000 (79%)]\tLoss: 746.686462\n",
            "Train Epoch: 150 [48640/60000 (81%)]\tLoss: 737.296204\n",
            "Train Epoch: 150 [49920/60000 (83%)]\tLoss: 754.142944\n",
            "Train Epoch: 150 [51200/60000 (85%)]\tLoss: 717.707764\n",
            "Train Epoch: 150 [52480/60000 (87%)]\tLoss: 748.768982\n",
            "Train Epoch: 150 [53760/60000 (90%)]\tLoss: 725.007690\n",
            "Train Epoch: 150 [55040/60000 (92%)]\tLoss: 731.244934\n",
            "Train Epoch: 150 [56320/60000 (94%)]\tLoss: 743.322632\n",
            "Train Epoch: 150 [57600/60000 (96%)]\tLoss: 741.858154\n",
            "Train Epoch: 150 [58880/60000 (98%)]\tLoss: 730.992859\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786864519119263\n",
            "\n",
            "Train Epoch: 151 [0/60000 (0%)]\tLoss: 754.339539\n",
            "Train Epoch: 151 [1280/60000 (2%)]\tLoss: 741.024719\n",
            "Train Epoch: 151 [2560/60000 (4%)]\tLoss: 714.396667\n",
            "Train Epoch: 151 [3840/60000 (6%)]\tLoss: 741.382263\n",
            "Train Epoch: 151 [5120/60000 (9%)]\tLoss: 739.757507\n",
            "Train Epoch: 151 [6400/60000 (11%)]\tLoss: 735.243896\n",
            "Train Epoch: 151 [7680/60000 (13%)]\tLoss: 733.792969\n",
            "Train Epoch: 151 [8960/60000 (15%)]\tLoss: 728.991760\n",
            "Train Epoch: 151 [10240/60000 (17%)]\tLoss: 726.208740\n",
            "Train Epoch: 151 [11520/60000 (19%)]\tLoss: 743.781555\n",
            "Train Epoch: 151 [12800/60000 (21%)]\tLoss: 743.107361\n",
            "Train Epoch: 151 [14080/60000 (23%)]\tLoss: 726.073975\n",
            "Train Epoch: 151 [15360/60000 (26%)]\tLoss: 746.736572\n",
            "Train Epoch: 151 [16640/60000 (28%)]\tLoss: 745.141357\n",
            "Train Epoch: 151 [17920/60000 (30%)]\tLoss: 702.063293\n",
            "Train Epoch: 151 [19200/60000 (32%)]\tLoss: 709.445374\n",
            "Train Epoch: 151 [20480/60000 (34%)]\tLoss: 723.592834\n",
            "Train Epoch: 151 [21760/60000 (36%)]\tLoss: 730.698120\n",
            "Train Epoch: 151 [23040/60000 (38%)]\tLoss: 716.761353\n",
            "Train Epoch: 151 [24320/60000 (41%)]\tLoss: 732.831421\n",
            "Train Epoch: 151 [25600/60000 (43%)]\tLoss: 726.998169\n",
            "Train Epoch: 151 [26880/60000 (45%)]\tLoss: 744.317871\n",
            "Train Epoch: 151 [28160/60000 (47%)]\tLoss: 741.918396\n",
            "Train Epoch: 151 [29440/60000 (49%)]\tLoss: 739.526489\n",
            "Train Epoch: 151 [30720/60000 (51%)]\tLoss: 739.700745\n",
            "Train Epoch: 151 [32000/60000 (53%)]\tLoss: 732.103882\n",
            "Train Epoch: 151 [33280/60000 (55%)]\tLoss: 714.406616\n",
            "Train Epoch: 151 [34560/60000 (58%)]\tLoss: 731.995972\n",
            "Train Epoch: 151 [35840/60000 (60%)]\tLoss: 735.129883\n",
            "Train Epoch: 151 [37120/60000 (62%)]\tLoss: 752.346497\n",
            "Train Epoch: 151 [38400/60000 (64%)]\tLoss: 739.730530\n",
            "Train Epoch: 151 [39680/60000 (66%)]\tLoss: 733.362549\n",
            "Train Epoch: 151 [40960/60000 (68%)]\tLoss: 749.116089\n",
            "Train Epoch: 151 [42240/60000 (70%)]\tLoss: 742.600098\n",
            "Train Epoch: 151 [43520/60000 (72%)]\tLoss: 747.335327\n",
            "Train Epoch: 151 [44800/60000 (75%)]\tLoss: 738.629089\n",
            "Train Epoch: 151 [46080/60000 (77%)]\tLoss: 730.294128\n",
            "Train Epoch: 151 [47360/60000 (79%)]\tLoss: 758.100525\n",
            "Train Epoch: 151 [48640/60000 (81%)]\tLoss: 716.342224\n",
            "Train Epoch: 151 [49920/60000 (83%)]\tLoss: 737.039795\n",
            "Train Epoch: 151 [51200/60000 (85%)]\tLoss: 751.175415\n",
            "Train Epoch: 151 [52480/60000 (87%)]\tLoss: 735.322266\n",
            "Train Epoch: 151 [53760/60000 (90%)]\tLoss: 741.305359\n",
            "Train Epoch: 151 [55040/60000 (92%)]\tLoss: 768.278137\n",
            "Train Epoch: 151 [56320/60000 (94%)]\tLoss: 754.461670\n",
            "Train Epoch: 151 [57600/60000 (96%)]\tLoss: 739.833496\n",
            "Train Epoch: 151 [58880/60000 (98%)]\tLoss: 747.409241\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785639643669128\n",
            "\n",
            "Train Epoch: 152 [0/60000 (0%)]\tLoss: 735.332825\n",
            "Train Epoch: 152 [1280/60000 (2%)]\tLoss: 763.563416\n",
            "Train Epoch: 152 [2560/60000 (4%)]\tLoss: 748.607117\n",
            "Train Epoch: 152 [3840/60000 (6%)]\tLoss: 732.904785\n",
            "Train Epoch: 152 [5120/60000 (9%)]\tLoss: 728.138367\n",
            "Train Epoch: 152 [6400/60000 (11%)]\tLoss: 755.065369\n",
            "Train Epoch: 152 [7680/60000 (13%)]\tLoss: 739.603699\n",
            "Train Epoch: 152 [8960/60000 (15%)]\tLoss: 753.648010\n",
            "Train Epoch: 152 [10240/60000 (17%)]\tLoss: 713.366821\n",
            "Train Epoch: 152 [11520/60000 (19%)]\tLoss: 728.715576\n",
            "Train Epoch: 152 [12800/60000 (21%)]\tLoss: 713.429626\n",
            "Train Epoch: 152 [14080/60000 (23%)]\tLoss: 759.175781\n",
            "Train Epoch: 152 [15360/60000 (26%)]\tLoss: 737.319458\n",
            "Train Epoch: 152 [16640/60000 (28%)]\tLoss: 744.407471\n",
            "Train Epoch: 152 [17920/60000 (30%)]\tLoss: 742.681396\n",
            "Train Epoch: 152 [19200/60000 (32%)]\tLoss: 735.043335\n",
            "Train Epoch: 152 [20480/60000 (34%)]\tLoss: 758.176208\n",
            "Train Epoch: 152 [21760/60000 (36%)]\tLoss: 707.419067\n",
            "Train Epoch: 152 [23040/60000 (38%)]\tLoss: 732.624573\n",
            "Train Epoch: 152 [24320/60000 (41%)]\tLoss: 741.165955\n",
            "Train Epoch: 152 [25600/60000 (43%)]\tLoss: 748.483704\n",
            "Train Epoch: 152 [26880/60000 (45%)]\tLoss: 730.404297\n",
            "Train Epoch: 152 [28160/60000 (47%)]\tLoss: 728.768677\n",
            "Train Epoch: 152 [29440/60000 (49%)]\tLoss: 756.082825\n",
            "Train Epoch: 152 [30720/60000 (51%)]\tLoss: 764.309570\n",
            "Train Epoch: 152 [32000/60000 (53%)]\tLoss: 721.267273\n",
            "Train Epoch: 152 [33280/60000 (55%)]\tLoss: 736.916504\n",
            "Train Epoch: 152 [34560/60000 (58%)]\tLoss: 712.419434\n",
            "Train Epoch: 152 [35840/60000 (60%)]\tLoss: 726.746765\n",
            "Train Epoch: 152 [37120/60000 (62%)]\tLoss: 746.544922\n",
            "Train Epoch: 152 [38400/60000 (64%)]\tLoss: 745.425964\n",
            "Train Epoch: 152 [39680/60000 (66%)]\tLoss: 726.351440\n",
            "Train Epoch: 152 [40960/60000 (68%)]\tLoss: 752.181335\n",
            "Train Epoch: 152 [42240/60000 (70%)]\tLoss: 735.327209\n",
            "Train Epoch: 152 [43520/60000 (72%)]\tLoss: 758.334595\n",
            "Train Epoch: 152 [44800/60000 (75%)]\tLoss: 730.885620\n",
            "Train Epoch: 152 [46080/60000 (77%)]\tLoss: 719.703552\n",
            "Train Epoch: 152 [47360/60000 (79%)]\tLoss: 745.758057\n",
            "Train Epoch: 152 [48640/60000 (81%)]\tLoss: 724.119263\n",
            "Train Epoch: 152 [49920/60000 (83%)]\tLoss: 723.477783\n",
            "Train Epoch: 152 [51200/60000 (85%)]\tLoss: 743.665771\n",
            "Train Epoch: 152 [52480/60000 (87%)]\tLoss: 747.655579\n",
            "Train Epoch: 152 [53760/60000 (90%)]\tLoss: 735.604126\n",
            "Train Epoch: 152 [55040/60000 (92%)]\tLoss: 740.929810\n",
            "Train Epoch: 152 [56320/60000 (94%)]\tLoss: 738.082031\n",
            "Train Epoch: 152 [57600/60000 (96%)]\tLoss: 727.217102\n",
            "Train Epoch: 152 [58880/60000 (98%)]\tLoss: 727.972656\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785211980342865\n",
            "\n",
            "Train Epoch: 153 [0/60000 (0%)]\tLoss: 731.359314\n",
            "Train Epoch: 153 [1280/60000 (2%)]\tLoss: 738.690369\n",
            "Train Epoch: 153 [2560/60000 (4%)]\tLoss: 726.103394\n",
            "Train Epoch: 153 [3840/60000 (6%)]\tLoss: 722.716309\n",
            "Train Epoch: 153 [5120/60000 (9%)]\tLoss: 750.644226\n",
            "Train Epoch: 153 [6400/60000 (11%)]\tLoss: 740.771729\n",
            "Train Epoch: 153 [7680/60000 (13%)]\tLoss: 753.779907\n",
            "Train Epoch: 153 [8960/60000 (15%)]\tLoss: 737.802856\n",
            "Train Epoch: 153 [10240/60000 (17%)]\tLoss: 742.979126\n",
            "Train Epoch: 153 [11520/60000 (19%)]\tLoss: 710.831116\n",
            "Train Epoch: 153 [12800/60000 (21%)]\tLoss: 731.058411\n",
            "Train Epoch: 153 [14080/60000 (23%)]\tLoss: 712.407776\n",
            "Train Epoch: 153 [15360/60000 (26%)]\tLoss: 731.264221\n",
            "Train Epoch: 153 [16640/60000 (28%)]\tLoss: 735.791199\n",
            "Train Epoch: 153 [17920/60000 (30%)]\tLoss: 737.061401\n",
            "Train Epoch: 153 [19200/60000 (32%)]\tLoss: 723.412354\n",
            "Train Epoch: 153 [20480/60000 (34%)]\tLoss: 745.714233\n",
            "Train Epoch: 153 [21760/60000 (36%)]\tLoss: 750.098633\n",
            "Train Epoch: 153 [23040/60000 (38%)]\tLoss: 728.777954\n",
            "Train Epoch: 153 [24320/60000 (41%)]\tLoss: 740.095581\n",
            "Train Epoch: 153 [25600/60000 (43%)]\tLoss: 716.228394\n",
            "Train Epoch: 153 [26880/60000 (45%)]\tLoss: 741.924194\n",
            "Train Epoch: 153 [28160/60000 (47%)]\tLoss: 727.722961\n",
            "Train Epoch: 153 [29440/60000 (49%)]\tLoss: 714.356445\n",
            "Train Epoch: 153 [30720/60000 (51%)]\tLoss: 734.165710\n",
            "Train Epoch: 153 [32000/60000 (53%)]\tLoss: 738.734070\n",
            "Train Epoch: 153 [33280/60000 (55%)]\tLoss: 724.771057\n",
            "Train Epoch: 153 [34560/60000 (58%)]\tLoss: 738.849792\n",
            "Train Epoch: 153 [35840/60000 (60%)]\tLoss: 761.953552\n",
            "Train Epoch: 153 [37120/60000 (62%)]\tLoss: 769.853394\n",
            "Train Epoch: 153 [38400/60000 (64%)]\tLoss: 749.488159\n",
            "Train Epoch: 153 [39680/60000 (66%)]\tLoss: 739.689758\n",
            "Train Epoch: 153 [40960/60000 (68%)]\tLoss: 733.860657\n",
            "Train Epoch: 153 [42240/60000 (70%)]\tLoss: 751.877075\n",
            "Train Epoch: 153 [43520/60000 (72%)]\tLoss: 727.862915\n",
            "Train Epoch: 153 [44800/60000 (75%)]\tLoss: 742.114380\n",
            "Train Epoch: 153 [46080/60000 (77%)]\tLoss: 761.992493\n",
            "Train Epoch: 153 [47360/60000 (79%)]\tLoss: 731.580933\n",
            "Train Epoch: 153 [48640/60000 (81%)]\tLoss: 738.641052\n",
            "Train Epoch: 153 [49920/60000 (83%)]\tLoss: 744.396912\n",
            "Train Epoch: 153 [51200/60000 (85%)]\tLoss: 715.973877\n",
            "Train Epoch: 153 [52480/60000 (87%)]\tLoss: 729.404297\n",
            "Train Epoch: 153 [53760/60000 (90%)]\tLoss: 740.370667\n",
            "Train Epoch: 153 [55040/60000 (92%)]\tLoss: 718.675598\n",
            "Train Epoch: 153 [56320/60000 (94%)]\tLoss: 746.572021\n",
            "Train Epoch: 153 [57600/60000 (96%)]\tLoss: 740.112244\n",
            "Train Epoch: 153 [58880/60000 (98%)]\tLoss: 727.750793\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786740839481354\n",
            "\n",
            "Train Epoch: 154 [0/60000 (0%)]\tLoss: 728.905212\n",
            "Train Epoch: 154 [1280/60000 (2%)]\tLoss: 734.517029\n",
            "Train Epoch: 154 [2560/60000 (4%)]\tLoss: 740.452637\n",
            "Train Epoch: 154 [3840/60000 (6%)]\tLoss: 732.020813\n",
            "Train Epoch: 154 [5120/60000 (9%)]\tLoss: 762.322205\n",
            "Train Epoch: 154 [6400/60000 (11%)]\tLoss: 743.003845\n",
            "Train Epoch: 154 [7680/60000 (13%)]\tLoss: 719.588318\n",
            "Train Epoch: 154 [8960/60000 (15%)]\tLoss: 722.164734\n",
            "Train Epoch: 154 [10240/60000 (17%)]\tLoss: 727.020203\n",
            "Train Epoch: 154 [11520/60000 (19%)]\tLoss: 722.138977\n",
            "Train Epoch: 154 [12800/60000 (21%)]\tLoss: 749.714539\n",
            "Train Epoch: 154 [14080/60000 (23%)]\tLoss: 724.588501\n",
            "Train Epoch: 154 [15360/60000 (26%)]\tLoss: 726.419067\n",
            "Train Epoch: 154 [16640/60000 (28%)]\tLoss: 736.964783\n",
            "Train Epoch: 154 [17920/60000 (30%)]\tLoss: 713.119263\n",
            "Train Epoch: 154 [19200/60000 (32%)]\tLoss: 726.055664\n",
            "Train Epoch: 154 [20480/60000 (34%)]\tLoss: 742.901428\n",
            "Train Epoch: 154 [21760/60000 (36%)]\tLoss: 738.669556\n",
            "Train Epoch: 154 [23040/60000 (38%)]\tLoss: 712.077942\n",
            "Train Epoch: 154 [24320/60000 (41%)]\tLoss: 746.216919\n",
            "Train Epoch: 154 [25600/60000 (43%)]\tLoss: 721.039429\n",
            "Train Epoch: 154 [26880/60000 (45%)]\tLoss: 733.379333\n",
            "Train Epoch: 154 [28160/60000 (47%)]\tLoss: 750.025146\n",
            "Train Epoch: 154 [29440/60000 (49%)]\tLoss: 737.896790\n",
            "Train Epoch: 154 [30720/60000 (51%)]\tLoss: 738.762939\n",
            "Train Epoch: 154 [32000/60000 (53%)]\tLoss: 735.811584\n",
            "Train Epoch: 154 [33280/60000 (55%)]\tLoss: 746.118042\n",
            "Train Epoch: 154 [34560/60000 (58%)]\tLoss: 714.367554\n",
            "Train Epoch: 154 [35840/60000 (60%)]\tLoss: 736.397949\n",
            "Train Epoch: 154 [37120/60000 (62%)]\tLoss: 758.504211\n",
            "Train Epoch: 154 [38400/60000 (64%)]\tLoss: 759.629456\n",
            "Train Epoch: 154 [39680/60000 (66%)]\tLoss: 745.813171\n",
            "Train Epoch: 154 [40960/60000 (68%)]\tLoss: 738.161377\n",
            "Train Epoch: 154 [42240/60000 (70%)]\tLoss: 743.289612\n",
            "Train Epoch: 154 [43520/60000 (72%)]\tLoss: 712.709412\n",
            "Train Epoch: 154 [44800/60000 (75%)]\tLoss: 717.447205\n",
            "Train Epoch: 154 [46080/60000 (77%)]\tLoss: 740.606140\n",
            "Train Epoch: 154 [47360/60000 (79%)]\tLoss: 730.884888\n",
            "Train Epoch: 154 [48640/60000 (81%)]\tLoss: 732.342407\n",
            "Train Epoch: 154 [49920/60000 (83%)]\tLoss: 723.040894\n",
            "Train Epoch: 154 [51200/60000 (85%)]\tLoss: 735.791565\n",
            "Train Epoch: 154 [52480/60000 (87%)]\tLoss: 744.363342\n",
            "Train Epoch: 154 [53760/60000 (90%)]\tLoss: 728.743408\n",
            "Train Epoch: 154 [55040/60000 (92%)]\tLoss: 724.711365\n",
            "Train Epoch: 154 [56320/60000 (94%)]\tLoss: 733.266541\n",
            "Train Epoch: 154 [57600/60000 (96%)]\tLoss: 742.873108\n",
            "Train Epoch: 154 [58880/60000 (98%)]\tLoss: 736.027588\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780021905899048\n",
            "\n",
            "Train Epoch: 155 [0/60000 (0%)]\tLoss: 720.861816\n",
            "Train Epoch: 155 [1280/60000 (2%)]\tLoss: 747.254272\n",
            "Train Epoch: 155 [2560/60000 (4%)]\tLoss: 715.685852\n",
            "Train Epoch: 155 [3840/60000 (6%)]\tLoss: 724.106995\n",
            "Train Epoch: 155 [5120/60000 (9%)]\tLoss: 754.523987\n",
            "Train Epoch: 155 [6400/60000 (11%)]\tLoss: 736.773560\n",
            "Train Epoch: 155 [7680/60000 (13%)]\tLoss: 738.581848\n",
            "Train Epoch: 155 [8960/60000 (15%)]\tLoss: 765.412781\n",
            "Train Epoch: 155 [10240/60000 (17%)]\tLoss: 729.218872\n",
            "Train Epoch: 155 [11520/60000 (19%)]\tLoss: 734.168945\n",
            "Train Epoch: 155 [12800/60000 (21%)]\tLoss: 724.600769\n",
            "Train Epoch: 155 [14080/60000 (23%)]\tLoss: 743.650574\n",
            "Train Epoch: 155 [15360/60000 (26%)]\tLoss: 723.921814\n",
            "Train Epoch: 155 [16640/60000 (28%)]\tLoss: 770.650574\n",
            "Train Epoch: 155 [17920/60000 (30%)]\tLoss: 734.017334\n",
            "Train Epoch: 155 [19200/60000 (32%)]\tLoss: 734.802856\n",
            "Train Epoch: 155 [20480/60000 (34%)]\tLoss: 729.363831\n",
            "Train Epoch: 155 [21760/60000 (36%)]\tLoss: 709.127808\n",
            "Train Epoch: 155 [23040/60000 (38%)]\tLoss: 727.476074\n",
            "Train Epoch: 155 [24320/60000 (41%)]\tLoss: 734.983215\n",
            "Train Epoch: 155 [25600/60000 (43%)]\tLoss: 743.898621\n",
            "Train Epoch: 155 [26880/60000 (45%)]\tLoss: 758.449402\n",
            "Train Epoch: 155 [28160/60000 (47%)]\tLoss: 728.324158\n",
            "Train Epoch: 155 [29440/60000 (49%)]\tLoss: 734.643860\n",
            "Train Epoch: 155 [30720/60000 (51%)]\tLoss: 718.267517\n",
            "Train Epoch: 155 [32000/60000 (53%)]\tLoss: 706.756592\n",
            "Train Epoch: 155 [33280/60000 (55%)]\tLoss: 730.418213\n",
            "Train Epoch: 155 [34560/60000 (58%)]\tLoss: 751.810425\n",
            "Train Epoch: 155 [35840/60000 (60%)]\tLoss: 734.463501\n",
            "Train Epoch: 155 [37120/60000 (62%)]\tLoss: 723.251892\n",
            "Train Epoch: 155 [38400/60000 (64%)]\tLoss: 744.539062\n",
            "Train Epoch: 155 [39680/60000 (66%)]\tLoss: 732.240906\n",
            "Train Epoch: 155 [40960/60000 (68%)]\tLoss: 742.076660\n",
            "Train Epoch: 155 [42240/60000 (70%)]\tLoss: 730.752808\n",
            "Train Epoch: 155 [43520/60000 (72%)]\tLoss: 714.993835\n",
            "Train Epoch: 155 [44800/60000 (75%)]\tLoss: 731.889343\n",
            "Train Epoch: 155 [46080/60000 (77%)]\tLoss: 745.122009\n",
            "Train Epoch: 155 [47360/60000 (79%)]\tLoss: 750.651001\n",
            "Train Epoch: 155 [48640/60000 (81%)]\tLoss: 750.087524\n",
            "Train Epoch: 155 [49920/60000 (83%)]\tLoss: 733.595093\n",
            "Train Epoch: 155 [51200/60000 (85%)]\tLoss: 743.137939\n",
            "Train Epoch: 155 [52480/60000 (87%)]\tLoss: 729.277527\n",
            "Train Epoch: 155 [53760/60000 (90%)]\tLoss: 730.267029\n",
            "Train Epoch: 155 [55040/60000 (92%)]\tLoss: 733.086792\n",
            "Train Epoch: 155 [56320/60000 (94%)]\tLoss: 744.191467\n",
            "Train Epoch: 155 [57600/60000 (96%)]\tLoss: 725.183899\n",
            "Train Epoch: 155 [58880/60000 (98%)]\tLoss: 714.868286\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780690968036652\n",
            "\n",
            "Train Epoch: 156 [0/60000 (0%)]\tLoss: 730.703369\n",
            "Train Epoch: 156 [1280/60000 (2%)]\tLoss: 739.059143\n",
            "Train Epoch: 156 [2560/60000 (4%)]\tLoss: 759.907349\n",
            "Train Epoch: 156 [3840/60000 (6%)]\tLoss: 752.098694\n",
            "Train Epoch: 156 [5120/60000 (9%)]\tLoss: 737.742493\n",
            "Train Epoch: 156 [6400/60000 (11%)]\tLoss: 739.109619\n",
            "Train Epoch: 156 [7680/60000 (13%)]\tLoss: 746.069763\n",
            "Train Epoch: 156 [8960/60000 (15%)]\tLoss: 724.660645\n",
            "Train Epoch: 156 [10240/60000 (17%)]\tLoss: 741.344910\n",
            "Train Epoch: 156 [11520/60000 (19%)]\tLoss: 744.289978\n",
            "Train Epoch: 156 [12800/60000 (21%)]\tLoss: 734.150940\n",
            "Train Epoch: 156 [14080/60000 (23%)]\tLoss: 724.540955\n",
            "Train Epoch: 156 [15360/60000 (26%)]\tLoss: 751.797913\n",
            "Train Epoch: 156 [16640/60000 (28%)]\tLoss: 736.299805\n",
            "Train Epoch: 156 [17920/60000 (30%)]\tLoss: 738.247681\n",
            "Train Epoch: 156 [19200/60000 (32%)]\tLoss: 733.180481\n",
            "Train Epoch: 156 [20480/60000 (34%)]\tLoss: 746.941833\n",
            "Train Epoch: 156 [21760/60000 (36%)]\tLoss: 753.263977\n",
            "Train Epoch: 156 [23040/60000 (38%)]\tLoss: 758.922424\n",
            "Train Epoch: 156 [24320/60000 (41%)]\tLoss: 732.083801\n",
            "Train Epoch: 156 [25600/60000 (43%)]\tLoss: 730.559326\n",
            "Train Epoch: 156 [26880/60000 (45%)]\tLoss: 717.925049\n",
            "Train Epoch: 156 [28160/60000 (47%)]\tLoss: 737.631653\n",
            "Train Epoch: 156 [29440/60000 (49%)]\tLoss: 750.044006\n",
            "Train Epoch: 156 [30720/60000 (51%)]\tLoss: 743.385620\n",
            "Train Epoch: 156 [32000/60000 (53%)]\tLoss: 732.670288\n",
            "Train Epoch: 156 [33280/60000 (55%)]\tLoss: 748.738831\n",
            "Train Epoch: 156 [34560/60000 (58%)]\tLoss: 751.125427\n",
            "Train Epoch: 156 [35840/60000 (60%)]\tLoss: 735.263245\n",
            "Train Epoch: 156 [37120/60000 (62%)]\tLoss: 725.418274\n",
            "Train Epoch: 156 [38400/60000 (64%)]\tLoss: 745.889404\n",
            "Train Epoch: 156 [39680/60000 (66%)]\tLoss: 741.487610\n",
            "Train Epoch: 156 [40960/60000 (68%)]\tLoss: 727.744812\n",
            "Train Epoch: 156 [42240/60000 (70%)]\tLoss: 768.725159\n",
            "Train Epoch: 156 [43520/60000 (72%)]\tLoss: 711.597656\n",
            "Train Epoch: 156 [44800/60000 (75%)]\tLoss: 726.299744\n",
            "Train Epoch: 156 [46080/60000 (77%)]\tLoss: 736.148254\n",
            "Train Epoch: 156 [47360/60000 (79%)]\tLoss: 732.453125\n",
            "Train Epoch: 156 [48640/60000 (81%)]\tLoss: 754.919006\n",
            "Train Epoch: 156 [49920/60000 (83%)]\tLoss: 733.371338\n",
            "Train Epoch: 156 [51200/60000 (85%)]\tLoss: 754.797852\n",
            "Train Epoch: 156 [52480/60000 (87%)]\tLoss: 730.868530\n",
            "Train Epoch: 156 [53760/60000 (90%)]\tLoss: 747.607727\n",
            "Train Epoch: 156 [55040/60000 (92%)]\tLoss: 748.987488\n",
            "Train Epoch: 156 [56320/60000 (94%)]\tLoss: 733.974426\n",
            "Train Epoch: 156 [57600/60000 (96%)]\tLoss: 736.975830\n",
            "Train Epoch: 156 [58880/60000 (98%)]\tLoss: 732.164917\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978507936000824\n",
            "\n",
            "Train Epoch: 157 [0/60000 (0%)]\tLoss: 741.114319\n",
            "Train Epoch: 157 [1280/60000 (2%)]\tLoss: 742.650818\n",
            "Train Epoch: 157 [2560/60000 (4%)]\tLoss: 738.975708\n",
            "Train Epoch: 157 [3840/60000 (6%)]\tLoss: 744.303833\n",
            "Train Epoch: 157 [5120/60000 (9%)]\tLoss: 755.245178\n",
            "Train Epoch: 157 [6400/60000 (11%)]\tLoss: 729.364380\n",
            "Train Epoch: 157 [7680/60000 (13%)]\tLoss: 719.583740\n",
            "Train Epoch: 157 [8960/60000 (15%)]\tLoss: 713.457642\n",
            "Train Epoch: 157 [10240/60000 (17%)]\tLoss: 752.597961\n",
            "Train Epoch: 157 [11520/60000 (19%)]\tLoss: 726.474670\n",
            "Train Epoch: 157 [12800/60000 (21%)]\tLoss: 748.122925\n",
            "Train Epoch: 157 [14080/60000 (23%)]\tLoss: 729.585388\n",
            "Train Epoch: 157 [15360/60000 (26%)]\tLoss: 742.453369\n",
            "Train Epoch: 157 [16640/60000 (28%)]\tLoss: 761.188660\n",
            "Train Epoch: 157 [17920/60000 (30%)]\tLoss: 731.868042\n",
            "Train Epoch: 157 [19200/60000 (32%)]\tLoss: 736.642639\n",
            "Train Epoch: 157 [20480/60000 (34%)]\tLoss: 734.060303\n",
            "Train Epoch: 157 [21760/60000 (36%)]\tLoss: 730.885986\n",
            "Train Epoch: 157 [23040/60000 (38%)]\tLoss: 731.830200\n",
            "Train Epoch: 157 [24320/60000 (41%)]\tLoss: 748.534241\n",
            "Train Epoch: 157 [25600/60000 (43%)]\tLoss: 736.138000\n",
            "Train Epoch: 157 [26880/60000 (45%)]\tLoss: 714.239990\n",
            "Train Epoch: 157 [28160/60000 (47%)]\tLoss: 746.148071\n",
            "Train Epoch: 157 [29440/60000 (49%)]\tLoss: 734.428711\n",
            "Train Epoch: 157 [30720/60000 (51%)]\tLoss: 734.837219\n",
            "Train Epoch: 157 [32000/60000 (53%)]\tLoss: 750.824036\n",
            "Train Epoch: 157 [33280/60000 (55%)]\tLoss: 736.911560\n",
            "Train Epoch: 157 [34560/60000 (58%)]\tLoss: 739.778931\n",
            "Train Epoch: 157 [35840/60000 (60%)]\tLoss: 723.480896\n",
            "Train Epoch: 157 [37120/60000 (62%)]\tLoss: 733.192566\n",
            "Train Epoch: 157 [38400/60000 (64%)]\tLoss: 728.923218\n",
            "Train Epoch: 157 [39680/60000 (66%)]\tLoss: 711.815796\n",
            "Train Epoch: 157 [40960/60000 (68%)]\tLoss: 741.344910\n",
            "Train Epoch: 157 [42240/60000 (70%)]\tLoss: 743.266785\n",
            "Train Epoch: 157 [43520/60000 (72%)]\tLoss: 705.387817\n",
            "Train Epoch: 157 [44800/60000 (75%)]\tLoss: 763.338135\n",
            "Train Epoch: 157 [46080/60000 (77%)]\tLoss: 746.598694\n",
            "Train Epoch: 157 [47360/60000 (79%)]\tLoss: 732.154907\n",
            "Train Epoch: 157 [48640/60000 (81%)]\tLoss: 718.090027\n",
            "Train Epoch: 157 [49920/60000 (83%)]\tLoss: 745.156433\n",
            "Train Epoch: 157 [51200/60000 (85%)]\tLoss: 714.144470\n",
            "Train Epoch: 157 [52480/60000 (87%)]\tLoss: 748.329407\n",
            "Train Epoch: 157 [53760/60000 (90%)]\tLoss: 741.847717\n",
            "Train Epoch: 157 [55040/60000 (92%)]\tLoss: 726.918274\n",
            "Train Epoch: 157 [56320/60000 (94%)]\tLoss: 731.858704\n",
            "Train Epoch: 157 [57600/60000 (96%)]\tLoss: 734.368958\n",
            "Train Epoch: 157 [58880/60000 (98%)]\tLoss: 717.014771\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978258341550827\n",
            "\n",
            "Train Epoch: 158 [0/60000 (0%)]\tLoss: 726.684998\n",
            "Train Epoch: 158 [1280/60000 (2%)]\tLoss: 706.046021\n",
            "Train Epoch: 158 [2560/60000 (4%)]\tLoss: 744.734131\n",
            "Train Epoch: 158 [3840/60000 (6%)]\tLoss: 712.735046\n",
            "Train Epoch: 158 [5120/60000 (9%)]\tLoss: 745.773132\n",
            "Train Epoch: 158 [6400/60000 (11%)]\tLoss: 740.340759\n",
            "Train Epoch: 158 [7680/60000 (13%)]\tLoss: 708.891418\n",
            "Train Epoch: 158 [8960/60000 (15%)]\tLoss: 726.953186\n",
            "Train Epoch: 158 [10240/60000 (17%)]\tLoss: 728.950317\n",
            "Train Epoch: 158 [11520/60000 (19%)]\tLoss: 733.266235\n",
            "Train Epoch: 158 [12800/60000 (21%)]\tLoss: 751.202576\n",
            "Train Epoch: 158 [14080/60000 (23%)]\tLoss: 741.650757\n",
            "Train Epoch: 158 [15360/60000 (26%)]\tLoss: 707.655029\n",
            "Train Epoch: 158 [16640/60000 (28%)]\tLoss: 730.662170\n",
            "Train Epoch: 158 [17920/60000 (30%)]\tLoss: 738.469482\n",
            "Train Epoch: 158 [19200/60000 (32%)]\tLoss: 712.411804\n",
            "Train Epoch: 158 [20480/60000 (34%)]\tLoss: 753.374939\n",
            "Train Epoch: 158 [21760/60000 (36%)]\tLoss: 727.937500\n",
            "Train Epoch: 158 [23040/60000 (38%)]\tLoss: 738.244019\n",
            "Train Epoch: 158 [24320/60000 (41%)]\tLoss: 732.704590\n",
            "Train Epoch: 158 [25600/60000 (43%)]\tLoss: 747.942017\n",
            "Train Epoch: 158 [26880/60000 (45%)]\tLoss: 749.355774\n",
            "Train Epoch: 158 [28160/60000 (47%)]\tLoss: 753.828430\n",
            "Train Epoch: 158 [29440/60000 (49%)]\tLoss: 735.339233\n",
            "Train Epoch: 158 [30720/60000 (51%)]\tLoss: 720.013916\n",
            "Train Epoch: 158 [32000/60000 (53%)]\tLoss: 740.132324\n",
            "Train Epoch: 158 [33280/60000 (55%)]\tLoss: 744.081482\n",
            "Train Epoch: 158 [34560/60000 (58%)]\tLoss: 731.618408\n",
            "Train Epoch: 158 [35840/60000 (60%)]\tLoss: 721.206665\n",
            "Train Epoch: 158 [37120/60000 (62%)]\tLoss: 751.426697\n",
            "Train Epoch: 158 [38400/60000 (64%)]\tLoss: 721.262329\n",
            "Train Epoch: 158 [39680/60000 (66%)]\tLoss: 725.964783\n",
            "Train Epoch: 158 [40960/60000 (68%)]\tLoss: 743.066101\n",
            "Train Epoch: 158 [42240/60000 (70%)]\tLoss: 741.716125\n",
            "Train Epoch: 158 [43520/60000 (72%)]\tLoss: 740.608948\n",
            "Train Epoch: 158 [44800/60000 (75%)]\tLoss: 742.340088\n",
            "Train Epoch: 158 [46080/60000 (77%)]\tLoss: 735.236450\n",
            "Train Epoch: 158 [47360/60000 (79%)]\tLoss: 728.719971\n",
            "Train Epoch: 158 [48640/60000 (81%)]\tLoss: 734.313110\n",
            "Train Epoch: 158 [49920/60000 (83%)]\tLoss: 724.326172\n",
            "Train Epoch: 158 [51200/60000 (85%)]\tLoss: 743.972534\n",
            "Train Epoch: 158 [52480/60000 (87%)]\tLoss: 722.991028\n",
            "Train Epoch: 158 [53760/60000 (90%)]\tLoss: 719.342407\n",
            "Train Epoch: 158 [55040/60000 (92%)]\tLoss: 751.358826\n",
            "Train Epoch: 158 [56320/60000 (94%)]\tLoss: 767.237000\n",
            "Train Epoch: 158 [57600/60000 (96%)]\tLoss: 720.201660\n",
            "Train Epoch: 158 [58880/60000 (98%)]\tLoss: 718.233154\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782550632953644\n",
            "\n",
            "Train Epoch: 159 [0/60000 (0%)]\tLoss: 735.798584\n",
            "Train Epoch: 159 [1280/60000 (2%)]\tLoss: 731.868164\n",
            "Train Epoch: 159 [2560/60000 (4%)]\tLoss: 729.298706\n",
            "Train Epoch: 159 [3840/60000 (6%)]\tLoss: 756.413818\n",
            "Train Epoch: 159 [5120/60000 (9%)]\tLoss: 747.564026\n",
            "Train Epoch: 159 [6400/60000 (11%)]\tLoss: 735.154846\n",
            "Train Epoch: 159 [7680/60000 (13%)]\tLoss: 740.742065\n",
            "Train Epoch: 159 [8960/60000 (15%)]\tLoss: 735.067749\n",
            "Train Epoch: 159 [10240/60000 (17%)]\tLoss: 746.872559\n",
            "Train Epoch: 159 [11520/60000 (19%)]\tLoss: 730.691772\n",
            "Train Epoch: 159 [12800/60000 (21%)]\tLoss: 740.626404\n",
            "Train Epoch: 159 [14080/60000 (23%)]\tLoss: 748.713989\n",
            "Train Epoch: 159 [15360/60000 (26%)]\tLoss: 719.716980\n",
            "Train Epoch: 159 [16640/60000 (28%)]\tLoss: 718.822449\n",
            "Train Epoch: 159 [17920/60000 (30%)]\tLoss: 740.917358\n",
            "Train Epoch: 159 [19200/60000 (32%)]\tLoss: 733.824951\n",
            "Train Epoch: 159 [20480/60000 (34%)]\tLoss: 756.726990\n",
            "Train Epoch: 159 [21760/60000 (36%)]\tLoss: 748.671326\n",
            "Train Epoch: 159 [23040/60000 (38%)]\tLoss: 745.488281\n",
            "Train Epoch: 159 [24320/60000 (41%)]\tLoss: 710.883911\n",
            "Train Epoch: 159 [25600/60000 (43%)]\tLoss: 711.680542\n",
            "Train Epoch: 159 [26880/60000 (45%)]\tLoss: 743.204041\n",
            "Train Epoch: 159 [28160/60000 (47%)]\tLoss: 738.858826\n",
            "Train Epoch: 159 [29440/60000 (49%)]\tLoss: 734.188660\n",
            "Train Epoch: 159 [30720/60000 (51%)]\tLoss: 737.392151\n",
            "Train Epoch: 159 [32000/60000 (53%)]\tLoss: 736.991211\n",
            "Train Epoch: 159 [33280/60000 (55%)]\tLoss: 757.004395\n",
            "Train Epoch: 159 [34560/60000 (58%)]\tLoss: 729.016602\n",
            "Train Epoch: 159 [35840/60000 (60%)]\tLoss: 748.678223\n",
            "Train Epoch: 159 [37120/60000 (62%)]\tLoss: 711.163757\n",
            "Train Epoch: 159 [38400/60000 (64%)]\tLoss: 748.835083\n",
            "Train Epoch: 159 [39680/60000 (66%)]\tLoss: 742.285217\n",
            "Train Epoch: 159 [40960/60000 (68%)]\tLoss: 735.129883\n",
            "Train Epoch: 159 [42240/60000 (70%)]\tLoss: 725.849976\n",
            "Train Epoch: 159 [43520/60000 (72%)]\tLoss: 754.859924\n",
            "Train Epoch: 159 [44800/60000 (75%)]\tLoss: 723.237915\n",
            "Train Epoch: 159 [46080/60000 (77%)]\tLoss: 753.602112\n",
            "Train Epoch: 159 [47360/60000 (79%)]\tLoss: 734.084778\n",
            "Train Epoch: 159 [48640/60000 (81%)]\tLoss: 727.518372\n",
            "Train Epoch: 159 [49920/60000 (83%)]\tLoss: 753.366272\n",
            "Train Epoch: 159 [51200/60000 (85%)]\tLoss: 767.832458\n",
            "Train Epoch: 159 [52480/60000 (87%)]\tLoss: 719.510803\n",
            "Train Epoch: 159 [53760/60000 (90%)]\tLoss: 754.340454\n",
            "Train Epoch: 159 [55040/60000 (92%)]\tLoss: 729.693909\n",
            "Train Epoch: 159 [56320/60000 (94%)]\tLoss: 738.210327\n",
            "Train Epoch: 159 [57600/60000 (96%)]\tLoss: 719.938538\n",
            "Train Epoch: 159 [58880/60000 (98%)]\tLoss: 740.148315\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978064626455307\n",
            "\n",
            "Train Epoch: 160 [0/60000 (0%)]\tLoss: 744.574768\n",
            "Train Epoch: 160 [1280/60000 (2%)]\tLoss: 740.298828\n",
            "Train Epoch: 160 [2560/60000 (4%)]\tLoss: 722.069336\n",
            "Train Epoch: 160 [3840/60000 (6%)]\tLoss: 736.726562\n",
            "Train Epoch: 160 [5120/60000 (9%)]\tLoss: 744.544617\n",
            "Train Epoch: 160 [6400/60000 (11%)]\tLoss: 741.206604\n",
            "Train Epoch: 160 [7680/60000 (13%)]\tLoss: 716.626709\n",
            "Train Epoch: 160 [8960/60000 (15%)]\tLoss: 760.211121\n",
            "Train Epoch: 160 [10240/60000 (17%)]\tLoss: 721.775391\n",
            "Train Epoch: 160 [11520/60000 (19%)]\tLoss: 734.798645\n",
            "Train Epoch: 160 [12800/60000 (21%)]\tLoss: 738.481262\n",
            "Train Epoch: 160 [14080/60000 (23%)]\tLoss: 752.435974\n",
            "Train Epoch: 160 [15360/60000 (26%)]\tLoss: 731.595032\n",
            "Train Epoch: 160 [16640/60000 (28%)]\tLoss: 723.805603\n",
            "Train Epoch: 160 [17920/60000 (30%)]\tLoss: 741.658325\n",
            "Train Epoch: 160 [19200/60000 (32%)]\tLoss: 738.184143\n",
            "Train Epoch: 160 [20480/60000 (34%)]\tLoss: 744.239319\n",
            "Train Epoch: 160 [21760/60000 (36%)]\tLoss: 716.059326\n",
            "Train Epoch: 160 [23040/60000 (38%)]\tLoss: 728.794617\n",
            "Train Epoch: 160 [24320/60000 (41%)]\tLoss: 741.499573\n",
            "Train Epoch: 160 [25600/60000 (43%)]\tLoss: 734.465637\n",
            "Train Epoch: 160 [26880/60000 (45%)]\tLoss: 742.939575\n",
            "Train Epoch: 160 [28160/60000 (47%)]\tLoss: 719.296936\n",
            "Train Epoch: 160 [29440/60000 (49%)]\tLoss: 738.532104\n",
            "Train Epoch: 160 [30720/60000 (51%)]\tLoss: 723.145691\n",
            "Train Epoch: 160 [32000/60000 (53%)]\tLoss: 738.006165\n",
            "Train Epoch: 160 [33280/60000 (55%)]\tLoss: 728.193604\n",
            "Train Epoch: 160 [34560/60000 (58%)]\tLoss: 731.563965\n",
            "Train Epoch: 160 [35840/60000 (60%)]\tLoss: 749.789246\n",
            "Train Epoch: 160 [37120/60000 (62%)]\tLoss: 743.096069\n",
            "Train Epoch: 160 [38400/60000 (64%)]\tLoss: 722.054810\n",
            "Train Epoch: 160 [39680/60000 (66%)]\tLoss: 728.610352\n",
            "Train Epoch: 160 [40960/60000 (68%)]\tLoss: 740.206177\n",
            "Train Epoch: 160 [42240/60000 (70%)]\tLoss: 728.515015\n",
            "Train Epoch: 160 [43520/60000 (72%)]\tLoss: 766.257935\n",
            "Train Epoch: 160 [44800/60000 (75%)]\tLoss: 740.152405\n",
            "Train Epoch: 160 [46080/60000 (77%)]\tLoss: 774.017578\n",
            "Train Epoch: 160 [47360/60000 (79%)]\tLoss: 733.575317\n",
            "Train Epoch: 160 [48640/60000 (81%)]\tLoss: 747.835693\n",
            "Train Epoch: 160 [49920/60000 (83%)]\tLoss: 753.016602\n",
            "Train Epoch: 160 [51200/60000 (85%)]\tLoss: 716.875061\n",
            "Train Epoch: 160 [52480/60000 (87%)]\tLoss: 734.798523\n",
            "Train Epoch: 160 [53760/60000 (90%)]\tLoss: 746.257629\n",
            "Train Epoch: 160 [55040/60000 (92%)]\tLoss: 743.526062\n",
            "Train Epoch: 160 [56320/60000 (94%)]\tLoss: 734.664185\n",
            "Train Epoch: 160 [57600/60000 (96%)]\tLoss: 720.055176\n",
            "Train Epoch: 160 [58880/60000 (98%)]\tLoss: 739.476013\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784316420555115\n",
            "\n",
            "Train Epoch: 161 [0/60000 (0%)]\tLoss: 742.555237\n",
            "Train Epoch: 161 [1280/60000 (2%)]\tLoss: 746.721130\n",
            "Train Epoch: 161 [2560/60000 (4%)]\tLoss: 723.385315\n",
            "Train Epoch: 161 [3840/60000 (6%)]\tLoss: 736.851807\n",
            "Train Epoch: 161 [5120/60000 (9%)]\tLoss: 736.014893\n",
            "Train Epoch: 161 [6400/60000 (11%)]\tLoss: 734.802979\n",
            "Train Epoch: 161 [7680/60000 (13%)]\tLoss: 756.805237\n",
            "Train Epoch: 161 [8960/60000 (15%)]\tLoss: 722.072144\n",
            "Train Epoch: 161 [10240/60000 (17%)]\tLoss: 715.020508\n",
            "Train Epoch: 161 [11520/60000 (19%)]\tLoss: 732.073608\n",
            "Train Epoch: 161 [12800/60000 (21%)]\tLoss: 734.464722\n",
            "Train Epoch: 161 [14080/60000 (23%)]\tLoss: 737.174744\n",
            "Train Epoch: 161 [15360/60000 (26%)]\tLoss: 714.426453\n",
            "Train Epoch: 161 [16640/60000 (28%)]\tLoss: 698.007263\n",
            "Train Epoch: 161 [17920/60000 (30%)]\tLoss: 738.673340\n",
            "Train Epoch: 161 [19200/60000 (32%)]\tLoss: 712.606262\n",
            "Train Epoch: 161 [20480/60000 (34%)]\tLoss: 712.749268\n",
            "Train Epoch: 161 [21760/60000 (36%)]\tLoss: 721.867126\n",
            "Train Epoch: 161 [23040/60000 (38%)]\tLoss: 728.336914\n",
            "Train Epoch: 161 [24320/60000 (41%)]\tLoss: 721.140320\n",
            "Train Epoch: 161 [25600/60000 (43%)]\tLoss: 740.968628\n",
            "Train Epoch: 161 [26880/60000 (45%)]\tLoss: 748.698303\n",
            "Train Epoch: 161 [28160/60000 (47%)]\tLoss: 749.249695\n",
            "Train Epoch: 161 [29440/60000 (49%)]\tLoss: 721.954773\n",
            "Train Epoch: 161 [30720/60000 (51%)]\tLoss: 721.852417\n",
            "Train Epoch: 161 [32000/60000 (53%)]\tLoss: 750.886719\n",
            "Train Epoch: 161 [33280/60000 (55%)]\tLoss: 728.356506\n",
            "Train Epoch: 161 [34560/60000 (58%)]\tLoss: 738.405701\n",
            "Train Epoch: 161 [35840/60000 (60%)]\tLoss: 727.428467\n",
            "Train Epoch: 161 [37120/60000 (62%)]\tLoss: 742.220642\n",
            "Train Epoch: 161 [38400/60000 (64%)]\tLoss: 721.713196\n",
            "Train Epoch: 161 [39680/60000 (66%)]\tLoss: 735.926880\n",
            "Train Epoch: 161 [40960/60000 (68%)]\tLoss: 740.799316\n",
            "Train Epoch: 161 [42240/60000 (70%)]\tLoss: 761.961548\n",
            "Train Epoch: 161 [43520/60000 (72%)]\tLoss: 734.691284\n",
            "Train Epoch: 161 [44800/60000 (75%)]\tLoss: 731.666260\n",
            "Train Epoch: 161 [46080/60000 (77%)]\tLoss: 709.702698\n",
            "Train Epoch: 161 [47360/60000 (79%)]\tLoss: 737.265015\n",
            "Train Epoch: 161 [48640/60000 (81%)]\tLoss: 739.941162\n",
            "Train Epoch: 161 [49920/60000 (83%)]\tLoss: 726.877808\n",
            "Train Epoch: 161 [51200/60000 (85%)]\tLoss: 741.189941\n",
            "Train Epoch: 161 [52480/60000 (87%)]\tLoss: 725.495728\n",
            "Train Epoch: 161 [53760/60000 (90%)]\tLoss: 712.822815\n",
            "Train Epoch: 161 [55040/60000 (92%)]\tLoss: 731.066467\n",
            "Train Epoch: 161 [56320/60000 (94%)]\tLoss: 726.043030\n",
            "Train Epoch: 161 [57600/60000 (96%)]\tLoss: 747.442017\n",
            "Train Epoch: 161 [58880/60000 (98%)]\tLoss: 757.690613\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782142341136932\n",
            "\n",
            "Train Epoch: 162 [0/60000 (0%)]\tLoss: 730.932861\n",
            "Train Epoch: 162 [1280/60000 (2%)]\tLoss: 743.781433\n",
            "Train Epoch: 162 [2560/60000 (4%)]\tLoss: 716.323547\n",
            "Train Epoch: 162 [3840/60000 (6%)]\tLoss: 721.243530\n",
            "Train Epoch: 162 [5120/60000 (9%)]\tLoss: 742.105164\n",
            "Train Epoch: 162 [6400/60000 (11%)]\tLoss: 733.806213\n",
            "Train Epoch: 162 [7680/60000 (13%)]\tLoss: 736.403687\n",
            "Train Epoch: 162 [8960/60000 (15%)]\tLoss: 740.933899\n",
            "Train Epoch: 162 [10240/60000 (17%)]\tLoss: 729.643677\n",
            "Train Epoch: 162 [11520/60000 (19%)]\tLoss: 750.006226\n",
            "Train Epoch: 162 [12800/60000 (21%)]\tLoss: 765.995239\n",
            "Train Epoch: 162 [14080/60000 (23%)]\tLoss: 734.121216\n",
            "Train Epoch: 162 [15360/60000 (26%)]\tLoss: 736.759338\n",
            "Train Epoch: 162 [16640/60000 (28%)]\tLoss: 736.647156\n",
            "Train Epoch: 162 [17920/60000 (30%)]\tLoss: 737.722229\n",
            "Train Epoch: 162 [19200/60000 (32%)]\tLoss: 737.918823\n",
            "Train Epoch: 162 [20480/60000 (34%)]\tLoss: 742.379700\n",
            "Train Epoch: 162 [21760/60000 (36%)]\tLoss: 756.320068\n",
            "Train Epoch: 162 [23040/60000 (38%)]\tLoss: 747.197571\n",
            "Train Epoch: 162 [24320/60000 (41%)]\tLoss: 737.686707\n",
            "Train Epoch: 162 [25600/60000 (43%)]\tLoss: 724.449158\n",
            "Train Epoch: 162 [26880/60000 (45%)]\tLoss: 731.924500\n",
            "Train Epoch: 162 [28160/60000 (47%)]\tLoss: 740.932983\n",
            "Train Epoch: 162 [29440/60000 (49%)]\tLoss: 719.057617\n",
            "Train Epoch: 162 [30720/60000 (51%)]\tLoss: 732.660583\n",
            "Train Epoch: 162 [32000/60000 (53%)]\tLoss: 750.982849\n",
            "Train Epoch: 162 [33280/60000 (55%)]\tLoss: 757.866455\n",
            "Train Epoch: 162 [34560/60000 (58%)]\tLoss: 749.550110\n",
            "Train Epoch: 162 [35840/60000 (60%)]\tLoss: 731.896851\n",
            "Train Epoch: 162 [37120/60000 (62%)]\tLoss: 743.584473\n",
            "Train Epoch: 162 [38400/60000 (64%)]\tLoss: 748.701721\n",
            "Train Epoch: 162 [39680/60000 (66%)]\tLoss: 730.001221\n",
            "Train Epoch: 162 [40960/60000 (68%)]\tLoss: 755.784546\n",
            "Train Epoch: 162 [42240/60000 (70%)]\tLoss: 756.931824\n",
            "Train Epoch: 162 [43520/60000 (72%)]\tLoss: 737.877502\n",
            "Train Epoch: 162 [44800/60000 (75%)]\tLoss: 745.321716\n",
            "Train Epoch: 162 [46080/60000 (77%)]\tLoss: 716.307800\n",
            "Train Epoch: 162 [47360/60000 (79%)]\tLoss: 730.570007\n",
            "Train Epoch: 162 [48640/60000 (81%)]\tLoss: 759.341736\n",
            "Train Epoch: 162 [49920/60000 (83%)]\tLoss: 756.146118\n",
            "Train Epoch: 162 [51200/60000 (85%)]\tLoss: 739.901001\n",
            "Train Epoch: 162 [52480/60000 (87%)]\tLoss: 729.742554\n",
            "Train Epoch: 162 [53760/60000 (90%)]\tLoss: 715.044556\n",
            "Train Epoch: 162 [55040/60000 (92%)]\tLoss: 732.420410\n",
            "Train Epoch: 162 [56320/60000 (94%)]\tLoss: 751.042175\n",
            "Train Epoch: 162 [57600/60000 (96%)]\tLoss: 733.039429\n",
            "Train Epoch: 162 [58880/60000 (98%)]\tLoss: 734.375854\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978045403957367\n",
            "\n",
            "Train Epoch: 163 [0/60000 (0%)]\tLoss: 740.472290\n",
            "Train Epoch: 163 [1280/60000 (2%)]\tLoss: 720.887085\n",
            "Train Epoch: 163 [2560/60000 (4%)]\tLoss: 746.007141\n",
            "Train Epoch: 163 [3840/60000 (6%)]\tLoss: 726.177124\n",
            "Train Epoch: 163 [5120/60000 (9%)]\tLoss: 755.413208\n",
            "Train Epoch: 163 [6400/60000 (11%)]\tLoss: 747.692627\n",
            "Train Epoch: 163 [7680/60000 (13%)]\tLoss: 734.043030\n",
            "Train Epoch: 163 [8960/60000 (15%)]\tLoss: 754.090759\n",
            "Train Epoch: 163 [10240/60000 (17%)]\tLoss: 737.724365\n",
            "Train Epoch: 163 [11520/60000 (19%)]\tLoss: 749.758240\n",
            "Train Epoch: 163 [12800/60000 (21%)]\tLoss: 750.654358\n",
            "Train Epoch: 163 [14080/60000 (23%)]\tLoss: 750.161194\n",
            "Train Epoch: 163 [15360/60000 (26%)]\tLoss: 723.630432\n",
            "Train Epoch: 163 [16640/60000 (28%)]\tLoss: 721.104919\n",
            "Train Epoch: 163 [17920/60000 (30%)]\tLoss: 715.949768\n",
            "Train Epoch: 163 [19200/60000 (32%)]\tLoss: 714.678223\n",
            "Train Epoch: 163 [20480/60000 (34%)]\tLoss: 728.625549\n",
            "Train Epoch: 163 [21760/60000 (36%)]\tLoss: 726.094788\n",
            "Train Epoch: 163 [23040/60000 (38%)]\tLoss: 730.655579\n",
            "Train Epoch: 163 [24320/60000 (41%)]\tLoss: 724.335571\n",
            "Train Epoch: 163 [25600/60000 (43%)]\tLoss: 751.476807\n",
            "Train Epoch: 163 [26880/60000 (45%)]\tLoss: 749.390442\n",
            "Train Epoch: 163 [28160/60000 (47%)]\tLoss: 713.940979\n",
            "Train Epoch: 163 [29440/60000 (49%)]\tLoss: 734.144836\n",
            "Train Epoch: 163 [30720/60000 (51%)]\tLoss: 725.140259\n",
            "Train Epoch: 163 [32000/60000 (53%)]\tLoss: 729.548157\n",
            "Train Epoch: 163 [33280/60000 (55%)]\tLoss: 732.495483\n",
            "Train Epoch: 163 [34560/60000 (58%)]\tLoss: 767.109802\n",
            "Train Epoch: 163 [35840/60000 (60%)]\tLoss: 715.761047\n",
            "Train Epoch: 163 [37120/60000 (62%)]\tLoss: 742.618652\n",
            "Train Epoch: 163 [38400/60000 (64%)]\tLoss: 768.386841\n",
            "Train Epoch: 163 [39680/60000 (66%)]\tLoss: 758.834595\n",
            "Train Epoch: 163 [40960/60000 (68%)]\tLoss: 730.717712\n",
            "Train Epoch: 163 [42240/60000 (70%)]\tLoss: 749.250000\n",
            "Train Epoch: 163 [43520/60000 (72%)]\tLoss: 732.006653\n",
            "Train Epoch: 163 [44800/60000 (75%)]\tLoss: 732.116333\n",
            "Train Epoch: 163 [46080/60000 (77%)]\tLoss: 733.992859\n",
            "Train Epoch: 163 [47360/60000 (79%)]\tLoss: 730.177185\n",
            "Train Epoch: 163 [48640/60000 (81%)]\tLoss: 754.678711\n",
            "Train Epoch: 163 [49920/60000 (83%)]\tLoss: 738.580078\n",
            "Train Epoch: 163 [51200/60000 (85%)]\tLoss: 723.707214\n",
            "Train Epoch: 163 [52480/60000 (87%)]\tLoss: 732.067505\n",
            "Train Epoch: 163 [53760/60000 (90%)]\tLoss: 737.684509\n",
            "Train Epoch: 163 [55040/60000 (92%)]\tLoss: 760.684814\n",
            "Train Epoch: 163 [56320/60000 (94%)]\tLoss: 729.345154\n",
            "Train Epoch: 163 [57600/60000 (96%)]\tLoss: 741.183472\n",
            "Train Epoch: 163 [58880/60000 (98%)]\tLoss: 744.637207\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978631168603897\n",
            "\n",
            "Train Epoch: 164 [0/60000 (0%)]\tLoss: 740.191345\n",
            "Train Epoch: 164 [1280/60000 (2%)]\tLoss: 711.718811\n",
            "Train Epoch: 164 [2560/60000 (4%)]\tLoss: 745.159058\n",
            "Train Epoch: 164 [3840/60000 (6%)]\tLoss: 698.099304\n",
            "Train Epoch: 164 [5120/60000 (9%)]\tLoss: 719.328003\n",
            "Train Epoch: 164 [6400/60000 (11%)]\tLoss: 748.978394\n",
            "Train Epoch: 164 [7680/60000 (13%)]\tLoss: 721.545715\n",
            "Train Epoch: 164 [8960/60000 (15%)]\tLoss: 733.019775\n",
            "Train Epoch: 164 [10240/60000 (17%)]\tLoss: 737.215149\n",
            "Train Epoch: 164 [11520/60000 (19%)]\tLoss: 713.503296\n",
            "Train Epoch: 164 [12800/60000 (21%)]\tLoss: 726.626465\n",
            "Train Epoch: 164 [14080/60000 (23%)]\tLoss: 724.535095\n",
            "Train Epoch: 164 [15360/60000 (26%)]\tLoss: 745.814148\n",
            "Train Epoch: 164 [16640/60000 (28%)]\tLoss: 743.703369\n",
            "Train Epoch: 164 [17920/60000 (30%)]\tLoss: 731.201050\n",
            "Train Epoch: 164 [19200/60000 (32%)]\tLoss: 748.186096\n",
            "Train Epoch: 164 [20480/60000 (34%)]\tLoss: 710.450623\n",
            "Train Epoch: 164 [21760/60000 (36%)]\tLoss: 744.846252\n",
            "Train Epoch: 164 [23040/60000 (38%)]\tLoss: 713.882202\n",
            "Train Epoch: 164 [24320/60000 (41%)]\tLoss: 754.649109\n",
            "Train Epoch: 164 [25600/60000 (43%)]\tLoss: 727.736511\n",
            "Train Epoch: 164 [26880/60000 (45%)]\tLoss: 735.098267\n",
            "Train Epoch: 164 [28160/60000 (47%)]\tLoss: 724.188416\n",
            "Train Epoch: 164 [29440/60000 (49%)]\tLoss: 727.856201\n",
            "Train Epoch: 164 [30720/60000 (51%)]\tLoss: 715.349426\n",
            "Train Epoch: 164 [32000/60000 (53%)]\tLoss: 727.723083\n",
            "Train Epoch: 164 [33280/60000 (55%)]\tLoss: 747.492371\n",
            "Train Epoch: 164 [34560/60000 (58%)]\tLoss: 758.834045\n",
            "Train Epoch: 164 [35840/60000 (60%)]\tLoss: 707.937256\n",
            "Train Epoch: 164 [37120/60000 (62%)]\tLoss: 737.986145\n",
            "Train Epoch: 164 [38400/60000 (64%)]\tLoss: 715.545044\n",
            "Train Epoch: 164 [39680/60000 (66%)]\tLoss: 752.139648\n",
            "Train Epoch: 164 [40960/60000 (68%)]\tLoss: 751.244324\n",
            "Train Epoch: 164 [42240/60000 (70%)]\tLoss: 739.415222\n",
            "Train Epoch: 164 [43520/60000 (72%)]\tLoss: 735.378845\n",
            "Train Epoch: 164 [44800/60000 (75%)]\tLoss: 711.253235\n",
            "Train Epoch: 164 [46080/60000 (77%)]\tLoss: 737.416870\n",
            "Train Epoch: 164 [47360/60000 (79%)]\tLoss: 759.854431\n",
            "Train Epoch: 164 [48640/60000 (81%)]\tLoss: 737.994446\n",
            "Train Epoch: 164 [49920/60000 (83%)]\tLoss: 741.748352\n",
            "Train Epoch: 164 [51200/60000 (85%)]\tLoss: 738.435913\n",
            "Train Epoch: 164 [52480/60000 (87%)]\tLoss: 727.792664\n",
            "Train Epoch: 164 [53760/60000 (90%)]\tLoss: 737.619812\n",
            "Train Epoch: 164 [55040/60000 (92%)]\tLoss: 735.631653\n",
            "Train Epoch: 164 [56320/60000 (94%)]\tLoss: 733.619934\n",
            "Train Epoch: 164 [57600/60000 (96%)]\tLoss: 748.236023\n",
            "Train Epoch: 164 [58880/60000 (98%)]\tLoss: 754.880066\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784046709537506\n",
            "\n",
            "Train Epoch: 165 [0/60000 (0%)]\tLoss: 745.017578\n",
            "Train Epoch: 165 [1280/60000 (2%)]\tLoss: 726.213867\n",
            "Train Epoch: 165 [2560/60000 (4%)]\tLoss: 735.281677\n",
            "Train Epoch: 165 [3840/60000 (6%)]\tLoss: 717.705261\n",
            "Train Epoch: 165 [5120/60000 (9%)]\tLoss: 756.303406\n",
            "Train Epoch: 165 [6400/60000 (11%)]\tLoss: 759.877014\n",
            "Train Epoch: 165 [7680/60000 (13%)]\tLoss: 726.200317\n",
            "Train Epoch: 165 [8960/60000 (15%)]\tLoss: 730.201111\n",
            "Train Epoch: 165 [10240/60000 (17%)]\tLoss: 763.659607\n",
            "Train Epoch: 165 [11520/60000 (19%)]\tLoss: 719.136108\n",
            "Train Epoch: 165 [12800/60000 (21%)]\tLoss: 715.218933\n",
            "Train Epoch: 165 [14080/60000 (23%)]\tLoss: 725.781067\n",
            "Train Epoch: 165 [15360/60000 (26%)]\tLoss: 774.156067\n",
            "Train Epoch: 165 [16640/60000 (28%)]\tLoss: 755.627563\n",
            "Train Epoch: 165 [17920/60000 (30%)]\tLoss: 729.640442\n",
            "Train Epoch: 165 [19200/60000 (32%)]\tLoss: 775.211426\n",
            "Train Epoch: 165 [20480/60000 (34%)]\tLoss: 748.627441\n",
            "Train Epoch: 165 [21760/60000 (36%)]\tLoss: 694.585815\n",
            "Train Epoch: 165 [23040/60000 (38%)]\tLoss: 730.067688\n",
            "Train Epoch: 165 [24320/60000 (41%)]\tLoss: 736.926758\n",
            "Train Epoch: 165 [25600/60000 (43%)]\tLoss: 738.344727\n",
            "Train Epoch: 165 [26880/60000 (45%)]\tLoss: 743.140198\n",
            "Train Epoch: 165 [28160/60000 (47%)]\tLoss: 748.489868\n",
            "Train Epoch: 165 [29440/60000 (49%)]\tLoss: 761.111755\n",
            "Train Epoch: 165 [30720/60000 (51%)]\tLoss: 749.150146\n",
            "Train Epoch: 165 [32000/60000 (53%)]\tLoss: 746.128296\n",
            "Train Epoch: 165 [33280/60000 (55%)]\tLoss: 741.969421\n",
            "Train Epoch: 165 [34560/60000 (58%)]\tLoss: 708.604370\n",
            "Train Epoch: 165 [35840/60000 (60%)]\tLoss: 743.608337\n",
            "Train Epoch: 165 [37120/60000 (62%)]\tLoss: 733.673401\n",
            "Train Epoch: 165 [38400/60000 (64%)]\tLoss: 736.707336\n",
            "Train Epoch: 165 [39680/60000 (66%)]\tLoss: 735.555786\n",
            "Train Epoch: 165 [40960/60000 (68%)]\tLoss: 715.207275\n",
            "Train Epoch: 165 [42240/60000 (70%)]\tLoss: 748.801208\n",
            "Train Epoch: 165 [43520/60000 (72%)]\tLoss: 737.021667\n",
            "Train Epoch: 165 [44800/60000 (75%)]\tLoss: 736.418762\n",
            "Train Epoch: 165 [46080/60000 (77%)]\tLoss: 733.584473\n",
            "Train Epoch: 165 [47360/60000 (79%)]\tLoss: 760.805115\n",
            "Train Epoch: 165 [48640/60000 (81%)]\tLoss: 735.343201\n",
            "Train Epoch: 165 [49920/60000 (83%)]\tLoss: 694.610046\n",
            "Train Epoch: 165 [51200/60000 (85%)]\tLoss: 742.121887\n",
            "Train Epoch: 165 [52480/60000 (87%)]\tLoss: 729.538452\n",
            "Train Epoch: 165 [53760/60000 (90%)]\tLoss: 746.792419\n",
            "Train Epoch: 165 [55040/60000 (92%)]\tLoss: 732.477173\n",
            "Train Epoch: 165 [56320/60000 (94%)]\tLoss: 738.341125\n",
            "Train Epoch: 165 [57600/60000 (96%)]\tLoss: 733.236206\n",
            "Train Epoch: 165 [58880/60000 (98%)]\tLoss: 728.270630\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788523018360138\n",
            "\n",
            "Train Epoch: 166 [0/60000 (0%)]\tLoss: 725.548218\n",
            "Train Epoch: 166 [1280/60000 (2%)]\tLoss: 763.731262\n",
            "Train Epoch: 166 [2560/60000 (4%)]\tLoss: 731.937866\n",
            "Train Epoch: 166 [3840/60000 (6%)]\tLoss: 730.400940\n",
            "Train Epoch: 166 [5120/60000 (9%)]\tLoss: 739.629517\n",
            "Train Epoch: 166 [6400/60000 (11%)]\tLoss: 726.824707\n",
            "Train Epoch: 166 [7680/60000 (13%)]\tLoss: 724.999634\n",
            "Train Epoch: 166 [8960/60000 (15%)]\tLoss: 722.536743\n",
            "Train Epoch: 166 [10240/60000 (17%)]\tLoss: 727.405090\n",
            "Train Epoch: 166 [11520/60000 (19%)]\tLoss: 751.342712\n",
            "Train Epoch: 166 [12800/60000 (21%)]\tLoss: 741.417664\n",
            "Train Epoch: 166 [14080/60000 (23%)]\tLoss: 704.636108\n",
            "Train Epoch: 166 [15360/60000 (26%)]\tLoss: 751.979065\n",
            "Train Epoch: 166 [16640/60000 (28%)]\tLoss: 754.641663\n",
            "Train Epoch: 166 [17920/60000 (30%)]\tLoss: 757.243469\n",
            "Train Epoch: 166 [19200/60000 (32%)]\tLoss: 746.771118\n",
            "Train Epoch: 166 [20480/60000 (34%)]\tLoss: 724.003601\n",
            "Train Epoch: 166 [21760/60000 (36%)]\tLoss: 733.787659\n",
            "Train Epoch: 166 [23040/60000 (38%)]\tLoss: 748.967224\n",
            "Train Epoch: 166 [24320/60000 (41%)]\tLoss: 758.899292\n",
            "Train Epoch: 166 [25600/60000 (43%)]\tLoss: 709.096863\n",
            "Train Epoch: 166 [26880/60000 (45%)]\tLoss: 725.752502\n",
            "Train Epoch: 166 [28160/60000 (47%)]\tLoss: 740.357483\n",
            "Train Epoch: 166 [29440/60000 (49%)]\tLoss: 740.360229\n",
            "Train Epoch: 166 [30720/60000 (51%)]\tLoss: 721.424011\n",
            "Train Epoch: 166 [32000/60000 (53%)]\tLoss: 734.658936\n",
            "Train Epoch: 166 [33280/60000 (55%)]\tLoss: 731.942993\n",
            "Train Epoch: 166 [34560/60000 (58%)]\tLoss: 755.215210\n",
            "Train Epoch: 166 [35840/60000 (60%)]\tLoss: 718.289062\n",
            "Train Epoch: 166 [37120/60000 (62%)]\tLoss: 750.827454\n",
            "Train Epoch: 166 [38400/60000 (64%)]\tLoss: 724.532227\n",
            "Train Epoch: 166 [39680/60000 (66%)]\tLoss: 755.060852\n",
            "Train Epoch: 166 [40960/60000 (68%)]\tLoss: 728.919922\n",
            "Train Epoch: 166 [42240/60000 (70%)]\tLoss: 740.334717\n",
            "Train Epoch: 166 [43520/60000 (72%)]\tLoss: 728.090759\n",
            "Train Epoch: 166 [44800/60000 (75%)]\tLoss: 745.611267\n",
            "Train Epoch: 166 [46080/60000 (77%)]\tLoss: 752.546082\n",
            "Train Epoch: 166 [47360/60000 (79%)]\tLoss: 751.704041\n",
            "Train Epoch: 166 [48640/60000 (81%)]\tLoss: 735.705811\n",
            "Train Epoch: 166 [49920/60000 (83%)]\tLoss: 725.938660\n",
            "Train Epoch: 166 [51200/60000 (85%)]\tLoss: 730.631775\n",
            "Train Epoch: 166 [52480/60000 (87%)]\tLoss: 743.320618\n",
            "Train Epoch: 166 [53760/60000 (90%)]\tLoss: 744.894714\n",
            "Train Epoch: 166 [55040/60000 (92%)]\tLoss: 739.716064\n",
            "Train Epoch: 166 [56320/60000 (94%)]\tLoss: 732.482910\n",
            "Train Epoch: 166 [57600/60000 (96%)]\tLoss: 755.216553\n",
            "Train Epoch: 166 [58880/60000 (98%)]\tLoss: 754.264099\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781392812728882\n",
            "\n",
            "Train Epoch: 167 [0/60000 (0%)]\tLoss: 721.053406\n",
            "Train Epoch: 167 [1280/60000 (2%)]\tLoss: 729.150452\n",
            "Train Epoch: 167 [2560/60000 (4%)]\tLoss: 735.595520\n",
            "Train Epoch: 167 [3840/60000 (6%)]\tLoss: 725.311035\n",
            "Train Epoch: 167 [5120/60000 (9%)]\tLoss: 730.581055\n",
            "Train Epoch: 167 [6400/60000 (11%)]\tLoss: 728.346558\n",
            "Train Epoch: 167 [7680/60000 (13%)]\tLoss: 727.085083\n",
            "Train Epoch: 167 [8960/60000 (15%)]\tLoss: 740.698425\n",
            "Train Epoch: 167 [10240/60000 (17%)]\tLoss: 709.166260\n",
            "Train Epoch: 167 [11520/60000 (19%)]\tLoss: 725.763000\n",
            "Train Epoch: 167 [12800/60000 (21%)]\tLoss: 724.496643\n",
            "Train Epoch: 167 [14080/60000 (23%)]\tLoss: 726.166382\n",
            "Train Epoch: 167 [15360/60000 (26%)]\tLoss: 753.242126\n",
            "Train Epoch: 167 [16640/60000 (28%)]\tLoss: 747.481750\n",
            "Train Epoch: 167 [17920/60000 (30%)]\tLoss: 726.005920\n",
            "Train Epoch: 167 [19200/60000 (32%)]\tLoss: 734.758240\n",
            "Train Epoch: 167 [20480/60000 (34%)]\tLoss: 725.495483\n",
            "Train Epoch: 167 [21760/60000 (36%)]\tLoss: 747.018005\n",
            "Train Epoch: 167 [23040/60000 (38%)]\tLoss: 740.839294\n",
            "Train Epoch: 167 [24320/60000 (41%)]\tLoss: 723.312805\n",
            "Train Epoch: 167 [25600/60000 (43%)]\tLoss: 741.306641\n",
            "Train Epoch: 167 [26880/60000 (45%)]\tLoss: 717.094849\n",
            "Train Epoch: 167 [28160/60000 (47%)]\tLoss: 719.299011\n",
            "Train Epoch: 167 [29440/60000 (49%)]\tLoss: 726.203674\n",
            "Train Epoch: 167 [30720/60000 (51%)]\tLoss: 771.959229\n",
            "Train Epoch: 167 [32000/60000 (53%)]\tLoss: 767.939880\n",
            "Train Epoch: 167 [33280/60000 (55%)]\tLoss: 720.709900\n",
            "Train Epoch: 167 [34560/60000 (58%)]\tLoss: 735.393127\n",
            "Train Epoch: 167 [35840/60000 (60%)]\tLoss: 751.983032\n",
            "Train Epoch: 167 [37120/60000 (62%)]\tLoss: 737.380066\n",
            "Train Epoch: 167 [38400/60000 (64%)]\tLoss: 725.430054\n",
            "Train Epoch: 167 [39680/60000 (66%)]\tLoss: 748.332703\n",
            "Train Epoch: 167 [40960/60000 (68%)]\tLoss: 750.135254\n",
            "Train Epoch: 167 [42240/60000 (70%)]\tLoss: 734.476135\n",
            "Train Epoch: 167 [43520/60000 (72%)]\tLoss: 763.560303\n",
            "Train Epoch: 167 [44800/60000 (75%)]\tLoss: 720.472412\n",
            "Train Epoch: 167 [46080/60000 (77%)]\tLoss: 743.654053\n",
            "Train Epoch: 167 [47360/60000 (79%)]\tLoss: 741.763977\n",
            "Train Epoch: 167 [48640/60000 (81%)]\tLoss: 732.565735\n",
            "Train Epoch: 167 [49920/60000 (83%)]\tLoss: 730.659912\n",
            "Train Epoch: 167 [51200/60000 (85%)]\tLoss: 732.046631\n",
            "Train Epoch: 167 [52480/60000 (87%)]\tLoss: 753.011475\n",
            "Train Epoch: 167 [53760/60000 (90%)]\tLoss: 732.635620\n",
            "Train Epoch: 167 [55040/60000 (92%)]\tLoss: 738.066406\n",
            "Train Epoch: 167 [56320/60000 (94%)]\tLoss: 745.889221\n",
            "Train Epoch: 167 [57600/60000 (96%)]\tLoss: 736.217285\n",
            "Train Epoch: 167 [58880/60000 (98%)]\tLoss: 728.238342\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788096845149994\n",
            "\n",
            "Train Epoch: 168 [0/60000 (0%)]\tLoss: 731.820007\n",
            "Train Epoch: 168 [1280/60000 (2%)]\tLoss: 736.793091\n",
            "Train Epoch: 168 [2560/60000 (4%)]\tLoss: 749.876953\n",
            "Train Epoch: 168 [3840/60000 (6%)]\tLoss: 749.812134\n",
            "Train Epoch: 168 [5120/60000 (9%)]\tLoss: 729.314697\n",
            "Train Epoch: 168 [6400/60000 (11%)]\tLoss: 726.563416\n",
            "Train Epoch: 168 [7680/60000 (13%)]\tLoss: 720.049011\n",
            "Train Epoch: 168 [8960/60000 (15%)]\tLoss: 756.055359\n",
            "Train Epoch: 168 [10240/60000 (17%)]\tLoss: 739.590576\n",
            "Train Epoch: 168 [11520/60000 (19%)]\tLoss: 758.392029\n",
            "Train Epoch: 168 [12800/60000 (21%)]\tLoss: 718.156921\n",
            "Train Epoch: 168 [14080/60000 (23%)]\tLoss: 738.745239\n",
            "Train Epoch: 168 [15360/60000 (26%)]\tLoss: 727.320923\n",
            "Train Epoch: 168 [16640/60000 (28%)]\tLoss: 745.564392\n",
            "Train Epoch: 168 [17920/60000 (30%)]\tLoss: 727.398132\n",
            "Train Epoch: 168 [19200/60000 (32%)]\tLoss: 754.685791\n",
            "Train Epoch: 168 [20480/60000 (34%)]\tLoss: 722.907288\n",
            "Train Epoch: 168 [21760/60000 (36%)]\tLoss: 747.312622\n",
            "Train Epoch: 168 [23040/60000 (38%)]\tLoss: 727.128662\n",
            "Train Epoch: 168 [24320/60000 (41%)]\tLoss: 735.824219\n",
            "Train Epoch: 168 [25600/60000 (43%)]\tLoss: 738.406433\n",
            "Train Epoch: 168 [26880/60000 (45%)]\tLoss: 730.994873\n",
            "Train Epoch: 168 [28160/60000 (47%)]\tLoss: 716.466614\n",
            "Train Epoch: 168 [29440/60000 (49%)]\tLoss: 742.529846\n",
            "Train Epoch: 168 [30720/60000 (51%)]\tLoss: 746.961853\n",
            "Train Epoch: 168 [32000/60000 (53%)]\tLoss: 729.934753\n",
            "Train Epoch: 168 [33280/60000 (55%)]\tLoss: 745.896912\n",
            "Train Epoch: 168 [34560/60000 (58%)]\tLoss: 728.508545\n",
            "Train Epoch: 168 [35840/60000 (60%)]\tLoss: 757.877869\n",
            "Train Epoch: 168 [37120/60000 (62%)]\tLoss: 732.828186\n",
            "Train Epoch: 168 [38400/60000 (64%)]\tLoss: 699.254395\n",
            "Train Epoch: 168 [39680/60000 (66%)]\tLoss: 748.442444\n",
            "Train Epoch: 168 [40960/60000 (68%)]\tLoss: 720.588440\n",
            "Train Epoch: 168 [42240/60000 (70%)]\tLoss: 744.918396\n",
            "Train Epoch: 168 [43520/60000 (72%)]\tLoss: 726.575439\n",
            "Train Epoch: 168 [44800/60000 (75%)]\tLoss: 729.310730\n",
            "Train Epoch: 168 [46080/60000 (77%)]\tLoss: 720.440918\n",
            "Train Epoch: 168 [47360/60000 (79%)]\tLoss: 708.173523\n",
            "Train Epoch: 168 [48640/60000 (81%)]\tLoss: 762.531738\n",
            "Train Epoch: 168 [49920/60000 (83%)]\tLoss: 750.453430\n",
            "Train Epoch: 168 [51200/60000 (85%)]\tLoss: 738.892761\n",
            "Train Epoch: 168 [52480/60000 (87%)]\tLoss: 726.696655\n",
            "Train Epoch: 168 [53760/60000 (90%)]\tLoss: 732.063293\n",
            "Train Epoch: 168 [55040/60000 (92%)]\tLoss: 706.797363\n",
            "Train Epoch: 168 [56320/60000 (94%)]\tLoss: 747.943909\n",
            "Train Epoch: 168 [57600/60000 (96%)]\tLoss: 742.678040\n",
            "Train Epoch: 168 [58880/60000 (98%)]\tLoss: 733.073914\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788417220115662\n",
            "\n",
            "Train Epoch: 169 [0/60000 (0%)]\tLoss: 757.768311\n",
            "Train Epoch: 169 [1280/60000 (2%)]\tLoss: 762.889832\n",
            "Train Epoch: 169 [2560/60000 (4%)]\tLoss: 735.216125\n",
            "Train Epoch: 169 [3840/60000 (6%)]\tLoss: 726.878479\n",
            "Train Epoch: 169 [5120/60000 (9%)]\tLoss: 737.122681\n",
            "Train Epoch: 169 [6400/60000 (11%)]\tLoss: 741.093506\n",
            "Train Epoch: 169 [7680/60000 (13%)]\tLoss: 722.698730\n",
            "Train Epoch: 169 [8960/60000 (15%)]\tLoss: 730.177734\n",
            "Train Epoch: 169 [10240/60000 (17%)]\tLoss: 758.343445\n",
            "Train Epoch: 169 [11520/60000 (19%)]\tLoss: 743.602539\n",
            "Train Epoch: 169 [12800/60000 (21%)]\tLoss: 756.783447\n",
            "Train Epoch: 169 [14080/60000 (23%)]\tLoss: 758.103210\n",
            "Train Epoch: 169 [15360/60000 (26%)]\tLoss: 771.730896\n",
            "Train Epoch: 169 [16640/60000 (28%)]\tLoss: 746.786865\n",
            "Train Epoch: 169 [17920/60000 (30%)]\tLoss: 740.649963\n",
            "Train Epoch: 169 [19200/60000 (32%)]\tLoss: 716.872009\n",
            "Train Epoch: 169 [20480/60000 (34%)]\tLoss: 753.067017\n",
            "Train Epoch: 169 [21760/60000 (36%)]\tLoss: 734.652161\n",
            "Train Epoch: 169 [23040/60000 (38%)]\tLoss: 722.072693\n",
            "Train Epoch: 169 [24320/60000 (41%)]\tLoss: 744.244019\n",
            "Train Epoch: 169 [25600/60000 (43%)]\tLoss: 743.065613\n",
            "Train Epoch: 169 [26880/60000 (45%)]\tLoss: 755.879517\n",
            "Train Epoch: 169 [28160/60000 (47%)]\tLoss: 733.754211\n",
            "Train Epoch: 169 [29440/60000 (49%)]\tLoss: 718.931335\n",
            "Train Epoch: 169 [30720/60000 (51%)]\tLoss: 725.885620\n",
            "Train Epoch: 169 [32000/60000 (53%)]\tLoss: 728.858704\n",
            "Train Epoch: 169 [33280/60000 (55%)]\tLoss: 738.192993\n",
            "Train Epoch: 169 [34560/60000 (58%)]\tLoss: 748.346985\n",
            "Train Epoch: 169 [35840/60000 (60%)]\tLoss: 714.596619\n",
            "Train Epoch: 169 [37120/60000 (62%)]\tLoss: 741.945496\n",
            "Train Epoch: 169 [38400/60000 (64%)]\tLoss: 743.009460\n",
            "Train Epoch: 169 [39680/60000 (66%)]\tLoss: 741.097961\n",
            "Train Epoch: 169 [40960/60000 (68%)]\tLoss: 750.756897\n",
            "Train Epoch: 169 [42240/60000 (70%)]\tLoss: 726.133301\n",
            "Train Epoch: 169 [43520/60000 (72%)]\tLoss: 739.791809\n",
            "Train Epoch: 169 [44800/60000 (75%)]\tLoss: 712.066772\n",
            "Train Epoch: 169 [46080/60000 (77%)]\tLoss: 750.925171\n",
            "Train Epoch: 169 [47360/60000 (79%)]\tLoss: 737.187378\n",
            "Train Epoch: 169 [48640/60000 (81%)]\tLoss: 734.443298\n",
            "Train Epoch: 169 [49920/60000 (83%)]\tLoss: 712.190674\n",
            "Train Epoch: 169 [51200/60000 (85%)]\tLoss: 731.781189\n",
            "Train Epoch: 169 [52480/60000 (87%)]\tLoss: 743.315857\n",
            "Train Epoch: 169 [53760/60000 (90%)]\tLoss: 771.402039\n",
            "Train Epoch: 169 [55040/60000 (92%)]\tLoss: 725.843445\n",
            "Train Epoch: 169 [56320/60000 (94%)]\tLoss: 723.972900\n",
            "Train Epoch: 169 [57600/60000 (96%)]\tLoss: 742.303162\n",
            "Train Epoch: 169 [58880/60000 (98%)]\tLoss: 735.666565\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783638417720795\n",
            "\n",
            "Train Epoch: 170 [0/60000 (0%)]\tLoss: 734.081848\n",
            "Train Epoch: 170 [1280/60000 (2%)]\tLoss: 730.290344\n",
            "Train Epoch: 170 [2560/60000 (4%)]\tLoss: 753.387207\n",
            "Train Epoch: 170 [3840/60000 (6%)]\tLoss: 747.065918\n",
            "Train Epoch: 170 [5120/60000 (9%)]\tLoss: 742.659424\n",
            "Train Epoch: 170 [6400/60000 (11%)]\tLoss: 739.398621\n",
            "Train Epoch: 170 [7680/60000 (13%)]\tLoss: 730.095398\n",
            "Train Epoch: 170 [8960/60000 (15%)]\tLoss: 718.890930\n",
            "Train Epoch: 170 [10240/60000 (17%)]\tLoss: 741.816345\n",
            "Train Epoch: 170 [11520/60000 (19%)]\tLoss: 740.151855\n",
            "Train Epoch: 170 [12800/60000 (21%)]\tLoss: 718.941162\n",
            "Train Epoch: 170 [14080/60000 (23%)]\tLoss: 748.480713\n",
            "Train Epoch: 170 [15360/60000 (26%)]\tLoss: 741.306396\n",
            "Train Epoch: 170 [16640/60000 (28%)]\tLoss: 756.953186\n",
            "Train Epoch: 170 [17920/60000 (30%)]\tLoss: 749.570007\n",
            "Train Epoch: 170 [19200/60000 (32%)]\tLoss: 774.581970\n",
            "Train Epoch: 170 [20480/60000 (34%)]\tLoss: 740.407227\n",
            "Train Epoch: 170 [21760/60000 (36%)]\tLoss: 742.656006\n",
            "Train Epoch: 170 [23040/60000 (38%)]\tLoss: 788.996704\n",
            "Train Epoch: 170 [24320/60000 (41%)]\tLoss: 731.908325\n",
            "Train Epoch: 170 [25600/60000 (43%)]\tLoss: 751.914001\n",
            "Train Epoch: 170 [26880/60000 (45%)]\tLoss: 736.954590\n",
            "Train Epoch: 170 [28160/60000 (47%)]\tLoss: 729.961121\n",
            "Train Epoch: 170 [29440/60000 (49%)]\tLoss: 746.596313\n",
            "Train Epoch: 170 [30720/60000 (51%)]\tLoss: 730.743774\n",
            "Train Epoch: 170 [32000/60000 (53%)]\tLoss: 743.674072\n",
            "Train Epoch: 170 [33280/60000 (55%)]\tLoss: 715.579956\n",
            "Train Epoch: 170 [34560/60000 (58%)]\tLoss: 730.725891\n",
            "Train Epoch: 170 [35840/60000 (60%)]\tLoss: 726.722961\n",
            "Train Epoch: 170 [37120/60000 (62%)]\tLoss: 758.745056\n",
            "Train Epoch: 170 [38400/60000 (64%)]\tLoss: 732.190308\n",
            "Train Epoch: 170 [39680/60000 (66%)]\tLoss: 753.467102\n",
            "Train Epoch: 170 [40960/60000 (68%)]\tLoss: 742.059204\n",
            "Train Epoch: 170 [42240/60000 (70%)]\tLoss: 739.590820\n",
            "Train Epoch: 170 [43520/60000 (72%)]\tLoss: 728.617065\n",
            "Train Epoch: 170 [44800/60000 (75%)]\tLoss: 744.482910\n",
            "Train Epoch: 170 [46080/60000 (77%)]\tLoss: 751.802368\n",
            "Train Epoch: 170 [47360/60000 (79%)]\tLoss: 735.327942\n",
            "Train Epoch: 170 [48640/60000 (81%)]\tLoss: 750.584595\n",
            "Train Epoch: 170 [49920/60000 (83%)]\tLoss: 727.229248\n",
            "Train Epoch: 170 [51200/60000 (85%)]\tLoss: 758.137695\n",
            "Train Epoch: 170 [52480/60000 (87%)]\tLoss: 719.079285\n",
            "Train Epoch: 170 [53760/60000 (90%)]\tLoss: 729.033020\n",
            "Train Epoch: 170 [55040/60000 (92%)]\tLoss: 728.064026\n",
            "Train Epoch: 170 [56320/60000 (94%)]\tLoss: 729.533142\n",
            "Train Epoch: 170 [57600/60000 (96%)]\tLoss: 747.056152\n",
            "Train Epoch: 170 [58880/60000 (98%)]\tLoss: 725.042603\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978289932012558\n",
            "\n",
            "Train Epoch: 171 [0/60000 (0%)]\tLoss: 726.370667\n",
            "Train Epoch: 171 [1280/60000 (2%)]\tLoss: 731.336243\n",
            "Train Epoch: 171 [2560/60000 (4%)]\tLoss: 720.723206\n",
            "Train Epoch: 171 [3840/60000 (6%)]\tLoss: 759.247681\n",
            "Train Epoch: 171 [5120/60000 (9%)]\tLoss: 721.332031\n",
            "Train Epoch: 171 [6400/60000 (11%)]\tLoss: 710.503052\n",
            "Train Epoch: 171 [7680/60000 (13%)]\tLoss: 737.979980\n",
            "Train Epoch: 171 [8960/60000 (15%)]\tLoss: 721.853943\n",
            "Train Epoch: 171 [10240/60000 (17%)]\tLoss: 727.104980\n",
            "Train Epoch: 171 [11520/60000 (19%)]\tLoss: 730.648010\n",
            "Train Epoch: 171 [12800/60000 (21%)]\tLoss: 726.883545\n",
            "Train Epoch: 171 [14080/60000 (23%)]\tLoss: 699.171082\n",
            "Train Epoch: 171 [15360/60000 (26%)]\tLoss: 729.711121\n",
            "Train Epoch: 171 [16640/60000 (28%)]\tLoss: 725.351685\n",
            "Train Epoch: 171 [17920/60000 (30%)]\tLoss: 742.723755\n",
            "Train Epoch: 171 [19200/60000 (32%)]\tLoss: 756.526611\n",
            "Train Epoch: 171 [20480/60000 (34%)]\tLoss: 727.675293\n",
            "Train Epoch: 171 [21760/60000 (36%)]\tLoss: 748.412842\n",
            "Train Epoch: 171 [23040/60000 (38%)]\tLoss: 721.935242\n",
            "Train Epoch: 171 [24320/60000 (41%)]\tLoss: 731.471863\n",
            "Train Epoch: 171 [25600/60000 (43%)]\tLoss: 736.789062\n",
            "Train Epoch: 171 [26880/60000 (45%)]\tLoss: 754.655212\n",
            "Train Epoch: 171 [28160/60000 (47%)]\tLoss: 707.850403\n",
            "Train Epoch: 171 [29440/60000 (49%)]\tLoss: 724.566711\n",
            "Train Epoch: 171 [30720/60000 (51%)]\tLoss: 750.798645\n",
            "Train Epoch: 171 [32000/60000 (53%)]\tLoss: 763.795105\n",
            "Train Epoch: 171 [33280/60000 (55%)]\tLoss: 742.021973\n",
            "Train Epoch: 171 [34560/60000 (58%)]\tLoss: 740.330505\n",
            "Train Epoch: 171 [35840/60000 (60%)]\tLoss: 721.548279\n",
            "Train Epoch: 171 [37120/60000 (62%)]\tLoss: 739.775757\n",
            "Train Epoch: 171 [38400/60000 (64%)]\tLoss: 727.853271\n",
            "Train Epoch: 171 [39680/60000 (66%)]\tLoss: 736.872986\n",
            "Train Epoch: 171 [40960/60000 (68%)]\tLoss: 707.067322\n",
            "Train Epoch: 171 [42240/60000 (70%)]\tLoss: 758.716553\n",
            "Train Epoch: 171 [43520/60000 (72%)]\tLoss: 737.388672\n",
            "Train Epoch: 171 [44800/60000 (75%)]\tLoss: 729.822021\n",
            "Train Epoch: 171 [46080/60000 (77%)]\tLoss: 741.811462\n",
            "Train Epoch: 171 [47360/60000 (79%)]\tLoss: 762.158020\n",
            "Train Epoch: 171 [48640/60000 (81%)]\tLoss: 745.797302\n",
            "Train Epoch: 171 [49920/60000 (83%)]\tLoss: 743.138733\n",
            "Train Epoch: 171 [51200/60000 (85%)]\tLoss: 740.746338\n",
            "Train Epoch: 171 [52480/60000 (87%)]\tLoss: 736.117065\n",
            "Train Epoch: 171 [53760/60000 (90%)]\tLoss: 735.968994\n",
            "Train Epoch: 171 [55040/60000 (92%)]\tLoss: 761.498901\n",
            "Train Epoch: 171 [56320/60000 (94%)]\tLoss: 762.516235\n",
            "Train Epoch: 171 [57600/60000 (96%)]\tLoss: 732.151550\n",
            "Train Epoch: 171 [58880/60000 (98%)]\tLoss: 752.906677\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978013664484024\n",
            "\n",
            "Train Epoch: 172 [0/60000 (0%)]\tLoss: 745.685791\n",
            "Train Epoch: 172 [1280/60000 (2%)]\tLoss: 747.485168\n",
            "Train Epoch: 172 [2560/60000 (4%)]\tLoss: 740.249451\n",
            "Train Epoch: 172 [3840/60000 (6%)]\tLoss: 733.761963\n",
            "Train Epoch: 172 [5120/60000 (9%)]\tLoss: 743.533813\n",
            "Train Epoch: 172 [6400/60000 (11%)]\tLoss: 751.027832\n",
            "Train Epoch: 172 [7680/60000 (13%)]\tLoss: 742.669739\n",
            "Train Epoch: 172 [8960/60000 (15%)]\tLoss: 743.733276\n",
            "Train Epoch: 172 [10240/60000 (17%)]\tLoss: 743.267639\n",
            "Train Epoch: 172 [11520/60000 (19%)]\tLoss: 744.126038\n",
            "Train Epoch: 172 [12800/60000 (21%)]\tLoss: 753.573853\n",
            "Train Epoch: 172 [14080/60000 (23%)]\tLoss: 749.728271\n",
            "Train Epoch: 172 [15360/60000 (26%)]\tLoss: 734.992737\n",
            "Train Epoch: 172 [16640/60000 (28%)]\tLoss: 736.789856\n",
            "Train Epoch: 172 [17920/60000 (30%)]\tLoss: 729.237793\n",
            "Train Epoch: 172 [19200/60000 (32%)]\tLoss: 734.760010\n",
            "Train Epoch: 172 [20480/60000 (34%)]\tLoss: 722.650635\n",
            "Train Epoch: 172 [21760/60000 (36%)]\tLoss: 736.328735\n",
            "Train Epoch: 172 [23040/60000 (38%)]\tLoss: 743.023621\n",
            "Train Epoch: 172 [24320/60000 (41%)]\tLoss: 718.954773\n",
            "Train Epoch: 172 [25600/60000 (43%)]\tLoss: 733.819336\n",
            "Train Epoch: 172 [26880/60000 (45%)]\tLoss: 722.079041\n",
            "Train Epoch: 172 [28160/60000 (47%)]\tLoss: 748.848145\n",
            "Train Epoch: 172 [29440/60000 (49%)]\tLoss: 734.826965\n",
            "Train Epoch: 172 [30720/60000 (51%)]\tLoss: 758.175842\n",
            "Train Epoch: 172 [32000/60000 (53%)]\tLoss: 719.732666\n",
            "Train Epoch: 172 [33280/60000 (55%)]\tLoss: 736.543640\n",
            "Train Epoch: 172 [34560/60000 (58%)]\tLoss: 725.650757\n",
            "Train Epoch: 172 [35840/60000 (60%)]\tLoss: 763.362610\n",
            "Train Epoch: 172 [37120/60000 (62%)]\tLoss: 741.799988\n",
            "Train Epoch: 172 [38400/60000 (64%)]\tLoss: 746.051147\n",
            "Train Epoch: 172 [39680/60000 (66%)]\tLoss: 749.807007\n",
            "Train Epoch: 172 [40960/60000 (68%)]\tLoss: 751.070496\n",
            "Train Epoch: 172 [42240/60000 (70%)]\tLoss: 721.710144\n",
            "Train Epoch: 172 [43520/60000 (72%)]\tLoss: 743.438721\n",
            "Train Epoch: 172 [44800/60000 (75%)]\tLoss: 768.672974\n",
            "Train Epoch: 172 [46080/60000 (77%)]\tLoss: 717.973633\n",
            "Train Epoch: 172 [47360/60000 (79%)]\tLoss: 724.351440\n",
            "Train Epoch: 172 [48640/60000 (81%)]\tLoss: 754.218689\n",
            "Train Epoch: 172 [49920/60000 (83%)]\tLoss: 737.333008\n",
            "Train Epoch: 172 [51200/60000 (85%)]\tLoss: 712.072083\n",
            "Train Epoch: 172 [52480/60000 (87%)]\tLoss: 719.173096\n",
            "Train Epoch: 172 [53760/60000 (90%)]\tLoss: 727.700745\n",
            "Train Epoch: 172 [55040/60000 (92%)]\tLoss: 736.599915\n",
            "Train Epoch: 172 [56320/60000 (94%)]\tLoss: 704.017090\n",
            "Train Epoch: 172 [57600/60000 (96%)]\tLoss: 722.062378\n",
            "Train Epoch: 172 [58880/60000 (98%)]\tLoss: 746.425476\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785451889038086\n",
            "\n",
            "Train Epoch: 173 [0/60000 (0%)]\tLoss: 721.063110\n",
            "Train Epoch: 173 [1280/60000 (2%)]\tLoss: 750.310242\n",
            "Train Epoch: 173 [2560/60000 (4%)]\tLoss: 747.480713\n",
            "Train Epoch: 173 [3840/60000 (6%)]\tLoss: 717.789795\n",
            "Train Epoch: 173 [5120/60000 (9%)]\tLoss: 727.646729\n",
            "Train Epoch: 173 [6400/60000 (11%)]\tLoss: 731.512512\n",
            "Train Epoch: 173 [7680/60000 (13%)]\tLoss: 720.710266\n",
            "Train Epoch: 173 [8960/60000 (15%)]\tLoss: 751.858093\n",
            "Train Epoch: 173 [10240/60000 (17%)]\tLoss: 727.112366\n",
            "Train Epoch: 173 [11520/60000 (19%)]\tLoss: 761.291077\n",
            "Train Epoch: 173 [12800/60000 (21%)]\tLoss: 758.604187\n",
            "Train Epoch: 173 [14080/60000 (23%)]\tLoss: 724.517700\n",
            "Train Epoch: 173 [15360/60000 (26%)]\tLoss: 716.665955\n",
            "Train Epoch: 173 [16640/60000 (28%)]\tLoss: 744.703796\n",
            "Train Epoch: 173 [17920/60000 (30%)]\tLoss: 738.914612\n",
            "Train Epoch: 173 [19200/60000 (32%)]\tLoss: 738.569031\n",
            "Train Epoch: 173 [20480/60000 (34%)]\tLoss: 729.103821\n",
            "Train Epoch: 173 [21760/60000 (36%)]\tLoss: 744.800659\n",
            "Train Epoch: 173 [23040/60000 (38%)]\tLoss: 731.819214\n",
            "Train Epoch: 173 [24320/60000 (41%)]\tLoss: 725.399597\n",
            "Train Epoch: 173 [25600/60000 (43%)]\tLoss: 749.922180\n",
            "Train Epoch: 173 [26880/60000 (45%)]\tLoss: 723.327637\n",
            "Train Epoch: 173 [28160/60000 (47%)]\tLoss: 758.231628\n",
            "Train Epoch: 173 [29440/60000 (49%)]\tLoss: 739.753052\n",
            "Train Epoch: 173 [30720/60000 (51%)]\tLoss: 756.271973\n",
            "Train Epoch: 173 [32000/60000 (53%)]\tLoss: 738.177856\n",
            "Train Epoch: 173 [33280/60000 (55%)]\tLoss: 735.065979\n",
            "Train Epoch: 173 [34560/60000 (58%)]\tLoss: 738.693481\n",
            "Train Epoch: 173 [35840/60000 (60%)]\tLoss: 744.370178\n",
            "Train Epoch: 173 [37120/60000 (62%)]\tLoss: 722.941040\n",
            "Train Epoch: 173 [38400/60000 (64%)]\tLoss: 723.109802\n",
            "Train Epoch: 173 [39680/60000 (66%)]\tLoss: 715.990356\n",
            "Train Epoch: 173 [40960/60000 (68%)]\tLoss: 725.901245\n",
            "Train Epoch: 173 [42240/60000 (70%)]\tLoss: 735.019043\n",
            "Train Epoch: 173 [43520/60000 (72%)]\tLoss: 740.036865\n",
            "Train Epoch: 173 [44800/60000 (75%)]\tLoss: 722.328430\n",
            "Train Epoch: 173 [46080/60000 (77%)]\tLoss: 749.603821\n",
            "Train Epoch: 173 [47360/60000 (79%)]\tLoss: 742.114685\n",
            "Train Epoch: 173 [48640/60000 (81%)]\tLoss: 722.421814\n",
            "Train Epoch: 173 [49920/60000 (83%)]\tLoss: 728.558899\n",
            "Train Epoch: 173 [51200/60000 (85%)]\tLoss: 739.376892\n",
            "Train Epoch: 173 [52480/60000 (87%)]\tLoss: 716.558533\n",
            "Train Epoch: 173 [53760/60000 (90%)]\tLoss: 751.031067\n",
            "Train Epoch: 173 [55040/60000 (92%)]\tLoss: 700.321411\n",
            "Train Epoch: 173 [56320/60000 (94%)]\tLoss: 728.624390\n",
            "Train Epoch: 173 [57600/60000 (96%)]\tLoss: 744.044800\n",
            "Train Epoch: 173 [58880/60000 (98%)]\tLoss: 747.926758\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782306253910065\n",
            "\n",
            "Train Epoch: 174 [0/60000 (0%)]\tLoss: 725.017334\n",
            "Train Epoch: 174 [1280/60000 (2%)]\tLoss: 727.714050\n",
            "Train Epoch: 174 [2560/60000 (4%)]\tLoss: 730.431091\n",
            "Train Epoch: 174 [3840/60000 (6%)]\tLoss: 730.376404\n",
            "Train Epoch: 174 [5120/60000 (9%)]\tLoss: 747.724060\n",
            "Train Epoch: 174 [6400/60000 (11%)]\tLoss: 732.914673\n",
            "Train Epoch: 174 [7680/60000 (13%)]\tLoss: 736.007446\n",
            "Train Epoch: 174 [8960/60000 (15%)]\tLoss: 758.853943\n",
            "Train Epoch: 174 [10240/60000 (17%)]\tLoss: 717.602295\n",
            "Train Epoch: 174 [11520/60000 (19%)]\tLoss: 742.159912\n",
            "Train Epoch: 174 [12800/60000 (21%)]\tLoss: 751.423401\n",
            "Train Epoch: 174 [14080/60000 (23%)]\tLoss: 758.092285\n",
            "Train Epoch: 174 [15360/60000 (26%)]\tLoss: 717.809753\n",
            "Train Epoch: 174 [16640/60000 (28%)]\tLoss: 746.494263\n",
            "Train Epoch: 174 [17920/60000 (30%)]\tLoss: 690.540405\n",
            "Train Epoch: 174 [19200/60000 (32%)]\tLoss: 747.620728\n",
            "Train Epoch: 174 [20480/60000 (34%)]\tLoss: 743.075500\n",
            "Train Epoch: 174 [21760/60000 (36%)]\tLoss: 745.993530\n",
            "Train Epoch: 174 [23040/60000 (38%)]\tLoss: 746.143005\n",
            "Train Epoch: 174 [24320/60000 (41%)]\tLoss: 744.697815\n",
            "Train Epoch: 174 [25600/60000 (43%)]\tLoss: 713.082642\n",
            "Train Epoch: 174 [26880/60000 (45%)]\tLoss: 738.199097\n",
            "Train Epoch: 174 [28160/60000 (47%)]\tLoss: 734.618042\n",
            "Train Epoch: 174 [29440/60000 (49%)]\tLoss: 732.279907\n",
            "Train Epoch: 174 [30720/60000 (51%)]\tLoss: 746.300049\n",
            "Train Epoch: 174 [32000/60000 (53%)]\tLoss: 733.451416\n",
            "Train Epoch: 174 [33280/60000 (55%)]\tLoss: 749.583252\n",
            "Train Epoch: 174 [34560/60000 (58%)]\tLoss: 691.955139\n",
            "Train Epoch: 174 [35840/60000 (60%)]\tLoss: 745.224243\n",
            "Train Epoch: 174 [37120/60000 (62%)]\tLoss: 737.677612\n",
            "Train Epoch: 174 [38400/60000 (64%)]\tLoss: 732.540161\n",
            "Train Epoch: 174 [39680/60000 (66%)]\tLoss: 742.822266\n",
            "Train Epoch: 174 [40960/60000 (68%)]\tLoss: 764.232300\n",
            "Train Epoch: 174 [42240/60000 (70%)]\tLoss: 721.895996\n",
            "Train Epoch: 174 [43520/60000 (72%)]\tLoss: 736.571167\n",
            "Train Epoch: 174 [44800/60000 (75%)]\tLoss: 742.943848\n",
            "Train Epoch: 174 [46080/60000 (77%)]\tLoss: 735.333557\n",
            "Train Epoch: 174 [47360/60000 (79%)]\tLoss: 733.873962\n",
            "Train Epoch: 174 [48640/60000 (81%)]\tLoss: 754.995361\n",
            "Train Epoch: 174 [49920/60000 (83%)]\tLoss: 735.705933\n",
            "Train Epoch: 174 [51200/60000 (85%)]\tLoss: 740.720276\n",
            "Train Epoch: 174 [52480/60000 (87%)]\tLoss: 745.230957\n",
            "Train Epoch: 174 [53760/60000 (90%)]\tLoss: 728.716064\n",
            "Train Epoch: 174 [55040/60000 (92%)]\tLoss: 755.749329\n",
            "Train Epoch: 174 [56320/60000 (94%)]\tLoss: 718.363037\n",
            "Train Epoch: 174 [57600/60000 (96%)]\tLoss: 738.271301\n",
            "Train Epoch: 174 [58880/60000 (98%)]\tLoss: 739.789551\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784468412399292\n",
            "\n",
            "Train Epoch: 175 [0/60000 (0%)]\tLoss: 719.731873\n",
            "Train Epoch: 175 [1280/60000 (2%)]\tLoss: 729.673096\n",
            "Train Epoch: 175 [2560/60000 (4%)]\tLoss: 740.618469\n",
            "Train Epoch: 175 [3840/60000 (6%)]\tLoss: 734.816589\n",
            "Train Epoch: 175 [5120/60000 (9%)]\tLoss: 709.541016\n",
            "Train Epoch: 175 [6400/60000 (11%)]\tLoss: 741.585876\n",
            "Train Epoch: 175 [7680/60000 (13%)]\tLoss: 741.154724\n",
            "Train Epoch: 175 [8960/60000 (15%)]\tLoss: 746.042114\n",
            "Train Epoch: 175 [10240/60000 (17%)]\tLoss: 729.731323\n",
            "Train Epoch: 175 [11520/60000 (19%)]\tLoss: 736.583130\n",
            "Train Epoch: 175 [12800/60000 (21%)]\tLoss: 742.238098\n",
            "Train Epoch: 175 [14080/60000 (23%)]\tLoss: 743.026367\n",
            "Train Epoch: 175 [15360/60000 (26%)]\tLoss: 761.078125\n",
            "Train Epoch: 175 [16640/60000 (28%)]\tLoss: 728.379761\n",
            "Train Epoch: 175 [17920/60000 (30%)]\tLoss: 747.115417\n",
            "Train Epoch: 175 [19200/60000 (32%)]\tLoss: 734.375000\n",
            "Train Epoch: 175 [20480/60000 (34%)]\tLoss: 740.569946\n",
            "Train Epoch: 175 [21760/60000 (36%)]\tLoss: 752.927490\n",
            "Train Epoch: 175 [23040/60000 (38%)]\tLoss: 755.798828\n",
            "Train Epoch: 175 [24320/60000 (41%)]\tLoss: 747.144226\n",
            "Train Epoch: 175 [25600/60000 (43%)]\tLoss: 725.458008\n",
            "Train Epoch: 175 [26880/60000 (45%)]\tLoss: 717.657898\n",
            "Train Epoch: 175 [28160/60000 (47%)]\tLoss: 742.184998\n",
            "Train Epoch: 175 [29440/60000 (49%)]\tLoss: 720.281921\n",
            "Train Epoch: 175 [30720/60000 (51%)]\tLoss: 756.538086\n",
            "Train Epoch: 175 [32000/60000 (53%)]\tLoss: 763.148987\n",
            "Train Epoch: 175 [33280/60000 (55%)]\tLoss: 749.168762\n",
            "Train Epoch: 175 [34560/60000 (58%)]\tLoss: 732.789490\n",
            "Train Epoch: 175 [35840/60000 (60%)]\tLoss: 738.119751\n",
            "Train Epoch: 175 [37120/60000 (62%)]\tLoss: 752.628479\n",
            "Train Epoch: 175 [38400/60000 (64%)]\tLoss: 730.275330\n",
            "Train Epoch: 175 [39680/60000 (66%)]\tLoss: 717.777405\n",
            "Train Epoch: 175 [40960/60000 (68%)]\tLoss: 758.237427\n",
            "Train Epoch: 175 [42240/60000 (70%)]\tLoss: 757.378845\n",
            "Train Epoch: 175 [43520/60000 (72%)]\tLoss: 712.991028\n",
            "Train Epoch: 175 [44800/60000 (75%)]\tLoss: 724.477478\n",
            "Train Epoch: 175 [46080/60000 (77%)]\tLoss: 745.202148\n",
            "Train Epoch: 175 [47360/60000 (79%)]\tLoss: 739.109741\n",
            "Train Epoch: 175 [48640/60000 (81%)]\tLoss: 766.118896\n",
            "Train Epoch: 175 [49920/60000 (83%)]\tLoss: 718.939819\n",
            "Train Epoch: 175 [51200/60000 (85%)]\tLoss: 732.415466\n",
            "Train Epoch: 175 [52480/60000 (87%)]\tLoss: 725.656006\n",
            "Train Epoch: 175 [53760/60000 (90%)]\tLoss: 750.046448\n",
            "Train Epoch: 175 [55040/60000 (92%)]\tLoss: 731.773804\n",
            "Train Epoch: 175 [56320/60000 (94%)]\tLoss: 755.216675\n",
            "Train Epoch: 175 [57600/60000 (96%)]\tLoss: 723.765747\n",
            "Train Epoch: 175 [58880/60000 (98%)]\tLoss: 734.428284\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978369951248169\n",
            "\n",
            "Train Epoch: 176 [0/60000 (0%)]\tLoss: 717.900269\n",
            "Train Epoch: 176 [1280/60000 (2%)]\tLoss: 724.127991\n",
            "Train Epoch: 176 [2560/60000 (4%)]\tLoss: 725.909424\n",
            "Train Epoch: 176 [3840/60000 (6%)]\tLoss: 745.316101\n",
            "Train Epoch: 176 [5120/60000 (9%)]\tLoss: 745.831177\n",
            "Train Epoch: 176 [6400/60000 (11%)]\tLoss: 761.649658\n",
            "Train Epoch: 176 [7680/60000 (13%)]\tLoss: 716.079346\n",
            "Train Epoch: 176 [8960/60000 (15%)]\tLoss: 749.977722\n",
            "Train Epoch: 176 [10240/60000 (17%)]\tLoss: 725.227661\n",
            "Train Epoch: 176 [11520/60000 (19%)]\tLoss: 748.374817\n",
            "Train Epoch: 176 [12800/60000 (21%)]\tLoss: 702.589111\n",
            "Train Epoch: 176 [14080/60000 (23%)]\tLoss: 725.354553\n",
            "Train Epoch: 176 [15360/60000 (26%)]\tLoss: 758.110718\n",
            "Train Epoch: 176 [16640/60000 (28%)]\tLoss: 755.561035\n",
            "Train Epoch: 176 [17920/60000 (30%)]\tLoss: 722.609619\n",
            "Train Epoch: 176 [19200/60000 (32%)]\tLoss: 762.770264\n",
            "Train Epoch: 176 [20480/60000 (34%)]\tLoss: 728.287659\n",
            "Train Epoch: 176 [21760/60000 (36%)]\tLoss: 741.714905\n",
            "Train Epoch: 176 [23040/60000 (38%)]\tLoss: 715.450134\n",
            "Train Epoch: 176 [24320/60000 (41%)]\tLoss: 717.577026\n",
            "Train Epoch: 176 [25600/60000 (43%)]\tLoss: 714.664917\n",
            "Train Epoch: 176 [26880/60000 (45%)]\tLoss: 731.622559\n",
            "Train Epoch: 176 [28160/60000 (47%)]\tLoss: 734.084656\n",
            "Train Epoch: 176 [29440/60000 (49%)]\tLoss: 755.063049\n",
            "Train Epoch: 176 [30720/60000 (51%)]\tLoss: 713.914307\n",
            "Train Epoch: 176 [32000/60000 (53%)]\tLoss: 746.953064\n",
            "Train Epoch: 176 [33280/60000 (55%)]\tLoss: 734.305786\n",
            "Train Epoch: 176 [34560/60000 (58%)]\tLoss: 750.900146\n",
            "Train Epoch: 176 [35840/60000 (60%)]\tLoss: 754.277954\n",
            "Train Epoch: 176 [37120/60000 (62%)]\tLoss: 716.125183\n",
            "Train Epoch: 176 [38400/60000 (64%)]\tLoss: 766.906799\n",
            "Train Epoch: 176 [39680/60000 (66%)]\tLoss: 749.132080\n",
            "Train Epoch: 176 [40960/60000 (68%)]\tLoss: 746.270813\n",
            "Train Epoch: 176 [42240/60000 (70%)]\tLoss: 728.824829\n",
            "Train Epoch: 176 [43520/60000 (72%)]\tLoss: 722.271179\n",
            "Train Epoch: 176 [44800/60000 (75%)]\tLoss: 735.405579\n",
            "Train Epoch: 176 [46080/60000 (77%)]\tLoss: 744.000732\n",
            "Train Epoch: 176 [47360/60000 (79%)]\tLoss: 768.425964\n",
            "Train Epoch: 176 [48640/60000 (81%)]\tLoss: 710.916321\n",
            "Train Epoch: 176 [49920/60000 (83%)]\tLoss: 715.150818\n",
            "Train Epoch: 176 [51200/60000 (85%)]\tLoss: 729.529053\n",
            "Train Epoch: 176 [52480/60000 (87%)]\tLoss: 730.598633\n",
            "Train Epoch: 176 [53760/60000 (90%)]\tLoss: 732.344849\n",
            "Train Epoch: 176 [55040/60000 (92%)]\tLoss: 732.268372\n",
            "Train Epoch: 176 [56320/60000 (94%)]\tLoss: 715.183228\n",
            "Train Epoch: 176 [57600/60000 (96%)]\tLoss: 730.281067\n",
            "Train Epoch: 176 [58880/60000 (98%)]\tLoss: 738.616455\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784678518772125\n",
            "\n",
            "Train Epoch: 177 [0/60000 (0%)]\tLoss: 717.522034\n",
            "Train Epoch: 177 [1280/60000 (2%)]\tLoss: 747.348083\n",
            "Train Epoch: 177 [2560/60000 (4%)]\tLoss: 710.589172\n",
            "Train Epoch: 177 [3840/60000 (6%)]\tLoss: 741.401550\n",
            "Train Epoch: 177 [5120/60000 (9%)]\tLoss: 735.638672\n",
            "Train Epoch: 177 [6400/60000 (11%)]\tLoss: 723.366333\n",
            "Train Epoch: 177 [7680/60000 (13%)]\tLoss: 747.825317\n",
            "Train Epoch: 177 [8960/60000 (15%)]\tLoss: 722.825256\n",
            "Train Epoch: 177 [10240/60000 (17%)]\tLoss: 748.155334\n",
            "Train Epoch: 177 [11520/60000 (19%)]\tLoss: 773.902710\n",
            "Train Epoch: 177 [12800/60000 (21%)]\tLoss: 744.725525\n",
            "Train Epoch: 177 [14080/60000 (23%)]\tLoss: 726.160278\n",
            "Train Epoch: 177 [15360/60000 (26%)]\tLoss: 772.292664\n",
            "Train Epoch: 177 [16640/60000 (28%)]\tLoss: 734.980408\n",
            "Train Epoch: 177 [17920/60000 (30%)]\tLoss: 709.298584\n",
            "Train Epoch: 177 [19200/60000 (32%)]\tLoss: 726.388000\n",
            "Train Epoch: 177 [20480/60000 (34%)]\tLoss: 733.804749\n",
            "Train Epoch: 177 [21760/60000 (36%)]\tLoss: 727.092346\n",
            "Train Epoch: 177 [23040/60000 (38%)]\tLoss: 740.143372\n",
            "Train Epoch: 177 [24320/60000 (41%)]\tLoss: 719.428650\n",
            "Train Epoch: 177 [25600/60000 (43%)]\tLoss: 760.867493\n",
            "Train Epoch: 177 [26880/60000 (45%)]\tLoss: 742.255981\n",
            "Train Epoch: 177 [28160/60000 (47%)]\tLoss: 762.769653\n",
            "Train Epoch: 177 [29440/60000 (49%)]\tLoss: 759.751648\n",
            "Train Epoch: 177 [30720/60000 (51%)]\tLoss: 744.831604\n",
            "Train Epoch: 177 [32000/60000 (53%)]\tLoss: 739.890198\n",
            "Train Epoch: 177 [33280/60000 (55%)]\tLoss: 735.279419\n",
            "Train Epoch: 177 [34560/60000 (58%)]\tLoss: 757.790222\n",
            "Train Epoch: 177 [35840/60000 (60%)]\tLoss: 753.783630\n",
            "Train Epoch: 177 [37120/60000 (62%)]\tLoss: 733.459900\n",
            "Train Epoch: 177 [38400/60000 (64%)]\tLoss: 718.167969\n",
            "Train Epoch: 177 [39680/60000 (66%)]\tLoss: 746.616333\n",
            "Train Epoch: 177 [40960/60000 (68%)]\tLoss: 744.567444\n",
            "Train Epoch: 177 [42240/60000 (70%)]\tLoss: 747.845154\n",
            "Train Epoch: 177 [43520/60000 (72%)]\tLoss: 755.357239\n",
            "Train Epoch: 177 [44800/60000 (75%)]\tLoss: 712.032715\n",
            "Train Epoch: 177 [46080/60000 (77%)]\tLoss: 728.175293\n",
            "Train Epoch: 177 [47360/60000 (79%)]\tLoss: 715.785156\n",
            "Train Epoch: 177 [48640/60000 (81%)]\tLoss: 723.444031\n",
            "Train Epoch: 177 [49920/60000 (83%)]\tLoss: 733.902954\n",
            "Train Epoch: 177 [51200/60000 (85%)]\tLoss: 739.033386\n",
            "Train Epoch: 177 [52480/60000 (87%)]\tLoss: 742.515198\n",
            "Train Epoch: 177 [53760/60000 (90%)]\tLoss: 763.112793\n",
            "Train Epoch: 177 [55040/60000 (92%)]\tLoss: 746.010315\n",
            "Train Epoch: 177 [56320/60000 (94%)]\tLoss: 750.115967\n",
            "Train Epoch: 177 [57600/60000 (96%)]\tLoss: 721.121094\n",
            "Train Epoch: 177 [58880/60000 (98%)]\tLoss: 717.635864\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786261022090912\n",
            "\n",
            "Train Epoch: 178 [0/60000 (0%)]\tLoss: 720.502197\n",
            "Train Epoch: 178 [1280/60000 (2%)]\tLoss: 741.472351\n",
            "Train Epoch: 178 [2560/60000 (4%)]\tLoss: 744.518127\n",
            "Train Epoch: 178 [3840/60000 (6%)]\tLoss: 739.627625\n",
            "Train Epoch: 178 [5120/60000 (9%)]\tLoss: 737.835876\n",
            "Train Epoch: 178 [6400/60000 (11%)]\tLoss: 734.978210\n",
            "Train Epoch: 178 [7680/60000 (13%)]\tLoss: 737.081055\n",
            "Train Epoch: 178 [8960/60000 (15%)]\tLoss: 735.569519\n",
            "Train Epoch: 178 [10240/60000 (17%)]\tLoss: 738.588135\n",
            "Train Epoch: 178 [11520/60000 (19%)]\tLoss: 762.755005\n",
            "Train Epoch: 178 [12800/60000 (21%)]\tLoss: 734.702026\n",
            "Train Epoch: 178 [14080/60000 (23%)]\tLoss: 743.128540\n",
            "Train Epoch: 178 [15360/60000 (26%)]\tLoss: 761.906860\n",
            "Train Epoch: 178 [16640/60000 (28%)]\tLoss: 753.250122\n",
            "Train Epoch: 178 [17920/60000 (30%)]\tLoss: 726.494446\n",
            "Train Epoch: 178 [19200/60000 (32%)]\tLoss: 741.925598\n",
            "Train Epoch: 178 [20480/60000 (34%)]\tLoss: 756.906006\n",
            "Train Epoch: 178 [21760/60000 (36%)]\tLoss: 722.713135\n",
            "Train Epoch: 178 [23040/60000 (38%)]\tLoss: 736.511292\n",
            "Train Epoch: 178 [24320/60000 (41%)]\tLoss: 764.784485\n",
            "Train Epoch: 178 [25600/60000 (43%)]\tLoss: 746.300049\n",
            "Train Epoch: 178 [26880/60000 (45%)]\tLoss: 718.309021\n",
            "Train Epoch: 178 [28160/60000 (47%)]\tLoss: 746.877197\n",
            "Train Epoch: 178 [29440/60000 (49%)]\tLoss: 730.693726\n",
            "Train Epoch: 178 [30720/60000 (51%)]\tLoss: 733.543945\n",
            "Train Epoch: 178 [32000/60000 (53%)]\tLoss: 749.065613\n",
            "Train Epoch: 178 [33280/60000 (55%)]\tLoss: 728.795593\n",
            "Train Epoch: 178 [34560/60000 (58%)]\tLoss: 735.313293\n",
            "Train Epoch: 178 [35840/60000 (60%)]\tLoss: 724.243835\n",
            "Train Epoch: 178 [37120/60000 (62%)]\tLoss: 728.141235\n",
            "Train Epoch: 178 [38400/60000 (64%)]\tLoss: 745.971375\n",
            "Train Epoch: 178 [39680/60000 (66%)]\tLoss: 754.440308\n",
            "Train Epoch: 178 [40960/60000 (68%)]\tLoss: 773.947021\n",
            "Train Epoch: 178 [42240/60000 (70%)]\tLoss: 729.433899\n",
            "Train Epoch: 178 [43520/60000 (72%)]\tLoss: 729.231323\n",
            "Train Epoch: 178 [44800/60000 (75%)]\tLoss: 726.133606\n",
            "Train Epoch: 178 [46080/60000 (77%)]\tLoss: 740.598206\n",
            "Train Epoch: 178 [47360/60000 (79%)]\tLoss: 759.544067\n",
            "Train Epoch: 178 [48640/60000 (81%)]\tLoss: 767.757385\n",
            "Train Epoch: 178 [49920/60000 (83%)]\tLoss: 734.191406\n",
            "Train Epoch: 178 [51200/60000 (85%)]\tLoss: 755.069397\n",
            "Train Epoch: 178 [52480/60000 (87%)]\tLoss: 759.597656\n",
            "Train Epoch: 178 [53760/60000 (90%)]\tLoss: 763.538940\n",
            "Train Epoch: 178 [55040/60000 (92%)]\tLoss: 720.050476\n",
            "Train Epoch: 178 [56320/60000 (94%)]\tLoss: 753.067566\n",
            "Train Epoch: 178 [57600/60000 (96%)]\tLoss: 725.328796\n",
            "Train Epoch: 178 [58880/60000 (98%)]\tLoss: 736.139771\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784268736839294\n",
            "\n",
            "Train Epoch: 179 [0/60000 (0%)]\tLoss: 757.750305\n",
            "Train Epoch: 179 [1280/60000 (2%)]\tLoss: 743.562073\n",
            "Train Epoch: 179 [2560/60000 (4%)]\tLoss: 755.251221\n",
            "Train Epoch: 179 [3840/60000 (6%)]\tLoss: 745.648621\n",
            "Train Epoch: 179 [5120/60000 (9%)]\tLoss: 743.673218\n",
            "Train Epoch: 179 [6400/60000 (11%)]\tLoss: 727.338013\n",
            "Train Epoch: 179 [7680/60000 (13%)]\tLoss: 745.585266\n",
            "Train Epoch: 179 [8960/60000 (15%)]\tLoss: 749.021362\n",
            "Train Epoch: 179 [10240/60000 (17%)]\tLoss: 741.612366\n",
            "Train Epoch: 179 [11520/60000 (19%)]\tLoss: 746.131653\n",
            "Train Epoch: 179 [12800/60000 (21%)]\tLoss: 730.378113\n",
            "Train Epoch: 179 [14080/60000 (23%)]\tLoss: 744.089294\n",
            "Train Epoch: 179 [15360/60000 (26%)]\tLoss: 713.576172\n",
            "Train Epoch: 179 [16640/60000 (28%)]\tLoss: 727.226196\n",
            "Train Epoch: 179 [17920/60000 (30%)]\tLoss: 729.650269\n",
            "Train Epoch: 179 [19200/60000 (32%)]\tLoss: 737.941711\n",
            "Train Epoch: 179 [20480/60000 (34%)]\tLoss: 733.666260\n",
            "Train Epoch: 179 [21760/60000 (36%)]\tLoss: 733.467468\n",
            "Train Epoch: 179 [23040/60000 (38%)]\tLoss: 738.403992\n",
            "Train Epoch: 179 [24320/60000 (41%)]\tLoss: 749.370789\n",
            "Train Epoch: 179 [25600/60000 (43%)]\tLoss: 756.386047\n",
            "Train Epoch: 179 [26880/60000 (45%)]\tLoss: 740.727417\n",
            "Train Epoch: 179 [28160/60000 (47%)]\tLoss: 733.851501\n",
            "Train Epoch: 179 [29440/60000 (49%)]\tLoss: 708.291016\n",
            "Train Epoch: 179 [30720/60000 (51%)]\tLoss: 719.197754\n",
            "Train Epoch: 179 [32000/60000 (53%)]\tLoss: 767.656006\n",
            "Train Epoch: 179 [33280/60000 (55%)]\tLoss: 727.815979\n",
            "Train Epoch: 179 [34560/60000 (58%)]\tLoss: 733.732178\n",
            "Train Epoch: 179 [35840/60000 (60%)]\tLoss: 726.818115\n",
            "Train Epoch: 179 [37120/60000 (62%)]\tLoss: 728.286743\n",
            "Train Epoch: 179 [38400/60000 (64%)]\tLoss: 731.970764\n",
            "Train Epoch: 179 [39680/60000 (66%)]\tLoss: 706.490601\n",
            "Train Epoch: 179 [40960/60000 (68%)]\tLoss: 762.384338\n",
            "Train Epoch: 179 [42240/60000 (70%)]\tLoss: 731.902039\n",
            "Train Epoch: 179 [43520/60000 (72%)]\tLoss: 754.715088\n",
            "Train Epoch: 179 [44800/60000 (75%)]\tLoss: 738.745178\n",
            "Train Epoch: 179 [46080/60000 (77%)]\tLoss: 775.504517\n",
            "Train Epoch: 179 [47360/60000 (79%)]\tLoss: 714.008545\n",
            "Train Epoch: 179 [48640/60000 (81%)]\tLoss: 725.978394\n",
            "Train Epoch: 179 [49920/60000 (83%)]\tLoss: 733.228271\n",
            "Train Epoch: 179 [51200/60000 (85%)]\tLoss: 741.345215\n",
            "Train Epoch: 179 [52480/60000 (87%)]\tLoss: 721.891235\n",
            "Train Epoch: 179 [53760/60000 (90%)]\tLoss: 733.473999\n",
            "Train Epoch: 179 [55040/60000 (92%)]\tLoss: 734.330139\n",
            "Train Epoch: 179 [56320/60000 (94%)]\tLoss: 763.276855\n",
            "Train Epoch: 179 [57600/60000 (96%)]\tLoss: 732.845581\n",
            "Train Epoch: 179 [58880/60000 (98%)]\tLoss: 741.567566\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782187044620514\n",
            "\n",
            "Train Epoch: 180 [0/60000 (0%)]\tLoss: 743.633057\n",
            "Train Epoch: 180 [1280/60000 (2%)]\tLoss: 737.593079\n",
            "Train Epoch: 180 [2560/60000 (4%)]\tLoss: 716.565857\n",
            "Train Epoch: 180 [3840/60000 (6%)]\tLoss: 731.747986\n",
            "Train Epoch: 180 [5120/60000 (9%)]\tLoss: 750.712158\n",
            "Train Epoch: 180 [6400/60000 (11%)]\tLoss: 732.825806\n",
            "Train Epoch: 180 [7680/60000 (13%)]\tLoss: 753.652832\n",
            "Train Epoch: 180 [8960/60000 (15%)]\tLoss: 722.370361\n",
            "Train Epoch: 180 [10240/60000 (17%)]\tLoss: 754.377686\n",
            "Train Epoch: 180 [11520/60000 (19%)]\tLoss: 737.111023\n",
            "Train Epoch: 180 [12800/60000 (21%)]\tLoss: 720.582947\n",
            "Train Epoch: 180 [14080/60000 (23%)]\tLoss: 711.300110\n",
            "Train Epoch: 180 [15360/60000 (26%)]\tLoss: 749.672668\n",
            "Train Epoch: 180 [16640/60000 (28%)]\tLoss: 733.296143\n",
            "Train Epoch: 180 [17920/60000 (30%)]\tLoss: 737.397583\n",
            "Train Epoch: 180 [19200/60000 (32%)]\tLoss: 749.391907\n",
            "Train Epoch: 180 [20480/60000 (34%)]\tLoss: 758.687988\n",
            "Train Epoch: 180 [21760/60000 (36%)]\tLoss: 715.159546\n",
            "Train Epoch: 180 [23040/60000 (38%)]\tLoss: 729.809814\n",
            "Train Epoch: 180 [24320/60000 (41%)]\tLoss: 756.202026\n",
            "Train Epoch: 180 [25600/60000 (43%)]\tLoss: 744.180054\n",
            "Train Epoch: 180 [26880/60000 (45%)]\tLoss: 744.568176\n",
            "Train Epoch: 180 [28160/60000 (47%)]\tLoss: 752.336731\n",
            "Train Epoch: 180 [29440/60000 (49%)]\tLoss: 721.939209\n",
            "Train Epoch: 180 [30720/60000 (51%)]\tLoss: 719.097961\n",
            "Train Epoch: 180 [32000/60000 (53%)]\tLoss: 754.945923\n",
            "Train Epoch: 180 [33280/60000 (55%)]\tLoss: 742.131165\n",
            "Train Epoch: 180 [34560/60000 (58%)]\tLoss: 744.642639\n",
            "Train Epoch: 180 [35840/60000 (60%)]\tLoss: 709.673157\n",
            "Train Epoch: 180 [37120/60000 (62%)]\tLoss: 736.839417\n",
            "Train Epoch: 180 [38400/60000 (64%)]\tLoss: 708.571411\n",
            "Train Epoch: 180 [39680/60000 (66%)]\tLoss: 728.610046\n",
            "Train Epoch: 180 [40960/60000 (68%)]\tLoss: 762.212585\n",
            "Train Epoch: 180 [42240/60000 (70%)]\tLoss: 723.478027\n",
            "Train Epoch: 180 [43520/60000 (72%)]\tLoss: 736.211853\n",
            "Train Epoch: 180 [44800/60000 (75%)]\tLoss: 757.598389\n",
            "Train Epoch: 180 [46080/60000 (77%)]\tLoss: 732.581604\n",
            "Train Epoch: 180 [47360/60000 (79%)]\tLoss: 746.530579\n",
            "Train Epoch: 180 [48640/60000 (81%)]\tLoss: 762.371704\n",
            "Train Epoch: 180 [49920/60000 (83%)]\tLoss: 761.992920\n",
            "Train Epoch: 180 [51200/60000 (85%)]\tLoss: 737.341003\n",
            "Train Epoch: 180 [52480/60000 (87%)]\tLoss: 733.600037\n",
            "Train Epoch: 180 [53760/60000 (90%)]\tLoss: 734.434509\n",
            "Train Epoch: 180 [55040/60000 (92%)]\tLoss: 743.511169\n",
            "Train Epoch: 180 [56320/60000 (94%)]\tLoss: 716.549622\n",
            "Train Epoch: 180 [57600/60000 (96%)]\tLoss: 718.220093\n",
            "Train Epoch: 180 [58880/60000 (98%)]\tLoss: 742.499268\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978960782289505\n",
            "\n",
            "Train Epoch: 181 [0/60000 (0%)]\tLoss: 736.188049\n",
            "Train Epoch: 181 [1280/60000 (2%)]\tLoss: 740.219482\n",
            "Train Epoch: 181 [2560/60000 (4%)]\tLoss: 764.626404\n",
            "Train Epoch: 181 [3840/60000 (6%)]\tLoss: 738.655762\n",
            "Train Epoch: 181 [5120/60000 (9%)]\tLoss: 736.926086\n",
            "Train Epoch: 181 [6400/60000 (11%)]\tLoss: 736.716064\n",
            "Train Epoch: 181 [7680/60000 (13%)]\tLoss: 739.423340\n",
            "Train Epoch: 181 [8960/60000 (15%)]\tLoss: 730.834106\n",
            "Train Epoch: 181 [10240/60000 (17%)]\tLoss: 743.234375\n",
            "Train Epoch: 181 [11520/60000 (19%)]\tLoss: 734.912781\n",
            "Train Epoch: 181 [12800/60000 (21%)]\tLoss: 722.391357\n",
            "Train Epoch: 181 [14080/60000 (23%)]\tLoss: 758.141663\n",
            "Train Epoch: 181 [15360/60000 (26%)]\tLoss: 736.163696\n",
            "Train Epoch: 181 [16640/60000 (28%)]\tLoss: 730.199646\n",
            "Train Epoch: 181 [17920/60000 (30%)]\tLoss: 721.126465\n",
            "Train Epoch: 181 [19200/60000 (32%)]\tLoss: 731.395020\n",
            "Train Epoch: 181 [20480/60000 (34%)]\tLoss: 751.111328\n",
            "Train Epoch: 181 [21760/60000 (36%)]\tLoss: 733.837708\n",
            "Train Epoch: 181 [23040/60000 (38%)]\tLoss: 741.460999\n",
            "Train Epoch: 181 [24320/60000 (41%)]\tLoss: 734.286133\n",
            "Train Epoch: 181 [25600/60000 (43%)]\tLoss: 755.264465\n",
            "Train Epoch: 181 [26880/60000 (45%)]\tLoss: 735.388123\n",
            "Train Epoch: 181 [28160/60000 (47%)]\tLoss: 708.567200\n",
            "Train Epoch: 181 [29440/60000 (49%)]\tLoss: 698.338257\n",
            "Train Epoch: 181 [30720/60000 (51%)]\tLoss: 736.716431\n",
            "Train Epoch: 181 [32000/60000 (53%)]\tLoss: 717.344116\n",
            "Train Epoch: 181 [33280/60000 (55%)]\tLoss: 743.666260\n",
            "Train Epoch: 181 [34560/60000 (58%)]\tLoss: 723.515503\n",
            "Train Epoch: 181 [35840/60000 (60%)]\tLoss: 729.226135\n",
            "Train Epoch: 181 [37120/60000 (62%)]\tLoss: 751.200867\n",
            "Train Epoch: 181 [38400/60000 (64%)]\tLoss: 717.342773\n",
            "Train Epoch: 181 [39680/60000 (66%)]\tLoss: 749.918884\n",
            "Train Epoch: 181 [40960/60000 (68%)]\tLoss: 757.199280\n",
            "Train Epoch: 181 [42240/60000 (70%)]\tLoss: 771.597839\n",
            "Train Epoch: 181 [43520/60000 (72%)]\tLoss: 730.050537\n",
            "Train Epoch: 181 [44800/60000 (75%)]\tLoss: 742.119629\n",
            "Train Epoch: 181 [46080/60000 (77%)]\tLoss: 735.593445\n",
            "Train Epoch: 181 [47360/60000 (79%)]\tLoss: 732.600952\n",
            "Train Epoch: 181 [48640/60000 (81%)]\tLoss: 735.598328\n",
            "Train Epoch: 181 [49920/60000 (83%)]\tLoss: 729.686523\n",
            "Train Epoch: 181 [51200/60000 (85%)]\tLoss: 747.997986\n",
            "Train Epoch: 181 [52480/60000 (87%)]\tLoss: 723.595154\n",
            "Train Epoch: 181 [53760/60000 (90%)]\tLoss: 751.077576\n",
            "Train Epoch: 181 [55040/60000 (92%)]\tLoss: 747.788574\n",
            "Train Epoch: 181 [56320/60000 (94%)]\tLoss: 737.060120\n",
            "Train Epoch: 181 [57600/60000 (96%)]\tLoss: 749.308411\n",
            "Train Epoch: 181 [58880/60000 (98%)]\tLoss: 745.922729\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783076643943787\n",
            "\n",
            "Train Epoch: 182 [0/60000 (0%)]\tLoss: 751.187073\n",
            "Train Epoch: 182 [1280/60000 (2%)]\tLoss: 693.008423\n",
            "Train Epoch: 182 [2560/60000 (4%)]\tLoss: 720.108398\n",
            "Train Epoch: 182 [3840/60000 (6%)]\tLoss: 750.085754\n",
            "Train Epoch: 182 [5120/60000 (9%)]\tLoss: 754.508972\n",
            "Train Epoch: 182 [6400/60000 (11%)]\tLoss: 737.420105\n",
            "Train Epoch: 182 [7680/60000 (13%)]\tLoss: 701.975037\n",
            "Train Epoch: 182 [8960/60000 (15%)]\tLoss: 744.280029\n",
            "Train Epoch: 182 [10240/60000 (17%)]\tLoss: 746.344360\n",
            "Train Epoch: 182 [11520/60000 (19%)]\tLoss: 759.073120\n",
            "Train Epoch: 182 [12800/60000 (21%)]\tLoss: 736.837952\n",
            "Train Epoch: 182 [14080/60000 (23%)]\tLoss: 717.076660\n",
            "Train Epoch: 182 [15360/60000 (26%)]\tLoss: 722.259521\n",
            "Train Epoch: 182 [16640/60000 (28%)]\tLoss: 720.073853\n",
            "Train Epoch: 182 [17920/60000 (30%)]\tLoss: 752.136475\n",
            "Train Epoch: 182 [19200/60000 (32%)]\tLoss: 741.884888\n",
            "Train Epoch: 182 [20480/60000 (34%)]\tLoss: 726.386108\n",
            "Train Epoch: 182 [21760/60000 (36%)]\tLoss: 725.335815\n",
            "Train Epoch: 182 [23040/60000 (38%)]\tLoss: 725.803467\n",
            "Train Epoch: 182 [24320/60000 (41%)]\tLoss: 748.563904\n",
            "Train Epoch: 182 [25600/60000 (43%)]\tLoss: 726.819214\n",
            "Train Epoch: 182 [26880/60000 (45%)]\tLoss: 758.314819\n",
            "Train Epoch: 182 [28160/60000 (47%)]\tLoss: 760.927673\n",
            "Train Epoch: 182 [29440/60000 (49%)]\tLoss: 747.690674\n",
            "Train Epoch: 182 [30720/60000 (51%)]\tLoss: 722.411926\n",
            "Train Epoch: 182 [32000/60000 (53%)]\tLoss: 730.999146\n",
            "Train Epoch: 182 [33280/60000 (55%)]\tLoss: 749.520386\n",
            "Train Epoch: 182 [34560/60000 (58%)]\tLoss: 753.512878\n",
            "Train Epoch: 182 [35840/60000 (60%)]\tLoss: 741.406067\n",
            "Train Epoch: 182 [37120/60000 (62%)]\tLoss: 757.852417\n",
            "Train Epoch: 182 [38400/60000 (64%)]\tLoss: 736.281311\n",
            "Train Epoch: 182 [39680/60000 (66%)]\tLoss: 731.681763\n",
            "Train Epoch: 182 [40960/60000 (68%)]\tLoss: 710.607849\n",
            "Train Epoch: 182 [42240/60000 (70%)]\tLoss: 736.071411\n",
            "Train Epoch: 182 [43520/60000 (72%)]\tLoss: 749.028259\n",
            "Train Epoch: 182 [44800/60000 (75%)]\tLoss: 745.051331\n",
            "Train Epoch: 182 [46080/60000 (77%)]\tLoss: 729.677917\n",
            "Train Epoch: 182 [47360/60000 (79%)]\tLoss: 712.512878\n",
            "Train Epoch: 182 [48640/60000 (81%)]\tLoss: 703.944824\n",
            "Train Epoch: 182 [49920/60000 (83%)]\tLoss: 729.922424\n",
            "Train Epoch: 182 [51200/60000 (85%)]\tLoss: 726.974365\n",
            "Train Epoch: 182 [52480/60000 (87%)]\tLoss: 719.146606\n",
            "Train Epoch: 182 [53760/60000 (90%)]\tLoss: 715.309021\n",
            "Train Epoch: 182 [55040/60000 (92%)]\tLoss: 749.250793\n",
            "Train Epoch: 182 [56320/60000 (94%)]\tLoss: 731.728210\n",
            "Train Epoch: 182 [57600/60000 (96%)]\tLoss: 713.736877\n",
            "Train Epoch: 182 [58880/60000 (98%)]\tLoss: 734.374817\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787226617336273\n",
            "\n",
            "Train Epoch: 183 [0/60000 (0%)]\tLoss: 722.559753\n",
            "Train Epoch: 183 [1280/60000 (2%)]\tLoss: 756.473816\n",
            "Train Epoch: 183 [2560/60000 (4%)]\tLoss: 732.947327\n",
            "Train Epoch: 183 [3840/60000 (6%)]\tLoss: 763.453064\n",
            "Train Epoch: 183 [5120/60000 (9%)]\tLoss: 745.082214\n",
            "Train Epoch: 183 [6400/60000 (11%)]\tLoss: 757.401550\n",
            "Train Epoch: 183 [7680/60000 (13%)]\tLoss: 745.397034\n",
            "Train Epoch: 183 [8960/60000 (15%)]\tLoss: 743.179810\n",
            "Train Epoch: 183 [10240/60000 (17%)]\tLoss: 712.014404\n",
            "Train Epoch: 183 [11520/60000 (19%)]\tLoss: 724.066223\n",
            "Train Epoch: 183 [12800/60000 (21%)]\tLoss: 737.547119\n",
            "Train Epoch: 183 [14080/60000 (23%)]\tLoss: 751.540588\n",
            "Train Epoch: 183 [15360/60000 (26%)]\tLoss: 735.169250\n",
            "Train Epoch: 183 [16640/60000 (28%)]\tLoss: 731.760559\n",
            "Train Epoch: 183 [17920/60000 (30%)]\tLoss: 732.424988\n",
            "Train Epoch: 183 [19200/60000 (32%)]\tLoss: 728.729309\n",
            "Train Epoch: 183 [20480/60000 (34%)]\tLoss: 717.451599\n",
            "Train Epoch: 183 [21760/60000 (36%)]\tLoss: 736.731995\n",
            "Train Epoch: 183 [23040/60000 (38%)]\tLoss: 731.510010\n",
            "Train Epoch: 183 [24320/60000 (41%)]\tLoss: 756.720886\n",
            "Train Epoch: 183 [25600/60000 (43%)]\tLoss: 723.840088\n",
            "Train Epoch: 183 [26880/60000 (45%)]\tLoss: 727.217651\n",
            "Train Epoch: 183 [28160/60000 (47%)]\tLoss: 712.970032\n",
            "Train Epoch: 183 [29440/60000 (49%)]\tLoss: 746.374939\n",
            "Train Epoch: 183 [30720/60000 (51%)]\tLoss: 717.847107\n",
            "Train Epoch: 183 [32000/60000 (53%)]\tLoss: 753.304260\n",
            "Train Epoch: 183 [33280/60000 (55%)]\tLoss: 743.924194\n",
            "Train Epoch: 183 [34560/60000 (58%)]\tLoss: 722.045044\n",
            "Train Epoch: 183 [35840/60000 (60%)]\tLoss: 727.914062\n",
            "Train Epoch: 183 [37120/60000 (62%)]\tLoss: 744.603882\n",
            "Train Epoch: 183 [38400/60000 (64%)]\tLoss: 741.348816\n",
            "Train Epoch: 183 [39680/60000 (66%)]\tLoss: 745.263000\n",
            "Train Epoch: 183 [40960/60000 (68%)]\tLoss: 768.576965\n",
            "Train Epoch: 183 [42240/60000 (70%)]\tLoss: 746.347656\n",
            "Train Epoch: 183 [43520/60000 (72%)]\tLoss: 725.086548\n",
            "Train Epoch: 183 [44800/60000 (75%)]\tLoss: 731.847229\n",
            "Train Epoch: 183 [46080/60000 (77%)]\tLoss: 745.704041\n",
            "Train Epoch: 183 [47360/60000 (79%)]\tLoss: 718.677429\n",
            "Train Epoch: 183 [48640/60000 (81%)]\tLoss: 750.982239\n",
            "Train Epoch: 183 [49920/60000 (83%)]\tLoss: 732.229004\n",
            "Train Epoch: 183 [51200/60000 (85%)]\tLoss: 733.124939\n",
            "Train Epoch: 183 [52480/60000 (87%)]\tLoss: 731.023071\n",
            "Train Epoch: 183 [53760/60000 (90%)]\tLoss: 733.137695\n",
            "Train Epoch: 183 [55040/60000 (92%)]\tLoss: 720.784363\n",
            "Train Epoch: 183 [56320/60000 (94%)]\tLoss: 728.144409\n",
            "Train Epoch: 183 [57600/60000 (96%)]\tLoss: 713.149597\n",
            "Train Epoch: 183 [58880/60000 (98%)]\tLoss: 740.561401\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978038102388382\n",
            "\n",
            "Train Epoch: 184 [0/60000 (0%)]\tLoss: 714.414673\n",
            "Train Epoch: 184 [1280/60000 (2%)]\tLoss: 727.891724\n",
            "Train Epoch: 184 [2560/60000 (4%)]\tLoss: 752.945068\n",
            "Train Epoch: 184 [3840/60000 (6%)]\tLoss: 751.538513\n",
            "Train Epoch: 184 [5120/60000 (9%)]\tLoss: 744.544189\n",
            "Train Epoch: 184 [6400/60000 (11%)]\tLoss: 774.602478\n",
            "Train Epoch: 184 [7680/60000 (13%)]\tLoss: 742.669983\n",
            "Train Epoch: 184 [8960/60000 (15%)]\tLoss: 708.935974\n",
            "Train Epoch: 184 [10240/60000 (17%)]\tLoss: 750.475037\n",
            "Train Epoch: 184 [11520/60000 (19%)]\tLoss: 741.802063\n",
            "Train Epoch: 184 [12800/60000 (21%)]\tLoss: 740.458496\n",
            "Train Epoch: 184 [14080/60000 (23%)]\tLoss: 743.227295\n",
            "Train Epoch: 184 [15360/60000 (26%)]\tLoss: 721.012085\n",
            "Train Epoch: 184 [16640/60000 (28%)]\tLoss: 721.267944\n",
            "Train Epoch: 184 [17920/60000 (30%)]\tLoss: 747.638184\n",
            "Train Epoch: 184 [19200/60000 (32%)]\tLoss: 760.190308\n",
            "Train Epoch: 184 [20480/60000 (34%)]\tLoss: 721.789307\n",
            "Train Epoch: 184 [21760/60000 (36%)]\tLoss: 732.401672\n",
            "Train Epoch: 184 [23040/60000 (38%)]\tLoss: 721.824646\n",
            "Train Epoch: 184 [24320/60000 (41%)]\tLoss: 741.019836\n",
            "Train Epoch: 184 [25600/60000 (43%)]\tLoss: 726.384277\n",
            "Train Epoch: 184 [26880/60000 (45%)]\tLoss: 744.146545\n",
            "Train Epoch: 184 [28160/60000 (47%)]\tLoss: 725.626282\n",
            "Train Epoch: 184 [29440/60000 (49%)]\tLoss: 761.619019\n",
            "Train Epoch: 184 [30720/60000 (51%)]\tLoss: 737.445129\n",
            "Train Epoch: 184 [32000/60000 (53%)]\tLoss: 755.386963\n",
            "Train Epoch: 184 [33280/60000 (55%)]\tLoss: 750.749634\n",
            "Train Epoch: 184 [34560/60000 (58%)]\tLoss: 745.650452\n",
            "Train Epoch: 184 [35840/60000 (60%)]\tLoss: 711.009033\n",
            "Train Epoch: 184 [37120/60000 (62%)]\tLoss: 721.978821\n",
            "Train Epoch: 184 [38400/60000 (64%)]\tLoss: 724.889587\n",
            "Train Epoch: 184 [39680/60000 (66%)]\tLoss: 726.068970\n",
            "Train Epoch: 184 [40960/60000 (68%)]\tLoss: 713.387878\n",
            "Train Epoch: 184 [42240/60000 (70%)]\tLoss: 721.326416\n",
            "Train Epoch: 184 [43520/60000 (72%)]\tLoss: 729.937256\n",
            "Train Epoch: 184 [44800/60000 (75%)]\tLoss: 740.059875\n",
            "Train Epoch: 184 [46080/60000 (77%)]\tLoss: 741.245300\n",
            "Train Epoch: 184 [47360/60000 (79%)]\tLoss: 745.175232\n",
            "Train Epoch: 184 [48640/60000 (81%)]\tLoss: 762.351868\n",
            "Train Epoch: 184 [49920/60000 (83%)]\tLoss: 756.955261\n",
            "Train Epoch: 184 [51200/60000 (85%)]\tLoss: 737.376343\n",
            "Train Epoch: 184 [52480/60000 (87%)]\tLoss: 727.277466\n",
            "Train Epoch: 184 [53760/60000 (90%)]\tLoss: 742.766174\n",
            "Train Epoch: 184 [55040/60000 (92%)]\tLoss: 760.484436\n",
            "Train Epoch: 184 [56320/60000 (94%)]\tLoss: 773.186890\n",
            "Train Epoch: 184 [57600/60000 (96%)]\tLoss: 733.358582\n",
            "Train Epoch: 184 [58880/60000 (98%)]\tLoss: 747.077393\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782432913780212\n",
            "\n",
            "Train Epoch: 185 [0/60000 (0%)]\tLoss: 743.378296\n",
            "Train Epoch: 185 [1280/60000 (2%)]\tLoss: 730.869446\n",
            "Train Epoch: 185 [2560/60000 (4%)]\tLoss: 730.280701\n",
            "Train Epoch: 185 [3840/60000 (6%)]\tLoss: 740.417419\n",
            "Train Epoch: 185 [5120/60000 (9%)]\tLoss: 721.765869\n",
            "Train Epoch: 185 [6400/60000 (11%)]\tLoss: 737.817932\n",
            "Train Epoch: 185 [7680/60000 (13%)]\tLoss: 708.000549\n",
            "Train Epoch: 185 [8960/60000 (15%)]\tLoss: 752.579651\n",
            "Train Epoch: 185 [10240/60000 (17%)]\tLoss: 736.125793\n",
            "Train Epoch: 185 [11520/60000 (19%)]\tLoss: 756.441406\n",
            "Train Epoch: 185 [12800/60000 (21%)]\tLoss: 740.913757\n",
            "Train Epoch: 185 [14080/60000 (23%)]\tLoss: 758.829895\n",
            "Train Epoch: 185 [15360/60000 (26%)]\tLoss: 737.945984\n",
            "Train Epoch: 185 [16640/60000 (28%)]\tLoss: 741.059204\n",
            "Train Epoch: 185 [17920/60000 (30%)]\tLoss: 751.841736\n",
            "Train Epoch: 185 [19200/60000 (32%)]\tLoss: 726.343079\n",
            "Train Epoch: 185 [20480/60000 (34%)]\tLoss: 732.165283\n",
            "Train Epoch: 185 [21760/60000 (36%)]\tLoss: 749.486267\n",
            "Train Epoch: 185 [23040/60000 (38%)]\tLoss: 750.098694\n",
            "Train Epoch: 185 [24320/60000 (41%)]\tLoss: 754.451233\n",
            "Train Epoch: 185 [25600/60000 (43%)]\tLoss: 733.218262\n",
            "Train Epoch: 185 [26880/60000 (45%)]\tLoss: 747.943176\n",
            "Train Epoch: 185 [28160/60000 (47%)]\tLoss: 723.002441\n",
            "Train Epoch: 185 [29440/60000 (49%)]\tLoss: 743.428040\n",
            "Train Epoch: 185 [30720/60000 (51%)]\tLoss: 730.740173\n",
            "Train Epoch: 185 [32000/60000 (53%)]\tLoss: 744.362915\n",
            "Train Epoch: 185 [33280/60000 (55%)]\tLoss: 731.080017\n",
            "Train Epoch: 185 [34560/60000 (58%)]\tLoss: 744.103943\n",
            "Train Epoch: 185 [35840/60000 (60%)]\tLoss: 728.310547\n",
            "Train Epoch: 185 [37120/60000 (62%)]\tLoss: 743.994385\n",
            "Train Epoch: 185 [38400/60000 (64%)]\tLoss: 746.588989\n",
            "Train Epoch: 185 [39680/60000 (66%)]\tLoss: 749.048523\n",
            "Train Epoch: 185 [40960/60000 (68%)]\tLoss: 728.596680\n",
            "Train Epoch: 185 [42240/60000 (70%)]\tLoss: 735.583496\n",
            "Train Epoch: 185 [43520/60000 (72%)]\tLoss: 764.802551\n",
            "Train Epoch: 185 [44800/60000 (75%)]\tLoss: 746.752563\n",
            "Train Epoch: 185 [46080/60000 (77%)]\tLoss: 718.366089\n",
            "Train Epoch: 185 [47360/60000 (79%)]\tLoss: 723.285706\n",
            "Train Epoch: 185 [48640/60000 (81%)]\tLoss: 747.911499\n",
            "Train Epoch: 185 [49920/60000 (83%)]\tLoss: 732.763550\n",
            "Train Epoch: 185 [51200/60000 (85%)]\tLoss: 741.821167\n",
            "Train Epoch: 185 [52480/60000 (87%)]\tLoss: 720.218262\n",
            "Train Epoch: 185 [53760/60000 (90%)]\tLoss: 742.094971\n",
            "Train Epoch: 185 [55040/60000 (92%)]\tLoss: 735.338501\n",
            "Train Epoch: 185 [56320/60000 (94%)]\tLoss: 742.695740\n",
            "Train Epoch: 185 [57600/60000 (96%)]\tLoss: 715.802917\n",
            "Train Epoch: 185 [58880/60000 (98%)]\tLoss: 740.183044\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781893491744995\n",
            "\n",
            "Train Epoch: 186 [0/60000 (0%)]\tLoss: 758.008606\n",
            "Train Epoch: 186 [1280/60000 (2%)]\tLoss: 746.984924\n",
            "Train Epoch: 186 [2560/60000 (4%)]\tLoss: 742.936401\n",
            "Train Epoch: 186 [3840/60000 (6%)]\tLoss: 751.234009\n",
            "Train Epoch: 186 [5120/60000 (9%)]\tLoss: 752.468140\n",
            "Train Epoch: 186 [6400/60000 (11%)]\tLoss: 744.924316\n",
            "Train Epoch: 186 [7680/60000 (13%)]\tLoss: 746.752197\n",
            "Train Epoch: 186 [8960/60000 (15%)]\tLoss: 733.052002\n",
            "Train Epoch: 186 [10240/60000 (17%)]\tLoss: 726.618164\n",
            "Train Epoch: 186 [11520/60000 (19%)]\tLoss: 739.623596\n",
            "Train Epoch: 186 [12800/60000 (21%)]\tLoss: 776.355530\n",
            "Train Epoch: 186 [14080/60000 (23%)]\tLoss: 718.685852\n",
            "Train Epoch: 186 [15360/60000 (26%)]\tLoss: 759.945435\n",
            "Train Epoch: 186 [16640/60000 (28%)]\tLoss: 745.728210\n",
            "Train Epoch: 186 [17920/60000 (30%)]\tLoss: 730.960693\n",
            "Train Epoch: 186 [19200/60000 (32%)]\tLoss: 744.779724\n",
            "Train Epoch: 186 [20480/60000 (34%)]\tLoss: 724.050171\n",
            "Train Epoch: 186 [21760/60000 (36%)]\tLoss: 749.834229\n",
            "Train Epoch: 186 [23040/60000 (38%)]\tLoss: 749.419189\n",
            "Train Epoch: 186 [24320/60000 (41%)]\tLoss: 745.601318\n",
            "Train Epoch: 186 [25600/60000 (43%)]\tLoss: 727.888245\n",
            "Train Epoch: 186 [26880/60000 (45%)]\tLoss: 725.718628\n",
            "Train Epoch: 186 [28160/60000 (47%)]\tLoss: 744.693726\n",
            "Train Epoch: 186 [29440/60000 (49%)]\tLoss: 739.126221\n",
            "Train Epoch: 186 [30720/60000 (51%)]\tLoss: 725.878357\n",
            "Train Epoch: 186 [32000/60000 (53%)]\tLoss: 721.286133\n",
            "Train Epoch: 186 [33280/60000 (55%)]\tLoss: 774.101990\n",
            "Train Epoch: 186 [34560/60000 (58%)]\tLoss: 711.662048\n",
            "Train Epoch: 186 [35840/60000 (60%)]\tLoss: 748.303345\n",
            "Train Epoch: 186 [37120/60000 (62%)]\tLoss: 748.881409\n",
            "Train Epoch: 186 [38400/60000 (64%)]\tLoss: 716.799133\n",
            "Train Epoch: 186 [39680/60000 (66%)]\tLoss: 751.923889\n",
            "Train Epoch: 186 [40960/60000 (68%)]\tLoss: 743.206116\n",
            "Train Epoch: 186 [42240/60000 (70%)]\tLoss: 720.788025\n",
            "Train Epoch: 186 [43520/60000 (72%)]\tLoss: 749.322571\n",
            "Train Epoch: 186 [44800/60000 (75%)]\tLoss: 720.008179\n",
            "Train Epoch: 186 [46080/60000 (77%)]\tLoss: 751.535583\n",
            "Train Epoch: 186 [47360/60000 (79%)]\tLoss: 723.065979\n",
            "Train Epoch: 186 [48640/60000 (81%)]\tLoss: 743.005615\n",
            "Train Epoch: 186 [49920/60000 (83%)]\tLoss: 730.294250\n",
            "Train Epoch: 186 [51200/60000 (85%)]\tLoss: 730.899292\n",
            "Train Epoch: 186 [52480/60000 (87%)]\tLoss: 744.776245\n",
            "Train Epoch: 186 [53760/60000 (90%)]\tLoss: 745.206726\n",
            "Train Epoch: 186 [55040/60000 (92%)]\tLoss: 754.610229\n",
            "Train Epoch: 186 [56320/60000 (94%)]\tLoss: 733.288513\n",
            "Train Epoch: 186 [57600/60000 (96%)]\tLoss: 726.090881\n",
            "Train Epoch: 186 [58880/60000 (98%)]\tLoss: 738.474731\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786769151687622\n",
            "\n",
            "Train Epoch: 187 [0/60000 (0%)]\tLoss: 770.780457\n",
            "Train Epoch: 187 [1280/60000 (2%)]\tLoss: 742.374390\n",
            "Train Epoch: 187 [2560/60000 (4%)]\tLoss: 755.409729\n",
            "Train Epoch: 187 [3840/60000 (6%)]\tLoss: 743.496155\n",
            "Train Epoch: 187 [5120/60000 (9%)]\tLoss: 750.776489\n",
            "Train Epoch: 187 [6400/60000 (11%)]\tLoss: 747.282104\n",
            "Train Epoch: 187 [7680/60000 (13%)]\tLoss: 750.061829\n",
            "Train Epoch: 187 [8960/60000 (15%)]\tLoss: 714.839111\n",
            "Train Epoch: 187 [10240/60000 (17%)]\tLoss: 763.209229\n",
            "Train Epoch: 187 [11520/60000 (19%)]\tLoss: 744.068115\n",
            "Train Epoch: 187 [12800/60000 (21%)]\tLoss: 725.699829\n",
            "Train Epoch: 187 [14080/60000 (23%)]\tLoss: 762.343262\n",
            "Train Epoch: 187 [15360/60000 (26%)]\tLoss: 737.058044\n",
            "Train Epoch: 187 [16640/60000 (28%)]\tLoss: 745.794373\n",
            "Train Epoch: 187 [17920/60000 (30%)]\tLoss: 738.858337\n",
            "Train Epoch: 187 [19200/60000 (32%)]\tLoss: 747.776672\n",
            "Train Epoch: 187 [20480/60000 (34%)]\tLoss: 704.563843\n",
            "Train Epoch: 187 [21760/60000 (36%)]\tLoss: 706.665344\n",
            "Train Epoch: 187 [23040/60000 (38%)]\tLoss: 731.377747\n",
            "Train Epoch: 187 [24320/60000 (41%)]\tLoss: 747.641479\n",
            "Train Epoch: 187 [25600/60000 (43%)]\tLoss: 747.576233\n",
            "Train Epoch: 187 [26880/60000 (45%)]\tLoss: 717.358337\n",
            "Train Epoch: 187 [28160/60000 (47%)]\tLoss: 738.426208\n",
            "Train Epoch: 187 [29440/60000 (49%)]\tLoss: 720.575867\n",
            "Train Epoch: 187 [30720/60000 (51%)]\tLoss: 727.962830\n",
            "Train Epoch: 187 [32000/60000 (53%)]\tLoss: 762.278809\n",
            "Train Epoch: 187 [33280/60000 (55%)]\tLoss: 760.500793\n",
            "Train Epoch: 187 [34560/60000 (58%)]\tLoss: 728.272095\n",
            "Train Epoch: 187 [35840/60000 (60%)]\tLoss: 733.572632\n",
            "Train Epoch: 187 [37120/60000 (62%)]\tLoss: 750.107361\n",
            "Train Epoch: 187 [38400/60000 (64%)]\tLoss: 736.966431\n",
            "Train Epoch: 187 [39680/60000 (66%)]\tLoss: 738.965637\n",
            "Train Epoch: 187 [40960/60000 (68%)]\tLoss: 726.631042\n",
            "Train Epoch: 187 [42240/60000 (70%)]\tLoss: 725.916565\n",
            "Train Epoch: 187 [43520/60000 (72%)]\tLoss: 740.250122\n",
            "Train Epoch: 187 [44800/60000 (75%)]\tLoss: 728.534729\n",
            "Train Epoch: 187 [46080/60000 (77%)]\tLoss: 728.029053\n",
            "Train Epoch: 187 [47360/60000 (79%)]\tLoss: 731.044189\n",
            "Train Epoch: 187 [48640/60000 (81%)]\tLoss: 717.539368\n",
            "Train Epoch: 187 [49920/60000 (83%)]\tLoss: 723.833740\n",
            "Train Epoch: 187 [51200/60000 (85%)]\tLoss: 721.989563\n",
            "Train Epoch: 187 [52480/60000 (87%)]\tLoss: 745.979980\n",
            "Train Epoch: 187 [53760/60000 (90%)]\tLoss: 718.069153\n",
            "Train Epoch: 187 [55040/60000 (92%)]\tLoss: 738.372803\n",
            "Train Epoch: 187 [56320/60000 (94%)]\tLoss: 732.300842\n",
            "Train Epoch: 187 [57600/60000 (96%)]\tLoss: 743.601501\n",
            "Train Epoch: 187 [58880/60000 (98%)]\tLoss: 764.396912\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978171467781067\n",
            "\n",
            "Train Epoch: 188 [0/60000 (0%)]\tLoss: 733.011047\n",
            "Train Epoch: 188 [1280/60000 (2%)]\tLoss: 737.646729\n",
            "Train Epoch: 188 [2560/60000 (4%)]\tLoss: 754.382446\n",
            "Train Epoch: 188 [3840/60000 (6%)]\tLoss: 726.501343\n",
            "Train Epoch: 188 [5120/60000 (9%)]\tLoss: 731.931946\n",
            "Train Epoch: 188 [6400/60000 (11%)]\tLoss: 740.551453\n",
            "Train Epoch: 188 [7680/60000 (13%)]\tLoss: 734.734436\n",
            "Train Epoch: 188 [8960/60000 (15%)]\tLoss: 755.663574\n",
            "Train Epoch: 188 [10240/60000 (17%)]\tLoss: 749.340027\n",
            "Train Epoch: 188 [11520/60000 (19%)]\tLoss: 727.176941\n",
            "Train Epoch: 188 [12800/60000 (21%)]\tLoss: 742.256470\n",
            "Train Epoch: 188 [14080/60000 (23%)]\tLoss: 730.173706\n",
            "Train Epoch: 188 [15360/60000 (26%)]\tLoss: 754.251282\n",
            "Train Epoch: 188 [16640/60000 (28%)]\tLoss: 740.524841\n",
            "Train Epoch: 188 [17920/60000 (30%)]\tLoss: 727.888000\n",
            "Train Epoch: 188 [19200/60000 (32%)]\tLoss: 734.015137\n",
            "Train Epoch: 188 [20480/60000 (34%)]\tLoss: 754.932312\n",
            "Train Epoch: 188 [21760/60000 (36%)]\tLoss: 746.049805\n",
            "Train Epoch: 188 [23040/60000 (38%)]\tLoss: 733.598389\n",
            "Train Epoch: 188 [24320/60000 (41%)]\tLoss: 768.182983\n",
            "Train Epoch: 188 [25600/60000 (43%)]\tLoss: 738.455750\n",
            "Train Epoch: 188 [26880/60000 (45%)]\tLoss: 748.646240\n",
            "Train Epoch: 188 [28160/60000 (47%)]\tLoss: 734.281372\n",
            "Train Epoch: 188 [29440/60000 (49%)]\tLoss: 742.629456\n",
            "Train Epoch: 188 [30720/60000 (51%)]\tLoss: 733.288940\n",
            "Train Epoch: 188 [32000/60000 (53%)]\tLoss: 733.730408\n",
            "Train Epoch: 188 [33280/60000 (55%)]\tLoss: 747.430481\n",
            "Train Epoch: 188 [34560/60000 (58%)]\tLoss: 741.976990\n",
            "Train Epoch: 188 [35840/60000 (60%)]\tLoss: 741.072693\n",
            "Train Epoch: 188 [37120/60000 (62%)]\tLoss: 742.631592\n",
            "Train Epoch: 188 [38400/60000 (64%)]\tLoss: 731.686462\n",
            "Train Epoch: 188 [39680/60000 (66%)]\tLoss: 719.417419\n",
            "Train Epoch: 188 [40960/60000 (68%)]\tLoss: 726.978943\n",
            "Train Epoch: 188 [42240/60000 (70%)]\tLoss: 739.012878\n",
            "Train Epoch: 188 [43520/60000 (72%)]\tLoss: 740.564636\n",
            "Train Epoch: 188 [44800/60000 (75%)]\tLoss: 746.229248\n",
            "Train Epoch: 188 [46080/60000 (77%)]\tLoss: 741.663818\n",
            "Train Epoch: 188 [47360/60000 (79%)]\tLoss: 723.611755\n",
            "Train Epoch: 188 [48640/60000 (81%)]\tLoss: 723.053894\n",
            "Train Epoch: 188 [49920/60000 (83%)]\tLoss: 733.648682\n",
            "Train Epoch: 188 [51200/60000 (85%)]\tLoss: 734.752258\n",
            "Train Epoch: 188 [52480/60000 (87%)]\tLoss: 716.171387\n",
            "Train Epoch: 188 [53760/60000 (90%)]\tLoss: 748.365784\n",
            "Train Epoch: 188 [55040/60000 (92%)]\tLoss: 716.177002\n",
            "Train Epoch: 188 [56320/60000 (94%)]\tLoss: 717.243713\n",
            "Train Epoch: 188 [57600/60000 (96%)]\tLoss: 748.503723\n",
            "Train Epoch: 188 [58880/60000 (98%)]\tLoss: 732.899353\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978321373462677\n",
            "\n",
            "Train Epoch: 189 [0/60000 (0%)]\tLoss: 736.999390\n",
            "Train Epoch: 189 [1280/60000 (2%)]\tLoss: 743.820862\n",
            "Train Epoch: 189 [2560/60000 (4%)]\tLoss: 747.516907\n",
            "Train Epoch: 189 [3840/60000 (6%)]\tLoss: 712.453796\n",
            "Train Epoch: 189 [5120/60000 (9%)]\tLoss: 724.504089\n",
            "Train Epoch: 189 [6400/60000 (11%)]\tLoss: 744.477234\n",
            "Train Epoch: 189 [7680/60000 (13%)]\tLoss: 716.416138\n",
            "Train Epoch: 189 [8960/60000 (15%)]\tLoss: 722.372375\n",
            "Train Epoch: 189 [10240/60000 (17%)]\tLoss: 734.061829\n",
            "Train Epoch: 189 [11520/60000 (19%)]\tLoss: 732.288940\n",
            "Train Epoch: 189 [12800/60000 (21%)]\tLoss: 715.466370\n",
            "Train Epoch: 189 [14080/60000 (23%)]\tLoss: 756.843140\n",
            "Train Epoch: 189 [15360/60000 (26%)]\tLoss: 742.871399\n",
            "Train Epoch: 189 [16640/60000 (28%)]\tLoss: 732.895264\n",
            "Train Epoch: 189 [17920/60000 (30%)]\tLoss: 723.514221\n",
            "Train Epoch: 189 [19200/60000 (32%)]\tLoss: 740.448853\n",
            "Train Epoch: 189 [20480/60000 (34%)]\tLoss: 737.636292\n",
            "Train Epoch: 189 [21760/60000 (36%)]\tLoss: 737.927917\n",
            "Train Epoch: 189 [23040/60000 (38%)]\tLoss: 737.630798\n",
            "Train Epoch: 189 [24320/60000 (41%)]\tLoss: 736.631104\n",
            "Train Epoch: 189 [25600/60000 (43%)]\tLoss: 735.456299\n",
            "Train Epoch: 189 [26880/60000 (45%)]\tLoss: 731.312988\n",
            "Train Epoch: 189 [28160/60000 (47%)]\tLoss: 736.662598\n",
            "Train Epoch: 189 [29440/60000 (49%)]\tLoss: 763.107910\n",
            "Train Epoch: 189 [30720/60000 (51%)]\tLoss: 752.182007\n",
            "Train Epoch: 189 [32000/60000 (53%)]\tLoss: 740.811401\n",
            "Train Epoch: 189 [33280/60000 (55%)]\tLoss: 728.355957\n",
            "Train Epoch: 189 [34560/60000 (58%)]\tLoss: 748.374023\n",
            "Train Epoch: 189 [35840/60000 (60%)]\tLoss: 722.702271\n",
            "Train Epoch: 189 [37120/60000 (62%)]\tLoss: 766.642517\n",
            "Train Epoch: 189 [38400/60000 (64%)]\tLoss: 733.615662\n",
            "Train Epoch: 189 [39680/60000 (66%)]\tLoss: 741.037720\n",
            "Train Epoch: 189 [40960/60000 (68%)]\tLoss: 751.613159\n",
            "Train Epoch: 189 [42240/60000 (70%)]\tLoss: 749.194580\n",
            "Train Epoch: 189 [43520/60000 (72%)]\tLoss: 710.195190\n",
            "Train Epoch: 189 [44800/60000 (75%)]\tLoss: 715.937012\n",
            "Train Epoch: 189 [46080/60000 (77%)]\tLoss: 748.615356\n",
            "Train Epoch: 189 [47360/60000 (79%)]\tLoss: 719.963623\n",
            "Train Epoch: 189 [48640/60000 (81%)]\tLoss: 729.243164\n",
            "Train Epoch: 189 [49920/60000 (83%)]\tLoss: 749.939819\n",
            "Train Epoch: 189 [51200/60000 (85%)]\tLoss: 722.490356\n",
            "Train Epoch: 189 [52480/60000 (87%)]\tLoss: 745.192383\n",
            "Train Epoch: 189 [53760/60000 (90%)]\tLoss: 733.541565\n",
            "Train Epoch: 189 [55040/60000 (92%)]\tLoss: 752.920898\n",
            "Train Epoch: 189 [56320/60000 (94%)]\tLoss: 759.881897\n",
            "Train Epoch: 189 [57600/60000 (96%)]\tLoss: 724.561890\n",
            "Train Epoch: 189 [58880/60000 (98%)]\tLoss: 738.328247\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978614628314972\n",
            "\n",
            "Train Epoch: 190 [0/60000 (0%)]\tLoss: 724.719543\n",
            "Train Epoch: 190 [1280/60000 (2%)]\tLoss: 724.036316\n",
            "Train Epoch: 190 [2560/60000 (4%)]\tLoss: 731.753784\n",
            "Train Epoch: 190 [3840/60000 (6%)]\tLoss: 718.145691\n",
            "Train Epoch: 190 [5120/60000 (9%)]\tLoss: 721.557251\n",
            "Train Epoch: 190 [6400/60000 (11%)]\tLoss: 734.879944\n",
            "Train Epoch: 190 [7680/60000 (13%)]\tLoss: 733.151306\n",
            "Train Epoch: 190 [8960/60000 (15%)]\tLoss: 728.877991\n",
            "Train Epoch: 190 [10240/60000 (17%)]\tLoss: 731.190125\n",
            "Train Epoch: 190 [11520/60000 (19%)]\tLoss: 722.839844\n",
            "Train Epoch: 190 [12800/60000 (21%)]\tLoss: 724.778748\n",
            "Train Epoch: 190 [14080/60000 (23%)]\tLoss: 728.174683\n",
            "Train Epoch: 190 [15360/60000 (26%)]\tLoss: 754.111511\n",
            "Train Epoch: 190 [16640/60000 (28%)]\tLoss: 732.376526\n",
            "Train Epoch: 190 [17920/60000 (30%)]\tLoss: 727.571106\n",
            "Train Epoch: 190 [19200/60000 (32%)]\tLoss: 752.932007\n",
            "Train Epoch: 190 [20480/60000 (34%)]\tLoss: 712.928650\n",
            "Train Epoch: 190 [21760/60000 (36%)]\tLoss: 704.216125\n",
            "Train Epoch: 190 [23040/60000 (38%)]\tLoss: 738.037415\n",
            "Train Epoch: 190 [24320/60000 (41%)]\tLoss: 725.817505\n",
            "Train Epoch: 190 [25600/60000 (43%)]\tLoss: 735.100647\n",
            "Train Epoch: 190 [26880/60000 (45%)]\tLoss: 734.429138\n",
            "Train Epoch: 190 [28160/60000 (47%)]\tLoss: 752.425293\n",
            "Train Epoch: 190 [29440/60000 (49%)]\tLoss: 715.389099\n",
            "Train Epoch: 190 [30720/60000 (51%)]\tLoss: 728.576660\n",
            "Train Epoch: 190 [32000/60000 (53%)]\tLoss: 739.036499\n",
            "Train Epoch: 190 [33280/60000 (55%)]\tLoss: 750.291931\n",
            "Train Epoch: 190 [34560/60000 (58%)]\tLoss: 717.527283\n",
            "Train Epoch: 190 [35840/60000 (60%)]\tLoss: 728.126892\n",
            "Train Epoch: 190 [37120/60000 (62%)]\tLoss: 727.801819\n",
            "Train Epoch: 190 [38400/60000 (64%)]\tLoss: 745.062988\n",
            "Train Epoch: 190 [39680/60000 (66%)]\tLoss: 723.075562\n",
            "Train Epoch: 190 [40960/60000 (68%)]\tLoss: 724.175415\n",
            "Train Epoch: 190 [42240/60000 (70%)]\tLoss: 736.618103\n",
            "Train Epoch: 190 [43520/60000 (72%)]\tLoss: 717.440735\n",
            "Train Epoch: 190 [44800/60000 (75%)]\tLoss: 746.352905\n",
            "Train Epoch: 190 [46080/60000 (77%)]\tLoss: 718.992004\n",
            "Train Epoch: 190 [47360/60000 (79%)]\tLoss: 727.863220\n",
            "Train Epoch: 190 [48640/60000 (81%)]\tLoss: 738.964722\n",
            "Train Epoch: 190 [49920/60000 (83%)]\tLoss: 748.181580\n",
            "Train Epoch: 190 [51200/60000 (85%)]\tLoss: 720.244873\n",
            "Train Epoch: 190 [52480/60000 (87%)]\tLoss: 740.713135\n",
            "Train Epoch: 190 [53760/60000 (90%)]\tLoss: 737.993408\n",
            "Train Epoch: 190 [55040/60000 (92%)]\tLoss: 738.032104\n",
            "Train Epoch: 190 [56320/60000 (94%)]\tLoss: 730.198853\n",
            "Train Epoch: 190 [57600/60000 (96%)]\tLoss: 745.899841\n",
            "Train Epoch: 190 [58880/60000 (98%)]\tLoss: 739.448730\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783911108970642\n",
            "\n",
            "Train Epoch: 191 [0/60000 (0%)]\tLoss: 753.501892\n",
            "Train Epoch: 191 [1280/60000 (2%)]\tLoss: 726.505859\n",
            "Train Epoch: 191 [2560/60000 (4%)]\tLoss: 718.414490\n",
            "Train Epoch: 191 [3840/60000 (6%)]\tLoss: 726.559143\n",
            "Train Epoch: 191 [5120/60000 (9%)]\tLoss: 705.216187\n",
            "Train Epoch: 191 [6400/60000 (11%)]\tLoss: 741.506287\n",
            "Train Epoch: 191 [7680/60000 (13%)]\tLoss: 748.145020\n",
            "Train Epoch: 191 [8960/60000 (15%)]\tLoss: 743.273560\n",
            "Train Epoch: 191 [10240/60000 (17%)]\tLoss: 729.367004\n",
            "Train Epoch: 191 [11520/60000 (19%)]\tLoss: 740.626160\n",
            "Train Epoch: 191 [12800/60000 (21%)]\tLoss: 716.282654\n",
            "Train Epoch: 191 [14080/60000 (23%)]\tLoss: 759.795959\n",
            "Train Epoch: 191 [15360/60000 (26%)]\tLoss: 746.484070\n",
            "Train Epoch: 191 [16640/60000 (28%)]\tLoss: 726.102478\n",
            "Train Epoch: 191 [17920/60000 (30%)]\tLoss: 741.757080\n",
            "Train Epoch: 191 [19200/60000 (32%)]\tLoss: 760.285461\n",
            "Train Epoch: 191 [20480/60000 (34%)]\tLoss: 779.901123\n",
            "Train Epoch: 191 [21760/60000 (36%)]\tLoss: 749.106567\n",
            "Train Epoch: 191 [23040/60000 (38%)]\tLoss: 718.941101\n",
            "Train Epoch: 191 [24320/60000 (41%)]\tLoss: 747.488770\n",
            "Train Epoch: 191 [25600/60000 (43%)]\tLoss: 751.700989\n",
            "Train Epoch: 191 [26880/60000 (45%)]\tLoss: 725.574219\n",
            "Train Epoch: 191 [28160/60000 (47%)]\tLoss: 750.560608\n",
            "Train Epoch: 191 [29440/60000 (49%)]\tLoss: 750.627625\n",
            "Train Epoch: 191 [30720/60000 (51%)]\tLoss: 711.145386\n",
            "Train Epoch: 191 [32000/60000 (53%)]\tLoss: 744.007324\n",
            "Train Epoch: 191 [33280/60000 (55%)]\tLoss: 720.706543\n",
            "Train Epoch: 191 [34560/60000 (58%)]\tLoss: 730.085938\n",
            "Train Epoch: 191 [35840/60000 (60%)]\tLoss: 733.142517\n",
            "Train Epoch: 191 [37120/60000 (62%)]\tLoss: 716.599426\n",
            "Train Epoch: 191 [38400/60000 (64%)]\tLoss: 748.179810\n",
            "Train Epoch: 191 [39680/60000 (66%)]\tLoss: 726.461975\n",
            "Train Epoch: 191 [40960/60000 (68%)]\tLoss: 761.441223\n",
            "Train Epoch: 191 [42240/60000 (70%)]\tLoss: 733.975403\n",
            "Train Epoch: 191 [43520/60000 (72%)]\tLoss: 726.426880\n",
            "Train Epoch: 191 [44800/60000 (75%)]\tLoss: 723.560974\n",
            "Train Epoch: 191 [46080/60000 (77%)]\tLoss: 738.488708\n",
            "Train Epoch: 191 [47360/60000 (79%)]\tLoss: 735.213257\n",
            "Train Epoch: 191 [48640/60000 (81%)]\tLoss: 727.054626\n",
            "Train Epoch: 191 [49920/60000 (83%)]\tLoss: 727.936462\n",
            "Train Epoch: 191 [51200/60000 (85%)]\tLoss: 718.181091\n",
            "Train Epoch: 191 [52480/60000 (87%)]\tLoss: 760.025146\n",
            "Train Epoch: 191 [53760/60000 (90%)]\tLoss: 706.954041\n",
            "Train Epoch: 191 [55040/60000 (92%)]\tLoss: 721.264221\n",
            "Train Epoch: 191 [56320/60000 (94%)]\tLoss: 733.340088\n",
            "Train Epoch: 191 [57600/60000 (96%)]\tLoss: 716.027466\n",
            "Train Epoch: 191 [58880/60000 (98%)]\tLoss: 718.449707\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785664975643158\n",
            "\n",
            "Train Epoch: 192 [0/60000 (0%)]\tLoss: 729.125061\n",
            "Train Epoch: 192 [1280/60000 (2%)]\tLoss: 738.270996\n",
            "Train Epoch: 192 [2560/60000 (4%)]\tLoss: 736.086243\n",
            "Train Epoch: 192 [3840/60000 (6%)]\tLoss: 742.265381\n",
            "Train Epoch: 192 [5120/60000 (9%)]\tLoss: 742.746765\n",
            "Train Epoch: 192 [6400/60000 (11%)]\tLoss: 739.945007\n",
            "Train Epoch: 192 [7680/60000 (13%)]\tLoss: 736.839661\n",
            "Train Epoch: 192 [8960/60000 (15%)]\tLoss: 744.479980\n",
            "Train Epoch: 192 [10240/60000 (17%)]\tLoss: 730.685852\n",
            "Train Epoch: 192 [11520/60000 (19%)]\tLoss: 718.413330\n",
            "Train Epoch: 192 [12800/60000 (21%)]\tLoss: 757.383423\n",
            "Train Epoch: 192 [14080/60000 (23%)]\tLoss: 769.652527\n",
            "Train Epoch: 192 [15360/60000 (26%)]\tLoss: 733.780151\n",
            "Train Epoch: 192 [16640/60000 (28%)]\tLoss: 751.471191\n",
            "Train Epoch: 192 [17920/60000 (30%)]\tLoss: 736.333252\n",
            "Train Epoch: 192 [19200/60000 (32%)]\tLoss: 746.940613\n",
            "Train Epoch: 192 [20480/60000 (34%)]\tLoss: 736.631409\n",
            "Train Epoch: 192 [21760/60000 (36%)]\tLoss: 737.301697\n",
            "Train Epoch: 192 [23040/60000 (38%)]\tLoss: 736.003906\n",
            "Train Epoch: 192 [24320/60000 (41%)]\tLoss: 714.536804\n",
            "Train Epoch: 192 [25600/60000 (43%)]\tLoss: 723.587830\n",
            "Train Epoch: 192 [26880/60000 (45%)]\tLoss: 730.507080\n",
            "Train Epoch: 192 [28160/60000 (47%)]\tLoss: 733.391724\n",
            "Train Epoch: 192 [29440/60000 (49%)]\tLoss: 718.099487\n",
            "Train Epoch: 192 [30720/60000 (51%)]\tLoss: 763.765625\n",
            "Train Epoch: 192 [32000/60000 (53%)]\tLoss: 720.939270\n",
            "Train Epoch: 192 [33280/60000 (55%)]\tLoss: 741.547852\n",
            "Train Epoch: 192 [34560/60000 (58%)]\tLoss: 727.370850\n",
            "Train Epoch: 192 [35840/60000 (60%)]\tLoss: 725.259827\n",
            "Train Epoch: 192 [37120/60000 (62%)]\tLoss: 739.066101\n",
            "Train Epoch: 192 [38400/60000 (64%)]\tLoss: 743.523254\n",
            "Train Epoch: 192 [39680/60000 (66%)]\tLoss: 710.376404\n",
            "Train Epoch: 192 [40960/60000 (68%)]\tLoss: 748.890564\n",
            "Train Epoch: 192 [42240/60000 (70%)]\tLoss: 735.363464\n",
            "Train Epoch: 192 [43520/60000 (72%)]\tLoss: 741.328369\n",
            "Train Epoch: 192 [44800/60000 (75%)]\tLoss: 728.134583\n",
            "Train Epoch: 192 [46080/60000 (77%)]\tLoss: 714.231873\n",
            "Train Epoch: 192 [47360/60000 (79%)]\tLoss: 735.813660\n",
            "Train Epoch: 192 [48640/60000 (81%)]\tLoss: 733.949402\n",
            "Train Epoch: 192 [49920/60000 (83%)]\tLoss: 772.536072\n",
            "Train Epoch: 192 [51200/60000 (85%)]\tLoss: 733.643982\n",
            "Train Epoch: 192 [52480/60000 (87%)]\tLoss: 733.063660\n",
            "Train Epoch: 192 [53760/60000 (90%)]\tLoss: 752.514099\n",
            "Train Epoch: 192 [55040/60000 (92%)]\tLoss: 738.921021\n",
            "Train Epoch: 192 [56320/60000 (94%)]\tLoss: 731.689087\n",
            "Train Epoch: 192 [57600/60000 (96%)]\tLoss: 726.623779\n",
            "Train Epoch: 192 [58880/60000 (98%)]\tLoss: 746.053894\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788293540477753\n",
            "\n",
            "Train Epoch: 193 [0/60000 (0%)]\tLoss: 778.563293\n",
            "Train Epoch: 193 [1280/60000 (2%)]\tLoss: 738.957581\n",
            "Train Epoch: 193 [2560/60000 (4%)]\tLoss: 759.898499\n",
            "Train Epoch: 193 [3840/60000 (6%)]\tLoss: 738.227600\n",
            "Train Epoch: 193 [5120/60000 (9%)]\tLoss: 748.360840\n",
            "Train Epoch: 193 [6400/60000 (11%)]\tLoss: 746.804382\n",
            "Train Epoch: 193 [7680/60000 (13%)]\tLoss: 731.337158\n",
            "Train Epoch: 193 [8960/60000 (15%)]\tLoss: 695.777832\n",
            "Train Epoch: 193 [10240/60000 (17%)]\tLoss: 739.097473\n",
            "Train Epoch: 193 [11520/60000 (19%)]\tLoss: 726.620422\n",
            "Train Epoch: 193 [12800/60000 (21%)]\tLoss: 746.835938\n",
            "Train Epoch: 193 [14080/60000 (23%)]\tLoss: 736.891602\n",
            "Train Epoch: 193 [15360/60000 (26%)]\tLoss: 748.401306\n",
            "Train Epoch: 193 [16640/60000 (28%)]\tLoss: 715.099121\n",
            "Train Epoch: 193 [17920/60000 (30%)]\tLoss: 728.260681\n",
            "Train Epoch: 193 [19200/60000 (32%)]\tLoss: 733.866150\n",
            "Train Epoch: 193 [20480/60000 (34%)]\tLoss: 755.383911\n",
            "Train Epoch: 193 [21760/60000 (36%)]\tLoss: 747.188538\n",
            "Train Epoch: 193 [23040/60000 (38%)]\tLoss: 741.267761\n",
            "Train Epoch: 193 [24320/60000 (41%)]\tLoss: 720.675232\n",
            "Train Epoch: 193 [25600/60000 (43%)]\tLoss: 737.617554\n",
            "Train Epoch: 193 [26880/60000 (45%)]\tLoss: 740.939819\n",
            "Train Epoch: 193 [28160/60000 (47%)]\tLoss: 728.659485\n",
            "Train Epoch: 193 [29440/60000 (49%)]\tLoss: 744.835327\n",
            "Train Epoch: 193 [30720/60000 (51%)]\tLoss: 722.151978\n",
            "Train Epoch: 193 [32000/60000 (53%)]\tLoss: 708.806702\n",
            "Train Epoch: 193 [33280/60000 (55%)]\tLoss: 729.738403\n",
            "Train Epoch: 193 [34560/60000 (58%)]\tLoss: 740.439026\n",
            "Train Epoch: 193 [35840/60000 (60%)]\tLoss: 728.557617\n",
            "Train Epoch: 193 [37120/60000 (62%)]\tLoss: 731.590942\n",
            "Train Epoch: 193 [38400/60000 (64%)]\tLoss: 717.489563\n",
            "Train Epoch: 193 [39680/60000 (66%)]\tLoss: 741.795532\n",
            "Train Epoch: 193 [40960/60000 (68%)]\tLoss: 719.755615\n",
            "Train Epoch: 193 [42240/60000 (70%)]\tLoss: 738.220215\n",
            "Train Epoch: 193 [43520/60000 (72%)]\tLoss: 723.856995\n",
            "Train Epoch: 193 [44800/60000 (75%)]\tLoss: 730.888367\n",
            "Train Epoch: 193 [46080/60000 (77%)]\tLoss: 751.798584\n",
            "Train Epoch: 193 [47360/60000 (79%)]\tLoss: 736.800720\n",
            "Train Epoch: 193 [48640/60000 (81%)]\tLoss: 723.765442\n",
            "Train Epoch: 193 [49920/60000 (83%)]\tLoss: 744.124695\n",
            "Train Epoch: 193 [51200/60000 (85%)]\tLoss: 732.753174\n",
            "Train Epoch: 193 [52480/60000 (87%)]\tLoss: 727.004700\n",
            "Train Epoch: 193 [53760/60000 (90%)]\tLoss: 767.230835\n",
            "Train Epoch: 193 [55040/60000 (92%)]\tLoss: 731.015442\n",
            "Train Epoch: 193 [56320/60000 (94%)]\tLoss: 750.029480\n",
            "Train Epoch: 193 [57600/60000 (96%)]\tLoss: 731.521423\n",
            "Train Epoch: 193 [58880/60000 (98%)]\tLoss: 758.304138\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784091413021088\n",
            "\n",
            "Train Epoch: 194 [0/60000 (0%)]\tLoss: 735.876953\n",
            "Train Epoch: 194 [1280/60000 (2%)]\tLoss: 739.220276\n",
            "Train Epoch: 194 [2560/60000 (4%)]\tLoss: 715.719604\n",
            "Train Epoch: 194 [3840/60000 (6%)]\tLoss: 752.002747\n",
            "Train Epoch: 194 [5120/60000 (9%)]\tLoss: 749.401794\n",
            "Train Epoch: 194 [6400/60000 (11%)]\tLoss: 737.209839\n",
            "Train Epoch: 194 [7680/60000 (13%)]\tLoss: 767.289795\n",
            "Train Epoch: 194 [8960/60000 (15%)]\tLoss: 735.183960\n",
            "Train Epoch: 194 [10240/60000 (17%)]\tLoss: 746.133118\n",
            "Train Epoch: 194 [11520/60000 (19%)]\tLoss: 743.930359\n",
            "Train Epoch: 194 [12800/60000 (21%)]\tLoss: 745.204895\n",
            "Train Epoch: 194 [14080/60000 (23%)]\tLoss: 751.626587\n",
            "Train Epoch: 194 [15360/60000 (26%)]\tLoss: 758.358765\n",
            "Train Epoch: 194 [16640/60000 (28%)]\tLoss: 719.221680\n",
            "Train Epoch: 194 [17920/60000 (30%)]\tLoss: 725.936462\n",
            "Train Epoch: 194 [19200/60000 (32%)]\tLoss: 737.535156\n",
            "Train Epoch: 194 [20480/60000 (34%)]\tLoss: 745.153320\n",
            "Train Epoch: 194 [21760/60000 (36%)]\tLoss: 741.275269\n",
            "Train Epoch: 194 [23040/60000 (38%)]\tLoss: 718.139893\n",
            "Train Epoch: 194 [24320/60000 (41%)]\tLoss: 731.369446\n",
            "Train Epoch: 194 [25600/60000 (43%)]\tLoss: 743.377563\n",
            "Train Epoch: 194 [26880/60000 (45%)]\tLoss: 761.438232\n",
            "Train Epoch: 194 [28160/60000 (47%)]\tLoss: 747.906067\n",
            "Train Epoch: 194 [29440/60000 (49%)]\tLoss: 751.571899\n",
            "Train Epoch: 194 [30720/60000 (51%)]\tLoss: 725.907471\n",
            "Train Epoch: 194 [32000/60000 (53%)]\tLoss: 734.286743\n",
            "Train Epoch: 194 [33280/60000 (55%)]\tLoss: 738.758972\n",
            "Train Epoch: 194 [34560/60000 (58%)]\tLoss: 757.686279\n",
            "Train Epoch: 194 [35840/60000 (60%)]\tLoss: 763.741028\n",
            "Train Epoch: 194 [37120/60000 (62%)]\tLoss: 722.646851\n",
            "Train Epoch: 194 [38400/60000 (64%)]\tLoss: 760.338928\n",
            "Train Epoch: 194 [39680/60000 (66%)]\tLoss: 732.119202\n",
            "Train Epoch: 194 [40960/60000 (68%)]\tLoss: 731.716003\n",
            "Train Epoch: 194 [42240/60000 (70%)]\tLoss: 711.035156\n",
            "Train Epoch: 194 [43520/60000 (72%)]\tLoss: 737.759460\n",
            "Train Epoch: 194 [44800/60000 (75%)]\tLoss: 714.336365\n",
            "Train Epoch: 194 [46080/60000 (77%)]\tLoss: 748.028931\n",
            "Train Epoch: 194 [47360/60000 (79%)]\tLoss: 725.772339\n",
            "Train Epoch: 194 [48640/60000 (81%)]\tLoss: 739.798096\n",
            "Train Epoch: 194 [49920/60000 (83%)]\tLoss: 729.983948\n",
            "Train Epoch: 194 [51200/60000 (85%)]\tLoss: 732.097168\n",
            "Train Epoch: 194 [52480/60000 (87%)]\tLoss: 722.984680\n",
            "Train Epoch: 194 [53760/60000 (90%)]\tLoss: 734.080078\n",
            "Train Epoch: 194 [55040/60000 (92%)]\tLoss: 714.546387\n",
            "Train Epoch: 194 [56320/60000 (94%)]\tLoss: 738.310608\n",
            "Train Epoch: 194 [57600/60000 (96%)]\tLoss: 728.658020\n",
            "Train Epoch: 194 [58880/60000 (98%)]\tLoss: 756.281494\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785194098949432\n",
            "\n",
            "Train Epoch: 195 [0/60000 (0%)]\tLoss: 754.244385\n",
            "Train Epoch: 195 [1280/60000 (2%)]\tLoss: 748.003174\n",
            "Train Epoch: 195 [2560/60000 (4%)]\tLoss: 727.443054\n",
            "Train Epoch: 195 [3840/60000 (6%)]\tLoss: 725.904175\n",
            "Train Epoch: 195 [5120/60000 (9%)]\tLoss: 752.364136\n",
            "Train Epoch: 195 [6400/60000 (11%)]\tLoss: 720.345215\n",
            "Train Epoch: 195 [7680/60000 (13%)]\tLoss: 743.956543\n",
            "Train Epoch: 195 [8960/60000 (15%)]\tLoss: 733.897156\n",
            "Train Epoch: 195 [10240/60000 (17%)]\tLoss: 743.446777\n",
            "Train Epoch: 195 [11520/60000 (19%)]\tLoss: 742.463989\n",
            "Train Epoch: 195 [12800/60000 (21%)]\tLoss: 730.572632\n",
            "Train Epoch: 195 [14080/60000 (23%)]\tLoss: 744.670044\n",
            "Train Epoch: 195 [15360/60000 (26%)]\tLoss: 749.389343\n",
            "Train Epoch: 195 [16640/60000 (28%)]\tLoss: 723.552734\n",
            "Train Epoch: 195 [17920/60000 (30%)]\tLoss: 752.219971\n",
            "Train Epoch: 195 [19200/60000 (32%)]\tLoss: 734.160828\n",
            "Train Epoch: 195 [20480/60000 (34%)]\tLoss: 741.539795\n",
            "Train Epoch: 195 [21760/60000 (36%)]\tLoss: 747.139038\n",
            "Train Epoch: 195 [23040/60000 (38%)]\tLoss: 727.430603\n",
            "Train Epoch: 195 [24320/60000 (41%)]\tLoss: 737.303589\n",
            "Train Epoch: 195 [25600/60000 (43%)]\tLoss: 730.567932\n",
            "Train Epoch: 195 [26880/60000 (45%)]\tLoss: 737.549133\n",
            "Train Epoch: 195 [28160/60000 (47%)]\tLoss: 729.994690\n",
            "Train Epoch: 195 [29440/60000 (49%)]\tLoss: 726.243530\n",
            "Train Epoch: 195 [30720/60000 (51%)]\tLoss: 741.391235\n",
            "Train Epoch: 195 [32000/60000 (53%)]\tLoss: 738.106384\n",
            "Train Epoch: 195 [33280/60000 (55%)]\tLoss: 737.598450\n",
            "Train Epoch: 195 [34560/60000 (58%)]\tLoss: 720.346680\n",
            "Train Epoch: 195 [35840/60000 (60%)]\tLoss: 719.104736\n",
            "Train Epoch: 195 [37120/60000 (62%)]\tLoss: 744.796326\n",
            "Train Epoch: 195 [38400/60000 (64%)]\tLoss: 738.014038\n",
            "Train Epoch: 195 [39680/60000 (66%)]\tLoss: 765.627441\n",
            "Train Epoch: 195 [40960/60000 (68%)]\tLoss: 712.290466\n",
            "Train Epoch: 195 [42240/60000 (70%)]\tLoss: 754.004517\n",
            "Train Epoch: 195 [43520/60000 (72%)]\tLoss: 730.914368\n",
            "Train Epoch: 195 [44800/60000 (75%)]\tLoss: 747.923279\n",
            "Train Epoch: 195 [46080/60000 (77%)]\tLoss: 743.251160\n",
            "Train Epoch: 195 [47360/60000 (79%)]\tLoss: 724.743164\n",
            "Train Epoch: 195 [48640/60000 (81%)]\tLoss: 734.614319\n",
            "Train Epoch: 195 [49920/60000 (83%)]\tLoss: 730.680542\n",
            "Train Epoch: 195 [51200/60000 (85%)]\tLoss: 754.666016\n",
            "Train Epoch: 195 [52480/60000 (87%)]\tLoss: 715.448059\n",
            "Train Epoch: 195 [53760/60000 (90%)]\tLoss: 729.485107\n",
            "Train Epoch: 195 [55040/60000 (92%)]\tLoss: 726.424255\n",
            "Train Epoch: 195 [56320/60000 (94%)]\tLoss: 709.113953\n",
            "Train Epoch: 195 [57600/60000 (96%)]\tLoss: 729.831299\n",
            "Train Epoch: 195 [58880/60000 (98%)]\tLoss: 741.630554\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978663057088852\n",
            "\n",
            "Train Epoch: 196 [0/60000 (0%)]\tLoss: 717.851929\n",
            "Train Epoch: 196 [1280/60000 (2%)]\tLoss: 729.023987\n",
            "Train Epoch: 196 [2560/60000 (4%)]\tLoss: 748.342407\n",
            "Train Epoch: 196 [3840/60000 (6%)]\tLoss: 742.642334\n",
            "Train Epoch: 196 [5120/60000 (9%)]\tLoss: 741.445129\n",
            "Train Epoch: 196 [6400/60000 (11%)]\tLoss: 743.057129\n",
            "Train Epoch: 196 [7680/60000 (13%)]\tLoss: 736.686707\n",
            "Train Epoch: 196 [8960/60000 (15%)]\tLoss: 749.600708\n",
            "Train Epoch: 196 [10240/60000 (17%)]\tLoss: 746.466797\n",
            "Train Epoch: 196 [11520/60000 (19%)]\tLoss: 727.782898\n",
            "Train Epoch: 196 [12800/60000 (21%)]\tLoss: 735.036194\n",
            "Train Epoch: 196 [14080/60000 (23%)]\tLoss: 722.690063\n",
            "Train Epoch: 196 [15360/60000 (26%)]\tLoss: 743.296143\n",
            "Train Epoch: 196 [16640/60000 (28%)]\tLoss: 738.649414\n",
            "Train Epoch: 196 [17920/60000 (30%)]\tLoss: 743.921631\n",
            "Train Epoch: 196 [19200/60000 (32%)]\tLoss: 734.033752\n",
            "Train Epoch: 196 [20480/60000 (34%)]\tLoss: 736.599548\n",
            "Train Epoch: 196 [21760/60000 (36%)]\tLoss: 721.134644\n",
            "Train Epoch: 196 [23040/60000 (38%)]\tLoss: 743.558167\n",
            "Train Epoch: 196 [24320/60000 (41%)]\tLoss: 738.980957\n",
            "Train Epoch: 196 [25600/60000 (43%)]\tLoss: 732.932495\n",
            "Train Epoch: 196 [26880/60000 (45%)]\tLoss: 735.362305\n",
            "Train Epoch: 196 [28160/60000 (47%)]\tLoss: 752.047852\n",
            "Train Epoch: 196 [29440/60000 (49%)]\tLoss: 714.162964\n",
            "Train Epoch: 196 [30720/60000 (51%)]\tLoss: 754.312378\n",
            "Train Epoch: 196 [32000/60000 (53%)]\tLoss: 742.483459\n",
            "Train Epoch: 196 [33280/60000 (55%)]\tLoss: 760.166260\n",
            "Train Epoch: 196 [34560/60000 (58%)]\tLoss: 719.691406\n",
            "Train Epoch: 196 [35840/60000 (60%)]\tLoss: 723.727478\n",
            "Train Epoch: 196 [37120/60000 (62%)]\tLoss: 731.761169\n",
            "Train Epoch: 196 [38400/60000 (64%)]\tLoss: 755.117249\n",
            "Train Epoch: 196 [39680/60000 (66%)]\tLoss: 746.622253\n",
            "Train Epoch: 196 [40960/60000 (68%)]\tLoss: 746.512573\n",
            "Train Epoch: 196 [42240/60000 (70%)]\tLoss: 730.373169\n",
            "Train Epoch: 196 [43520/60000 (72%)]\tLoss: 743.542114\n",
            "Train Epoch: 196 [44800/60000 (75%)]\tLoss: 711.656921\n",
            "Train Epoch: 196 [46080/60000 (77%)]\tLoss: 717.023438\n",
            "Train Epoch: 196 [47360/60000 (79%)]\tLoss: 740.779236\n",
            "Train Epoch: 196 [48640/60000 (81%)]\tLoss: 753.038330\n",
            "Train Epoch: 196 [49920/60000 (83%)]\tLoss: 723.401306\n",
            "Train Epoch: 196 [51200/60000 (85%)]\tLoss: 734.489746\n",
            "Train Epoch: 196 [52480/60000 (87%)]\tLoss: 738.884766\n",
            "Train Epoch: 196 [53760/60000 (90%)]\tLoss: 747.319763\n",
            "Train Epoch: 196 [55040/60000 (92%)]\tLoss: 737.814331\n",
            "Train Epoch: 196 [56320/60000 (94%)]\tLoss: 740.076111\n",
            "Train Epoch: 196 [57600/60000 (96%)]\tLoss: 742.707947\n",
            "Train Epoch: 196 [58880/60000 (98%)]\tLoss: 740.652100\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978774070739746\n",
            "\n",
            "Train Epoch: 197 [0/60000 (0%)]\tLoss: 754.940186\n",
            "Train Epoch: 197 [1280/60000 (2%)]\tLoss: 727.216675\n",
            "Train Epoch: 197 [2560/60000 (4%)]\tLoss: 721.337158\n",
            "Train Epoch: 197 [3840/60000 (6%)]\tLoss: 729.799194\n",
            "Train Epoch: 197 [5120/60000 (9%)]\tLoss: 727.338013\n",
            "Train Epoch: 197 [6400/60000 (11%)]\tLoss: 740.382629\n",
            "Train Epoch: 197 [7680/60000 (13%)]\tLoss: 719.688477\n",
            "Train Epoch: 197 [8960/60000 (15%)]\tLoss: 735.538391\n",
            "Train Epoch: 197 [10240/60000 (17%)]\tLoss: 735.753113\n",
            "Train Epoch: 197 [11520/60000 (19%)]\tLoss: 748.961731\n",
            "Train Epoch: 197 [12800/60000 (21%)]\tLoss: 744.202881\n",
            "Train Epoch: 197 [14080/60000 (23%)]\tLoss: 733.743958\n",
            "Train Epoch: 197 [15360/60000 (26%)]\tLoss: 742.507996\n",
            "Train Epoch: 197 [16640/60000 (28%)]\tLoss: 759.367981\n",
            "Train Epoch: 197 [17920/60000 (30%)]\tLoss: 754.072266\n",
            "Train Epoch: 197 [19200/60000 (32%)]\tLoss: 707.746887\n",
            "Train Epoch: 197 [20480/60000 (34%)]\tLoss: 695.736328\n",
            "Train Epoch: 197 [21760/60000 (36%)]\tLoss: 711.543152\n",
            "Train Epoch: 197 [23040/60000 (38%)]\tLoss: 726.185120\n",
            "Train Epoch: 197 [24320/60000 (41%)]\tLoss: 721.562561\n",
            "Train Epoch: 197 [25600/60000 (43%)]\tLoss: 725.556396\n",
            "Train Epoch: 197 [26880/60000 (45%)]\tLoss: 737.145264\n",
            "Train Epoch: 197 [28160/60000 (47%)]\tLoss: 750.449219\n",
            "Train Epoch: 197 [29440/60000 (49%)]\tLoss: 751.079163\n",
            "Train Epoch: 197 [30720/60000 (51%)]\tLoss: 731.585876\n",
            "Train Epoch: 197 [32000/60000 (53%)]\tLoss: 729.870422\n",
            "Train Epoch: 197 [33280/60000 (55%)]\tLoss: 716.089844\n",
            "Train Epoch: 197 [34560/60000 (58%)]\tLoss: 746.260986\n",
            "Train Epoch: 197 [35840/60000 (60%)]\tLoss: 721.428894\n",
            "Train Epoch: 197 [37120/60000 (62%)]\tLoss: 731.122253\n",
            "Train Epoch: 197 [38400/60000 (64%)]\tLoss: 747.909546\n",
            "Train Epoch: 197 [39680/60000 (66%)]\tLoss: 743.824646\n",
            "Train Epoch: 197 [40960/60000 (68%)]\tLoss: 728.667297\n",
            "Train Epoch: 197 [42240/60000 (70%)]\tLoss: 744.967041\n",
            "Train Epoch: 197 [43520/60000 (72%)]\tLoss: 725.681274\n",
            "Train Epoch: 197 [44800/60000 (75%)]\tLoss: 756.623779\n",
            "Train Epoch: 197 [46080/60000 (77%)]\tLoss: 743.642639\n",
            "Train Epoch: 197 [47360/60000 (79%)]\tLoss: 761.061768\n",
            "Train Epoch: 197 [48640/60000 (81%)]\tLoss: 719.168701\n",
            "Train Epoch: 197 [49920/60000 (83%)]\tLoss: 711.444153\n",
            "Train Epoch: 197 [51200/60000 (85%)]\tLoss: 762.078247\n",
            "Train Epoch: 197 [52480/60000 (87%)]\tLoss: 747.531372\n",
            "Train Epoch: 197 [53760/60000 (90%)]\tLoss: 731.976196\n",
            "Train Epoch: 197 [55040/60000 (92%)]\tLoss: 723.174561\n",
            "Train Epoch: 197 [56320/60000 (94%)]\tLoss: 723.629089\n",
            "Train Epoch: 197 [57600/60000 (96%)]\tLoss: 730.625671\n",
            "Train Epoch: 197 [58880/60000 (98%)]\tLoss: 719.416626\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784103333950043\n",
            "\n",
            "Train Epoch: 198 [0/60000 (0%)]\tLoss: 719.989014\n",
            "Train Epoch: 198 [1280/60000 (2%)]\tLoss: 735.202393\n",
            "Train Epoch: 198 [2560/60000 (4%)]\tLoss: 731.789001\n",
            "Train Epoch: 198 [3840/60000 (6%)]\tLoss: 746.199036\n",
            "Train Epoch: 198 [5120/60000 (9%)]\tLoss: 749.132263\n",
            "Train Epoch: 198 [6400/60000 (11%)]\tLoss: 743.996094\n",
            "Train Epoch: 198 [7680/60000 (13%)]\tLoss: 703.477722\n",
            "Train Epoch: 198 [8960/60000 (15%)]\tLoss: 738.384155\n",
            "Train Epoch: 198 [10240/60000 (17%)]\tLoss: 718.187134\n",
            "Train Epoch: 198 [11520/60000 (19%)]\tLoss: 716.793335\n",
            "Train Epoch: 198 [12800/60000 (21%)]\tLoss: 738.355835\n",
            "Train Epoch: 198 [14080/60000 (23%)]\tLoss: 771.722351\n",
            "Train Epoch: 198 [15360/60000 (26%)]\tLoss: 721.403503\n",
            "Train Epoch: 198 [16640/60000 (28%)]\tLoss: 734.534729\n",
            "Train Epoch: 198 [17920/60000 (30%)]\tLoss: 712.998474\n",
            "Train Epoch: 198 [19200/60000 (32%)]\tLoss: 730.604797\n",
            "Train Epoch: 198 [20480/60000 (34%)]\tLoss: 720.354858\n",
            "Train Epoch: 198 [21760/60000 (36%)]\tLoss: 736.871277\n",
            "Train Epoch: 198 [23040/60000 (38%)]\tLoss: 758.405457\n",
            "Train Epoch: 198 [24320/60000 (41%)]\tLoss: 754.511047\n",
            "Train Epoch: 198 [25600/60000 (43%)]\tLoss: 718.217651\n",
            "Train Epoch: 198 [26880/60000 (45%)]\tLoss: 731.110046\n",
            "Train Epoch: 198 [28160/60000 (47%)]\tLoss: 744.632874\n",
            "Train Epoch: 198 [29440/60000 (49%)]\tLoss: 740.393372\n",
            "Train Epoch: 198 [30720/60000 (51%)]\tLoss: 731.542908\n",
            "Train Epoch: 198 [32000/60000 (53%)]\tLoss: 723.973999\n",
            "Train Epoch: 198 [33280/60000 (55%)]\tLoss: 717.204590\n",
            "Train Epoch: 198 [34560/60000 (58%)]\tLoss: 734.965881\n",
            "Train Epoch: 198 [35840/60000 (60%)]\tLoss: 731.423828\n",
            "Train Epoch: 198 [37120/60000 (62%)]\tLoss: 734.349426\n",
            "Train Epoch: 198 [38400/60000 (64%)]\tLoss: 724.619385\n",
            "Train Epoch: 198 [39680/60000 (66%)]\tLoss: 760.087830\n",
            "Train Epoch: 198 [40960/60000 (68%)]\tLoss: 745.109863\n",
            "Train Epoch: 198 [42240/60000 (70%)]\tLoss: 720.960327\n",
            "Train Epoch: 198 [43520/60000 (72%)]\tLoss: 708.723267\n",
            "Train Epoch: 198 [44800/60000 (75%)]\tLoss: 742.875366\n",
            "Train Epoch: 198 [46080/60000 (77%)]\tLoss: 722.452026\n",
            "Train Epoch: 198 [47360/60000 (79%)]\tLoss: 736.242310\n",
            "Train Epoch: 198 [48640/60000 (81%)]\tLoss: 738.403870\n",
            "Train Epoch: 198 [49920/60000 (83%)]\tLoss: 756.221436\n",
            "Train Epoch: 198 [51200/60000 (85%)]\tLoss: 752.462036\n",
            "Train Epoch: 198 [52480/60000 (87%)]\tLoss: 731.404053\n",
            "Train Epoch: 198 [53760/60000 (90%)]\tLoss: 731.745422\n",
            "Train Epoch: 198 [55040/60000 (92%)]\tLoss: 739.782227\n",
            "Train Epoch: 198 [56320/60000 (94%)]\tLoss: 732.104309\n",
            "Train Epoch: 198 [57600/60000 (96%)]\tLoss: 747.869385\n",
            "Train Epoch: 198 [58880/60000 (98%)]\tLoss: 746.200989\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783487915992737\n",
            "\n",
            "Train Epoch: 199 [0/60000 (0%)]\tLoss: 732.102905\n",
            "Train Epoch: 199 [1280/60000 (2%)]\tLoss: 733.296814\n",
            "Train Epoch: 199 [2560/60000 (4%)]\tLoss: 729.304626\n",
            "Train Epoch: 199 [3840/60000 (6%)]\tLoss: 754.332336\n",
            "Train Epoch: 199 [5120/60000 (9%)]\tLoss: 745.811768\n",
            "Train Epoch: 199 [6400/60000 (11%)]\tLoss: 732.560913\n",
            "Train Epoch: 199 [7680/60000 (13%)]\tLoss: 737.570923\n",
            "Train Epoch: 199 [8960/60000 (15%)]\tLoss: 746.126709\n",
            "Train Epoch: 199 [10240/60000 (17%)]\tLoss: 758.776611\n",
            "Train Epoch: 199 [11520/60000 (19%)]\tLoss: 729.040527\n",
            "Train Epoch: 199 [12800/60000 (21%)]\tLoss: 738.376892\n",
            "Train Epoch: 199 [14080/60000 (23%)]\tLoss: 742.486145\n",
            "Train Epoch: 199 [15360/60000 (26%)]\tLoss: 744.241577\n",
            "Train Epoch: 199 [16640/60000 (28%)]\tLoss: 730.233337\n",
            "Train Epoch: 199 [17920/60000 (30%)]\tLoss: 724.921448\n",
            "Train Epoch: 199 [19200/60000 (32%)]\tLoss: 723.276978\n",
            "Train Epoch: 199 [20480/60000 (34%)]\tLoss: 703.548523\n",
            "Train Epoch: 199 [21760/60000 (36%)]\tLoss: 755.418762\n",
            "Train Epoch: 199 [23040/60000 (38%)]\tLoss: 737.608948\n",
            "Train Epoch: 199 [24320/60000 (41%)]\tLoss: 738.936279\n",
            "Train Epoch: 199 [25600/60000 (43%)]\tLoss: 729.803162\n",
            "Train Epoch: 199 [26880/60000 (45%)]\tLoss: 750.939392\n",
            "Train Epoch: 199 [28160/60000 (47%)]\tLoss: 737.007751\n",
            "Train Epoch: 199 [29440/60000 (49%)]\tLoss: 730.613464\n",
            "Train Epoch: 199 [30720/60000 (51%)]\tLoss: 748.567932\n",
            "Train Epoch: 199 [32000/60000 (53%)]\tLoss: 743.511719\n",
            "Train Epoch: 199 [33280/60000 (55%)]\tLoss: 732.469788\n",
            "Train Epoch: 199 [34560/60000 (58%)]\tLoss: 723.230652\n",
            "Train Epoch: 199 [35840/60000 (60%)]\tLoss: 738.780090\n",
            "Train Epoch: 199 [37120/60000 (62%)]\tLoss: 732.854126\n",
            "Train Epoch: 199 [38400/60000 (64%)]\tLoss: 751.829956\n",
            "Train Epoch: 199 [39680/60000 (66%)]\tLoss: 725.181580\n",
            "Train Epoch: 199 [40960/60000 (68%)]\tLoss: 737.694580\n",
            "Train Epoch: 199 [42240/60000 (70%)]\tLoss: 743.038086\n",
            "Train Epoch: 199 [43520/60000 (72%)]\tLoss: 761.636230\n",
            "Train Epoch: 199 [44800/60000 (75%)]\tLoss: 740.093079\n",
            "Train Epoch: 199 [46080/60000 (77%)]\tLoss: 756.860046\n",
            "Train Epoch: 199 [47360/60000 (79%)]\tLoss: 740.128357\n",
            "Train Epoch: 199 [48640/60000 (81%)]\tLoss: 724.439941\n",
            "Train Epoch: 199 [49920/60000 (83%)]\tLoss: 738.095947\n",
            "Train Epoch: 199 [51200/60000 (85%)]\tLoss: 715.061523\n",
            "Train Epoch: 199 [52480/60000 (87%)]\tLoss: 738.560547\n",
            "Train Epoch: 199 [53760/60000 (90%)]\tLoss: 756.467834\n",
            "Train Epoch: 199 [55040/60000 (92%)]\tLoss: 703.150818\n",
            "Train Epoch: 199 [56320/60000 (94%)]\tLoss: 731.118347\n",
            "Train Epoch: 199 [57600/60000 (96%)]\tLoss: 728.218689\n",
            "Train Epoch: 199 [58880/60000 (98%)]\tLoss: 760.567810\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978398859500885\n",
            "\n",
            "Train Epoch: 200 [0/60000 (0%)]\tLoss: 710.047058\n",
            "Train Epoch: 200 [1280/60000 (2%)]\tLoss: 710.968994\n",
            "Train Epoch: 200 [2560/60000 (4%)]\tLoss: 735.865295\n",
            "Train Epoch: 200 [3840/60000 (6%)]\tLoss: 759.238770\n",
            "Train Epoch: 200 [5120/60000 (9%)]\tLoss: 736.108459\n",
            "Train Epoch: 200 [6400/60000 (11%)]\tLoss: 733.903992\n",
            "Train Epoch: 200 [7680/60000 (13%)]\tLoss: 737.378723\n",
            "Train Epoch: 200 [8960/60000 (15%)]\tLoss: 758.926392\n",
            "Train Epoch: 200 [10240/60000 (17%)]\tLoss: 772.822693\n",
            "Train Epoch: 200 [11520/60000 (19%)]\tLoss: 732.539917\n",
            "Train Epoch: 200 [12800/60000 (21%)]\tLoss: 723.894226\n",
            "Train Epoch: 200 [14080/60000 (23%)]\tLoss: 740.693176\n",
            "Train Epoch: 200 [15360/60000 (26%)]\tLoss: 739.092651\n",
            "Train Epoch: 200 [16640/60000 (28%)]\tLoss: 760.406006\n",
            "Train Epoch: 200 [17920/60000 (30%)]\tLoss: 739.408447\n",
            "Train Epoch: 200 [19200/60000 (32%)]\tLoss: 753.441406\n",
            "Train Epoch: 200 [20480/60000 (34%)]\tLoss: 712.704346\n",
            "Train Epoch: 200 [21760/60000 (36%)]\tLoss: 722.255127\n",
            "Train Epoch: 200 [23040/60000 (38%)]\tLoss: 720.514282\n",
            "Train Epoch: 200 [24320/60000 (41%)]\tLoss: 732.707825\n",
            "Train Epoch: 200 [25600/60000 (43%)]\tLoss: 756.798096\n",
            "Train Epoch: 200 [26880/60000 (45%)]\tLoss: 709.690735\n",
            "Train Epoch: 200 [28160/60000 (47%)]\tLoss: 721.661865\n",
            "Train Epoch: 200 [29440/60000 (49%)]\tLoss: 722.385803\n",
            "Train Epoch: 200 [30720/60000 (51%)]\tLoss: 741.649536\n",
            "Train Epoch: 200 [32000/60000 (53%)]\tLoss: 743.248047\n",
            "Train Epoch: 200 [33280/60000 (55%)]\tLoss: 746.407776\n",
            "Train Epoch: 200 [34560/60000 (58%)]\tLoss: 726.094116\n",
            "Train Epoch: 200 [35840/60000 (60%)]\tLoss: 720.475891\n",
            "Train Epoch: 200 [37120/60000 (62%)]\tLoss: 741.659668\n",
            "Train Epoch: 200 [38400/60000 (64%)]\tLoss: 729.772278\n",
            "Train Epoch: 200 [39680/60000 (66%)]\tLoss: 749.492798\n",
            "Train Epoch: 200 [40960/60000 (68%)]\tLoss: 722.287720\n",
            "Train Epoch: 200 [42240/60000 (70%)]\tLoss: 739.011902\n",
            "Train Epoch: 200 [43520/60000 (72%)]\tLoss: 737.388306\n",
            "Train Epoch: 200 [44800/60000 (75%)]\tLoss: 718.589417\n",
            "Train Epoch: 200 [46080/60000 (77%)]\tLoss: 715.670288\n",
            "Train Epoch: 200 [47360/60000 (79%)]\tLoss: 744.068542\n",
            "Train Epoch: 200 [48640/60000 (81%)]\tLoss: 737.125305\n",
            "Train Epoch: 200 [49920/60000 (83%)]\tLoss: 729.062805\n",
            "Train Epoch: 200 [51200/60000 (85%)]\tLoss: 734.129578\n",
            "Train Epoch: 200 [52480/60000 (87%)]\tLoss: 715.383606\n",
            "Train Epoch: 200 [53760/60000 (90%)]\tLoss: 721.513062\n",
            "Train Epoch: 200 [55040/60000 (92%)]\tLoss: 739.825745\n",
            "Train Epoch: 200 [56320/60000 (94%)]\tLoss: 742.181946\n",
            "Train Epoch: 200 [57600/60000 (96%)]\tLoss: 728.576233\n",
            "Train Epoch: 200 [58880/60000 (98%)]\tLoss: 756.680359\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784072041511536\n",
            "\n",
            "Train Epoch: 201 [0/60000 (0%)]\tLoss: 743.618347\n",
            "Train Epoch: 201 [1280/60000 (2%)]\tLoss: 737.798035\n",
            "Train Epoch: 201 [2560/60000 (4%)]\tLoss: 759.030762\n",
            "Train Epoch: 201 [3840/60000 (6%)]\tLoss: 739.679688\n",
            "Train Epoch: 201 [5120/60000 (9%)]\tLoss: 719.507263\n",
            "Train Epoch: 201 [6400/60000 (11%)]\tLoss: 757.861023\n",
            "Train Epoch: 201 [7680/60000 (13%)]\tLoss: 745.654358\n",
            "Train Epoch: 201 [8960/60000 (15%)]\tLoss: 723.973694\n",
            "Train Epoch: 201 [10240/60000 (17%)]\tLoss: 722.601501\n",
            "Train Epoch: 201 [11520/60000 (19%)]\tLoss: 726.010803\n",
            "Train Epoch: 201 [12800/60000 (21%)]\tLoss: 739.968750\n",
            "Train Epoch: 201 [14080/60000 (23%)]\tLoss: 743.303711\n",
            "Train Epoch: 201 [15360/60000 (26%)]\tLoss: 761.855652\n",
            "Train Epoch: 201 [16640/60000 (28%)]\tLoss: 732.356262\n",
            "Train Epoch: 201 [17920/60000 (30%)]\tLoss: 759.470215\n",
            "Train Epoch: 201 [19200/60000 (32%)]\tLoss: 718.880066\n",
            "Train Epoch: 201 [20480/60000 (34%)]\tLoss: 751.928528\n",
            "Train Epoch: 201 [21760/60000 (36%)]\tLoss: 745.566162\n",
            "Train Epoch: 201 [23040/60000 (38%)]\tLoss: 739.685730\n",
            "Train Epoch: 201 [24320/60000 (41%)]\tLoss: 745.069031\n",
            "Train Epoch: 201 [25600/60000 (43%)]\tLoss: 731.591797\n",
            "Train Epoch: 201 [26880/60000 (45%)]\tLoss: 729.798523\n",
            "Train Epoch: 201 [28160/60000 (47%)]\tLoss: 762.115601\n",
            "Train Epoch: 201 [29440/60000 (49%)]\tLoss: 731.331299\n",
            "Train Epoch: 201 [30720/60000 (51%)]\tLoss: 744.749634\n",
            "Train Epoch: 201 [32000/60000 (53%)]\tLoss: 730.712952\n",
            "Train Epoch: 201 [33280/60000 (55%)]\tLoss: 711.193542\n",
            "Train Epoch: 201 [34560/60000 (58%)]\tLoss: 731.301941\n",
            "Train Epoch: 201 [35840/60000 (60%)]\tLoss: 712.934692\n",
            "Train Epoch: 201 [37120/60000 (62%)]\tLoss: 705.340698\n",
            "Train Epoch: 201 [38400/60000 (64%)]\tLoss: 746.645752\n",
            "Train Epoch: 201 [39680/60000 (66%)]\tLoss: 738.283020\n",
            "Train Epoch: 201 [40960/60000 (68%)]\tLoss: 733.381409\n",
            "Train Epoch: 201 [42240/60000 (70%)]\tLoss: 727.044189\n",
            "Train Epoch: 201 [43520/60000 (72%)]\tLoss: 726.698303\n",
            "Train Epoch: 201 [44800/60000 (75%)]\tLoss: 721.079041\n",
            "Train Epoch: 201 [46080/60000 (77%)]\tLoss: 734.339478\n",
            "Train Epoch: 201 [47360/60000 (79%)]\tLoss: 714.796692\n",
            "Train Epoch: 201 [48640/60000 (81%)]\tLoss: 728.953735\n",
            "Train Epoch: 201 [49920/60000 (83%)]\tLoss: 741.966736\n",
            "Train Epoch: 201 [51200/60000 (85%)]\tLoss: 737.096741\n",
            "Train Epoch: 201 [52480/60000 (87%)]\tLoss: 721.618591\n",
            "Train Epoch: 201 [53760/60000 (90%)]\tLoss: 754.768799\n",
            "Train Epoch: 201 [55040/60000 (92%)]\tLoss: 727.327148\n",
            "Train Epoch: 201 [56320/60000 (94%)]\tLoss: 721.759399\n",
            "Train Epoch: 201 [57600/60000 (96%)]\tLoss: 736.555481\n",
            "Train Epoch: 201 [58880/60000 (98%)]\tLoss: 743.469482\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781960546970367\n",
            "\n",
            "Train Epoch: 202 [0/60000 (0%)]\tLoss: 748.652344\n",
            "Train Epoch: 202 [1280/60000 (2%)]\tLoss: 722.131958\n",
            "Train Epoch: 202 [2560/60000 (4%)]\tLoss: 743.730652\n",
            "Train Epoch: 202 [3840/60000 (6%)]\tLoss: 740.663452\n",
            "Train Epoch: 202 [5120/60000 (9%)]\tLoss: 736.922119\n",
            "Train Epoch: 202 [6400/60000 (11%)]\tLoss: 748.744446\n",
            "Train Epoch: 202 [7680/60000 (13%)]\tLoss: 733.006409\n",
            "Train Epoch: 202 [8960/60000 (15%)]\tLoss: 766.119263\n",
            "Train Epoch: 202 [10240/60000 (17%)]\tLoss: 692.089355\n",
            "Train Epoch: 202 [11520/60000 (19%)]\tLoss: 743.676575\n",
            "Train Epoch: 202 [12800/60000 (21%)]\tLoss: 745.277588\n",
            "Train Epoch: 202 [14080/60000 (23%)]\tLoss: 735.856262\n",
            "Train Epoch: 202 [15360/60000 (26%)]\tLoss: 717.578491\n",
            "Train Epoch: 202 [16640/60000 (28%)]\tLoss: 729.790527\n",
            "Train Epoch: 202 [17920/60000 (30%)]\tLoss: 738.546631\n",
            "Train Epoch: 202 [19200/60000 (32%)]\tLoss: 732.102844\n",
            "Train Epoch: 202 [20480/60000 (34%)]\tLoss: 746.138977\n",
            "Train Epoch: 202 [21760/60000 (36%)]\tLoss: 725.977478\n",
            "Train Epoch: 202 [23040/60000 (38%)]\tLoss: 748.240356\n",
            "Train Epoch: 202 [24320/60000 (41%)]\tLoss: 708.947571\n",
            "Train Epoch: 202 [25600/60000 (43%)]\tLoss: 752.893188\n",
            "Train Epoch: 202 [26880/60000 (45%)]\tLoss: 744.844116\n",
            "Train Epoch: 202 [28160/60000 (47%)]\tLoss: 737.494263\n",
            "Train Epoch: 202 [29440/60000 (49%)]\tLoss: 717.814148\n",
            "Train Epoch: 202 [30720/60000 (51%)]\tLoss: 766.999634\n",
            "Train Epoch: 202 [32000/60000 (53%)]\tLoss: 733.777161\n",
            "Train Epoch: 202 [33280/60000 (55%)]\tLoss: 742.345032\n",
            "Train Epoch: 202 [34560/60000 (58%)]\tLoss: 732.246460\n",
            "Train Epoch: 202 [35840/60000 (60%)]\tLoss: 734.272278\n",
            "Train Epoch: 202 [37120/60000 (62%)]\tLoss: 731.312378\n",
            "Train Epoch: 202 [38400/60000 (64%)]\tLoss: 717.523376\n",
            "Train Epoch: 202 [39680/60000 (66%)]\tLoss: 716.022095\n",
            "Train Epoch: 202 [40960/60000 (68%)]\tLoss: 749.566711\n",
            "Train Epoch: 202 [42240/60000 (70%)]\tLoss: 736.153503\n",
            "Train Epoch: 202 [43520/60000 (72%)]\tLoss: 724.137329\n",
            "Train Epoch: 202 [44800/60000 (75%)]\tLoss: 745.671448\n",
            "Train Epoch: 202 [46080/60000 (77%)]\tLoss: 753.484558\n",
            "Train Epoch: 202 [47360/60000 (79%)]\tLoss: 743.827087\n",
            "Train Epoch: 202 [48640/60000 (81%)]\tLoss: 738.145020\n",
            "Train Epoch: 202 [49920/60000 (83%)]\tLoss: 758.160889\n",
            "Train Epoch: 202 [51200/60000 (85%)]\tLoss: 729.608215\n",
            "Train Epoch: 202 [52480/60000 (87%)]\tLoss: 746.073547\n",
            "Train Epoch: 202 [53760/60000 (90%)]\tLoss: 767.097351\n",
            "Train Epoch: 202 [55040/60000 (92%)]\tLoss: 737.224426\n",
            "Train Epoch: 202 [56320/60000 (94%)]\tLoss: 714.074463\n",
            "Train Epoch: 202 [57600/60000 (96%)]\tLoss: 726.829712\n",
            "Train Epoch: 202 [58880/60000 (98%)]\tLoss: 756.191040\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978432834148407\n",
            "\n",
            "Train Epoch: 203 [0/60000 (0%)]\tLoss: 741.314880\n",
            "Train Epoch: 203 [1280/60000 (2%)]\tLoss: 731.285339\n",
            "Train Epoch: 203 [2560/60000 (4%)]\tLoss: 730.013489\n",
            "Train Epoch: 203 [3840/60000 (6%)]\tLoss: 727.336548\n",
            "Train Epoch: 203 [5120/60000 (9%)]\tLoss: 729.686523\n",
            "Train Epoch: 203 [6400/60000 (11%)]\tLoss: 730.714783\n",
            "Train Epoch: 203 [7680/60000 (13%)]\tLoss: 725.829102\n",
            "Train Epoch: 203 [8960/60000 (15%)]\tLoss: 755.154907\n",
            "Train Epoch: 203 [10240/60000 (17%)]\tLoss: 750.595276\n",
            "Train Epoch: 203 [11520/60000 (19%)]\tLoss: 720.633667\n",
            "Train Epoch: 203 [12800/60000 (21%)]\tLoss: 712.419922\n",
            "Train Epoch: 203 [14080/60000 (23%)]\tLoss: 765.429443\n",
            "Train Epoch: 203 [15360/60000 (26%)]\tLoss: 729.205994\n",
            "Train Epoch: 203 [16640/60000 (28%)]\tLoss: 742.750061\n",
            "Train Epoch: 203 [17920/60000 (30%)]\tLoss: 759.479919\n",
            "Train Epoch: 203 [19200/60000 (32%)]\tLoss: 725.473694\n",
            "Train Epoch: 203 [20480/60000 (34%)]\tLoss: 755.755676\n",
            "Train Epoch: 203 [21760/60000 (36%)]\tLoss: 755.846741\n",
            "Train Epoch: 203 [23040/60000 (38%)]\tLoss: 739.697754\n",
            "Train Epoch: 203 [24320/60000 (41%)]\tLoss: 734.937805\n",
            "Train Epoch: 203 [25600/60000 (43%)]\tLoss: 722.481506\n",
            "Train Epoch: 203 [26880/60000 (45%)]\tLoss: 727.680359\n",
            "Train Epoch: 203 [28160/60000 (47%)]\tLoss: 732.412537\n",
            "Train Epoch: 203 [29440/60000 (49%)]\tLoss: 737.424500\n",
            "Train Epoch: 203 [30720/60000 (51%)]\tLoss: 735.054565\n",
            "Train Epoch: 203 [32000/60000 (53%)]\tLoss: 718.776794\n",
            "Train Epoch: 203 [33280/60000 (55%)]\tLoss: 738.099243\n",
            "Train Epoch: 203 [34560/60000 (58%)]\tLoss: 719.359314\n",
            "Train Epoch: 203 [35840/60000 (60%)]\tLoss: 713.431702\n",
            "Train Epoch: 203 [37120/60000 (62%)]\tLoss: 727.003113\n",
            "Train Epoch: 203 [38400/60000 (64%)]\tLoss: 738.332214\n",
            "Train Epoch: 203 [39680/60000 (66%)]\tLoss: 734.677795\n",
            "Train Epoch: 203 [40960/60000 (68%)]\tLoss: 753.407410\n",
            "Train Epoch: 203 [42240/60000 (70%)]\tLoss: 720.388733\n",
            "Train Epoch: 203 [43520/60000 (72%)]\tLoss: 713.445007\n",
            "Train Epoch: 203 [44800/60000 (75%)]\tLoss: 741.558533\n",
            "Train Epoch: 203 [46080/60000 (77%)]\tLoss: 739.950439\n",
            "Train Epoch: 203 [47360/60000 (79%)]\tLoss: 732.407654\n",
            "Train Epoch: 203 [48640/60000 (81%)]\tLoss: 733.388672\n",
            "Train Epoch: 203 [49920/60000 (83%)]\tLoss: 738.539062\n",
            "Train Epoch: 203 [51200/60000 (85%)]\tLoss: 743.995239\n",
            "Train Epoch: 203 [52480/60000 (87%)]\tLoss: 746.172180\n",
            "Train Epoch: 203 [53760/60000 (90%)]\tLoss: 719.918152\n",
            "Train Epoch: 203 [55040/60000 (92%)]\tLoss: 720.819519\n",
            "Train Epoch: 203 [56320/60000 (94%)]\tLoss: 714.705566\n",
            "Train Epoch: 203 [57600/60000 (96%)]\tLoss: 721.986938\n",
            "Train Epoch: 203 [58880/60000 (98%)]\tLoss: 760.548035\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783945381641388\n",
            "\n",
            "Train Epoch: 204 [0/60000 (0%)]\tLoss: 761.424438\n",
            "Train Epoch: 204 [1280/60000 (2%)]\tLoss: 742.884644\n",
            "Train Epoch: 204 [2560/60000 (4%)]\tLoss: 718.895935\n",
            "Train Epoch: 204 [3840/60000 (6%)]\tLoss: 752.285767\n",
            "Train Epoch: 204 [5120/60000 (9%)]\tLoss: 719.297363\n",
            "Train Epoch: 204 [6400/60000 (11%)]\tLoss: 713.041931\n",
            "Train Epoch: 204 [7680/60000 (13%)]\tLoss: 726.741211\n",
            "Train Epoch: 204 [8960/60000 (15%)]\tLoss: 727.587585\n",
            "Train Epoch: 204 [10240/60000 (17%)]\tLoss: 718.809509\n",
            "Train Epoch: 204 [11520/60000 (19%)]\tLoss: 725.355103\n",
            "Train Epoch: 204 [12800/60000 (21%)]\tLoss: 744.474792\n",
            "Train Epoch: 204 [14080/60000 (23%)]\tLoss: 731.020508\n",
            "Train Epoch: 204 [15360/60000 (26%)]\tLoss: 726.146362\n",
            "Train Epoch: 204 [16640/60000 (28%)]\tLoss: 728.836487\n",
            "Train Epoch: 204 [17920/60000 (30%)]\tLoss: 732.463989\n",
            "Train Epoch: 204 [19200/60000 (32%)]\tLoss: 733.604248\n",
            "Train Epoch: 204 [20480/60000 (34%)]\tLoss: 731.794800\n",
            "Train Epoch: 204 [21760/60000 (36%)]\tLoss: 768.206604\n",
            "Train Epoch: 204 [23040/60000 (38%)]\tLoss: 722.461121\n",
            "Train Epoch: 204 [24320/60000 (41%)]\tLoss: 765.379456\n",
            "Train Epoch: 204 [25600/60000 (43%)]\tLoss: 723.822327\n",
            "Train Epoch: 204 [26880/60000 (45%)]\tLoss: 724.352112\n",
            "Train Epoch: 204 [28160/60000 (47%)]\tLoss: 748.211670\n",
            "Train Epoch: 204 [29440/60000 (49%)]\tLoss: 720.415283\n",
            "Train Epoch: 204 [30720/60000 (51%)]\tLoss: 752.055664\n",
            "Train Epoch: 204 [32000/60000 (53%)]\tLoss: 737.409973\n",
            "Train Epoch: 204 [33280/60000 (55%)]\tLoss: 753.644226\n",
            "Train Epoch: 204 [34560/60000 (58%)]\tLoss: 724.805359\n",
            "Train Epoch: 204 [35840/60000 (60%)]\tLoss: 733.568909\n",
            "Train Epoch: 204 [37120/60000 (62%)]\tLoss: 738.655762\n",
            "Train Epoch: 204 [38400/60000 (64%)]\tLoss: 738.847656\n",
            "Train Epoch: 204 [39680/60000 (66%)]\tLoss: 742.236145\n",
            "Train Epoch: 204 [40960/60000 (68%)]\tLoss: 755.759705\n",
            "Train Epoch: 204 [42240/60000 (70%)]\tLoss: 752.019287\n",
            "Train Epoch: 204 [43520/60000 (72%)]\tLoss: 781.032043\n",
            "Train Epoch: 204 [44800/60000 (75%)]\tLoss: 718.539795\n",
            "Train Epoch: 204 [46080/60000 (77%)]\tLoss: 725.691101\n",
            "Train Epoch: 204 [47360/60000 (79%)]\tLoss: 734.975037\n",
            "Train Epoch: 204 [48640/60000 (81%)]\tLoss: 752.028015\n",
            "Train Epoch: 204 [49920/60000 (83%)]\tLoss: 730.351196\n",
            "Train Epoch: 204 [51200/60000 (85%)]\tLoss: 732.015320\n",
            "Train Epoch: 204 [52480/60000 (87%)]\tLoss: 744.948059\n",
            "Train Epoch: 204 [53760/60000 (90%)]\tLoss: 759.487915\n",
            "Train Epoch: 204 [55040/60000 (92%)]\tLoss: 728.887146\n",
            "Train Epoch: 204 [56320/60000 (94%)]\tLoss: 735.470398\n",
            "Train Epoch: 204 [57600/60000 (96%)]\tLoss: 747.572144\n",
            "Train Epoch: 204 [58880/60000 (98%)]\tLoss: 734.942871\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782724976539612\n",
            "\n",
            "Train Epoch: 205 [0/60000 (0%)]\tLoss: 715.061707\n",
            "Train Epoch: 205 [1280/60000 (2%)]\tLoss: 730.120361\n",
            "Train Epoch: 205 [2560/60000 (4%)]\tLoss: 735.564331\n",
            "Train Epoch: 205 [3840/60000 (6%)]\tLoss: 738.053284\n",
            "Train Epoch: 205 [5120/60000 (9%)]\tLoss: 729.163879\n",
            "Train Epoch: 205 [6400/60000 (11%)]\tLoss: 735.699280\n",
            "Train Epoch: 205 [7680/60000 (13%)]\tLoss: 724.805664\n",
            "Train Epoch: 205 [8960/60000 (15%)]\tLoss: 732.348450\n",
            "Train Epoch: 205 [10240/60000 (17%)]\tLoss: 721.284790\n",
            "Train Epoch: 205 [11520/60000 (19%)]\tLoss: 736.199829\n",
            "Train Epoch: 205 [12800/60000 (21%)]\tLoss: 749.749756\n",
            "Train Epoch: 205 [14080/60000 (23%)]\tLoss: 710.471191\n",
            "Train Epoch: 205 [15360/60000 (26%)]\tLoss: 708.554260\n",
            "Train Epoch: 205 [16640/60000 (28%)]\tLoss: 740.250732\n",
            "Train Epoch: 205 [17920/60000 (30%)]\tLoss: 739.626953\n",
            "Train Epoch: 205 [19200/60000 (32%)]\tLoss: 745.373291\n",
            "Train Epoch: 205 [20480/60000 (34%)]\tLoss: 754.033325\n",
            "Train Epoch: 205 [21760/60000 (36%)]\tLoss: 720.113647\n",
            "Train Epoch: 205 [23040/60000 (38%)]\tLoss: 703.339966\n",
            "Train Epoch: 205 [24320/60000 (41%)]\tLoss: 765.465881\n",
            "Train Epoch: 205 [25600/60000 (43%)]\tLoss: 711.855530\n",
            "Train Epoch: 205 [26880/60000 (45%)]\tLoss: 724.222961\n",
            "Train Epoch: 205 [28160/60000 (47%)]\tLoss: 735.894226\n",
            "Train Epoch: 205 [29440/60000 (49%)]\tLoss: 751.974792\n",
            "Train Epoch: 205 [30720/60000 (51%)]\tLoss: 727.388062\n",
            "Train Epoch: 205 [32000/60000 (53%)]\tLoss: 733.488708\n",
            "Train Epoch: 205 [33280/60000 (55%)]\tLoss: 749.486633\n",
            "Train Epoch: 205 [34560/60000 (58%)]\tLoss: 759.653381\n",
            "Train Epoch: 205 [35840/60000 (60%)]\tLoss: 736.923401\n",
            "Train Epoch: 205 [37120/60000 (62%)]\tLoss: 736.015442\n",
            "Train Epoch: 205 [38400/60000 (64%)]\tLoss: 760.154114\n",
            "Train Epoch: 205 [39680/60000 (66%)]\tLoss: 744.195435\n",
            "Train Epoch: 205 [40960/60000 (68%)]\tLoss: 717.750000\n",
            "Train Epoch: 205 [42240/60000 (70%)]\tLoss: 730.822876\n",
            "Train Epoch: 205 [43520/60000 (72%)]\tLoss: 711.279968\n",
            "Train Epoch: 205 [44800/60000 (75%)]\tLoss: 736.761902\n",
            "Train Epoch: 205 [46080/60000 (77%)]\tLoss: 724.242493\n",
            "Train Epoch: 205 [47360/60000 (79%)]\tLoss: 731.740479\n",
            "Train Epoch: 205 [48640/60000 (81%)]\tLoss: 746.302612\n",
            "Train Epoch: 205 [49920/60000 (83%)]\tLoss: 731.983276\n",
            "Train Epoch: 205 [51200/60000 (85%)]\tLoss: 763.636658\n",
            "Train Epoch: 205 [52480/60000 (87%)]\tLoss: 717.735840\n",
            "Train Epoch: 205 [53760/60000 (90%)]\tLoss: 721.011169\n",
            "Train Epoch: 205 [55040/60000 (92%)]\tLoss: 763.807861\n",
            "Train Epoch: 205 [56320/60000 (94%)]\tLoss: 734.006287\n",
            "Train Epoch: 205 [57600/60000 (96%)]\tLoss: 726.525757\n",
            "Train Epoch: 205 [58880/60000 (98%)]\tLoss: 722.509583\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784879684448242\n",
            "\n",
            "Train Epoch: 206 [0/60000 (0%)]\tLoss: 739.960876\n",
            "Train Epoch: 206 [1280/60000 (2%)]\tLoss: 737.511230\n",
            "Train Epoch: 206 [2560/60000 (4%)]\tLoss: 712.052002\n",
            "Train Epoch: 206 [3840/60000 (6%)]\tLoss: 729.627563\n",
            "Train Epoch: 206 [5120/60000 (9%)]\tLoss: 717.861023\n",
            "Train Epoch: 206 [6400/60000 (11%)]\tLoss: 733.155273\n",
            "Train Epoch: 206 [7680/60000 (13%)]\tLoss: 734.252808\n",
            "Train Epoch: 206 [8960/60000 (15%)]\tLoss: 743.957458\n",
            "Train Epoch: 206 [10240/60000 (17%)]\tLoss: 727.628723\n",
            "Train Epoch: 206 [11520/60000 (19%)]\tLoss: 734.856628\n",
            "Train Epoch: 206 [12800/60000 (21%)]\tLoss: 721.296570\n",
            "Train Epoch: 206 [14080/60000 (23%)]\tLoss: 755.911499\n",
            "Train Epoch: 206 [15360/60000 (26%)]\tLoss: 739.469543\n",
            "Train Epoch: 206 [16640/60000 (28%)]\tLoss: 744.725037\n",
            "Train Epoch: 206 [17920/60000 (30%)]\tLoss: 739.786133\n",
            "Train Epoch: 206 [19200/60000 (32%)]\tLoss: 732.100464\n",
            "Train Epoch: 206 [20480/60000 (34%)]\tLoss: 732.387024\n",
            "Train Epoch: 206 [21760/60000 (36%)]\tLoss: 757.280579\n",
            "Train Epoch: 206 [23040/60000 (38%)]\tLoss: 757.827332\n",
            "Train Epoch: 206 [24320/60000 (41%)]\tLoss: 760.061096\n",
            "Train Epoch: 206 [25600/60000 (43%)]\tLoss: 764.183533\n",
            "Train Epoch: 206 [26880/60000 (45%)]\tLoss: 730.346436\n",
            "Train Epoch: 206 [28160/60000 (47%)]\tLoss: 725.255676\n",
            "Train Epoch: 206 [29440/60000 (49%)]\tLoss: 735.939880\n",
            "Train Epoch: 206 [30720/60000 (51%)]\tLoss: 759.851685\n",
            "Train Epoch: 206 [32000/60000 (53%)]\tLoss: 751.423706\n",
            "Train Epoch: 206 [33280/60000 (55%)]\tLoss: 759.150940\n",
            "Train Epoch: 206 [34560/60000 (58%)]\tLoss: 735.616211\n",
            "Train Epoch: 206 [35840/60000 (60%)]\tLoss: 744.848694\n",
            "Train Epoch: 206 [37120/60000 (62%)]\tLoss: 755.897583\n",
            "Train Epoch: 206 [38400/60000 (64%)]\tLoss: 736.918396\n",
            "Train Epoch: 206 [39680/60000 (66%)]\tLoss: 736.534668\n",
            "Train Epoch: 206 [40960/60000 (68%)]\tLoss: 735.098816\n",
            "Train Epoch: 206 [42240/60000 (70%)]\tLoss: 745.874451\n",
            "Train Epoch: 206 [43520/60000 (72%)]\tLoss: 721.709961\n",
            "Train Epoch: 206 [44800/60000 (75%)]\tLoss: 728.757812\n",
            "Train Epoch: 206 [46080/60000 (77%)]\tLoss: 742.248962\n",
            "Train Epoch: 206 [47360/60000 (79%)]\tLoss: 751.955811\n",
            "Train Epoch: 206 [48640/60000 (81%)]\tLoss: 732.593323\n",
            "Train Epoch: 206 [49920/60000 (83%)]\tLoss: 758.450439\n",
            "Train Epoch: 206 [51200/60000 (85%)]\tLoss: 741.365295\n",
            "Train Epoch: 206 [52480/60000 (87%)]\tLoss: 760.505005\n",
            "Train Epoch: 206 [53760/60000 (90%)]\tLoss: 734.702759\n",
            "Train Epoch: 206 [55040/60000 (92%)]\tLoss: 746.658020\n",
            "Train Epoch: 206 [56320/60000 (94%)]\tLoss: 742.704590\n",
            "Train Epoch: 206 [57600/60000 (96%)]\tLoss: 707.241211\n",
            "Train Epoch: 206 [58880/60000 (98%)]\tLoss: 733.965881\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783857464790344\n",
            "\n",
            "Train Epoch: 207 [0/60000 (0%)]\tLoss: 737.998657\n",
            "Train Epoch: 207 [1280/60000 (2%)]\tLoss: 737.372131\n",
            "Train Epoch: 207 [2560/60000 (4%)]\tLoss: 728.881653\n",
            "Train Epoch: 207 [3840/60000 (6%)]\tLoss: 728.249512\n",
            "Train Epoch: 207 [5120/60000 (9%)]\tLoss: 753.938904\n",
            "Train Epoch: 207 [6400/60000 (11%)]\tLoss: 730.153442\n",
            "Train Epoch: 207 [7680/60000 (13%)]\tLoss: 742.565491\n",
            "Train Epoch: 207 [8960/60000 (15%)]\tLoss: 735.616699\n",
            "Train Epoch: 207 [10240/60000 (17%)]\tLoss: 710.720581\n",
            "Train Epoch: 207 [11520/60000 (19%)]\tLoss: 735.614746\n",
            "Train Epoch: 207 [12800/60000 (21%)]\tLoss: 760.200256\n",
            "Train Epoch: 207 [14080/60000 (23%)]\tLoss: 752.119507\n",
            "Train Epoch: 207 [15360/60000 (26%)]\tLoss: 705.348328\n",
            "Train Epoch: 207 [16640/60000 (28%)]\tLoss: 739.861206\n",
            "Train Epoch: 207 [17920/60000 (30%)]\tLoss: 739.604248\n",
            "Train Epoch: 207 [19200/60000 (32%)]\tLoss: 705.717529\n",
            "Train Epoch: 207 [20480/60000 (34%)]\tLoss: 734.988037\n",
            "Train Epoch: 207 [21760/60000 (36%)]\tLoss: 734.190674\n",
            "Train Epoch: 207 [23040/60000 (38%)]\tLoss: 722.282410\n",
            "Train Epoch: 207 [24320/60000 (41%)]\tLoss: 737.763794\n",
            "Train Epoch: 207 [25600/60000 (43%)]\tLoss: 748.847595\n",
            "Train Epoch: 207 [26880/60000 (45%)]\tLoss: 754.341431\n",
            "Train Epoch: 207 [28160/60000 (47%)]\tLoss: 765.727783\n",
            "Train Epoch: 207 [29440/60000 (49%)]\tLoss: 740.798462\n",
            "Train Epoch: 207 [30720/60000 (51%)]\tLoss: 748.194763\n",
            "Train Epoch: 207 [32000/60000 (53%)]\tLoss: 722.626831\n",
            "Train Epoch: 207 [33280/60000 (55%)]\tLoss: 722.419128\n",
            "Train Epoch: 207 [34560/60000 (58%)]\tLoss: 725.946960\n",
            "Train Epoch: 207 [35840/60000 (60%)]\tLoss: 730.886292\n",
            "Train Epoch: 207 [37120/60000 (62%)]\tLoss: 760.663696\n",
            "Train Epoch: 207 [38400/60000 (64%)]\tLoss: 726.559814\n",
            "Train Epoch: 207 [39680/60000 (66%)]\tLoss: 729.130249\n",
            "Train Epoch: 207 [40960/60000 (68%)]\tLoss: 749.394592\n",
            "Train Epoch: 207 [42240/60000 (70%)]\tLoss: 741.742310\n",
            "Train Epoch: 207 [43520/60000 (72%)]\tLoss: 762.874023\n",
            "Train Epoch: 207 [44800/60000 (75%)]\tLoss: 744.760742\n",
            "Train Epoch: 207 [46080/60000 (77%)]\tLoss: 737.142212\n",
            "Train Epoch: 207 [47360/60000 (79%)]\tLoss: 746.179382\n",
            "Train Epoch: 207 [48640/60000 (81%)]\tLoss: 744.994812\n",
            "Train Epoch: 207 [49920/60000 (83%)]\tLoss: 743.179382\n",
            "Train Epoch: 207 [51200/60000 (85%)]\tLoss: 739.521484\n",
            "Train Epoch: 207 [52480/60000 (87%)]\tLoss: 735.981079\n",
            "Train Epoch: 207 [53760/60000 (90%)]\tLoss: 747.749573\n",
            "Train Epoch: 207 [55040/60000 (92%)]\tLoss: 717.352966\n",
            "Train Epoch: 207 [56320/60000 (94%)]\tLoss: 735.244690\n",
            "Train Epoch: 207 [57600/60000 (96%)]\tLoss: 730.002869\n",
            "Train Epoch: 207 [58880/60000 (98%)]\tLoss: 750.491089\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781722128391266\n",
            "\n",
            "Train Epoch: 208 [0/60000 (0%)]\tLoss: 765.628357\n",
            "Train Epoch: 208 [1280/60000 (2%)]\tLoss: 730.566589\n",
            "Train Epoch: 208 [2560/60000 (4%)]\tLoss: 758.144775\n",
            "Train Epoch: 208 [3840/60000 (6%)]\tLoss: 725.557739\n",
            "Train Epoch: 208 [5120/60000 (9%)]\tLoss: 729.109619\n",
            "Train Epoch: 208 [6400/60000 (11%)]\tLoss: 736.217773\n",
            "Train Epoch: 208 [7680/60000 (13%)]\tLoss: 729.373840\n",
            "Train Epoch: 208 [8960/60000 (15%)]\tLoss: 729.074219\n",
            "Train Epoch: 208 [10240/60000 (17%)]\tLoss: 741.105652\n",
            "Train Epoch: 208 [11520/60000 (19%)]\tLoss: 732.595154\n",
            "Train Epoch: 208 [12800/60000 (21%)]\tLoss: 735.205200\n",
            "Train Epoch: 208 [14080/60000 (23%)]\tLoss: 735.704407\n",
            "Train Epoch: 208 [15360/60000 (26%)]\tLoss: 726.766846\n",
            "Train Epoch: 208 [16640/60000 (28%)]\tLoss: 729.428894\n",
            "Train Epoch: 208 [17920/60000 (30%)]\tLoss: 733.312317\n",
            "Train Epoch: 208 [19200/60000 (32%)]\tLoss: 739.281311\n",
            "Train Epoch: 208 [20480/60000 (34%)]\tLoss: 729.685974\n",
            "Train Epoch: 208 [21760/60000 (36%)]\tLoss: 750.145264\n",
            "Train Epoch: 208 [23040/60000 (38%)]\tLoss: 739.442566\n",
            "Train Epoch: 208 [24320/60000 (41%)]\tLoss: 732.059265\n",
            "Train Epoch: 208 [25600/60000 (43%)]\tLoss: 740.581848\n",
            "Train Epoch: 208 [26880/60000 (45%)]\tLoss: 716.174255\n",
            "Train Epoch: 208 [28160/60000 (47%)]\tLoss: 753.828003\n",
            "Train Epoch: 208 [29440/60000 (49%)]\tLoss: 740.021606\n",
            "Train Epoch: 208 [30720/60000 (51%)]\tLoss: 720.513306\n",
            "Train Epoch: 208 [32000/60000 (53%)]\tLoss: 726.336548\n",
            "Train Epoch: 208 [33280/60000 (55%)]\tLoss: 718.087341\n",
            "Train Epoch: 208 [34560/60000 (58%)]\tLoss: 721.374817\n",
            "Train Epoch: 208 [35840/60000 (60%)]\tLoss: 731.713440\n",
            "Train Epoch: 208 [37120/60000 (62%)]\tLoss: 726.435974\n",
            "Train Epoch: 208 [38400/60000 (64%)]\tLoss: 749.779358\n",
            "Train Epoch: 208 [39680/60000 (66%)]\tLoss: 736.417664\n",
            "Train Epoch: 208 [40960/60000 (68%)]\tLoss: 711.057007\n",
            "Train Epoch: 208 [42240/60000 (70%)]\tLoss: 733.307495\n",
            "Train Epoch: 208 [43520/60000 (72%)]\tLoss: 756.948364\n",
            "Train Epoch: 208 [44800/60000 (75%)]\tLoss: 748.523071\n",
            "Train Epoch: 208 [46080/60000 (77%)]\tLoss: 745.515930\n",
            "Train Epoch: 208 [47360/60000 (79%)]\tLoss: 768.981567\n",
            "Train Epoch: 208 [48640/60000 (81%)]\tLoss: 713.030762\n",
            "Train Epoch: 208 [49920/60000 (83%)]\tLoss: 737.945862\n",
            "Train Epoch: 208 [51200/60000 (85%)]\tLoss: 754.437378\n",
            "Train Epoch: 208 [52480/60000 (87%)]\tLoss: 769.729797\n",
            "Train Epoch: 208 [53760/60000 (90%)]\tLoss: 739.449036\n",
            "Train Epoch: 208 [55040/60000 (92%)]\tLoss: 745.863037\n",
            "Train Epoch: 208 [56320/60000 (94%)]\tLoss: 730.705078\n",
            "Train Epoch: 208 [57600/60000 (96%)]\tLoss: 750.695068\n",
            "Train Epoch: 208 [58880/60000 (98%)]\tLoss: 735.204285\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788488745689392\n",
            "\n",
            "Train Epoch: 209 [0/60000 (0%)]\tLoss: 713.996460\n",
            "Train Epoch: 209 [1280/60000 (2%)]\tLoss: 756.997375\n",
            "Train Epoch: 209 [2560/60000 (4%)]\tLoss: 699.144165\n",
            "Train Epoch: 209 [3840/60000 (6%)]\tLoss: 711.876404\n",
            "Train Epoch: 209 [5120/60000 (9%)]\tLoss: 749.761536\n",
            "Train Epoch: 209 [6400/60000 (11%)]\tLoss: 701.468567\n",
            "Train Epoch: 209 [7680/60000 (13%)]\tLoss: 708.457153\n",
            "Train Epoch: 209 [8960/60000 (15%)]\tLoss: 707.498169\n",
            "Train Epoch: 209 [10240/60000 (17%)]\tLoss: 731.463440\n",
            "Train Epoch: 209 [11520/60000 (19%)]\tLoss: 737.921509\n",
            "Train Epoch: 209 [12800/60000 (21%)]\tLoss: 747.220093\n",
            "Train Epoch: 209 [14080/60000 (23%)]\tLoss: 738.303467\n",
            "Train Epoch: 209 [15360/60000 (26%)]\tLoss: 737.518127\n",
            "Train Epoch: 209 [16640/60000 (28%)]\tLoss: 730.603333\n",
            "Train Epoch: 209 [17920/60000 (30%)]\tLoss: 757.855225\n",
            "Train Epoch: 209 [19200/60000 (32%)]\tLoss: 747.977051\n",
            "Train Epoch: 209 [20480/60000 (34%)]\tLoss: 738.126648\n",
            "Train Epoch: 209 [21760/60000 (36%)]\tLoss: 737.106018\n",
            "Train Epoch: 209 [23040/60000 (38%)]\tLoss: 749.016479\n",
            "Train Epoch: 209 [24320/60000 (41%)]\tLoss: 737.168213\n",
            "Train Epoch: 209 [25600/60000 (43%)]\tLoss: 754.186462\n",
            "Train Epoch: 209 [26880/60000 (45%)]\tLoss: 708.866638\n",
            "Train Epoch: 209 [28160/60000 (47%)]\tLoss: 724.374390\n",
            "Train Epoch: 209 [29440/60000 (49%)]\tLoss: 721.755676\n",
            "Train Epoch: 209 [30720/60000 (51%)]\tLoss: 736.497498\n",
            "Train Epoch: 209 [32000/60000 (53%)]\tLoss: 745.430786\n",
            "Train Epoch: 209 [33280/60000 (55%)]\tLoss: 751.123291\n",
            "Train Epoch: 209 [34560/60000 (58%)]\tLoss: 726.885132\n",
            "Train Epoch: 209 [35840/60000 (60%)]\tLoss: 735.848877\n",
            "Train Epoch: 209 [37120/60000 (62%)]\tLoss: 741.672729\n",
            "Train Epoch: 209 [38400/60000 (64%)]\tLoss: 734.130737\n",
            "Train Epoch: 209 [39680/60000 (66%)]\tLoss: 740.547913\n",
            "Train Epoch: 209 [40960/60000 (68%)]\tLoss: 725.731018\n",
            "Train Epoch: 209 [42240/60000 (70%)]\tLoss: 734.063965\n",
            "Train Epoch: 209 [43520/60000 (72%)]\tLoss: 737.134949\n",
            "Train Epoch: 209 [44800/60000 (75%)]\tLoss: 735.408813\n",
            "Train Epoch: 209 [46080/60000 (77%)]\tLoss: 719.630615\n",
            "Train Epoch: 209 [47360/60000 (79%)]\tLoss: 727.813354\n",
            "Train Epoch: 209 [48640/60000 (81%)]\tLoss: 723.490173\n",
            "Train Epoch: 209 [49920/60000 (83%)]\tLoss: 728.303040\n",
            "Train Epoch: 209 [51200/60000 (85%)]\tLoss: 718.192688\n",
            "Train Epoch: 209 [52480/60000 (87%)]\tLoss: 732.317566\n",
            "Train Epoch: 209 [53760/60000 (90%)]\tLoss: 737.334351\n",
            "Train Epoch: 209 [55040/60000 (92%)]\tLoss: 722.014771\n",
            "Train Epoch: 209 [56320/60000 (94%)]\tLoss: 744.519653\n",
            "Train Epoch: 209 [57600/60000 (96%)]\tLoss: 744.070190\n",
            "Train Epoch: 209 [58880/60000 (98%)]\tLoss: 709.424011\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781167805194855\n",
            "\n",
            "Train Epoch: 210 [0/60000 (0%)]\tLoss: 744.393921\n",
            "Train Epoch: 210 [1280/60000 (2%)]\tLoss: 725.253479\n",
            "Train Epoch: 210 [2560/60000 (4%)]\tLoss: 715.541931\n",
            "Train Epoch: 210 [3840/60000 (6%)]\tLoss: 709.980042\n",
            "Train Epoch: 210 [5120/60000 (9%)]\tLoss: 715.921814\n",
            "Train Epoch: 210 [6400/60000 (11%)]\tLoss: 723.950134\n",
            "Train Epoch: 210 [7680/60000 (13%)]\tLoss: 711.983337\n",
            "Train Epoch: 210 [8960/60000 (15%)]\tLoss: 748.038269\n",
            "Train Epoch: 210 [10240/60000 (17%)]\tLoss: 757.788879\n",
            "Train Epoch: 210 [11520/60000 (19%)]\tLoss: 735.714294\n",
            "Train Epoch: 210 [12800/60000 (21%)]\tLoss: 732.332031\n",
            "Train Epoch: 210 [14080/60000 (23%)]\tLoss: 740.230713\n",
            "Train Epoch: 210 [15360/60000 (26%)]\tLoss: 724.646973\n",
            "Train Epoch: 210 [16640/60000 (28%)]\tLoss: 761.203308\n",
            "Train Epoch: 210 [17920/60000 (30%)]\tLoss: 727.100708\n",
            "Train Epoch: 210 [19200/60000 (32%)]\tLoss: 736.780457\n",
            "Train Epoch: 210 [20480/60000 (34%)]\tLoss: 741.944336\n",
            "Train Epoch: 210 [21760/60000 (36%)]\tLoss: 733.448730\n",
            "Train Epoch: 210 [23040/60000 (38%)]\tLoss: 737.163940\n",
            "Train Epoch: 210 [24320/60000 (41%)]\tLoss: 736.050171\n",
            "Train Epoch: 210 [25600/60000 (43%)]\tLoss: 725.958801\n",
            "Train Epoch: 210 [26880/60000 (45%)]\tLoss: 737.646545\n",
            "Train Epoch: 210 [28160/60000 (47%)]\tLoss: 752.724731\n",
            "Train Epoch: 210 [29440/60000 (49%)]\tLoss: 715.266663\n",
            "Train Epoch: 210 [30720/60000 (51%)]\tLoss: 724.299805\n",
            "Train Epoch: 210 [32000/60000 (53%)]\tLoss: 743.290405\n",
            "Train Epoch: 210 [33280/60000 (55%)]\tLoss: 736.402344\n",
            "Train Epoch: 210 [34560/60000 (58%)]\tLoss: 743.633362\n",
            "Train Epoch: 210 [35840/60000 (60%)]\tLoss: 719.976379\n",
            "Train Epoch: 210 [37120/60000 (62%)]\tLoss: 758.614929\n",
            "Train Epoch: 210 [38400/60000 (64%)]\tLoss: 734.316101\n",
            "Train Epoch: 210 [39680/60000 (66%)]\tLoss: 752.827881\n",
            "Train Epoch: 210 [40960/60000 (68%)]\tLoss: 740.843506\n",
            "Train Epoch: 210 [42240/60000 (70%)]\tLoss: 730.731506\n",
            "Train Epoch: 210 [43520/60000 (72%)]\tLoss: 735.121582\n",
            "Train Epoch: 210 [44800/60000 (75%)]\tLoss: 730.156006\n",
            "Train Epoch: 210 [46080/60000 (77%)]\tLoss: 714.481506\n",
            "Train Epoch: 210 [47360/60000 (79%)]\tLoss: 727.211487\n",
            "Train Epoch: 210 [48640/60000 (81%)]\tLoss: 768.500854\n",
            "Train Epoch: 210 [49920/60000 (83%)]\tLoss: 727.190918\n",
            "Train Epoch: 210 [51200/60000 (85%)]\tLoss: 745.700562\n",
            "Train Epoch: 210 [52480/60000 (87%)]\tLoss: 756.544006\n",
            "Train Epoch: 210 [53760/60000 (90%)]\tLoss: 724.273254\n",
            "Train Epoch: 210 [55040/60000 (92%)]\tLoss: 718.689087\n",
            "Train Epoch: 210 [56320/60000 (94%)]\tLoss: 732.047607\n",
            "Train Epoch: 210 [57600/60000 (96%)]\tLoss: 742.229248\n",
            "Train Epoch: 210 [58880/60000 (98%)]\tLoss: 735.195435\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786079227924347\n",
            "\n",
            "Train Epoch: 211 [0/60000 (0%)]\tLoss: 758.623230\n",
            "Train Epoch: 211 [1280/60000 (2%)]\tLoss: 733.081116\n",
            "Train Epoch: 211 [2560/60000 (4%)]\tLoss: 726.526428\n",
            "Train Epoch: 211 [3840/60000 (6%)]\tLoss: 725.408875\n",
            "Train Epoch: 211 [5120/60000 (9%)]\tLoss: 744.561340\n",
            "Train Epoch: 211 [6400/60000 (11%)]\tLoss: 723.004028\n",
            "Train Epoch: 211 [7680/60000 (13%)]\tLoss: 748.947571\n",
            "Train Epoch: 211 [8960/60000 (15%)]\tLoss: 716.617737\n",
            "Train Epoch: 211 [10240/60000 (17%)]\tLoss: 725.286560\n",
            "Train Epoch: 211 [11520/60000 (19%)]\tLoss: 730.799011\n",
            "Train Epoch: 211 [12800/60000 (21%)]\tLoss: 733.028748\n",
            "Train Epoch: 211 [14080/60000 (23%)]\tLoss: 739.347595\n",
            "Train Epoch: 211 [15360/60000 (26%)]\tLoss: 744.140015\n",
            "Train Epoch: 211 [16640/60000 (28%)]\tLoss: 738.541626\n",
            "Train Epoch: 211 [17920/60000 (30%)]\tLoss: 734.886902\n",
            "Train Epoch: 211 [19200/60000 (32%)]\tLoss: 721.266052\n",
            "Train Epoch: 211 [20480/60000 (34%)]\tLoss: 738.228088\n",
            "Train Epoch: 211 [21760/60000 (36%)]\tLoss: 723.615356\n",
            "Train Epoch: 211 [23040/60000 (38%)]\tLoss: 736.064209\n",
            "Train Epoch: 211 [24320/60000 (41%)]\tLoss: 728.568298\n",
            "Train Epoch: 211 [25600/60000 (43%)]\tLoss: 718.479919\n",
            "Train Epoch: 211 [26880/60000 (45%)]\tLoss: 721.824219\n",
            "Train Epoch: 211 [28160/60000 (47%)]\tLoss: 734.073792\n",
            "Train Epoch: 211 [29440/60000 (49%)]\tLoss: 725.117249\n",
            "Train Epoch: 211 [30720/60000 (51%)]\tLoss: 720.938965\n",
            "Train Epoch: 211 [32000/60000 (53%)]\tLoss: 744.918823\n",
            "Train Epoch: 211 [33280/60000 (55%)]\tLoss: 743.807373\n",
            "Train Epoch: 211 [34560/60000 (58%)]\tLoss: 758.016357\n",
            "Train Epoch: 211 [35840/60000 (60%)]\tLoss: 751.730957\n",
            "Train Epoch: 211 [37120/60000 (62%)]\tLoss: 728.035461\n",
            "Train Epoch: 211 [38400/60000 (64%)]\tLoss: 737.410583\n",
            "Train Epoch: 211 [39680/60000 (66%)]\tLoss: 720.759033\n",
            "Train Epoch: 211 [40960/60000 (68%)]\tLoss: 725.339172\n",
            "Train Epoch: 211 [42240/60000 (70%)]\tLoss: 707.419373\n",
            "Train Epoch: 211 [43520/60000 (72%)]\tLoss: 763.243652\n",
            "Train Epoch: 211 [44800/60000 (75%)]\tLoss: 734.980774\n",
            "Train Epoch: 211 [46080/60000 (77%)]\tLoss: 750.285034\n",
            "Train Epoch: 211 [47360/60000 (79%)]\tLoss: 737.802063\n",
            "Train Epoch: 211 [48640/60000 (81%)]\tLoss: 732.135803\n",
            "Train Epoch: 211 [49920/60000 (83%)]\tLoss: 730.321838\n",
            "Train Epoch: 211 [51200/60000 (85%)]\tLoss: 750.326172\n",
            "Train Epoch: 211 [52480/60000 (87%)]\tLoss: 757.567871\n",
            "Train Epoch: 211 [53760/60000 (90%)]\tLoss: 762.836487\n",
            "Train Epoch: 211 [55040/60000 (92%)]\tLoss: 729.643555\n",
            "Train Epoch: 211 [56320/60000 (94%)]\tLoss: 747.011719\n",
            "Train Epoch: 211 [57600/60000 (96%)]\tLoss: 724.810181\n",
            "Train Epoch: 211 [58880/60000 (98%)]\tLoss: 723.042053\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783271849155426\n",
            "\n",
            "Train Epoch: 212 [0/60000 (0%)]\tLoss: 729.512024\n",
            "Train Epoch: 212 [1280/60000 (2%)]\tLoss: 767.951965\n",
            "Train Epoch: 212 [2560/60000 (4%)]\tLoss: 728.331299\n",
            "Train Epoch: 212 [3840/60000 (6%)]\tLoss: 751.868042\n",
            "Train Epoch: 212 [5120/60000 (9%)]\tLoss: 726.811279\n",
            "Train Epoch: 212 [6400/60000 (11%)]\tLoss: 736.596558\n",
            "Train Epoch: 212 [7680/60000 (13%)]\tLoss: 735.690063\n",
            "Train Epoch: 212 [8960/60000 (15%)]\tLoss: 739.701294\n",
            "Train Epoch: 212 [10240/60000 (17%)]\tLoss: 741.612183\n",
            "Train Epoch: 212 [11520/60000 (19%)]\tLoss: 719.531433\n",
            "Train Epoch: 212 [12800/60000 (21%)]\tLoss: 720.264709\n",
            "Train Epoch: 212 [14080/60000 (23%)]\tLoss: 745.516907\n",
            "Train Epoch: 212 [15360/60000 (26%)]\tLoss: 762.881836\n",
            "Train Epoch: 212 [16640/60000 (28%)]\tLoss: 760.179688\n",
            "Train Epoch: 212 [17920/60000 (30%)]\tLoss: 729.674683\n",
            "Train Epoch: 212 [19200/60000 (32%)]\tLoss: 734.584473\n",
            "Train Epoch: 212 [20480/60000 (34%)]\tLoss: 745.790833\n",
            "Train Epoch: 212 [21760/60000 (36%)]\tLoss: 748.404907\n",
            "Train Epoch: 212 [23040/60000 (38%)]\tLoss: 762.912781\n",
            "Train Epoch: 212 [24320/60000 (41%)]\tLoss: 735.244080\n",
            "Train Epoch: 212 [25600/60000 (43%)]\tLoss: 736.782166\n",
            "Train Epoch: 212 [26880/60000 (45%)]\tLoss: 734.843445\n",
            "Train Epoch: 212 [28160/60000 (47%)]\tLoss: 752.875732\n",
            "Train Epoch: 212 [29440/60000 (49%)]\tLoss: 718.927002\n",
            "Train Epoch: 212 [30720/60000 (51%)]\tLoss: 720.726013\n",
            "Train Epoch: 212 [32000/60000 (53%)]\tLoss: 716.995789\n",
            "Train Epoch: 212 [33280/60000 (55%)]\tLoss: 730.641541\n",
            "Train Epoch: 212 [34560/60000 (58%)]\tLoss: 735.305115\n",
            "Train Epoch: 212 [35840/60000 (60%)]\tLoss: 722.374084\n",
            "Train Epoch: 212 [37120/60000 (62%)]\tLoss: 741.984192\n",
            "Train Epoch: 212 [38400/60000 (64%)]\tLoss: 739.666931\n",
            "Train Epoch: 212 [39680/60000 (66%)]\tLoss: 734.405029\n",
            "Train Epoch: 212 [40960/60000 (68%)]\tLoss: 735.838745\n",
            "Train Epoch: 212 [42240/60000 (70%)]\tLoss: 741.683167\n",
            "Train Epoch: 212 [43520/60000 (72%)]\tLoss: 718.743530\n",
            "Train Epoch: 212 [44800/60000 (75%)]\tLoss: 742.783691\n",
            "Train Epoch: 212 [46080/60000 (77%)]\tLoss: 756.847107\n",
            "Train Epoch: 212 [47360/60000 (79%)]\tLoss: 712.053650\n",
            "Train Epoch: 212 [48640/60000 (81%)]\tLoss: 747.197021\n",
            "Train Epoch: 212 [49920/60000 (83%)]\tLoss: 750.505493\n",
            "Train Epoch: 212 [51200/60000 (85%)]\tLoss: 737.409790\n",
            "Train Epoch: 212 [52480/60000 (87%)]\tLoss: 726.838501\n",
            "Train Epoch: 212 [53760/60000 (90%)]\tLoss: 770.724609\n",
            "Train Epoch: 212 [55040/60000 (92%)]\tLoss: 727.216370\n",
            "Train Epoch: 212 [56320/60000 (94%)]\tLoss: 761.025696\n",
            "Train Epoch: 212 [57600/60000 (96%)]\tLoss: 739.699585\n",
            "Train Epoch: 212 [58880/60000 (98%)]\tLoss: 728.677551\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782021641731262\n",
            "\n",
            "Train Epoch: 213 [0/60000 (0%)]\tLoss: 759.617432\n",
            "Train Epoch: 213 [1280/60000 (2%)]\tLoss: 737.753357\n",
            "Train Epoch: 213 [2560/60000 (4%)]\tLoss: 706.154541\n",
            "Train Epoch: 213 [3840/60000 (6%)]\tLoss: 727.526062\n",
            "Train Epoch: 213 [5120/60000 (9%)]\tLoss: 741.288086\n",
            "Train Epoch: 213 [6400/60000 (11%)]\tLoss: 738.529785\n",
            "Train Epoch: 213 [7680/60000 (13%)]\tLoss: 748.727051\n",
            "Train Epoch: 213 [8960/60000 (15%)]\tLoss: 732.845459\n",
            "Train Epoch: 213 [10240/60000 (17%)]\tLoss: 741.768677\n",
            "Train Epoch: 213 [11520/60000 (19%)]\tLoss: 731.848999\n",
            "Train Epoch: 213 [12800/60000 (21%)]\tLoss: 738.647461\n",
            "Train Epoch: 213 [14080/60000 (23%)]\tLoss: 724.643738\n",
            "Train Epoch: 213 [15360/60000 (26%)]\tLoss: 732.045654\n",
            "Train Epoch: 213 [16640/60000 (28%)]\tLoss: 722.582703\n",
            "Train Epoch: 213 [17920/60000 (30%)]\tLoss: 757.598999\n",
            "Train Epoch: 213 [19200/60000 (32%)]\tLoss: 740.767456\n",
            "Train Epoch: 213 [20480/60000 (34%)]\tLoss: 722.443787\n",
            "Train Epoch: 213 [21760/60000 (36%)]\tLoss: 705.967041\n",
            "Train Epoch: 213 [23040/60000 (38%)]\tLoss: 746.642944\n",
            "Train Epoch: 213 [24320/60000 (41%)]\tLoss: 756.858704\n",
            "Train Epoch: 213 [25600/60000 (43%)]\tLoss: 730.759277\n",
            "Train Epoch: 213 [26880/60000 (45%)]\tLoss: 725.621887\n",
            "Train Epoch: 213 [28160/60000 (47%)]\tLoss: 742.257690\n",
            "Train Epoch: 213 [29440/60000 (49%)]\tLoss: 727.864563\n",
            "Train Epoch: 213 [30720/60000 (51%)]\tLoss: 740.290039\n",
            "Train Epoch: 213 [32000/60000 (53%)]\tLoss: 774.232666\n",
            "Train Epoch: 213 [33280/60000 (55%)]\tLoss: 735.782532\n",
            "Train Epoch: 213 [34560/60000 (58%)]\tLoss: 740.481812\n",
            "Train Epoch: 213 [35840/60000 (60%)]\tLoss: 722.225220\n",
            "Train Epoch: 213 [37120/60000 (62%)]\tLoss: 731.648743\n",
            "Train Epoch: 213 [38400/60000 (64%)]\tLoss: 749.923645\n",
            "Train Epoch: 213 [39680/60000 (66%)]\tLoss: 714.325439\n",
            "Train Epoch: 213 [40960/60000 (68%)]\tLoss: 699.823853\n",
            "Train Epoch: 213 [42240/60000 (70%)]\tLoss: 759.454651\n",
            "Train Epoch: 213 [43520/60000 (72%)]\tLoss: 711.890930\n",
            "Train Epoch: 213 [44800/60000 (75%)]\tLoss: 735.370239\n",
            "Train Epoch: 213 [46080/60000 (77%)]\tLoss: 742.401733\n",
            "Train Epoch: 213 [47360/60000 (79%)]\tLoss: 712.326965\n",
            "Train Epoch: 213 [48640/60000 (81%)]\tLoss: 741.639771\n",
            "Train Epoch: 213 [49920/60000 (83%)]\tLoss: 722.319702\n",
            "Train Epoch: 213 [51200/60000 (85%)]\tLoss: 719.658325\n",
            "Train Epoch: 213 [52480/60000 (87%)]\tLoss: 717.234863\n",
            "Train Epoch: 213 [53760/60000 (90%)]\tLoss: 745.446350\n",
            "Train Epoch: 213 [55040/60000 (92%)]\tLoss: 710.199707\n",
            "Train Epoch: 213 [56320/60000 (94%)]\tLoss: 740.480225\n",
            "Train Epoch: 213 [57600/60000 (96%)]\tLoss: 731.640137\n",
            "Train Epoch: 213 [58880/60000 (98%)]\tLoss: 735.815186\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978408247232437\n",
            "\n",
            "Train Epoch: 214 [0/60000 (0%)]\tLoss: 731.569763\n",
            "Train Epoch: 214 [1280/60000 (2%)]\tLoss: 740.020386\n",
            "Train Epoch: 214 [2560/60000 (4%)]\tLoss: 727.937866\n",
            "Train Epoch: 214 [3840/60000 (6%)]\tLoss: 749.958313\n",
            "Train Epoch: 214 [5120/60000 (9%)]\tLoss: 718.814453\n",
            "Train Epoch: 214 [6400/60000 (11%)]\tLoss: 741.260681\n",
            "Train Epoch: 214 [7680/60000 (13%)]\tLoss: 694.121216\n",
            "Train Epoch: 214 [8960/60000 (15%)]\tLoss: 743.909668\n",
            "Train Epoch: 214 [10240/60000 (17%)]\tLoss: 741.240356\n",
            "Train Epoch: 214 [11520/60000 (19%)]\tLoss: 707.374207\n",
            "Train Epoch: 214 [12800/60000 (21%)]\tLoss: 746.269836\n",
            "Train Epoch: 214 [14080/60000 (23%)]\tLoss: 768.102722\n",
            "Train Epoch: 214 [15360/60000 (26%)]\tLoss: 744.557251\n",
            "Train Epoch: 214 [16640/60000 (28%)]\tLoss: 717.814941\n",
            "Train Epoch: 214 [17920/60000 (30%)]\tLoss: 738.854797\n",
            "Train Epoch: 214 [19200/60000 (32%)]\tLoss: 735.204712\n",
            "Train Epoch: 214 [20480/60000 (34%)]\tLoss: 746.646667\n",
            "Train Epoch: 214 [21760/60000 (36%)]\tLoss: 710.272583\n",
            "Train Epoch: 214 [23040/60000 (38%)]\tLoss: 734.289368\n",
            "Train Epoch: 214 [24320/60000 (41%)]\tLoss: 730.489258\n",
            "Train Epoch: 214 [25600/60000 (43%)]\tLoss: 753.307617\n",
            "Train Epoch: 214 [26880/60000 (45%)]\tLoss: 724.530334\n",
            "Train Epoch: 214 [28160/60000 (47%)]\tLoss: 714.381470\n",
            "Train Epoch: 214 [29440/60000 (49%)]\tLoss: 726.911926\n",
            "Train Epoch: 214 [30720/60000 (51%)]\tLoss: 717.694519\n",
            "Train Epoch: 214 [32000/60000 (53%)]\tLoss: 747.680176\n",
            "Train Epoch: 214 [33280/60000 (55%)]\tLoss: 747.921814\n",
            "Train Epoch: 214 [34560/60000 (58%)]\tLoss: 747.321777\n",
            "Train Epoch: 214 [35840/60000 (60%)]\tLoss: 760.203979\n",
            "Train Epoch: 214 [37120/60000 (62%)]\tLoss: 748.981995\n",
            "Train Epoch: 214 [38400/60000 (64%)]\tLoss: 733.756348\n",
            "Train Epoch: 214 [39680/60000 (66%)]\tLoss: 702.471863\n",
            "Train Epoch: 214 [40960/60000 (68%)]\tLoss: 749.127319\n",
            "Train Epoch: 214 [42240/60000 (70%)]\tLoss: 725.254578\n",
            "Train Epoch: 214 [43520/60000 (72%)]\tLoss: 711.182617\n",
            "Train Epoch: 214 [44800/60000 (75%)]\tLoss: 733.268250\n",
            "Train Epoch: 214 [46080/60000 (77%)]\tLoss: 720.560120\n",
            "Train Epoch: 214 [47360/60000 (79%)]\tLoss: 726.768066\n",
            "Train Epoch: 214 [48640/60000 (81%)]\tLoss: 747.740356\n",
            "Train Epoch: 214 [49920/60000 (83%)]\tLoss: 758.905273\n",
            "Train Epoch: 214 [51200/60000 (85%)]\tLoss: 755.316406\n",
            "Train Epoch: 214 [52480/60000 (87%)]\tLoss: 726.939270\n",
            "Train Epoch: 214 [53760/60000 (90%)]\tLoss: 707.732910\n",
            "Train Epoch: 214 [55040/60000 (92%)]\tLoss: 722.724670\n",
            "Train Epoch: 214 [56320/60000 (94%)]\tLoss: 753.082825\n",
            "Train Epoch: 214 [57600/60000 (96%)]\tLoss: 731.473206\n",
            "Train Epoch: 214 [58880/60000 (98%)]\tLoss: 735.142151\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785968959331512\n",
            "\n",
            "Train Epoch: 215 [0/60000 (0%)]\tLoss: 715.453369\n",
            "Train Epoch: 215 [1280/60000 (2%)]\tLoss: 750.524292\n",
            "Train Epoch: 215 [2560/60000 (4%)]\tLoss: 721.065430\n",
            "Train Epoch: 215 [3840/60000 (6%)]\tLoss: 718.577454\n",
            "Train Epoch: 215 [5120/60000 (9%)]\tLoss: 763.206360\n",
            "Train Epoch: 215 [6400/60000 (11%)]\tLoss: 726.194519\n",
            "Train Epoch: 215 [7680/60000 (13%)]\tLoss: 730.862183\n",
            "Train Epoch: 215 [8960/60000 (15%)]\tLoss: 743.962219\n",
            "Train Epoch: 215 [10240/60000 (17%)]\tLoss: 753.695679\n",
            "Train Epoch: 215 [11520/60000 (19%)]\tLoss: 749.263245\n",
            "Train Epoch: 215 [12800/60000 (21%)]\tLoss: 728.130432\n",
            "Train Epoch: 215 [14080/60000 (23%)]\tLoss: 745.785217\n",
            "Train Epoch: 215 [15360/60000 (26%)]\tLoss: 736.144775\n",
            "Train Epoch: 215 [16640/60000 (28%)]\tLoss: 724.543213\n",
            "Train Epoch: 215 [17920/60000 (30%)]\tLoss: 720.497253\n",
            "Train Epoch: 215 [19200/60000 (32%)]\tLoss: 747.825256\n",
            "Train Epoch: 215 [20480/60000 (34%)]\tLoss: 751.899780\n",
            "Train Epoch: 215 [21760/60000 (36%)]\tLoss: 742.902527\n",
            "Train Epoch: 215 [23040/60000 (38%)]\tLoss: 704.631287\n",
            "Train Epoch: 215 [24320/60000 (41%)]\tLoss: 729.366394\n",
            "Train Epoch: 215 [25600/60000 (43%)]\tLoss: 731.226257\n",
            "Train Epoch: 215 [26880/60000 (45%)]\tLoss: 742.396240\n",
            "Train Epoch: 215 [28160/60000 (47%)]\tLoss: 736.772461\n",
            "Train Epoch: 215 [29440/60000 (49%)]\tLoss: 716.716370\n",
            "Train Epoch: 215 [30720/60000 (51%)]\tLoss: 733.528381\n",
            "Train Epoch: 215 [32000/60000 (53%)]\tLoss: 742.553650\n",
            "Train Epoch: 215 [33280/60000 (55%)]\tLoss: 734.225403\n",
            "Train Epoch: 215 [34560/60000 (58%)]\tLoss: 727.797119\n",
            "Train Epoch: 215 [35840/60000 (60%)]\tLoss: 717.831726\n",
            "Train Epoch: 215 [37120/60000 (62%)]\tLoss: 735.837341\n",
            "Train Epoch: 215 [38400/60000 (64%)]\tLoss: 730.592041\n",
            "Train Epoch: 215 [39680/60000 (66%)]\tLoss: 736.932983\n",
            "Train Epoch: 215 [40960/60000 (68%)]\tLoss: 745.580688\n",
            "Train Epoch: 215 [42240/60000 (70%)]\tLoss: 756.630554\n",
            "Train Epoch: 215 [43520/60000 (72%)]\tLoss: 764.811157\n",
            "Train Epoch: 215 [44800/60000 (75%)]\tLoss: 732.392944\n",
            "Train Epoch: 215 [46080/60000 (77%)]\tLoss: 718.407837\n",
            "Train Epoch: 215 [47360/60000 (79%)]\tLoss: 747.899719\n",
            "Train Epoch: 215 [48640/60000 (81%)]\tLoss: 746.805054\n",
            "Train Epoch: 215 [49920/60000 (83%)]\tLoss: 761.435852\n",
            "Train Epoch: 215 [51200/60000 (85%)]\tLoss: 751.384827\n",
            "Train Epoch: 215 [52480/60000 (87%)]\tLoss: 732.368225\n",
            "Train Epoch: 215 [53760/60000 (90%)]\tLoss: 711.709900\n",
            "Train Epoch: 215 [55040/60000 (92%)]\tLoss: 733.010498\n",
            "Train Epoch: 215 [56320/60000 (94%)]\tLoss: 744.285889\n",
            "Train Epoch: 215 [57600/60000 (96%)]\tLoss: 723.157288\n",
            "Train Epoch: 215 [58880/60000 (98%)]\tLoss: 743.590637\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782710075378418\n",
            "\n",
            "Train Epoch: 216 [0/60000 (0%)]\tLoss: 726.912170\n",
            "Train Epoch: 216 [1280/60000 (2%)]\tLoss: 728.053955\n",
            "Train Epoch: 216 [2560/60000 (4%)]\tLoss: 728.788269\n",
            "Train Epoch: 216 [3840/60000 (6%)]\tLoss: 721.162231\n",
            "Train Epoch: 216 [5120/60000 (9%)]\tLoss: 775.028748\n",
            "Train Epoch: 216 [6400/60000 (11%)]\tLoss: 733.058472\n",
            "Train Epoch: 216 [7680/60000 (13%)]\tLoss: 725.367126\n",
            "Train Epoch: 216 [8960/60000 (15%)]\tLoss: 741.755249\n",
            "Train Epoch: 216 [10240/60000 (17%)]\tLoss: 734.516602\n",
            "Train Epoch: 216 [11520/60000 (19%)]\tLoss: 735.537598\n",
            "Train Epoch: 216 [12800/60000 (21%)]\tLoss: 739.919556\n",
            "Train Epoch: 216 [14080/60000 (23%)]\tLoss: 743.680115\n",
            "Train Epoch: 216 [15360/60000 (26%)]\tLoss: 733.729492\n",
            "Train Epoch: 216 [16640/60000 (28%)]\tLoss: 734.306152\n",
            "Train Epoch: 216 [17920/60000 (30%)]\tLoss: 732.334290\n",
            "Train Epoch: 216 [19200/60000 (32%)]\tLoss: 751.136658\n",
            "Train Epoch: 216 [20480/60000 (34%)]\tLoss: 733.434937\n",
            "Train Epoch: 216 [21760/60000 (36%)]\tLoss: 748.736572\n",
            "Train Epoch: 216 [23040/60000 (38%)]\tLoss: 744.049194\n",
            "Train Epoch: 216 [24320/60000 (41%)]\tLoss: 738.558533\n",
            "Train Epoch: 216 [25600/60000 (43%)]\tLoss: 744.948120\n",
            "Train Epoch: 216 [26880/60000 (45%)]\tLoss: 747.105591\n",
            "Train Epoch: 216 [28160/60000 (47%)]\tLoss: 731.122253\n",
            "Train Epoch: 216 [29440/60000 (49%)]\tLoss: 750.425171\n",
            "Train Epoch: 216 [30720/60000 (51%)]\tLoss: 746.972900\n",
            "Train Epoch: 216 [32000/60000 (53%)]\tLoss: 722.004150\n",
            "Train Epoch: 216 [33280/60000 (55%)]\tLoss: 730.424744\n",
            "Train Epoch: 216 [34560/60000 (58%)]\tLoss: 722.237488\n",
            "Train Epoch: 216 [35840/60000 (60%)]\tLoss: 723.788330\n",
            "Train Epoch: 216 [37120/60000 (62%)]\tLoss: 753.519836\n",
            "Train Epoch: 216 [38400/60000 (64%)]\tLoss: 714.201355\n",
            "Train Epoch: 216 [39680/60000 (66%)]\tLoss: 735.417297\n",
            "Train Epoch: 216 [40960/60000 (68%)]\tLoss: 747.862061\n",
            "Train Epoch: 216 [42240/60000 (70%)]\tLoss: 736.840271\n",
            "Train Epoch: 216 [43520/60000 (72%)]\tLoss: 720.822144\n",
            "Train Epoch: 216 [44800/60000 (75%)]\tLoss: 733.387268\n",
            "Train Epoch: 216 [46080/60000 (77%)]\tLoss: 736.330322\n",
            "Train Epoch: 216 [47360/60000 (79%)]\tLoss: 726.060242\n",
            "Train Epoch: 216 [48640/60000 (81%)]\tLoss: 746.409607\n",
            "Train Epoch: 216 [49920/60000 (83%)]\tLoss: 748.932312\n",
            "Train Epoch: 216 [51200/60000 (85%)]\tLoss: 747.377197\n",
            "Train Epoch: 216 [52480/60000 (87%)]\tLoss: 731.803345\n",
            "Train Epoch: 216 [53760/60000 (90%)]\tLoss: 743.479736\n",
            "Train Epoch: 216 [55040/60000 (92%)]\tLoss: 747.064209\n",
            "Train Epoch: 216 [56320/60000 (94%)]\tLoss: 726.760193\n",
            "Train Epoch: 216 [57600/60000 (96%)]\tLoss: 732.883789\n",
            "Train Epoch: 216 [58880/60000 (98%)]\tLoss: 709.325256\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978640854358673\n",
            "\n",
            "Train Epoch: 217 [0/60000 (0%)]\tLoss: 729.696472\n",
            "Train Epoch: 217 [1280/60000 (2%)]\tLoss: 739.513123\n",
            "Train Epoch: 217 [2560/60000 (4%)]\tLoss: 739.828003\n",
            "Train Epoch: 217 [3840/60000 (6%)]\tLoss: 752.057678\n",
            "Train Epoch: 217 [5120/60000 (9%)]\tLoss: 726.270325\n",
            "Train Epoch: 217 [6400/60000 (11%)]\tLoss: 744.111389\n",
            "Train Epoch: 217 [7680/60000 (13%)]\tLoss: 734.009155\n",
            "Train Epoch: 217 [8960/60000 (15%)]\tLoss: 758.511597\n",
            "Train Epoch: 217 [10240/60000 (17%)]\tLoss: 764.720764\n",
            "Train Epoch: 217 [11520/60000 (19%)]\tLoss: 740.326233\n",
            "Train Epoch: 217 [12800/60000 (21%)]\tLoss: 726.102661\n",
            "Train Epoch: 217 [14080/60000 (23%)]\tLoss: 756.712830\n",
            "Train Epoch: 217 [15360/60000 (26%)]\tLoss: 725.009644\n",
            "Train Epoch: 217 [16640/60000 (28%)]\tLoss: 730.492371\n",
            "Train Epoch: 217 [17920/60000 (30%)]\tLoss: 743.400330\n",
            "Train Epoch: 217 [19200/60000 (32%)]\tLoss: 713.498352\n",
            "Train Epoch: 217 [20480/60000 (34%)]\tLoss: 717.753479\n",
            "Train Epoch: 217 [21760/60000 (36%)]\tLoss: 725.013611\n",
            "Train Epoch: 217 [23040/60000 (38%)]\tLoss: 726.766846\n",
            "Train Epoch: 217 [24320/60000 (41%)]\tLoss: 760.911316\n",
            "Train Epoch: 217 [25600/60000 (43%)]\tLoss: 736.276306\n",
            "Train Epoch: 217 [26880/60000 (45%)]\tLoss: 750.455200\n",
            "Train Epoch: 217 [28160/60000 (47%)]\tLoss: 747.804871\n",
            "Train Epoch: 217 [29440/60000 (49%)]\tLoss: 736.116211\n",
            "Train Epoch: 217 [30720/60000 (51%)]\tLoss: 719.440063\n",
            "Train Epoch: 217 [32000/60000 (53%)]\tLoss: 749.469299\n",
            "Train Epoch: 217 [33280/60000 (55%)]\tLoss: 740.702820\n",
            "Train Epoch: 217 [34560/60000 (58%)]\tLoss: 721.253479\n",
            "Train Epoch: 217 [35840/60000 (60%)]\tLoss: 739.007263\n",
            "Train Epoch: 217 [37120/60000 (62%)]\tLoss: 740.612305\n",
            "Train Epoch: 217 [38400/60000 (64%)]\tLoss: 720.862915\n",
            "Train Epoch: 217 [39680/60000 (66%)]\tLoss: 714.400513\n",
            "Train Epoch: 217 [40960/60000 (68%)]\tLoss: 739.744385\n",
            "Train Epoch: 217 [42240/60000 (70%)]\tLoss: 704.538025\n",
            "Train Epoch: 217 [43520/60000 (72%)]\tLoss: 745.592407\n",
            "Train Epoch: 217 [44800/60000 (75%)]\tLoss: 743.843506\n",
            "Train Epoch: 217 [46080/60000 (77%)]\tLoss: 733.740479\n",
            "Train Epoch: 217 [47360/60000 (79%)]\tLoss: 748.700256\n",
            "Train Epoch: 217 [48640/60000 (81%)]\tLoss: 730.666565\n",
            "Train Epoch: 217 [49920/60000 (83%)]\tLoss: 747.116699\n",
            "Train Epoch: 217 [51200/60000 (85%)]\tLoss: 739.973999\n",
            "Train Epoch: 217 [52480/60000 (87%)]\tLoss: 750.843323\n",
            "Train Epoch: 217 [53760/60000 (90%)]\tLoss: 744.764709\n",
            "Train Epoch: 217 [55040/60000 (92%)]\tLoss: 774.213989\n",
            "Train Epoch: 217 [56320/60000 (94%)]\tLoss: 713.089294\n",
            "Train Epoch: 217 [57600/60000 (96%)]\tLoss: 771.136780\n",
            "Train Epoch: 217 [58880/60000 (98%)]\tLoss: 719.326111\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978262960910797\n",
            "\n",
            "Train Epoch: 218 [0/60000 (0%)]\tLoss: 726.064514\n",
            "Train Epoch: 218 [1280/60000 (2%)]\tLoss: 735.777039\n",
            "Train Epoch: 218 [2560/60000 (4%)]\tLoss: 736.170654\n",
            "Train Epoch: 218 [3840/60000 (6%)]\tLoss: 733.216980\n",
            "Train Epoch: 218 [5120/60000 (9%)]\tLoss: 736.411743\n",
            "Train Epoch: 218 [6400/60000 (11%)]\tLoss: 767.337524\n",
            "Train Epoch: 218 [7680/60000 (13%)]\tLoss: 741.525879\n",
            "Train Epoch: 218 [8960/60000 (15%)]\tLoss: 727.016724\n",
            "Train Epoch: 218 [10240/60000 (17%)]\tLoss: 721.982422\n",
            "Train Epoch: 218 [11520/60000 (19%)]\tLoss: 746.057617\n",
            "Train Epoch: 218 [12800/60000 (21%)]\tLoss: 736.793030\n",
            "Train Epoch: 218 [14080/60000 (23%)]\tLoss: 754.624634\n",
            "Train Epoch: 218 [15360/60000 (26%)]\tLoss: 734.052734\n",
            "Train Epoch: 218 [16640/60000 (28%)]\tLoss: 733.628662\n",
            "Train Epoch: 218 [17920/60000 (30%)]\tLoss: 734.656067\n",
            "Train Epoch: 218 [19200/60000 (32%)]\tLoss: 723.176575\n",
            "Train Epoch: 218 [20480/60000 (34%)]\tLoss: 728.892822\n",
            "Train Epoch: 218 [21760/60000 (36%)]\tLoss: 730.330139\n",
            "Train Epoch: 218 [23040/60000 (38%)]\tLoss: 729.235046\n",
            "Train Epoch: 218 [24320/60000 (41%)]\tLoss: 709.214233\n",
            "Train Epoch: 218 [25600/60000 (43%)]\tLoss: 761.940796\n",
            "Train Epoch: 218 [26880/60000 (45%)]\tLoss: 714.285706\n",
            "Train Epoch: 218 [28160/60000 (47%)]\tLoss: 750.986694\n",
            "Train Epoch: 218 [29440/60000 (49%)]\tLoss: 736.045227\n",
            "Train Epoch: 218 [30720/60000 (51%)]\tLoss: 734.108276\n",
            "Train Epoch: 218 [32000/60000 (53%)]\tLoss: 711.800842\n",
            "Train Epoch: 218 [33280/60000 (55%)]\tLoss: 759.346252\n",
            "Train Epoch: 218 [34560/60000 (58%)]\tLoss: 729.994019\n",
            "Train Epoch: 218 [35840/60000 (60%)]\tLoss: 736.166199\n",
            "Train Epoch: 218 [37120/60000 (62%)]\tLoss: 724.139587\n",
            "Train Epoch: 218 [38400/60000 (64%)]\tLoss: 726.605835\n",
            "Train Epoch: 218 [39680/60000 (66%)]\tLoss: 733.903381\n",
            "Train Epoch: 218 [40960/60000 (68%)]\tLoss: 710.749512\n",
            "Train Epoch: 218 [42240/60000 (70%)]\tLoss: 723.059875\n",
            "Train Epoch: 218 [43520/60000 (72%)]\tLoss: 735.972595\n",
            "Train Epoch: 218 [44800/60000 (75%)]\tLoss: 741.498108\n",
            "Train Epoch: 218 [46080/60000 (77%)]\tLoss: 745.993530\n",
            "Train Epoch: 218 [47360/60000 (79%)]\tLoss: 743.471741\n",
            "Train Epoch: 218 [48640/60000 (81%)]\tLoss: 718.715454\n",
            "Train Epoch: 218 [49920/60000 (83%)]\tLoss: 747.914551\n",
            "Train Epoch: 218 [51200/60000 (85%)]\tLoss: 726.798706\n",
            "Train Epoch: 218 [52480/60000 (87%)]\tLoss: 735.744934\n",
            "Train Epoch: 218 [53760/60000 (90%)]\tLoss: 734.656250\n",
            "Train Epoch: 218 [55040/60000 (92%)]\tLoss: 750.947266\n",
            "Train Epoch: 218 [56320/60000 (94%)]\tLoss: 723.895020\n",
            "Train Epoch: 218 [57600/60000 (96%)]\tLoss: 745.760254\n",
            "Train Epoch: 218 [58880/60000 (98%)]\tLoss: 721.916992\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781842827796936\n",
            "\n",
            "Train Epoch: 219 [0/60000 (0%)]\tLoss: 750.722778\n",
            "Train Epoch: 219 [1280/60000 (2%)]\tLoss: 743.987976\n",
            "Train Epoch: 219 [2560/60000 (4%)]\tLoss: 751.823669\n",
            "Train Epoch: 219 [3840/60000 (6%)]\tLoss: 736.540405\n",
            "Train Epoch: 219 [5120/60000 (9%)]\tLoss: 735.960632\n",
            "Train Epoch: 219 [6400/60000 (11%)]\tLoss: 737.150452\n",
            "Train Epoch: 219 [7680/60000 (13%)]\tLoss: 729.862000\n",
            "Train Epoch: 219 [8960/60000 (15%)]\tLoss: 743.320068\n",
            "Train Epoch: 219 [10240/60000 (17%)]\tLoss: 730.143311\n",
            "Train Epoch: 219 [11520/60000 (19%)]\tLoss: 745.912476\n",
            "Train Epoch: 219 [12800/60000 (21%)]\tLoss: 739.734253\n",
            "Train Epoch: 219 [14080/60000 (23%)]\tLoss: 750.937866\n",
            "Train Epoch: 219 [15360/60000 (26%)]\tLoss: 737.079773\n",
            "Train Epoch: 219 [16640/60000 (28%)]\tLoss: 748.561096\n",
            "Train Epoch: 219 [17920/60000 (30%)]\tLoss: 721.310120\n",
            "Train Epoch: 219 [19200/60000 (32%)]\tLoss: 731.866211\n",
            "Train Epoch: 219 [20480/60000 (34%)]\tLoss: 724.732910\n",
            "Train Epoch: 219 [21760/60000 (36%)]\tLoss: 737.778381\n",
            "Train Epoch: 219 [23040/60000 (38%)]\tLoss: 717.160034\n",
            "Train Epoch: 219 [24320/60000 (41%)]\tLoss: 742.675903\n",
            "Train Epoch: 219 [25600/60000 (43%)]\tLoss: 761.349548\n",
            "Train Epoch: 219 [26880/60000 (45%)]\tLoss: 728.518677\n",
            "Train Epoch: 219 [28160/60000 (47%)]\tLoss: 740.976440\n",
            "Train Epoch: 219 [29440/60000 (49%)]\tLoss: 734.184509\n",
            "Train Epoch: 219 [30720/60000 (51%)]\tLoss: 746.828491\n",
            "Train Epoch: 219 [32000/60000 (53%)]\tLoss: 738.388245\n",
            "Train Epoch: 219 [33280/60000 (55%)]\tLoss: 716.901001\n",
            "Train Epoch: 219 [34560/60000 (58%)]\tLoss: 725.930847\n",
            "Train Epoch: 219 [35840/60000 (60%)]\tLoss: 775.585327\n",
            "Train Epoch: 219 [37120/60000 (62%)]\tLoss: 747.518311\n",
            "Train Epoch: 219 [38400/60000 (64%)]\tLoss: 744.350769\n",
            "Train Epoch: 219 [39680/60000 (66%)]\tLoss: 744.179382\n",
            "Train Epoch: 219 [40960/60000 (68%)]\tLoss: 763.826660\n",
            "Train Epoch: 219 [42240/60000 (70%)]\tLoss: 751.362793\n",
            "Train Epoch: 219 [43520/60000 (72%)]\tLoss: 759.423462\n",
            "Train Epoch: 219 [44800/60000 (75%)]\tLoss: 747.993347\n",
            "Train Epoch: 219 [46080/60000 (77%)]\tLoss: 738.989563\n",
            "Train Epoch: 219 [47360/60000 (79%)]\tLoss: 744.475037\n",
            "Train Epoch: 219 [48640/60000 (81%)]\tLoss: 749.736206\n",
            "Train Epoch: 219 [49920/60000 (83%)]\tLoss: 726.115784\n",
            "Train Epoch: 219 [51200/60000 (85%)]\tLoss: 726.369873\n",
            "Train Epoch: 219 [52480/60000 (87%)]\tLoss: 733.214966\n",
            "Train Epoch: 219 [53760/60000 (90%)]\tLoss: 757.651001\n",
            "Train Epoch: 219 [55040/60000 (92%)]\tLoss: 750.065613\n",
            "Train Epoch: 219 [56320/60000 (94%)]\tLoss: 710.815063\n",
            "Train Epoch: 219 [57600/60000 (96%)]\tLoss: 724.957397\n",
            "Train Epoch: 219 [58880/60000 (98%)]\tLoss: 730.587524\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787971675395966\n",
            "\n",
            "Train Epoch: 220 [0/60000 (0%)]\tLoss: 745.435608\n",
            "Train Epoch: 220 [1280/60000 (2%)]\tLoss: 698.247314\n",
            "Train Epoch: 220 [2560/60000 (4%)]\tLoss: 732.671631\n",
            "Train Epoch: 220 [3840/60000 (6%)]\tLoss: 752.430237\n",
            "Train Epoch: 220 [5120/60000 (9%)]\tLoss: 744.320129\n",
            "Train Epoch: 220 [6400/60000 (11%)]\tLoss: 736.514832\n",
            "Train Epoch: 220 [7680/60000 (13%)]\tLoss: 726.416504\n",
            "Train Epoch: 220 [8960/60000 (15%)]\tLoss: 742.215332\n",
            "Train Epoch: 220 [10240/60000 (17%)]\tLoss: 755.146606\n",
            "Train Epoch: 220 [11520/60000 (19%)]\tLoss: 724.129700\n",
            "Train Epoch: 220 [12800/60000 (21%)]\tLoss: 722.799683\n",
            "Train Epoch: 220 [14080/60000 (23%)]\tLoss: 753.862427\n",
            "Train Epoch: 220 [15360/60000 (26%)]\tLoss: 738.773621\n",
            "Train Epoch: 220 [16640/60000 (28%)]\tLoss: 729.999817\n",
            "Train Epoch: 220 [17920/60000 (30%)]\tLoss: 741.170715\n",
            "Train Epoch: 220 [19200/60000 (32%)]\tLoss: 736.844666\n",
            "Train Epoch: 220 [20480/60000 (34%)]\tLoss: 719.926025\n",
            "Train Epoch: 220 [21760/60000 (36%)]\tLoss: 749.267029\n",
            "Train Epoch: 220 [23040/60000 (38%)]\tLoss: 725.869690\n",
            "Train Epoch: 220 [24320/60000 (41%)]\tLoss: 741.073608\n",
            "Train Epoch: 220 [25600/60000 (43%)]\tLoss: 738.215088\n",
            "Train Epoch: 220 [26880/60000 (45%)]\tLoss: 729.200012\n",
            "Train Epoch: 220 [28160/60000 (47%)]\tLoss: 753.477539\n",
            "Train Epoch: 220 [29440/60000 (49%)]\tLoss: 722.831726\n",
            "Train Epoch: 220 [30720/60000 (51%)]\tLoss: 755.666504\n",
            "Train Epoch: 220 [32000/60000 (53%)]\tLoss: 738.831177\n",
            "Train Epoch: 220 [33280/60000 (55%)]\tLoss: 748.622070\n",
            "Train Epoch: 220 [34560/60000 (58%)]\tLoss: 741.844727\n",
            "Train Epoch: 220 [35840/60000 (60%)]\tLoss: 735.561890\n",
            "Train Epoch: 220 [37120/60000 (62%)]\tLoss: 715.166199\n",
            "Train Epoch: 220 [38400/60000 (64%)]\tLoss: 753.807190\n",
            "Train Epoch: 220 [39680/60000 (66%)]\tLoss: 735.169922\n",
            "Train Epoch: 220 [40960/60000 (68%)]\tLoss: 732.113525\n",
            "Train Epoch: 220 [42240/60000 (70%)]\tLoss: 731.599487\n",
            "Train Epoch: 220 [43520/60000 (72%)]\tLoss: 761.788574\n",
            "Train Epoch: 220 [44800/60000 (75%)]\tLoss: 735.403625\n",
            "Train Epoch: 220 [46080/60000 (77%)]\tLoss: 747.547974\n",
            "Train Epoch: 220 [47360/60000 (79%)]\tLoss: 714.335022\n",
            "Train Epoch: 220 [48640/60000 (81%)]\tLoss: 744.594788\n",
            "Train Epoch: 220 [49920/60000 (83%)]\tLoss: 751.062195\n",
            "Train Epoch: 220 [51200/60000 (85%)]\tLoss: 714.558289\n",
            "Train Epoch: 220 [52480/60000 (87%)]\tLoss: 737.263794\n",
            "Train Epoch: 220 [53760/60000 (90%)]\tLoss: 735.463074\n",
            "Train Epoch: 220 [55040/60000 (92%)]\tLoss: 741.480835\n",
            "Train Epoch: 220 [56320/60000 (94%)]\tLoss: 736.757874\n",
            "Train Epoch: 220 [57600/60000 (96%)]\tLoss: 736.655212\n",
            "Train Epoch: 220 [58880/60000 (98%)]\tLoss: 747.099060\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783680140972137\n",
            "\n",
            "Train Epoch: 221 [0/60000 (0%)]\tLoss: 754.127197\n",
            "Train Epoch: 221 [1280/60000 (2%)]\tLoss: 749.155640\n",
            "Train Epoch: 221 [2560/60000 (4%)]\tLoss: 737.393555\n",
            "Train Epoch: 221 [3840/60000 (6%)]\tLoss: 748.799072\n",
            "Train Epoch: 221 [5120/60000 (9%)]\tLoss: 743.160339\n",
            "Train Epoch: 221 [6400/60000 (11%)]\tLoss: 745.256287\n",
            "Train Epoch: 221 [7680/60000 (13%)]\tLoss: 738.997559\n",
            "Train Epoch: 221 [8960/60000 (15%)]\tLoss: 719.895691\n",
            "Train Epoch: 221 [10240/60000 (17%)]\tLoss: 742.676392\n",
            "Train Epoch: 221 [11520/60000 (19%)]\tLoss: 741.400452\n",
            "Train Epoch: 221 [12800/60000 (21%)]\tLoss: 753.799805\n",
            "Train Epoch: 221 [14080/60000 (23%)]\tLoss: 739.478455\n",
            "Train Epoch: 221 [15360/60000 (26%)]\tLoss: 730.133240\n",
            "Train Epoch: 221 [16640/60000 (28%)]\tLoss: 749.189941\n",
            "Train Epoch: 221 [17920/60000 (30%)]\tLoss: 726.729553\n",
            "Train Epoch: 221 [19200/60000 (32%)]\tLoss: 712.118835\n",
            "Train Epoch: 221 [20480/60000 (34%)]\tLoss: 734.960205\n",
            "Train Epoch: 221 [21760/60000 (36%)]\tLoss: 723.745239\n",
            "Train Epoch: 221 [23040/60000 (38%)]\tLoss: 731.382996\n",
            "Train Epoch: 221 [24320/60000 (41%)]\tLoss: 709.542908\n",
            "Train Epoch: 221 [25600/60000 (43%)]\tLoss: 743.621277\n",
            "Train Epoch: 221 [26880/60000 (45%)]\tLoss: 740.134155\n",
            "Train Epoch: 221 [28160/60000 (47%)]\tLoss: 712.303955\n",
            "Train Epoch: 221 [29440/60000 (49%)]\tLoss: 764.295471\n",
            "Train Epoch: 221 [30720/60000 (51%)]\tLoss: 716.196167\n",
            "Train Epoch: 221 [32000/60000 (53%)]\tLoss: 746.258179\n",
            "Train Epoch: 221 [33280/60000 (55%)]\tLoss: 705.318420\n",
            "Train Epoch: 221 [34560/60000 (58%)]\tLoss: 756.097900\n",
            "Train Epoch: 221 [35840/60000 (60%)]\tLoss: 723.963867\n",
            "Train Epoch: 221 [37120/60000 (62%)]\tLoss: 748.775635\n",
            "Train Epoch: 221 [38400/60000 (64%)]\tLoss: 711.646912\n",
            "Train Epoch: 221 [39680/60000 (66%)]\tLoss: 743.575684\n",
            "Train Epoch: 221 [40960/60000 (68%)]\tLoss: 755.787842\n",
            "Train Epoch: 221 [42240/60000 (70%)]\tLoss: 751.427673\n",
            "Train Epoch: 221 [43520/60000 (72%)]\tLoss: 748.012329\n",
            "Train Epoch: 221 [44800/60000 (75%)]\tLoss: 716.154785\n",
            "Train Epoch: 221 [46080/60000 (77%)]\tLoss: 722.299500\n",
            "Train Epoch: 221 [47360/60000 (79%)]\tLoss: 735.877686\n",
            "Train Epoch: 221 [48640/60000 (81%)]\tLoss: 711.900696\n",
            "Train Epoch: 221 [49920/60000 (83%)]\tLoss: 751.571472\n",
            "Train Epoch: 221 [51200/60000 (85%)]\tLoss: 730.452515\n",
            "Train Epoch: 221 [52480/60000 (87%)]\tLoss: 726.495239\n",
            "Train Epoch: 221 [53760/60000 (90%)]\tLoss: 748.463013\n",
            "Train Epoch: 221 [55040/60000 (92%)]\tLoss: 768.917603\n",
            "Train Epoch: 221 [56320/60000 (94%)]\tLoss: 757.662109\n",
            "Train Epoch: 221 [57600/60000 (96%)]\tLoss: 742.369141\n",
            "Train Epoch: 221 [58880/60000 (98%)]\tLoss: 722.347534\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783976674079895\n",
            "\n",
            "Train Epoch: 222 [0/60000 (0%)]\tLoss: 702.681030\n",
            "Train Epoch: 222 [1280/60000 (2%)]\tLoss: 742.567200\n",
            "Train Epoch: 222 [2560/60000 (4%)]\tLoss: 743.336426\n",
            "Train Epoch: 222 [3840/60000 (6%)]\tLoss: 749.716736\n",
            "Train Epoch: 222 [5120/60000 (9%)]\tLoss: 743.557556\n",
            "Train Epoch: 222 [6400/60000 (11%)]\tLoss: 742.295349\n",
            "Train Epoch: 222 [7680/60000 (13%)]\tLoss: 741.538513\n",
            "Train Epoch: 222 [8960/60000 (15%)]\tLoss: 740.198853\n",
            "Train Epoch: 222 [10240/60000 (17%)]\tLoss: 734.634888\n",
            "Train Epoch: 222 [11520/60000 (19%)]\tLoss: 730.566772\n",
            "Train Epoch: 222 [12800/60000 (21%)]\tLoss: 743.578125\n",
            "Train Epoch: 222 [14080/60000 (23%)]\tLoss: 734.151855\n",
            "Train Epoch: 222 [15360/60000 (26%)]\tLoss: 754.341614\n",
            "Train Epoch: 222 [16640/60000 (28%)]\tLoss: 737.968079\n",
            "Train Epoch: 222 [17920/60000 (30%)]\tLoss: 739.570374\n",
            "Train Epoch: 222 [19200/60000 (32%)]\tLoss: 719.834167\n",
            "Train Epoch: 222 [20480/60000 (34%)]\tLoss: 742.145203\n",
            "Train Epoch: 222 [21760/60000 (36%)]\tLoss: 762.384033\n",
            "Train Epoch: 222 [23040/60000 (38%)]\tLoss: 697.688477\n",
            "Train Epoch: 222 [24320/60000 (41%)]\tLoss: 724.537048\n",
            "Train Epoch: 222 [25600/60000 (43%)]\tLoss: 725.528320\n",
            "Train Epoch: 222 [26880/60000 (45%)]\tLoss: 719.751343\n",
            "Train Epoch: 222 [28160/60000 (47%)]\tLoss: 706.429321\n",
            "Train Epoch: 222 [29440/60000 (49%)]\tLoss: 745.916260\n",
            "Train Epoch: 222 [30720/60000 (51%)]\tLoss: 719.204773\n",
            "Train Epoch: 222 [32000/60000 (53%)]\tLoss: 737.101379\n",
            "Train Epoch: 222 [33280/60000 (55%)]\tLoss: 718.197205\n",
            "Train Epoch: 222 [34560/60000 (58%)]\tLoss: 750.221130\n",
            "Train Epoch: 222 [35840/60000 (60%)]\tLoss: 761.438171\n",
            "Train Epoch: 222 [37120/60000 (62%)]\tLoss: 754.119263\n",
            "Train Epoch: 222 [38400/60000 (64%)]\tLoss: 732.224304\n",
            "Train Epoch: 222 [39680/60000 (66%)]\tLoss: 746.390564\n",
            "Train Epoch: 222 [40960/60000 (68%)]\tLoss: 724.109253\n",
            "Train Epoch: 222 [42240/60000 (70%)]\tLoss: 767.029358\n",
            "Train Epoch: 222 [43520/60000 (72%)]\tLoss: 716.009216\n",
            "Train Epoch: 222 [44800/60000 (75%)]\tLoss: 751.943726\n",
            "Train Epoch: 222 [46080/60000 (77%)]\tLoss: 750.373596\n",
            "Train Epoch: 222 [47360/60000 (79%)]\tLoss: 730.308350\n",
            "Train Epoch: 222 [48640/60000 (81%)]\tLoss: 732.673279\n",
            "Train Epoch: 222 [49920/60000 (83%)]\tLoss: 735.491821\n",
            "Train Epoch: 222 [51200/60000 (85%)]\tLoss: 764.774475\n",
            "Train Epoch: 222 [52480/60000 (87%)]\tLoss: 744.718018\n",
            "Train Epoch: 222 [53760/60000 (90%)]\tLoss: 732.750244\n",
            "Train Epoch: 222 [55040/60000 (92%)]\tLoss: 741.640015\n",
            "Train Epoch: 222 [56320/60000 (94%)]\tLoss: 740.384705\n",
            "Train Epoch: 222 [57600/60000 (96%)]\tLoss: 728.061951\n",
            "Train Epoch: 222 [58880/60000 (98%)]\tLoss: 740.806702\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781309366226196\n",
            "\n",
            "Train Epoch: 223 [0/60000 (0%)]\tLoss: 746.036377\n",
            "Train Epoch: 223 [1280/60000 (2%)]\tLoss: 741.876404\n",
            "Train Epoch: 223 [2560/60000 (4%)]\tLoss: 732.234741\n",
            "Train Epoch: 223 [3840/60000 (6%)]\tLoss: 738.054443\n",
            "Train Epoch: 223 [5120/60000 (9%)]\tLoss: 730.560730\n",
            "Train Epoch: 223 [6400/60000 (11%)]\tLoss: 733.790833\n",
            "Train Epoch: 223 [7680/60000 (13%)]\tLoss: 753.505066\n",
            "Train Epoch: 223 [8960/60000 (15%)]\tLoss: 706.856079\n",
            "Train Epoch: 223 [10240/60000 (17%)]\tLoss: 721.199280\n",
            "Train Epoch: 223 [11520/60000 (19%)]\tLoss: 753.028442\n",
            "Train Epoch: 223 [12800/60000 (21%)]\tLoss: 740.156616\n",
            "Train Epoch: 223 [14080/60000 (23%)]\tLoss: 700.257446\n",
            "Train Epoch: 223 [15360/60000 (26%)]\tLoss: 728.988770\n",
            "Train Epoch: 223 [16640/60000 (28%)]\tLoss: 756.246765\n",
            "Train Epoch: 223 [17920/60000 (30%)]\tLoss: 724.839844\n",
            "Train Epoch: 223 [19200/60000 (32%)]\tLoss: 745.901611\n",
            "Train Epoch: 223 [20480/60000 (34%)]\tLoss: 745.512634\n",
            "Train Epoch: 223 [21760/60000 (36%)]\tLoss: 752.333984\n",
            "Train Epoch: 223 [23040/60000 (38%)]\tLoss: 729.071411\n",
            "Train Epoch: 223 [24320/60000 (41%)]\tLoss: 714.164673\n",
            "Train Epoch: 223 [25600/60000 (43%)]\tLoss: 740.766907\n",
            "Train Epoch: 223 [26880/60000 (45%)]\tLoss: 714.269348\n",
            "Train Epoch: 223 [28160/60000 (47%)]\tLoss: 702.551086\n",
            "Train Epoch: 223 [29440/60000 (49%)]\tLoss: 746.077637\n",
            "Train Epoch: 223 [30720/60000 (51%)]\tLoss: 756.252747\n",
            "Train Epoch: 223 [32000/60000 (53%)]\tLoss: 747.165833\n",
            "Train Epoch: 223 [33280/60000 (55%)]\tLoss: 731.411072\n",
            "Train Epoch: 223 [34560/60000 (58%)]\tLoss: 732.121399\n",
            "Train Epoch: 223 [35840/60000 (60%)]\tLoss: 760.097412\n",
            "Train Epoch: 223 [37120/60000 (62%)]\tLoss: 765.140503\n",
            "Train Epoch: 223 [38400/60000 (64%)]\tLoss: 743.327820\n",
            "Train Epoch: 223 [39680/60000 (66%)]\tLoss: 716.474487\n",
            "Train Epoch: 223 [40960/60000 (68%)]\tLoss: 730.233887\n",
            "Train Epoch: 223 [42240/60000 (70%)]\tLoss: 743.185669\n",
            "Train Epoch: 223 [43520/60000 (72%)]\tLoss: 739.629883\n",
            "Train Epoch: 223 [44800/60000 (75%)]\tLoss: 738.012878\n",
            "Train Epoch: 223 [46080/60000 (77%)]\tLoss: 744.328552\n",
            "Train Epoch: 223 [47360/60000 (79%)]\tLoss: 748.727722\n",
            "Train Epoch: 223 [48640/60000 (81%)]\tLoss: 731.527039\n",
            "Train Epoch: 223 [49920/60000 (83%)]\tLoss: 747.937012\n",
            "Train Epoch: 223 [51200/60000 (85%)]\tLoss: 720.978638\n",
            "Train Epoch: 223 [52480/60000 (87%)]\tLoss: 747.268494\n",
            "Train Epoch: 223 [53760/60000 (90%)]\tLoss: 711.563660\n",
            "Train Epoch: 223 [55040/60000 (92%)]\tLoss: 747.458008\n",
            "Train Epoch: 223 [56320/60000 (94%)]\tLoss: 735.050293\n",
            "Train Epoch: 223 [57600/60000 (96%)]\tLoss: 744.188477\n",
            "Train Epoch: 223 [58880/60000 (98%)]\tLoss: 753.336853\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783493876457214\n",
            "\n",
            "Train Epoch: 224 [0/60000 (0%)]\tLoss: 718.877380\n",
            "Train Epoch: 224 [1280/60000 (2%)]\tLoss: 730.262329\n",
            "Train Epoch: 224 [2560/60000 (4%)]\tLoss: 747.576172\n",
            "Train Epoch: 224 [3840/60000 (6%)]\tLoss: 716.717163\n",
            "Train Epoch: 224 [5120/60000 (9%)]\tLoss: 716.419617\n",
            "Train Epoch: 224 [6400/60000 (11%)]\tLoss: 738.063049\n",
            "Train Epoch: 224 [7680/60000 (13%)]\tLoss: 732.127380\n",
            "Train Epoch: 224 [8960/60000 (15%)]\tLoss: 737.242432\n",
            "Train Epoch: 224 [10240/60000 (17%)]\tLoss: 731.370728\n",
            "Train Epoch: 224 [11520/60000 (19%)]\tLoss: 742.606384\n",
            "Train Epoch: 224 [12800/60000 (21%)]\tLoss: 749.577515\n",
            "Train Epoch: 224 [14080/60000 (23%)]\tLoss: 754.757874\n",
            "Train Epoch: 224 [15360/60000 (26%)]\tLoss: 716.987488\n",
            "Train Epoch: 224 [16640/60000 (28%)]\tLoss: 735.378906\n",
            "Train Epoch: 224 [17920/60000 (30%)]\tLoss: 736.283203\n",
            "Train Epoch: 224 [19200/60000 (32%)]\tLoss: 736.516846\n",
            "Train Epoch: 224 [20480/60000 (34%)]\tLoss: 725.557617\n",
            "Train Epoch: 224 [21760/60000 (36%)]\tLoss: 757.703918\n",
            "Train Epoch: 224 [23040/60000 (38%)]\tLoss: 732.094055\n",
            "Train Epoch: 224 [24320/60000 (41%)]\tLoss: 726.353394\n",
            "Train Epoch: 224 [25600/60000 (43%)]\tLoss: 735.438599\n",
            "Train Epoch: 224 [26880/60000 (45%)]\tLoss: 743.478516\n",
            "Train Epoch: 224 [28160/60000 (47%)]\tLoss: 735.498840\n",
            "Train Epoch: 224 [29440/60000 (49%)]\tLoss: 755.022888\n",
            "Train Epoch: 224 [30720/60000 (51%)]\tLoss: 723.804626\n",
            "Train Epoch: 224 [32000/60000 (53%)]\tLoss: 713.597412\n",
            "Train Epoch: 224 [33280/60000 (55%)]\tLoss: 722.300537\n",
            "Train Epoch: 224 [34560/60000 (58%)]\tLoss: 724.339355\n",
            "Train Epoch: 224 [35840/60000 (60%)]\tLoss: 753.836121\n",
            "Train Epoch: 224 [37120/60000 (62%)]\tLoss: 728.600525\n",
            "Train Epoch: 224 [38400/60000 (64%)]\tLoss: 732.124878\n",
            "Train Epoch: 224 [39680/60000 (66%)]\tLoss: 722.044556\n",
            "Train Epoch: 224 [40960/60000 (68%)]\tLoss: 741.401123\n",
            "Train Epoch: 224 [42240/60000 (70%)]\tLoss: 720.076477\n",
            "Train Epoch: 224 [43520/60000 (72%)]\tLoss: 749.087830\n",
            "Train Epoch: 224 [44800/60000 (75%)]\tLoss: 730.689209\n",
            "Train Epoch: 224 [46080/60000 (77%)]\tLoss: 739.742432\n",
            "Train Epoch: 224 [47360/60000 (79%)]\tLoss: 727.180176\n",
            "Train Epoch: 224 [48640/60000 (81%)]\tLoss: 718.017944\n",
            "Train Epoch: 224 [49920/60000 (83%)]\tLoss: 735.662720\n",
            "Train Epoch: 224 [51200/60000 (85%)]\tLoss: 737.458008\n",
            "Train Epoch: 224 [52480/60000 (87%)]\tLoss: 726.638855\n",
            "Train Epoch: 224 [53760/60000 (90%)]\tLoss: 729.850403\n",
            "Train Epoch: 224 [55040/60000 (92%)]\tLoss: 732.199036\n",
            "Train Epoch: 224 [56320/60000 (94%)]\tLoss: 720.786682\n",
            "Train Epoch: 224 [57600/60000 (96%)]\tLoss: 718.820251\n",
            "Train Epoch: 224 [58880/60000 (98%)]\tLoss: 736.074219\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782587885856628\n",
            "\n",
            "Train Epoch: 225 [0/60000 (0%)]\tLoss: 727.866882\n",
            "Train Epoch: 225 [1280/60000 (2%)]\tLoss: 727.079590\n",
            "Train Epoch: 225 [2560/60000 (4%)]\tLoss: 740.407898\n",
            "Train Epoch: 225 [3840/60000 (6%)]\tLoss: 719.526489\n",
            "Train Epoch: 225 [5120/60000 (9%)]\tLoss: 722.551941\n",
            "Train Epoch: 225 [6400/60000 (11%)]\tLoss: 722.509094\n",
            "Train Epoch: 225 [7680/60000 (13%)]\tLoss: 722.529724\n",
            "Train Epoch: 225 [8960/60000 (15%)]\tLoss: 743.331116\n",
            "Train Epoch: 225 [10240/60000 (17%)]\tLoss: 748.182617\n",
            "Train Epoch: 225 [11520/60000 (19%)]\tLoss: 728.159363\n",
            "Train Epoch: 225 [12800/60000 (21%)]\tLoss: 755.621460\n",
            "Train Epoch: 225 [14080/60000 (23%)]\tLoss: 720.796082\n",
            "Train Epoch: 225 [15360/60000 (26%)]\tLoss: 748.026245\n",
            "Train Epoch: 225 [16640/60000 (28%)]\tLoss: 732.199951\n",
            "Train Epoch: 225 [17920/60000 (30%)]\tLoss: 734.245605\n",
            "Train Epoch: 225 [19200/60000 (32%)]\tLoss: 715.031616\n",
            "Train Epoch: 225 [20480/60000 (34%)]\tLoss: 740.280823\n",
            "Train Epoch: 225 [21760/60000 (36%)]\tLoss: 713.698303\n",
            "Train Epoch: 225 [23040/60000 (38%)]\tLoss: 766.949280\n",
            "Train Epoch: 225 [24320/60000 (41%)]\tLoss: 726.451355\n",
            "Train Epoch: 225 [25600/60000 (43%)]\tLoss: 737.744934\n",
            "Train Epoch: 225 [26880/60000 (45%)]\tLoss: 741.224548\n",
            "Train Epoch: 225 [28160/60000 (47%)]\tLoss: 737.578308\n",
            "Train Epoch: 225 [29440/60000 (49%)]\tLoss: 720.519775\n",
            "Train Epoch: 225 [30720/60000 (51%)]\tLoss: 729.010925\n",
            "Train Epoch: 225 [32000/60000 (53%)]\tLoss: 741.851868\n",
            "Train Epoch: 225 [33280/60000 (55%)]\tLoss: 747.136292\n",
            "Train Epoch: 225 [34560/60000 (58%)]\tLoss: 745.715637\n",
            "Train Epoch: 225 [35840/60000 (60%)]\tLoss: 705.553406\n",
            "Train Epoch: 225 [37120/60000 (62%)]\tLoss: 764.721375\n",
            "Train Epoch: 225 [38400/60000 (64%)]\tLoss: 736.828796\n",
            "Train Epoch: 225 [39680/60000 (66%)]\tLoss: 738.148865\n",
            "Train Epoch: 225 [40960/60000 (68%)]\tLoss: 736.537292\n",
            "Train Epoch: 225 [42240/60000 (70%)]\tLoss: 745.748230\n",
            "Train Epoch: 225 [43520/60000 (72%)]\tLoss: 735.162720\n",
            "Train Epoch: 225 [44800/60000 (75%)]\tLoss: 746.846130\n",
            "Train Epoch: 225 [46080/60000 (77%)]\tLoss: 720.568481\n",
            "Train Epoch: 225 [47360/60000 (79%)]\tLoss: 712.413574\n",
            "Train Epoch: 225 [48640/60000 (81%)]\tLoss: 731.675659\n",
            "Train Epoch: 225 [49920/60000 (83%)]\tLoss: 744.231384\n",
            "Train Epoch: 225 [51200/60000 (85%)]\tLoss: 733.167053\n",
            "Train Epoch: 225 [52480/60000 (87%)]\tLoss: 707.008301\n",
            "Train Epoch: 225 [53760/60000 (90%)]\tLoss: 744.229309\n",
            "Train Epoch: 225 [55040/60000 (92%)]\tLoss: 759.480591\n",
            "Train Epoch: 225 [56320/60000 (94%)]\tLoss: 750.334229\n",
            "Train Epoch: 225 [57600/60000 (96%)]\tLoss: 757.451416\n",
            "Train Epoch: 225 [58880/60000 (98%)]\tLoss: 733.330933\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978159099817276\n",
            "\n",
            "Train Epoch: 226 [0/60000 (0%)]\tLoss: 738.772644\n",
            "Train Epoch: 226 [1280/60000 (2%)]\tLoss: 742.479187\n",
            "Train Epoch: 226 [2560/60000 (4%)]\tLoss: 751.575256\n",
            "Train Epoch: 226 [3840/60000 (6%)]\tLoss: 767.695007\n",
            "Train Epoch: 226 [5120/60000 (9%)]\tLoss: 712.980713\n",
            "Train Epoch: 226 [6400/60000 (11%)]\tLoss: 749.179810\n",
            "Train Epoch: 226 [7680/60000 (13%)]\tLoss: 724.317017\n",
            "Train Epoch: 226 [8960/60000 (15%)]\tLoss: 747.927185\n",
            "Train Epoch: 226 [10240/60000 (17%)]\tLoss: 738.274719\n",
            "Train Epoch: 226 [11520/60000 (19%)]\tLoss: 752.644653\n",
            "Train Epoch: 226 [12800/60000 (21%)]\tLoss: 763.215454\n",
            "Train Epoch: 226 [14080/60000 (23%)]\tLoss: 724.825134\n",
            "Train Epoch: 226 [15360/60000 (26%)]\tLoss: 730.171204\n",
            "Train Epoch: 226 [16640/60000 (28%)]\tLoss: 742.911743\n",
            "Train Epoch: 226 [17920/60000 (30%)]\tLoss: 739.441101\n",
            "Train Epoch: 226 [19200/60000 (32%)]\tLoss: 720.124695\n",
            "Train Epoch: 226 [20480/60000 (34%)]\tLoss: 746.658081\n",
            "Train Epoch: 226 [21760/60000 (36%)]\tLoss: 726.642029\n",
            "Train Epoch: 226 [23040/60000 (38%)]\tLoss: 748.174805\n",
            "Train Epoch: 226 [24320/60000 (41%)]\tLoss: 730.991211\n",
            "Train Epoch: 226 [25600/60000 (43%)]\tLoss: 735.866150\n",
            "Train Epoch: 226 [26880/60000 (45%)]\tLoss: 731.124573\n",
            "Train Epoch: 226 [28160/60000 (47%)]\tLoss: 738.689209\n",
            "Train Epoch: 226 [29440/60000 (49%)]\tLoss: 747.164062\n",
            "Train Epoch: 226 [30720/60000 (51%)]\tLoss: 732.578247\n",
            "Train Epoch: 226 [32000/60000 (53%)]\tLoss: 709.265198\n",
            "Train Epoch: 226 [33280/60000 (55%)]\tLoss: 743.696960\n",
            "Train Epoch: 226 [34560/60000 (58%)]\tLoss: 749.422180\n",
            "Train Epoch: 226 [35840/60000 (60%)]\tLoss: 752.650085\n",
            "Train Epoch: 226 [37120/60000 (62%)]\tLoss: 744.615845\n",
            "Train Epoch: 226 [38400/60000 (64%)]\tLoss: 736.387207\n",
            "Train Epoch: 226 [39680/60000 (66%)]\tLoss: 736.790344\n",
            "Train Epoch: 226 [40960/60000 (68%)]\tLoss: 741.163330\n",
            "Train Epoch: 226 [42240/60000 (70%)]\tLoss: 751.819702\n",
            "Train Epoch: 226 [43520/60000 (72%)]\tLoss: 723.918274\n",
            "Train Epoch: 226 [44800/60000 (75%)]\tLoss: 733.823792\n",
            "Train Epoch: 226 [46080/60000 (77%)]\tLoss: 738.463623\n",
            "Train Epoch: 226 [47360/60000 (79%)]\tLoss: 708.480286\n",
            "Train Epoch: 226 [48640/60000 (81%)]\tLoss: 753.289734\n",
            "Train Epoch: 226 [49920/60000 (83%)]\tLoss: 741.800903\n",
            "Train Epoch: 226 [51200/60000 (85%)]\tLoss: 746.219543\n",
            "Train Epoch: 226 [52480/60000 (87%)]\tLoss: 744.591553\n",
            "Train Epoch: 226 [53760/60000 (90%)]\tLoss: 740.613464\n",
            "Train Epoch: 226 [55040/60000 (92%)]\tLoss: 727.160950\n",
            "Train Epoch: 226 [56320/60000 (94%)]\tLoss: 732.671143\n",
            "Train Epoch: 226 [57600/60000 (96%)]\tLoss: 721.633911\n",
            "Train Epoch: 226 [58880/60000 (98%)]\tLoss: 747.258057\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978735625743866\n",
            "\n",
            "Train Epoch: 227 [0/60000 (0%)]\tLoss: 736.092224\n",
            "Train Epoch: 227 [1280/60000 (2%)]\tLoss: 731.922424\n",
            "Train Epoch: 227 [2560/60000 (4%)]\tLoss: 737.754761\n",
            "Train Epoch: 227 [3840/60000 (6%)]\tLoss: 743.771606\n",
            "Train Epoch: 227 [5120/60000 (9%)]\tLoss: 725.403442\n",
            "Train Epoch: 227 [6400/60000 (11%)]\tLoss: 741.413574\n",
            "Train Epoch: 227 [7680/60000 (13%)]\tLoss: 738.523438\n",
            "Train Epoch: 227 [8960/60000 (15%)]\tLoss: 731.317383\n",
            "Train Epoch: 227 [10240/60000 (17%)]\tLoss: 726.684387\n",
            "Train Epoch: 227 [11520/60000 (19%)]\tLoss: 730.781067\n",
            "Train Epoch: 227 [12800/60000 (21%)]\tLoss: 742.342468\n",
            "Train Epoch: 227 [14080/60000 (23%)]\tLoss: 756.458374\n",
            "Train Epoch: 227 [15360/60000 (26%)]\tLoss: 726.697815\n",
            "Train Epoch: 227 [16640/60000 (28%)]\tLoss: 749.362305\n",
            "Train Epoch: 227 [17920/60000 (30%)]\tLoss: 726.780579\n",
            "Train Epoch: 227 [19200/60000 (32%)]\tLoss: 740.596375\n",
            "Train Epoch: 227 [20480/60000 (34%)]\tLoss: 705.480164\n",
            "Train Epoch: 227 [21760/60000 (36%)]\tLoss: 739.817261\n",
            "Train Epoch: 227 [23040/60000 (38%)]\tLoss: 727.763123\n",
            "Train Epoch: 227 [24320/60000 (41%)]\tLoss: 734.022583\n",
            "Train Epoch: 227 [25600/60000 (43%)]\tLoss: 747.979858\n",
            "Train Epoch: 227 [26880/60000 (45%)]\tLoss: 721.262817\n",
            "Train Epoch: 227 [28160/60000 (47%)]\tLoss: 757.100403\n",
            "Train Epoch: 227 [29440/60000 (49%)]\tLoss: 734.015076\n",
            "Train Epoch: 227 [30720/60000 (51%)]\tLoss: 708.320740\n",
            "Train Epoch: 227 [32000/60000 (53%)]\tLoss: 737.878296\n",
            "Train Epoch: 227 [33280/60000 (55%)]\tLoss: 759.760742\n",
            "Train Epoch: 227 [34560/60000 (58%)]\tLoss: 738.610779\n",
            "Train Epoch: 227 [35840/60000 (60%)]\tLoss: 723.958313\n",
            "Train Epoch: 227 [37120/60000 (62%)]\tLoss: 734.041748\n",
            "Train Epoch: 227 [38400/60000 (64%)]\tLoss: 729.789490\n",
            "Train Epoch: 227 [39680/60000 (66%)]\tLoss: 743.120239\n",
            "Train Epoch: 227 [40960/60000 (68%)]\tLoss: 753.710083\n",
            "Train Epoch: 227 [42240/60000 (70%)]\tLoss: 739.789490\n",
            "Train Epoch: 227 [43520/60000 (72%)]\tLoss: 739.788269\n",
            "Train Epoch: 227 [44800/60000 (75%)]\tLoss: 760.734680\n",
            "Train Epoch: 227 [46080/60000 (77%)]\tLoss: 741.461304\n",
            "Train Epoch: 227 [47360/60000 (79%)]\tLoss: 746.758423\n",
            "Train Epoch: 227 [48640/60000 (81%)]\tLoss: 751.060669\n",
            "Train Epoch: 227 [49920/60000 (83%)]\tLoss: 744.016907\n",
            "Train Epoch: 227 [51200/60000 (85%)]\tLoss: 763.550110\n",
            "Train Epoch: 227 [52480/60000 (87%)]\tLoss: 739.670105\n",
            "Train Epoch: 227 [53760/60000 (90%)]\tLoss: 724.493591\n",
            "Train Epoch: 227 [55040/60000 (92%)]\tLoss: 731.110779\n",
            "Train Epoch: 227 [56320/60000 (94%)]\tLoss: 716.067444\n",
            "Train Epoch: 227 [57600/60000 (96%)]\tLoss: 710.894775\n",
            "Train Epoch: 227 [58880/60000 (98%)]\tLoss: 749.161926\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782356917858124\n",
            "\n",
            "Train Epoch: 228 [0/60000 (0%)]\tLoss: 729.613464\n",
            "Train Epoch: 228 [1280/60000 (2%)]\tLoss: 758.385010\n",
            "Train Epoch: 228 [2560/60000 (4%)]\tLoss: 728.660217\n",
            "Train Epoch: 228 [3840/60000 (6%)]\tLoss: 740.065735\n",
            "Train Epoch: 228 [5120/60000 (9%)]\tLoss: 723.527466\n",
            "Train Epoch: 228 [6400/60000 (11%)]\tLoss: 751.692139\n",
            "Train Epoch: 228 [7680/60000 (13%)]\tLoss: 733.404175\n",
            "Train Epoch: 228 [8960/60000 (15%)]\tLoss: 727.234314\n",
            "Train Epoch: 228 [10240/60000 (17%)]\tLoss: 733.916992\n",
            "Train Epoch: 228 [11520/60000 (19%)]\tLoss: 750.627625\n",
            "Train Epoch: 228 [12800/60000 (21%)]\tLoss: 738.825012\n",
            "Train Epoch: 228 [14080/60000 (23%)]\tLoss: 735.106140\n",
            "Train Epoch: 228 [15360/60000 (26%)]\tLoss: 735.657593\n",
            "Train Epoch: 228 [16640/60000 (28%)]\tLoss: 748.534851\n",
            "Train Epoch: 228 [17920/60000 (30%)]\tLoss: 730.971619\n",
            "Train Epoch: 228 [19200/60000 (32%)]\tLoss: 706.454102\n",
            "Train Epoch: 228 [20480/60000 (34%)]\tLoss: 732.347778\n",
            "Train Epoch: 228 [21760/60000 (36%)]\tLoss: 731.922791\n",
            "Train Epoch: 228 [23040/60000 (38%)]\tLoss: 736.552551\n",
            "Train Epoch: 228 [24320/60000 (41%)]\tLoss: 717.165955\n",
            "Train Epoch: 228 [25600/60000 (43%)]\tLoss: 737.507080\n",
            "Train Epoch: 228 [26880/60000 (45%)]\tLoss: 720.465515\n",
            "Train Epoch: 228 [28160/60000 (47%)]\tLoss: 731.758850\n",
            "Train Epoch: 228 [29440/60000 (49%)]\tLoss: 732.753479\n",
            "Train Epoch: 228 [30720/60000 (51%)]\tLoss: 710.751099\n",
            "Train Epoch: 228 [32000/60000 (53%)]\tLoss: 719.629211\n",
            "Train Epoch: 228 [33280/60000 (55%)]\tLoss: 744.037598\n",
            "Train Epoch: 228 [34560/60000 (58%)]\tLoss: 730.060791\n",
            "Train Epoch: 228 [35840/60000 (60%)]\tLoss: 752.636902\n",
            "Train Epoch: 228 [37120/60000 (62%)]\tLoss: 733.971069\n",
            "Train Epoch: 228 [38400/60000 (64%)]\tLoss: 733.637756\n",
            "Train Epoch: 228 [39680/60000 (66%)]\tLoss: 743.670166\n",
            "Train Epoch: 228 [40960/60000 (68%)]\tLoss: 700.928650\n",
            "Train Epoch: 228 [42240/60000 (70%)]\tLoss: 747.154663\n",
            "Train Epoch: 228 [43520/60000 (72%)]\tLoss: 764.790222\n",
            "Train Epoch: 228 [44800/60000 (75%)]\tLoss: 740.968079\n",
            "Train Epoch: 228 [46080/60000 (77%)]\tLoss: 733.943237\n",
            "Train Epoch: 228 [47360/60000 (79%)]\tLoss: 730.895386\n",
            "Train Epoch: 228 [48640/60000 (81%)]\tLoss: 726.251770\n",
            "Train Epoch: 228 [49920/60000 (83%)]\tLoss: 744.707397\n",
            "Train Epoch: 228 [51200/60000 (85%)]\tLoss: 749.330505\n",
            "Train Epoch: 228 [52480/60000 (87%)]\tLoss: 766.736389\n",
            "Train Epoch: 228 [53760/60000 (90%)]\tLoss: 732.674561\n",
            "Train Epoch: 228 [55040/60000 (92%)]\tLoss: 737.198486\n",
            "Train Epoch: 228 [56320/60000 (94%)]\tLoss: 739.828857\n",
            "Train Epoch: 228 [57600/60000 (96%)]\tLoss: 728.263611\n",
            "Train Epoch: 228 [58880/60000 (98%)]\tLoss: 749.825562\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783516228199005\n",
            "\n",
            "Train Epoch: 229 [0/60000 (0%)]\tLoss: 766.360474\n",
            "Train Epoch: 229 [1280/60000 (2%)]\tLoss: 734.392151\n",
            "Train Epoch: 229 [2560/60000 (4%)]\tLoss: 737.648193\n",
            "Train Epoch: 229 [3840/60000 (6%)]\tLoss: 763.250427\n",
            "Train Epoch: 229 [5120/60000 (9%)]\tLoss: 751.253662\n",
            "Train Epoch: 229 [6400/60000 (11%)]\tLoss: 734.897339\n",
            "Train Epoch: 229 [7680/60000 (13%)]\tLoss: 735.069763\n",
            "Train Epoch: 229 [8960/60000 (15%)]\tLoss: 770.872925\n",
            "Train Epoch: 229 [10240/60000 (17%)]\tLoss: 744.651062\n",
            "Train Epoch: 229 [11520/60000 (19%)]\tLoss: 730.659302\n",
            "Train Epoch: 229 [12800/60000 (21%)]\tLoss: 749.741882\n",
            "Train Epoch: 229 [14080/60000 (23%)]\tLoss: 735.864258\n",
            "Train Epoch: 229 [15360/60000 (26%)]\tLoss: 736.486938\n",
            "Train Epoch: 229 [16640/60000 (28%)]\tLoss: 735.843750\n",
            "Train Epoch: 229 [17920/60000 (30%)]\tLoss: 771.334839\n",
            "Train Epoch: 229 [19200/60000 (32%)]\tLoss: 730.178711\n",
            "Train Epoch: 229 [20480/60000 (34%)]\tLoss: 738.239136\n",
            "Train Epoch: 229 [21760/60000 (36%)]\tLoss: 733.319946\n",
            "Train Epoch: 229 [23040/60000 (38%)]\tLoss: 750.468140\n",
            "Train Epoch: 229 [24320/60000 (41%)]\tLoss: 727.543701\n",
            "Train Epoch: 229 [25600/60000 (43%)]\tLoss: 723.485046\n",
            "Train Epoch: 229 [26880/60000 (45%)]\tLoss: 735.602722\n",
            "Train Epoch: 229 [28160/60000 (47%)]\tLoss: 742.926270\n",
            "Train Epoch: 229 [29440/60000 (49%)]\tLoss: 745.052490\n",
            "Train Epoch: 229 [30720/60000 (51%)]\tLoss: 749.839172\n",
            "Train Epoch: 229 [32000/60000 (53%)]\tLoss: 718.539551\n",
            "Train Epoch: 229 [33280/60000 (55%)]\tLoss: 718.217163\n",
            "Train Epoch: 229 [34560/60000 (58%)]\tLoss: 714.964844\n",
            "Train Epoch: 229 [35840/60000 (60%)]\tLoss: 754.225037\n",
            "Train Epoch: 229 [37120/60000 (62%)]\tLoss: 757.319153\n",
            "Train Epoch: 229 [38400/60000 (64%)]\tLoss: 728.011047\n",
            "Train Epoch: 229 [39680/60000 (66%)]\tLoss: 724.375427\n",
            "Train Epoch: 229 [40960/60000 (68%)]\tLoss: 751.071899\n",
            "Train Epoch: 229 [42240/60000 (70%)]\tLoss: 717.082031\n",
            "Train Epoch: 229 [43520/60000 (72%)]\tLoss: 738.910339\n",
            "Train Epoch: 229 [44800/60000 (75%)]\tLoss: 733.918579\n",
            "Train Epoch: 229 [46080/60000 (77%)]\tLoss: 742.250671\n",
            "Train Epoch: 229 [47360/60000 (79%)]\tLoss: 736.267883\n",
            "Train Epoch: 229 [48640/60000 (81%)]\tLoss: 756.289673\n",
            "Train Epoch: 229 [49920/60000 (83%)]\tLoss: 721.995056\n",
            "Train Epoch: 229 [51200/60000 (85%)]\tLoss: 725.843201\n",
            "Train Epoch: 229 [52480/60000 (87%)]\tLoss: 756.733948\n",
            "Train Epoch: 229 [53760/60000 (90%)]\tLoss: 716.593140\n",
            "Train Epoch: 229 [55040/60000 (92%)]\tLoss: 745.095825\n",
            "Train Epoch: 229 [56320/60000 (94%)]\tLoss: 717.768127\n",
            "Train Epoch: 229 [57600/60000 (96%)]\tLoss: 751.641602\n",
            "Train Epoch: 229 [58880/60000 (98%)]\tLoss: 750.524292\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784797728061676\n",
            "\n",
            "Train Epoch: 230 [0/60000 (0%)]\tLoss: 722.146851\n",
            "Train Epoch: 230 [1280/60000 (2%)]\tLoss: 734.657715\n",
            "Train Epoch: 230 [2560/60000 (4%)]\tLoss: 751.075867\n",
            "Train Epoch: 230 [3840/60000 (6%)]\tLoss: 754.828430\n",
            "Train Epoch: 230 [5120/60000 (9%)]\tLoss: 718.864258\n",
            "Train Epoch: 230 [6400/60000 (11%)]\tLoss: 746.397766\n",
            "Train Epoch: 230 [7680/60000 (13%)]\tLoss: 750.409302\n",
            "Train Epoch: 230 [8960/60000 (15%)]\tLoss: 743.271790\n",
            "Train Epoch: 230 [10240/60000 (17%)]\tLoss: 735.636108\n",
            "Train Epoch: 230 [11520/60000 (19%)]\tLoss: 759.106995\n",
            "Train Epoch: 230 [12800/60000 (21%)]\tLoss: 737.724915\n",
            "Train Epoch: 230 [14080/60000 (23%)]\tLoss: 747.588745\n",
            "Train Epoch: 230 [15360/60000 (26%)]\tLoss: 731.785706\n",
            "Train Epoch: 230 [16640/60000 (28%)]\tLoss: 742.127319\n",
            "Train Epoch: 230 [17920/60000 (30%)]\tLoss: 749.323120\n",
            "Train Epoch: 230 [19200/60000 (32%)]\tLoss: 720.780334\n",
            "Train Epoch: 230 [20480/60000 (34%)]\tLoss: 739.322937\n",
            "Train Epoch: 230 [21760/60000 (36%)]\tLoss: 725.666870\n",
            "Train Epoch: 230 [23040/60000 (38%)]\tLoss: 732.002136\n",
            "Train Epoch: 230 [24320/60000 (41%)]\tLoss: 736.996155\n",
            "Train Epoch: 230 [25600/60000 (43%)]\tLoss: 754.087402\n",
            "Train Epoch: 230 [26880/60000 (45%)]\tLoss: 722.956482\n",
            "Train Epoch: 230 [28160/60000 (47%)]\tLoss: 745.572205\n",
            "Train Epoch: 230 [29440/60000 (49%)]\tLoss: 754.318176\n",
            "Train Epoch: 230 [30720/60000 (51%)]\tLoss: 745.908997\n",
            "Train Epoch: 230 [32000/60000 (53%)]\tLoss: 731.926453\n",
            "Train Epoch: 230 [33280/60000 (55%)]\tLoss: 743.450134\n",
            "Train Epoch: 230 [34560/60000 (58%)]\tLoss: 761.780273\n",
            "Train Epoch: 230 [35840/60000 (60%)]\tLoss: 713.883728\n",
            "Train Epoch: 230 [37120/60000 (62%)]\tLoss: 758.978394\n",
            "Train Epoch: 230 [38400/60000 (64%)]\tLoss: 737.018066\n",
            "Train Epoch: 230 [39680/60000 (66%)]\tLoss: 711.460693\n",
            "Train Epoch: 230 [40960/60000 (68%)]\tLoss: 721.741150\n",
            "Train Epoch: 230 [42240/60000 (70%)]\tLoss: 724.564758\n",
            "Train Epoch: 230 [43520/60000 (72%)]\tLoss: 732.773010\n",
            "Train Epoch: 230 [44800/60000 (75%)]\tLoss: 731.805237\n",
            "Train Epoch: 230 [46080/60000 (77%)]\tLoss: 731.376282\n",
            "Train Epoch: 230 [47360/60000 (79%)]\tLoss: 729.448120\n",
            "Train Epoch: 230 [48640/60000 (81%)]\tLoss: 745.254517\n",
            "Train Epoch: 230 [49920/60000 (83%)]\tLoss: 734.289368\n",
            "Train Epoch: 230 [51200/60000 (85%)]\tLoss: 735.602234\n",
            "Train Epoch: 230 [52480/60000 (87%)]\tLoss: 728.824341\n",
            "Train Epoch: 230 [53760/60000 (90%)]\tLoss: 723.358704\n",
            "Train Epoch: 230 [55040/60000 (92%)]\tLoss: 729.220764\n",
            "Train Epoch: 230 [56320/60000 (94%)]\tLoss: 736.166931\n",
            "Train Epoch: 230 [57600/60000 (96%)]\tLoss: 716.601807\n",
            "Train Epoch: 230 [58880/60000 (98%)]\tLoss: 734.357788\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783943891525269\n",
            "\n",
            "Train Epoch: 231 [0/60000 (0%)]\tLoss: 723.867004\n",
            "Train Epoch: 231 [1280/60000 (2%)]\tLoss: 748.770874\n",
            "Train Epoch: 231 [2560/60000 (4%)]\tLoss: 716.741943\n",
            "Train Epoch: 231 [3840/60000 (6%)]\tLoss: 735.984314\n",
            "Train Epoch: 231 [5120/60000 (9%)]\tLoss: 741.625244\n",
            "Train Epoch: 231 [6400/60000 (11%)]\tLoss: 729.591064\n",
            "Train Epoch: 231 [7680/60000 (13%)]\tLoss: 731.048889\n",
            "Train Epoch: 231 [8960/60000 (15%)]\tLoss: 747.373169\n",
            "Train Epoch: 231 [10240/60000 (17%)]\tLoss: 744.033813\n",
            "Train Epoch: 231 [11520/60000 (19%)]\tLoss: 737.408997\n",
            "Train Epoch: 231 [12800/60000 (21%)]\tLoss: 762.015076\n",
            "Train Epoch: 231 [14080/60000 (23%)]\tLoss: 731.511353\n",
            "Train Epoch: 231 [15360/60000 (26%)]\tLoss: 731.651855\n",
            "Train Epoch: 231 [16640/60000 (28%)]\tLoss: 738.160522\n",
            "Train Epoch: 231 [17920/60000 (30%)]\tLoss: 728.604858\n",
            "Train Epoch: 231 [19200/60000 (32%)]\tLoss: 752.866150\n",
            "Train Epoch: 231 [20480/60000 (34%)]\tLoss: 742.634094\n",
            "Train Epoch: 231 [21760/60000 (36%)]\tLoss: 758.778381\n",
            "Train Epoch: 231 [23040/60000 (38%)]\tLoss: 728.360779\n",
            "Train Epoch: 231 [24320/60000 (41%)]\tLoss: 756.479126\n",
            "Train Epoch: 231 [25600/60000 (43%)]\tLoss: 726.183228\n",
            "Train Epoch: 231 [26880/60000 (45%)]\tLoss: 721.609619\n",
            "Train Epoch: 231 [28160/60000 (47%)]\tLoss: 732.681580\n",
            "Train Epoch: 231 [29440/60000 (49%)]\tLoss: 730.994141\n",
            "Train Epoch: 231 [30720/60000 (51%)]\tLoss: 739.937744\n",
            "Train Epoch: 231 [32000/60000 (53%)]\tLoss: 753.354553\n",
            "Train Epoch: 231 [33280/60000 (55%)]\tLoss: 731.724548\n",
            "Train Epoch: 231 [34560/60000 (58%)]\tLoss: 748.280640\n",
            "Train Epoch: 231 [35840/60000 (60%)]\tLoss: 724.085510\n",
            "Train Epoch: 231 [37120/60000 (62%)]\tLoss: 736.025940\n",
            "Train Epoch: 231 [38400/60000 (64%)]\tLoss: 743.582581\n",
            "Train Epoch: 231 [39680/60000 (66%)]\tLoss: 740.393555\n",
            "Train Epoch: 231 [40960/60000 (68%)]\tLoss: 736.728455\n",
            "Train Epoch: 231 [42240/60000 (70%)]\tLoss: 751.297241\n",
            "Train Epoch: 231 [43520/60000 (72%)]\tLoss: 718.196716\n",
            "Train Epoch: 231 [44800/60000 (75%)]\tLoss: 743.661316\n",
            "Train Epoch: 231 [46080/60000 (77%)]\tLoss: 747.496094\n",
            "Train Epoch: 231 [47360/60000 (79%)]\tLoss: 714.657654\n",
            "Train Epoch: 231 [48640/60000 (81%)]\tLoss: 708.196228\n",
            "Train Epoch: 231 [49920/60000 (83%)]\tLoss: 713.825562\n",
            "Train Epoch: 231 [51200/60000 (85%)]\tLoss: 731.503113\n",
            "Train Epoch: 231 [52480/60000 (87%)]\tLoss: 728.629761\n",
            "Train Epoch: 231 [53760/60000 (90%)]\tLoss: 739.074524\n",
            "Train Epoch: 231 [55040/60000 (92%)]\tLoss: 727.234558\n",
            "Train Epoch: 231 [56320/60000 (94%)]\tLoss: 722.045654\n",
            "Train Epoch: 231 [57600/60000 (96%)]\tLoss: 732.664490\n",
            "Train Epoch: 231 [58880/60000 (98%)]\tLoss: 737.747192\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19787593185901642\n",
            "\n",
            "Train Epoch: 232 [0/60000 (0%)]\tLoss: 736.925354\n",
            "Train Epoch: 232 [1280/60000 (2%)]\tLoss: 727.780090\n",
            "Train Epoch: 232 [2560/60000 (4%)]\tLoss: 758.301758\n",
            "Train Epoch: 232 [3840/60000 (6%)]\tLoss: 720.789368\n",
            "Train Epoch: 232 [5120/60000 (9%)]\tLoss: 740.402100\n",
            "Train Epoch: 232 [6400/60000 (11%)]\tLoss: 726.472717\n",
            "Train Epoch: 232 [7680/60000 (13%)]\tLoss: 738.087769\n",
            "Train Epoch: 232 [8960/60000 (15%)]\tLoss: 761.084839\n",
            "Train Epoch: 232 [10240/60000 (17%)]\tLoss: 720.769104\n",
            "Train Epoch: 232 [11520/60000 (19%)]\tLoss: 781.674561\n",
            "Train Epoch: 232 [12800/60000 (21%)]\tLoss: 749.064148\n",
            "Train Epoch: 232 [14080/60000 (23%)]\tLoss: 734.011841\n",
            "Train Epoch: 232 [15360/60000 (26%)]\tLoss: 730.028809\n",
            "Train Epoch: 232 [16640/60000 (28%)]\tLoss: 755.030273\n",
            "Train Epoch: 232 [17920/60000 (30%)]\tLoss: 751.453979\n",
            "Train Epoch: 232 [19200/60000 (32%)]\tLoss: 739.456177\n",
            "Train Epoch: 232 [20480/60000 (34%)]\tLoss: 757.390076\n",
            "Train Epoch: 232 [21760/60000 (36%)]\tLoss: 738.328735\n",
            "Train Epoch: 232 [23040/60000 (38%)]\tLoss: 750.405640\n",
            "Train Epoch: 232 [24320/60000 (41%)]\tLoss: 723.110901\n",
            "Train Epoch: 232 [25600/60000 (43%)]\tLoss: 731.387756\n",
            "Train Epoch: 232 [26880/60000 (45%)]\tLoss: 741.260010\n",
            "Train Epoch: 232 [28160/60000 (47%)]\tLoss: 750.074768\n",
            "Train Epoch: 232 [29440/60000 (49%)]\tLoss: 730.446655\n",
            "Train Epoch: 232 [30720/60000 (51%)]\tLoss: 731.914429\n",
            "Train Epoch: 232 [32000/60000 (53%)]\tLoss: 739.556335\n",
            "Train Epoch: 232 [33280/60000 (55%)]\tLoss: 732.434265\n",
            "Train Epoch: 232 [34560/60000 (58%)]\tLoss: 744.039612\n",
            "Train Epoch: 232 [35840/60000 (60%)]\tLoss: 734.652527\n",
            "Train Epoch: 232 [37120/60000 (62%)]\tLoss: 719.957092\n",
            "Train Epoch: 232 [38400/60000 (64%)]\tLoss: 756.089966\n",
            "Train Epoch: 232 [39680/60000 (66%)]\tLoss: 722.113098\n",
            "Train Epoch: 232 [40960/60000 (68%)]\tLoss: 755.928467\n",
            "Train Epoch: 232 [42240/60000 (70%)]\tLoss: 732.907654\n",
            "Train Epoch: 232 [43520/60000 (72%)]\tLoss: 731.538025\n",
            "Train Epoch: 232 [44800/60000 (75%)]\tLoss: 752.200562\n",
            "Train Epoch: 232 [46080/60000 (77%)]\tLoss: 730.311951\n",
            "Train Epoch: 232 [47360/60000 (79%)]\tLoss: 744.453003\n",
            "Train Epoch: 232 [48640/60000 (81%)]\tLoss: 723.316895\n",
            "Train Epoch: 232 [49920/60000 (83%)]\tLoss: 746.263611\n",
            "Train Epoch: 232 [51200/60000 (85%)]\tLoss: 732.845398\n",
            "Train Epoch: 232 [52480/60000 (87%)]\tLoss: 731.103943\n",
            "Train Epoch: 232 [53760/60000 (90%)]\tLoss: 736.550232\n",
            "Train Epoch: 232 [55040/60000 (92%)]\tLoss: 756.649719\n",
            "Train Epoch: 232 [56320/60000 (94%)]\tLoss: 752.404175\n",
            "Train Epoch: 232 [57600/60000 (96%)]\tLoss: 732.613770\n",
            "Train Epoch: 232 [58880/60000 (98%)]\tLoss: 729.955444\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781915843486786\n",
            "\n",
            "Train Epoch: 233 [0/60000 (0%)]\tLoss: 752.490295\n",
            "Train Epoch: 233 [1280/60000 (2%)]\tLoss: 735.918823\n",
            "Train Epoch: 233 [2560/60000 (4%)]\tLoss: 751.617737\n",
            "Train Epoch: 233 [3840/60000 (6%)]\tLoss: 729.450256\n",
            "Train Epoch: 233 [5120/60000 (9%)]\tLoss: 735.750732\n",
            "Train Epoch: 233 [6400/60000 (11%)]\tLoss: 736.389221\n",
            "Train Epoch: 233 [7680/60000 (13%)]\tLoss: 738.167114\n",
            "Train Epoch: 233 [8960/60000 (15%)]\tLoss: 754.104065\n",
            "Train Epoch: 233 [10240/60000 (17%)]\tLoss: 711.835815\n",
            "Train Epoch: 233 [11520/60000 (19%)]\tLoss: 734.122192\n",
            "Train Epoch: 233 [12800/60000 (21%)]\tLoss: 749.878906\n",
            "Train Epoch: 233 [14080/60000 (23%)]\tLoss: 735.671265\n",
            "Train Epoch: 233 [15360/60000 (26%)]\tLoss: 746.219849\n",
            "Train Epoch: 233 [16640/60000 (28%)]\tLoss: 707.773926\n",
            "Train Epoch: 233 [17920/60000 (30%)]\tLoss: 750.717285\n",
            "Train Epoch: 233 [19200/60000 (32%)]\tLoss: 728.350159\n",
            "Train Epoch: 233 [20480/60000 (34%)]\tLoss: 767.764343\n",
            "Train Epoch: 233 [21760/60000 (36%)]\tLoss: 748.190552\n",
            "Train Epoch: 233 [23040/60000 (38%)]\tLoss: 719.777222\n",
            "Train Epoch: 233 [24320/60000 (41%)]\tLoss: 745.398621\n",
            "Train Epoch: 233 [25600/60000 (43%)]\tLoss: 763.336365\n",
            "Train Epoch: 233 [26880/60000 (45%)]\tLoss: 733.052490\n",
            "Train Epoch: 233 [28160/60000 (47%)]\tLoss: 734.185547\n",
            "Train Epoch: 233 [29440/60000 (49%)]\tLoss: 749.699097\n",
            "Train Epoch: 233 [30720/60000 (51%)]\tLoss: 725.401733\n",
            "Train Epoch: 233 [32000/60000 (53%)]\tLoss: 744.749573\n",
            "Train Epoch: 233 [33280/60000 (55%)]\tLoss: 749.849426\n",
            "Train Epoch: 233 [34560/60000 (58%)]\tLoss: 749.642029\n",
            "Train Epoch: 233 [35840/60000 (60%)]\tLoss: 733.594360\n",
            "Train Epoch: 233 [37120/60000 (62%)]\tLoss: 719.548889\n",
            "Train Epoch: 233 [38400/60000 (64%)]\tLoss: 723.177368\n",
            "Train Epoch: 233 [39680/60000 (66%)]\tLoss: 727.116272\n",
            "Train Epoch: 233 [40960/60000 (68%)]\tLoss: 721.380737\n",
            "Train Epoch: 233 [42240/60000 (70%)]\tLoss: 717.990112\n",
            "Train Epoch: 233 [43520/60000 (72%)]\tLoss: 719.914734\n",
            "Train Epoch: 233 [44800/60000 (75%)]\tLoss: 714.905151\n",
            "Train Epoch: 233 [46080/60000 (77%)]\tLoss: 724.511353\n",
            "Train Epoch: 233 [47360/60000 (79%)]\tLoss: 700.760986\n",
            "Train Epoch: 233 [48640/60000 (81%)]\tLoss: 726.026062\n",
            "Train Epoch: 233 [49920/60000 (83%)]\tLoss: 747.826538\n",
            "Train Epoch: 233 [51200/60000 (85%)]\tLoss: 739.479797\n",
            "Train Epoch: 233 [52480/60000 (87%)]\tLoss: 748.962952\n",
            "Train Epoch: 233 [53760/60000 (90%)]\tLoss: 735.169861\n",
            "Train Epoch: 233 [55040/60000 (92%)]\tLoss: 727.087769\n",
            "Train Epoch: 233 [56320/60000 (94%)]\tLoss: 736.719299\n",
            "Train Epoch: 233 [57600/60000 (96%)]\tLoss: 725.921265\n",
            "Train Epoch: 233 [58880/60000 (98%)]\tLoss: 741.021973\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978292465209961\n",
            "\n",
            "Train Epoch: 234 [0/60000 (0%)]\tLoss: 711.368958\n",
            "Train Epoch: 234 [1280/60000 (2%)]\tLoss: 754.745422\n",
            "Train Epoch: 234 [2560/60000 (4%)]\tLoss: 725.295654\n",
            "Train Epoch: 234 [3840/60000 (6%)]\tLoss: 739.209961\n",
            "Train Epoch: 234 [5120/60000 (9%)]\tLoss: 753.319153\n",
            "Train Epoch: 234 [6400/60000 (11%)]\tLoss: 750.410156\n",
            "Train Epoch: 234 [7680/60000 (13%)]\tLoss: 740.129944\n",
            "Train Epoch: 234 [8960/60000 (15%)]\tLoss: 722.413452\n",
            "Train Epoch: 234 [10240/60000 (17%)]\tLoss: 746.113525\n",
            "Train Epoch: 234 [11520/60000 (19%)]\tLoss: 740.997131\n",
            "Train Epoch: 234 [12800/60000 (21%)]\tLoss: 740.467896\n",
            "Train Epoch: 234 [14080/60000 (23%)]\tLoss: 748.849060\n",
            "Train Epoch: 234 [15360/60000 (26%)]\tLoss: 751.973145\n",
            "Train Epoch: 234 [16640/60000 (28%)]\tLoss: 745.718689\n",
            "Train Epoch: 234 [17920/60000 (30%)]\tLoss: 741.220337\n",
            "Train Epoch: 234 [19200/60000 (32%)]\tLoss: 744.225769\n",
            "Train Epoch: 234 [20480/60000 (34%)]\tLoss: 715.070312\n",
            "Train Epoch: 234 [21760/60000 (36%)]\tLoss: 734.025757\n",
            "Train Epoch: 234 [23040/60000 (38%)]\tLoss: 730.168213\n",
            "Train Epoch: 234 [24320/60000 (41%)]\tLoss: 716.421387\n",
            "Train Epoch: 234 [25600/60000 (43%)]\tLoss: 720.077637\n",
            "Train Epoch: 234 [26880/60000 (45%)]\tLoss: 771.755188\n",
            "Train Epoch: 234 [28160/60000 (47%)]\tLoss: 726.561829\n",
            "Train Epoch: 234 [29440/60000 (49%)]\tLoss: 704.098328\n",
            "Train Epoch: 234 [30720/60000 (51%)]\tLoss: 729.420837\n",
            "Train Epoch: 234 [32000/60000 (53%)]\tLoss: 736.106079\n",
            "Train Epoch: 234 [33280/60000 (55%)]\tLoss: 709.578979\n",
            "Train Epoch: 234 [34560/60000 (58%)]\tLoss: 729.770569\n",
            "Train Epoch: 234 [35840/60000 (60%)]\tLoss: 741.866516\n",
            "Train Epoch: 234 [37120/60000 (62%)]\tLoss: 712.526917\n",
            "Train Epoch: 234 [38400/60000 (64%)]\tLoss: 752.296387\n",
            "Train Epoch: 234 [39680/60000 (66%)]\tLoss: 738.929565\n",
            "Train Epoch: 234 [40960/60000 (68%)]\tLoss: 746.308838\n",
            "Train Epoch: 234 [42240/60000 (70%)]\tLoss: 700.955444\n",
            "Train Epoch: 234 [43520/60000 (72%)]\tLoss: 716.310120\n",
            "Train Epoch: 234 [44800/60000 (75%)]\tLoss: 704.432556\n",
            "Train Epoch: 234 [46080/60000 (77%)]\tLoss: 733.102112\n",
            "Train Epoch: 234 [47360/60000 (79%)]\tLoss: 725.238159\n",
            "Train Epoch: 234 [48640/60000 (81%)]\tLoss: 745.362854\n",
            "Train Epoch: 234 [49920/60000 (83%)]\tLoss: 733.061279\n",
            "Train Epoch: 234 [51200/60000 (85%)]\tLoss: 749.282898\n",
            "Train Epoch: 234 [52480/60000 (87%)]\tLoss: 757.256897\n",
            "Train Epoch: 234 [53760/60000 (90%)]\tLoss: 760.764404\n",
            "Train Epoch: 234 [55040/60000 (92%)]\tLoss: 756.809692\n",
            "Train Epoch: 234 [56320/60000 (94%)]\tLoss: 756.451355\n",
            "Train Epoch: 234 [57600/60000 (96%)]\tLoss: 735.744385\n",
            "Train Epoch: 234 [58880/60000 (98%)]\tLoss: 757.945618\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1979007124900818\n",
            "\n",
            "Train Epoch: 235 [0/60000 (0%)]\tLoss: 722.169189\n",
            "Train Epoch: 235 [1280/60000 (2%)]\tLoss: 755.512634\n",
            "Train Epoch: 235 [2560/60000 (4%)]\tLoss: 719.573608\n",
            "Train Epoch: 235 [3840/60000 (6%)]\tLoss: 731.152588\n",
            "Train Epoch: 235 [5120/60000 (9%)]\tLoss: 729.610840\n",
            "Train Epoch: 235 [6400/60000 (11%)]\tLoss: 725.116943\n",
            "Train Epoch: 235 [7680/60000 (13%)]\tLoss: 735.218079\n",
            "Train Epoch: 235 [8960/60000 (15%)]\tLoss: 764.304810\n",
            "Train Epoch: 235 [10240/60000 (17%)]\tLoss: 715.548157\n",
            "Train Epoch: 235 [11520/60000 (19%)]\tLoss: 742.897217\n",
            "Train Epoch: 235 [12800/60000 (21%)]\tLoss: 734.658447\n",
            "Train Epoch: 235 [14080/60000 (23%)]\tLoss: 751.650391\n",
            "Train Epoch: 235 [15360/60000 (26%)]\tLoss: 746.698853\n",
            "Train Epoch: 235 [16640/60000 (28%)]\tLoss: 722.346130\n",
            "Train Epoch: 235 [17920/60000 (30%)]\tLoss: 710.543884\n",
            "Train Epoch: 235 [19200/60000 (32%)]\tLoss: 735.980103\n",
            "Train Epoch: 235 [20480/60000 (34%)]\tLoss: 736.243408\n",
            "Train Epoch: 235 [21760/60000 (36%)]\tLoss: 760.614441\n",
            "Train Epoch: 235 [23040/60000 (38%)]\tLoss: 747.749817\n",
            "Train Epoch: 235 [24320/60000 (41%)]\tLoss: 717.502991\n",
            "Train Epoch: 235 [25600/60000 (43%)]\tLoss: 743.331238\n",
            "Train Epoch: 235 [26880/60000 (45%)]\tLoss: 735.263855\n",
            "Train Epoch: 235 [28160/60000 (47%)]\tLoss: 739.154602\n",
            "Train Epoch: 235 [29440/60000 (49%)]\tLoss: 714.798584\n",
            "Train Epoch: 235 [30720/60000 (51%)]\tLoss: 745.323853\n",
            "Train Epoch: 235 [32000/60000 (53%)]\tLoss: 750.395508\n",
            "Train Epoch: 235 [33280/60000 (55%)]\tLoss: 742.514099\n",
            "Train Epoch: 235 [34560/60000 (58%)]\tLoss: 736.113953\n",
            "Train Epoch: 235 [35840/60000 (60%)]\tLoss: 733.391296\n",
            "Train Epoch: 235 [37120/60000 (62%)]\tLoss: 730.487671\n",
            "Train Epoch: 235 [38400/60000 (64%)]\tLoss: 737.481018\n",
            "Train Epoch: 235 [39680/60000 (66%)]\tLoss: 744.100098\n",
            "Train Epoch: 235 [40960/60000 (68%)]\tLoss: 706.550598\n",
            "Train Epoch: 235 [42240/60000 (70%)]\tLoss: 732.372620\n",
            "Train Epoch: 235 [43520/60000 (72%)]\tLoss: 720.641052\n",
            "Train Epoch: 235 [44800/60000 (75%)]\tLoss: 754.939880\n",
            "Train Epoch: 235 [46080/60000 (77%)]\tLoss: 737.059265\n",
            "Train Epoch: 235 [47360/60000 (79%)]\tLoss: 754.186584\n",
            "Train Epoch: 235 [48640/60000 (81%)]\tLoss: 735.563660\n",
            "Train Epoch: 235 [49920/60000 (83%)]\tLoss: 737.487732\n",
            "Train Epoch: 235 [51200/60000 (85%)]\tLoss: 741.101013\n",
            "Train Epoch: 235 [52480/60000 (87%)]\tLoss: 725.938477\n",
            "Train Epoch: 235 [53760/60000 (90%)]\tLoss: 741.725891\n",
            "Train Epoch: 235 [55040/60000 (92%)]\tLoss: 728.291687\n",
            "Train Epoch: 235 [56320/60000 (94%)]\tLoss: 737.511658\n",
            "Train Epoch: 235 [57600/60000 (96%)]\tLoss: 759.046326\n",
            "Train Epoch: 235 [58880/60000 (98%)]\tLoss: 747.661072\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784845411777496\n",
            "\n",
            "Train Epoch: 236 [0/60000 (0%)]\tLoss: 714.714417\n",
            "Train Epoch: 236 [1280/60000 (2%)]\tLoss: 735.341187\n",
            "Train Epoch: 236 [2560/60000 (4%)]\tLoss: 731.651306\n",
            "Train Epoch: 236 [3840/60000 (6%)]\tLoss: 700.426758\n",
            "Train Epoch: 236 [5120/60000 (9%)]\tLoss: 730.448181\n",
            "Train Epoch: 236 [6400/60000 (11%)]\tLoss: 747.182617\n",
            "Train Epoch: 236 [7680/60000 (13%)]\tLoss: 763.958252\n",
            "Train Epoch: 236 [8960/60000 (15%)]\tLoss: 714.859619\n",
            "Train Epoch: 236 [10240/60000 (17%)]\tLoss: 751.083740\n",
            "Train Epoch: 236 [11520/60000 (19%)]\tLoss: 685.621155\n",
            "Train Epoch: 236 [12800/60000 (21%)]\tLoss: 745.981201\n",
            "Train Epoch: 236 [14080/60000 (23%)]\tLoss: 739.408386\n",
            "Train Epoch: 236 [15360/60000 (26%)]\tLoss: 748.362488\n",
            "Train Epoch: 236 [16640/60000 (28%)]\tLoss: 729.167969\n",
            "Train Epoch: 236 [17920/60000 (30%)]\tLoss: 722.229858\n",
            "Train Epoch: 236 [19200/60000 (32%)]\tLoss: 741.312317\n",
            "Train Epoch: 236 [20480/60000 (34%)]\tLoss: 734.651184\n",
            "Train Epoch: 236 [21760/60000 (36%)]\tLoss: 732.241760\n",
            "Train Epoch: 236 [23040/60000 (38%)]\tLoss: 748.678955\n",
            "Train Epoch: 236 [24320/60000 (41%)]\tLoss: 722.592773\n",
            "Train Epoch: 236 [25600/60000 (43%)]\tLoss: 733.627869\n",
            "Train Epoch: 236 [26880/60000 (45%)]\tLoss: 737.581360\n",
            "Train Epoch: 236 [28160/60000 (47%)]\tLoss: 725.568665\n",
            "Train Epoch: 236 [29440/60000 (49%)]\tLoss: 737.856873\n",
            "Train Epoch: 236 [30720/60000 (51%)]\tLoss: 735.077698\n",
            "Train Epoch: 236 [32000/60000 (53%)]\tLoss: 778.810608\n",
            "Train Epoch: 236 [33280/60000 (55%)]\tLoss: 745.973877\n",
            "Train Epoch: 236 [34560/60000 (58%)]\tLoss: 731.699768\n",
            "Train Epoch: 236 [35840/60000 (60%)]\tLoss: 728.924561\n",
            "Train Epoch: 236 [37120/60000 (62%)]\tLoss: 749.822021\n",
            "Train Epoch: 236 [38400/60000 (64%)]\tLoss: 748.739075\n",
            "Train Epoch: 236 [39680/60000 (66%)]\tLoss: 744.607788\n",
            "Train Epoch: 236 [40960/60000 (68%)]\tLoss: 742.088623\n",
            "Train Epoch: 236 [42240/60000 (70%)]\tLoss: 735.355103\n",
            "Train Epoch: 236 [43520/60000 (72%)]\tLoss: 727.730042\n",
            "Train Epoch: 236 [44800/60000 (75%)]\tLoss: 731.402832\n",
            "Train Epoch: 236 [46080/60000 (77%)]\tLoss: 715.064514\n",
            "Train Epoch: 236 [47360/60000 (79%)]\tLoss: 732.991089\n",
            "Train Epoch: 236 [48640/60000 (81%)]\tLoss: 755.829285\n",
            "Train Epoch: 236 [49920/60000 (83%)]\tLoss: 707.966003\n",
            "Train Epoch: 236 [51200/60000 (85%)]\tLoss: 726.155945\n",
            "Train Epoch: 236 [52480/60000 (87%)]\tLoss: 764.730225\n",
            "Train Epoch: 236 [53760/60000 (90%)]\tLoss: 731.904114\n",
            "Train Epoch: 236 [55040/60000 (92%)]\tLoss: 740.425720\n",
            "Train Epoch: 236 [56320/60000 (94%)]\tLoss: 727.651733\n",
            "Train Epoch: 236 [57600/60000 (96%)]\tLoss: 718.207092\n",
            "Train Epoch: 236 [58880/60000 (98%)]\tLoss: 751.899231\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782112538814545\n",
            "\n",
            "Train Epoch: 237 [0/60000 (0%)]\tLoss: 747.158691\n",
            "Train Epoch: 237 [1280/60000 (2%)]\tLoss: 741.956299\n",
            "Train Epoch: 237 [2560/60000 (4%)]\tLoss: 760.907532\n",
            "Train Epoch: 237 [3840/60000 (6%)]\tLoss: 728.918091\n",
            "Train Epoch: 237 [5120/60000 (9%)]\tLoss: 740.967102\n",
            "Train Epoch: 237 [6400/60000 (11%)]\tLoss: 733.125061\n",
            "Train Epoch: 237 [7680/60000 (13%)]\tLoss: 728.157227\n",
            "Train Epoch: 237 [8960/60000 (15%)]\tLoss: 732.034363\n",
            "Train Epoch: 237 [10240/60000 (17%)]\tLoss: 734.027161\n",
            "Train Epoch: 237 [11520/60000 (19%)]\tLoss: 729.556885\n",
            "Train Epoch: 237 [12800/60000 (21%)]\tLoss: 723.826233\n",
            "Train Epoch: 237 [14080/60000 (23%)]\tLoss: 748.549377\n",
            "Train Epoch: 237 [15360/60000 (26%)]\tLoss: 743.483765\n",
            "Train Epoch: 237 [16640/60000 (28%)]\tLoss: 760.002869\n",
            "Train Epoch: 237 [17920/60000 (30%)]\tLoss: 701.013245\n",
            "Train Epoch: 237 [19200/60000 (32%)]\tLoss: 740.411926\n",
            "Train Epoch: 237 [20480/60000 (34%)]\tLoss: 713.131165\n",
            "Train Epoch: 237 [21760/60000 (36%)]\tLoss: 746.772095\n",
            "Train Epoch: 237 [23040/60000 (38%)]\tLoss: 727.743530\n",
            "Train Epoch: 237 [24320/60000 (41%)]\tLoss: 727.426086\n",
            "Train Epoch: 237 [25600/60000 (43%)]\tLoss: 739.955200\n",
            "Train Epoch: 237 [26880/60000 (45%)]\tLoss: 727.924927\n",
            "Train Epoch: 237 [28160/60000 (47%)]\tLoss: 748.038269\n",
            "Train Epoch: 237 [29440/60000 (49%)]\tLoss: 718.452820\n",
            "Train Epoch: 237 [30720/60000 (51%)]\tLoss: 734.935791\n",
            "Train Epoch: 237 [32000/60000 (53%)]\tLoss: 719.568726\n",
            "Train Epoch: 237 [33280/60000 (55%)]\tLoss: 740.053101\n",
            "Train Epoch: 237 [34560/60000 (58%)]\tLoss: 715.768616\n",
            "Train Epoch: 237 [35840/60000 (60%)]\tLoss: 739.663635\n",
            "Train Epoch: 237 [37120/60000 (62%)]\tLoss: 754.250549\n",
            "Train Epoch: 237 [38400/60000 (64%)]\tLoss: 716.910828\n",
            "Train Epoch: 237 [39680/60000 (66%)]\tLoss: 718.723389\n",
            "Train Epoch: 237 [40960/60000 (68%)]\tLoss: 730.273926\n",
            "Train Epoch: 237 [42240/60000 (70%)]\tLoss: 772.772583\n",
            "Train Epoch: 237 [43520/60000 (72%)]\tLoss: 730.985718\n",
            "Train Epoch: 237 [44800/60000 (75%)]\tLoss: 755.677002\n",
            "Train Epoch: 237 [46080/60000 (77%)]\tLoss: 747.357544\n",
            "Train Epoch: 237 [47360/60000 (79%)]\tLoss: 732.006042\n",
            "Train Epoch: 237 [48640/60000 (81%)]\tLoss: 770.756470\n",
            "Train Epoch: 237 [49920/60000 (83%)]\tLoss: 752.386292\n",
            "Train Epoch: 237 [51200/60000 (85%)]\tLoss: 714.634338\n",
            "Train Epoch: 237 [52480/60000 (87%)]\tLoss: 723.608765\n",
            "Train Epoch: 237 [53760/60000 (90%)]\tLoss: 752.017944\n",
            "Train Epoch: 237 [55040/60000 (92%)]\tLoss: 747.447083\n",
            "Train Epoch: 237 [56320/60000 (94%)]\tLoss: 753.396240\n",
            "Train Epoch: 237 [57600/60000 (96%)]\tLoss: 737.653625\n",
            "Train Epoch: 237 [58880/60000 (98%)]\tLoss: 751.061279\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978832185268402\n",
            "\n",
            "Train Epoch: 238 [0/60000 (0%)]\tLoss: 732.460144\n",
            "Train Epoch: 238 [1280/60000 (2%)]\tLoss: 730.032593\n",
            "Train Epoch: 238 [2560/60000 (4%)]\tLoss: 736.239014\n",
            "Train Epoch: 238 [3840/60000 (6%)]\tLoss: 760.108887\n",
            "Train Epoch: 238 [5120/60000 (9%)]\tLoss: 732.018372\n",
            "Train Epoch: 238 [6400/60000 (11%)]\tLoss: 707.173767\n",
            "Train Epoch: 238 [7680/60000 (13%)]\tLoss: 722.918823\n",
            "Train Epoch: 238 [8960/60000 (15%)]\tLoss: 726.556519\n",
            "Train Epoch: 238 [10240/60000 (17%)]\tLoss: 754.126831\n",
            "Train Epoch: 238 [11520/60000 (19%)]\tLoss: 737.477905\n",
            "Train Epoch: 238 [12800/60000 (21%)]\tLoss: 715.765686\n",
            "Train Epoch: 238 [14080/60000 (23%)]\tLoss: 735.453674\n",
            "Train Epoch: 238 [15360/60000 (26%)]\tLoss: 718.401306\n",
            "Train Epoch: 238 [16640/60000 (28%)]\tLoss: 735.548462\n",
            "Train Epoch: 238 [17920/60000 (30%)]\tLoss: 754.275269\n",
            "Train Epoch: 238 [19200/60000 (32%)]\tLoss: 736.472717\n",
            "Train Epoch: 238 [20480/60000 (34%)]\tLoss: 738.079285\n",
            "Train Epoch: 238 [21760/60000 (36%)]\tLoss: 707.716797\n",
            "Train Epoch: 238 [23040/60000 (38%)]\tLoss: 743.196228\n",
            "Train Epoch: 238 [24320/60000 (41%)]\tLoss: 735.401306\n",
            "Train Epoch: 238 [25600/60000 (43%)]\tLoss: 736.673950\n",
            "Train Epoch: 238 [26880/60000 (45%)]\tLoss: 758.884766\n",
            "Train Epoch: 238 [28160/60000 (47%)]\tLoss: 728.296509\n",
            "Train Epoch: 238 [29440/60000 (49%)]\tLoss: 737.048340\n",
            "Train Epoch: 238 [30720/60000 (51%)]\tLoss: 735.428406\n",
            "Train Epoch: 238 [32000/60000 (53%)]\tLoss: 738.718262\n",
            "Train Epoch: 238 [33280/60000 (55%)]\tLoss: 725.694397\n",
            "Train Epoch: 238 [34560/60000 (58%)]\tLoss: 732.001648\n",
            "Train Epoch: 238 [35840/60000 (60%)]\tLoss: 728.765320\n",
            "Train Epoch: 238 [37120/60000 (62%)]\tLoss: 753.933716\n",
            "Train Epoch: 238 [38400/60000 (64%)]\tLoss: 723.968201\n",
            "Train Epoch: 238 [39680/60000 (66%)]\tLoss: 725.731140\n",
            "Train Epoch: 238 [40960/60000 (68%)]\tLoss: 729.668701\n",
            "Train Epoch: 238 [42240/60000 (70%)]\tLoss: 747.177307\n",
            "Train Epoch: 238 [43520/60000 (72%)]\tLoss: 740.717896\n",
            "Train Epoch: 238 [44800/60000 (75%)]\tLoss: 736.025452\n",
            "Train Epoch: 238 [46080/60000 (77%)]\tLoss: 751.837524\n",
            "Train Epoch: 238 [47360/60000 (79%)]\tLoss: 716.128967\n",
            "Train Epoch: 238 [48640/60000 (81%)]\tLoss: 731.484985\n",
            "Train Epoch: 238 [49920/60000 (83%)]\tLoss: 736.126709\n",
            "Train Epoch: 238 [51200/60000 (85%)]\tLoss: 719.794250\n",
            "Train Epoch: 238 [52480/60000 (87%)]\tLoss: 730.834900\n",
            "Train Epoch: 238 [53760/60000 (90%)]\tLoss: 737.844299\n",
            "Train Epoch: 238 [55040/60000 (92%)]\tLoss: 741.295593\n",
            "Train Epoch: 238 [56320/60000 (94%)]\tLoss: 727.650208\n",
            "Train Epoch: 238 [57600/60000 (96%)]\tLoss: 753.514771\n",
            "Train Epoch: 238 [58880/60000 (98%)]\tLoss: 743.741943\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781494140625\n",
            "\n",
            "Train Epoch: 239 [0/60000 (0%)]\tLoss: 745.007629\n",
            "Train Epoch: 239 [1280/60000 (2%)]\tLoss: 745.151306\n",
            "Train Epoch: 239 [2560/60000 (4%)]\tLoss: 721.828735\n",
            "Train Epoch: 239 [3840/60000 (6%)]\tLoss: 729.709595\n",
            "Train Epoch: 239 [5120/60000 (9%)]\tLoss: 723.174438\n",
            "Train Epoch: 239 [6400/60000 (11%)]\tLoss: 724.640259\n",
            "Train Epoch: 239 [7680/60000 (13%)]\tLoss: 736.749634\n",
            "Train Epoch: 239 [8960/60000 (15%)]\tLoss: 734.666870\n",
            "Train Epoch: 239 [10240/60000 (17%)]\tLoss: 751.858521\n",
            "Train Epoch: 239 [11520/60000 (19%)]\tLoss: 750.289307\n",
            "Train Epoch: 239 [12800/60000 (21%)]\tLoss: 730.167297\n",
            "Train Epoch: 239 [14080/60000 (23%)]\tLoss: 734.663940\n",
            "Train Epoch: 239 [15360/60000 (26%)]\tLoss: 732.449646\n",
            "Train Epoch: 239 [16640/60000 (28%)]\tLoss: 753.804443\n",
            "Train Epoch: 239 [17920/60000 (30%)]\tLoss: 748.082275\n",
            "Train Epoch: 239 [19200/60000 (32%)]\tLoss: 739.184448\n",
            "Train Epoch: 239 [20480/60000 (34%)]\tLoss: 755.501221\n",
            "Train Epoch: 239 [21760/60000 (36%)]\tLoss: 736.850342\n",
            "Train Epoch: 239 [23040/60000 (38%)]\tLoss: 742.058472\n",
            "Train Epoch: 239 [24320/60000 (41%)]\tLoss: 728.276611\n",
            "Train Epoch: 239 [25600/60000 (43%)]\tLoss: 727.661011\n",
            "Train Epoch: 239 [26880/60000 (45%)]\tLoss: 720.821777\n",
            "Train Epoch: 239 [28160/60000 (47%)]\tLoss: 736.610474\n",
            "Train Epoch: 239 [29440/60000 (49%)]\tLoss: 714.018066\n",
            "Train Epoch: 239 [30720/60000 (51%)]\tLoss: 723.265991\n",
            "Train Epoch: 239 [32000/60000 (53%)]\tLoss: 723.631592\n",
            "Train Epoch: 239 [33280/60000 (55%)]\tLoss: 733.764526\n",
            "Train Epoch: 239 [34560/60000 (58%)]\tLoss: 743.945862\n",
            "Train Epoch: 239 [35840/60000 (60%)]\tLoss: 761.405273\n",
            "Train Epoch: 239 [37120/60000 (62%)]\tLoss: 761.844360\n",
            "Train Epoch: 239 [38400/60000 (64%)]\tLoss: 730.509460\n",
            "Train Epoch: 239 [39680/60000 (66%)]\tLoss: 729.996826\n",
            "Train Epoch: 239 [40960/60000 (68%)]\tLoss: 705.961914\n",
            "Train Epoch: 239 [42240/60000 (70%)]\tLoss: 737.751160\n",
            "Train Epoch: 239 [43520/60000 (72%)]\tLoss: 759.688843\n",
            "Train Epoch: 239 [44800/60000 (75%)]\tLoss: 731.308350\n",
            "Train Epoch: 239 [46080/60000 (77%)]\tLoss: 761.982910\n",
            "Train Epoch: 239 [47360/60000 (79%)]\tLoss: 710.325562\n",
            "Train Epoch: 239 [48640/60000 (81%)]\tLoss: 723.860046\n",
            "Train Epoch: 239 [49920/60000 (83%)]\tLoss: 765.319519\n",
            "Train Epoch: 239 [51200/60000 (85%)]\tLoss: 743.846008\n",
            "Train Epoch: 239 [52480/60000 (87%)]\tLoss: 743.295227\n",
            "Train Epoch: 239 [53760/60000 (90%)]\tLoss: 729.873108\n",
            "Train Epoch: 239 [55040/60000 (92%)]\tLoss: 742.174927\n",
            "Train Epoch: 239 [56320/60000 (94%)]\tLoss: 753.651733\n",
            "Train Epoch: 239 [57600/60000 (96%)]\tLoss: 716.440918\n",
            "Train Epoch: 239 [58880/60000 (98%)]\tLoss: 709.759888\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783233106136322\n",
            "\n",
            "Train Epoch: 240 [0/60000 (0%)]\tLoss: 700.188599\n",
            "Train Epoch: 240 [1280/60000 (2%)]\tLoss: 727.437317\n",
            "Train Epoch: 240 [2560/60000 (4%)]\tLoss: 706.230591\n",
            "Train Epoch: 240 [3840/60000 (6%)]\tLoss: 711.653992\n",
            "Train Epoch: 240 [5120/60000 (9%)]\tLoss: 745.310669\n",
            "Train Epoch: 240 [6400/60000 (11%)]\tLoss: 754.343994\n",
            "Train Epoch: 240 [7680/60000 (13%)]\tLoss: 731.549622\n",
            "Train Epoch: 240 [8960/60000 (15%)]\tLoss: 736.139343\n",
            "Train Epoch: 240 [10240/60000 (17%)]\tLoss: 713.215332\n",
            "Train Epoch: 240 [11520/60000 (19%)]\tLoss: 734.256226\n",
            "Train Epoch: 240 [12800/60000 (21%)]\tLoss: 696.217163\n",
            "Train Epoch: 240 [14080/60000 (23%)]\tLoss: 747.972168\n",
            "Train Epoch: 240 [15360/60000 (26%)]\tLoss: 732.060059\n",
            "Train Epoch: 240 [16640/60000 (28%)]\tLoss: 721.814331\n",
            "Train Epoch: 240 [17920/60000 (30%)]\tLoss: 732.791931\n",
            "Train Epoch: 240 [19200/60000 (32%)]\tLoss: 741.199341\n",
            "Train Epoch: 240 [20480/60000 (34%)]\tLoss: 730.842224\n",
            "Train Epoch: 240 [21760/60000 (36%)]\tLoss: 766.612610\n",
            "Train Epoch: 240 [23040/60000 (38%)]\tLoss: 744.825806\n",
            "Train Epoch: 240 [24320/60000 (41%)]\tLoss: 733.850464\n",
            "Train Epoch: 240 [25600/60000 (43%)]\tLoss: 745.092896\n",
            "Train Epoch: 240 [26880/60000 (45%)]\tLoss: 738.237366\n",
            "Train Epoch: 240 [28160/60000 (47%)]\tLoss: 762.932800\n",
            "Train Epoch: 240 [29440/60000 (49%)]\tLoss: 748.602783\n",
            "Train Epoch: 240 [30720/60000 (51%)]\tLoss: 732.221985\n",
            "Train Epoch: 240 [32000/60000 (53%)]\tLoss: 749.310120\n",
            "Train Epoch: 240 [33280/60000 (55%)]\tLoss: 752.911194\n",
            "Train Epoch: 240 [34560/60000 (58%)]\tLoss: 743.685486\n",
            "Train Epoch: 240 [35840/60000 (60%)]\tLoss: 740.679749\n",
            "Train Epoch: 240 [37120/60000 (62%)]\tLoss: 720.185852\n",
            "Train Epoch: 240 [38400/60000 (64%)]\tLoss: 753.977600\n",
            "Train Epoch: 240 [39680/60000 (66%)]\tLoss: 738.313354\n",
            "Train Epoch: 240 [40960/60000 (68%)]\tLoss: 725.899109\n",
            "Train Epoch: 240 [42240/60000 (70%)]\tLoss: 760.275330\n",
            "Train Epoch: 240 [43520/60000 (72%)]\tLoss: 733.118164\n",
            "Train Epoch: 240 [44800/60000 (75%)]\tLoss: 757.864685\n",
            "Train Epoch: 240 [46080/60000 (77%)]\tLoss: 732.519409\n",
            "Train Epoch: 240 [47360/60000 (79%)]\tLoss: 744.396545\n",
            "Train Epoch: 240 [48640/60000 (81%)]\tLoss: 752.130371\n",
            "Train Epoch: 240 [49920/60000 (83%)]\tLoss: 745.772339\n",
            "Train Epoch: 240 [51200/60000 (85%)]\tLoss: 718.894348\n",
            "Train Epoch: 240 [52480/60000 (87%)]\tLoss: 753.264893\n",
            "Train Epoch: 240 [53760/60000 (90%)]\tLoss: 715.673340\n",
            "Train Epoch: 240 [55040/60000 (92%)]\tLoss: 746.576843\n",
            "Train Epoch: 240 [56320/60000 (94%)]\tLoss: 726.434082\n",
            "Train Epoch: 240 [57600/60000 (96%)]\tLoss: 763.882812\n",
            "Train Epoch: 240 [58880/60000 (98%)]\tLoss: 703.740356\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978401243686676\n",
            "\n",
            "Train Epoch: 241 [0/60000 (0%)]\tLoss: 739.660828\n",
            "Train Epoch: 241 [1280/60000 (2%)]\tLoss: 753.128784\n",
            "Train Epoch: 241 [2560/60000 (4%)]\tLoss: 722.367126\n",
            "Train Epoch: 241 [3840/60000 (6%)]\tLoss: 725.737000\n",
            "Train Epoch: 241 [5120/60000 (9%)]\tLoss: 738.657166\n",
            "Train Epoch: 241 [6400/60000 (11%)]\tLoss: 753.959351\n",
            "Train Epoch: 241 [7680/60000 (13%)]\tLoss: 728.603271\n",
            "Train Epoch: 241 [8960/60000 (15%)]\tLoss: 733.795837\n",
            "Train Epoch: 241 [10240/60000 (17%)]\tLoss: 763.542908\n",
            "Train Epoch: 241 [11520/60000 (19%)]\tLoss: 743.057190\n",
            "Train Epoch: 241 [12800/60000 (21%)]\tLoss: 732.590637\n",
            "Train Epoch: 241 [14080/60000 (23%)]\tLoss: 748.512085\n",
            "Train Epoch: 241 [15360/60000 (26%)]\tLoss: 727.411194\n",
            "Train Epoch: 241 [16640/60000 (28%)]\tLoss: 747.735657\n",
            "Train Epoch: 241 [17920/60000 (30%)]\tLoss: 737.328857\n",
            "Train Epoch: 241 [19200/60000 (32%)]\tLoss: 751.141785\n",
            "Train Epoch: 241 [20480/60000 (34%)]\tLoss: 750.373657\n",
            "Train Epoch: 241 [21760/60000 (36%)]\tLoss: 718.388489\n",
            "Train Epoch: 241 [23040/60000 (38%)]\tLoss: 737.701965\n",
            "Train Epoch: 241 [24320/60000 (41%)]\tLoss: 758.306885\n",
            "Train Epoch: 241 [25600/60000 (43%)]\tLoss: 743.000305\n",
            "Train Epoch: 241 [26880/60000 (45%)]\tLoss: 749.304810\n",
            "Train Epoch: 241 [28160/60000 (47%)]\tLoss: 761.041138\n",
            "Train Epoch: 241 [29440/60000 (49%)]\tLoss: 731.703491\n",
            "Train Epoch: 241 [30720/60000 (51%)]\tLoss: 740.041321\n",
            "Train Epoch: 241 [32000/60000 (53%)]\tLoss: 705.932190\n",
            "Train Epoch: 241 [33280/60000 (55%)]\tLoss: 731.956116\n",
            "Train Epoch: 241 [34560/60000 (58%)]\tLoss: 746.413208\n",
            "Train Epoch: 241 [35840/60000 (60%)]\tLoss: 738.580200\n",
            "Train Epoch: 241 [37120/60000 (62%)]\tLoss: 756.042175\n",
            "Train Epoch: 241 [38400/60000 (64%)]\tLoss: 743.359985\n",
            "Train Epoch: 241 [39680/60000 (66%)]\tLoss: 735.587585\n",
            "Train Epoch: 241 [40960/60000 (68%)]\tLoss: 753.526306\n",
            "Train Epoch: 241 [42240/60000 (70%)]\tLoss: 746.652588\n",
            "Train Epoch: 241 [43520/60000 (72%)]\tLoss: 747.237366\n",
            "Train Epoch: 241 [44800/60000 (75%)]\tLoss: 762.279785\n",
            "Train Epoch: 241 [46080/60000 (77%)]\tLoss: 740.393250\n",
            "Train Epoch: 241 [47360/60000 (79%)]\tLoss: 706.271973\n",
            "Train Epoch: 241 [48640/60000 (81%)]\tLoss: 750.491760\n",
            "Train Epoch: 241 [49920/60000 (83%)]\tLoss: 739.956055\n",
            "Train Epoch: 241 [51200/60000 (85%)]\tLoss: 742.358765\n",
            "Train Epoch: 241 [52480/60000 (87%)]\tLoss: 751.327087\n",
            "Train Epoch: 241 [53760/60000 (90%)]\tLoss: 720.979248\n",
            "Train Epoch: 241 [55040/60000 (92%)]\tLoss: 726.400085\n",
            "Train Epoch: 241 [56320/60000 (94%)]\tLoss: 738.662720\n",
            "Train Epoch: 241 [57600/60000 (96%)]\tLoss: 736.459412\n",
            "Train Epoch: 241 [58880/60000 (98%)]\tLoss: 741.129333\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783353805541992\n",
            "\n",
            "Train Epoch: 242 [0/60000 (0%)]\tLoss: 728.235840\n",
            "Train Epoch: 242 [1280/60000 (2%)]\tLoss: 743.862061\n",
            "Train Epoch: 242 [2560/60000 (4%)]\tLoss: 741.843872\n",
            "Train Epoch: 242 [3840/60000 (6%)]\tLoss: 730.775452\n",
            "Train Epoch: 242 [5120/60000 (9%)]\tLoss: 751.049194\n",
            "Train Epoch: 242 [6400/60000 (11%)]\tLoss: 746.486084\n",
            "Train Epoch: 242 [7680/60000 (13%)]\tLoss: 712.580139\n",
            "Train Epoch: 242 [8960/60000 (15%)]\tLoss: 744.931946\n",
            "Train Epoch: 242 [10240/60000 (17%)]\tLoss: 754.385376\n",
            "Train Epoch: 242 [11520/60000 (19%)]\tLoss: 748.564148\n",
            "Train Epoch: 242 [12800/60000 (21%)]\tLoss: 753.968201\n",
            "Train Epoch: 242 [14080/60000 (23%)]\tLoss: 735.516052\n",
            "Train Epoch: 242 [15360/60000 (26%)]\tLoss: 759.614380\n",
            "Train Epoch: 242 [16640/60000 (28%)]\tLoss: 732.206787\n",
            "Train Epoch: 242 [17920/60000 (30%)]\tLoss: 739.282166\n",
            "Train Epoch: 242 [19200/60000 (32%)]\tLoss: 742.363159\n",
            "Train Epoch: 242 [20480/60000 (34%)]\tLoss: 749.977661\n",
            "Train Epoch: 242 [21760/60000 (36%)]\tLoss: 743.184875\n",
            "Train Epoch: 242 [23040/60000 (38%)]\tLoss: 718.265381\n",
            "Train Epoch: 242 [24320/60000 (41%)]\tLoss: 751.841736\n",
            "Train Epoch: 242 [25600/60000 (43%)]\tLoss: 736.982910\n",
            "Train Epoch: 242 [26880/60000 (45%)]\tLoss: 750.849121\n",
            "Train Epoch: 242 [28160/60000 (47%)]\tLoss: 748.738770\n",
            "Train Epoch: 242 [29440/60000 (49%)]\tLoss: 743.224915\n",
            "Train Epoch: 242 [30720/60000 (51%)]\tLoss: 744.005493\n",
            "Train Epoch: 242 [32000/60000 (53%)]\tLoss: 755.790466\n",
            "Train Epoch: 242 [33280/60000 (55%)]\tLoss: 750.479248\n",
            "Train Epoch: 242 [34560/60000 (58%)]\tLoss: 742.192810\n",
            "Train Epoch: 242 [35840/60000 (60%)]\tLoss: 740.747375\n",
            "Train Epoch: 242 [37120/60000 (62%)]\tLoss: 733.314087\n",
            "Train Epoch: 242 [38400/60000 (64%)]\tLoss: 747.714966\n",
            "Train Epoch: 242 [39680/60000 (66%)]\tLoss: 739.499817\n",
            "Train Epoch: 242 [40960/60000 (68%)]\tLoss: 734.605591\n",
            "Train Epoch: 242 [42240/60000 (70%)]\tLoss: 725.222961\n",
            "Train Epoch: 242 [43520/60000 (72%)]\tLoss: 705.646606\n",
            "Train Epoch: 242 [44800/60000 (75%)]\tLoss: 752.380493\n",
            "Train Epoch: 242 [46080/60000 (77%)]\tLoss: 721.664062\n",
            "Train Epoch: 242 [47360/60000 (79%)]\tLoss: 761.849609\n",
            "Train Epoch: 242 [48640/60000 (81%)]\tLoss: 747.730042\n",
            "Train Epoch: 242 [49920/60000 (83%)]\tLoss: 720.705078\n",
            "Train Epoch: 242 [51200/60000 (85%)]\tLoss: 730.049805\n",
            "Train Epoch: 242 [52480/60000 (87%)]\tLoss: 737.565552\n",
            "Train Epoch: 242 [53760/60000 (90%)]\tLoss: 744.690308\n",
            "Train Epoch: 242 [55040/60000 (92%)]\tLoss: 728.947754\n",
            "Train Epoch: 242 [56320/60000 (94%)]\tLoss: 739.644470\n",
            "Train Epoch: 242 [57600/60000 (96%)]\tLoss: 740.006104\n",
            "Train Epoch: 242 [58880/60000 (98%)]\tLoss: 737.893494\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781823456287384\n",
            "\n",
            "Train Epoch: 243 [0/60000 (0%)]\tLoss: 710.266663\n",
            "Train Epoch: 243 [1280/60000 (2%)]\tLoss: 754.763123\n",
            "Train Epoch: 243 [2560/60000 (4%)]\tLoss: 726.237793\n",
            "Train Epoch: 243 [3840/60000 (6%)]\tLoss: 733.333069\n",
            "Train Epoch: 243 [5120/60000 (9%)]\tLoss: 730.553101\n",
            "Train Epoch: 243 [6400/60000 (11%)]\tLoss: 754.635620\n",
            "Train Epoch: 243 [7680/60000 (13%)]\tLoss: 727.836487\n",
            "Train Epoch: 243 [8960/60000 (15%)]\tLoss: 743.426636\n",
            "Train Epoch: 243 [10240/60000 (17%)]\tLoss: 740.212769\n",
            "Train Epoch: 243 [11520/60000 (19%)]\tLoss: 724.423584\n",
            "Train Epoch: 243 [12800/60000 (21%)]\tLoss: 720.491882\n",
            "Train Epoch: 243 [14080/60000 (23%)]\tLoss: 716.921143\n",
            "Train Epoch: 243 [15360/60000 (26%)]\tLoss: 739.731018\n",
            "Train Epoch: 243 [16640/60000 (28%)]\tLoss: 732.017334\n",
            "Train Epoch: 243 [17920/60000 (30%)]\tLoss: 724.591125\n",
            "Train Epoch: 243 [19200/60000 (32%)]\tLoss: 734.059570\n",
            "Train Epoch: 243 [20480/60000 (34%)]\tLoss: 753.860962\n",
            "Train Epoch: 243 [21760/60000 (36%)]\tLoss: 749.514404\n",
            "Train Epoch: 243 [23040/60000 (38%)]\tLoss: 756.676819\n",
            "Train Epoch: 243 [24320/60000 (41%)]\tLoss: 722.796448\n",
            "Train Epoch: 243 [25600/60000 (43%)]\tLoss: 748.245972\n",
            "Train Epoch: 243 [26880/60000 (45%)]\tLoss: 747.918579\n",
            "Train Epoch: 243 [28160/60000 (47%)]\tLoss: 725.564270\n",
            "Train Epoch: 243 [29440/60000 (49%)]\tLoss: 758.300659\n",
            "Train Epoch: 243 [30720/60000 (51%)]\tLoss: 736.478333\n",
            "Train Epoch: 243 [32000/60000 (53%)]\tLoss: 736.628723\n",
            "Train Epoch: 243 [33280/60000 (55%)]\tLoss: 744.163147\n",
            "Train Epoch: 243 [34560/60000 (58%)]\tLoss: 704.604431\n",
            "Train Epoch: 243 [35840/60000 (60%)]\tLoss: 719.886841\n",
            "Train Epoch: 243 [37120/60000 (62%)]\tLoss: 740.597168\n",
            "Train Epoch: 243 [38400/60000 (64%)]\tLoss: 751.367676\n",
            "Train Epoch: 243 [39680/60000 (66%)]\tLoss: 732.971924\n",
            "Train Epoch: 243 [40960/60000 (68%)]\tLoss: 765.607910\n",
            "Train Epoch: 243 [42240/60000 (70%)]\tLoss: 740.033875\n",
            "Train Epoch: 243 [43520/60000 (72%)]\tLoss: 711.170288\n",
            "Train Epoch: 243 [44800/60000 (75%)]\tLoss: 742.017700\n",
            "Train Epoch: 243 [46080/60000 (77%)]\tLoss: 713.198669\n",
            "Train Epoch: 243 [47360/60000 (79%)]\tLoss: 738.641907\n",
            "Train Epoch: 243 [48640/60000 (81%)]\tLoss: 729.803101\n",
            "Train Epoch: 243 [49920/60000 (83%)]\tLoss: 726.670349\n",
            "Train Epoch: 243 [51200/60000 (85%)]\tLoss: 740.518433\n",
            "Train Epoch: 243 [52480/60000 (87%)]\tLoss: 739.083313\n",
            "Train Epoch: 243 [53760/60000 (90%)]\tLoss: 722.233398\n",
            "Train Epoch: 243 [55040/60000 (92%)]\tLoss: 723.514099\n",
            "Train Epoch: 243 [56320/60000 (94%)]\tLoss: 746.465698\n",
            "Train Epoch: 243 [57600/60000 (96%)]\tLoss: 734.928162\n",
            "Train Epoch: 243 [58880/60000 (98%)]\tLoss: 735.286133\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782963395118713\n",
            "\n",
            "Train Epoch: 244 [0/60000 (0%)]\tLoss: 734.446472\n",
            "Train Epoch: 244 [1280/60000 (2%)]\tLoss: 726.514099\n",
            "Train Epoch: 244 [2560/60000 (4%)]\tLoss: 730.671875\n",
            "Train Epoch: 244 [3840/60000 (6%)]\tLoss: 727.338196\n",
            "Train Epoch: 244 [5120/60000 (9%)]\tLoss: 726.758301\n",
            "Train Epoch: 244 [6400/60000 (11%)]\tLoss: 714.562317\n",
            "Train Epoch: 244 [7680/60000 (13%)]\tLoss: 731.718384\n",
            "Train Epoch: 244 [8960/60000 (15%)]\tLoss: 736.643860\n",
            "Train Epoch: 244 [10240/60000 (17%)]\tLoss: 710.539185\n",
            "Train Epoch: 244 [11520/60000 (19%)]\tLoss: 761.036926\n",
            "Train Epoch: 244 [12800/60000 (21%)]\tLoss: 708.548645\n",
            "Train Epoch: 244 [14080/60000 (23%)]\tLoss: 728.137207\n",
            "Train Epoch: 244 [15360/60000 (26%)]\tLoss: 733.459351\n",
            "Train Epoch: 244 [16640/60000 (28%)]\tLoss: 725.498779\n",
            "Train Epoch: 244 [17920/60000 (30%)]\tLoss: 746.096619\n",
            "Train Epoch: 244 [19200/60000 (32%)]\tLoss: 723.265686\n",
            "Train Epoch: 244 [20480/60000 (34%)]\tLoss: 736.847473\n",
            "Train Epoch: 244 [21760/60000 (36%)]\tLoss: 724.595337\n",
            "Train Epoch: 244 [23040/60000 (38%)]\tLoss: 720.391846\n",
            "Train Epoch: 244 [24320/60000 (41%)]\tLoss: 724.934143\n",
            "Train Epoch: 244 [25600/60000 (43%)]\tLoss: 723.988892\n",
            "Train Epoch: 244 [26880/60000 (45%)]\tLoss: 728.685791\n",
            "Train Epoch: 244 [28160/60000 (47%)]\tLoss: 730.109131\n",
            "Train Epoch: 244 [29440/60000 (49%)]\tLoss: 748.126587\n",
            "Train Epoch: 244 [30720/60000 (51%)]\tLoss: 762.321472\n",
            "Train Epoch: 244 [32000/60000 (53%)]\tLoss: 712.228210\n",
            "Train Epoch: 244 [33280/60000 (55%)]\tLoss: 717.760559\n",
            "Train Epoch: 244 [34560/60000 (58%)]\tLoss: 743.915283\n",
            "Train Epoch: 244 [35840/60000 (60%)]\tLoss: 740.062073\n",
            "Train Epoch: 244 [37120/60000 (62%)]\tLoss: 745.153992\n",
            "Train Epoch: 244 [38400/60000 (64%)]\tLoss: 749.796387\n",
            "Train Epoch: 244 [39680/60000 (66%)]\tLoss: 726.711792\n",
            "Train Epoch: 244 [40960/60000 (68%)]\tLoss: 730.839111\n",
            "Train Epoch: 244 [42240/60000 (70%)]\tLoss: 742.582947\n",
            "Train Epoch: 244 [43520/60000 (72%)]\tLoss: 742.705933\n",
            "Train Epoch: 244 [44800/60000 (75%)]\tLoss: 750.191406\n",
            "Train Epoch: 244 [46080/60000 (77%)]\tLoss: 741.533203\n",
            "Train Epoch: 244 [47360/60000 (79%)]\tLoss: 741.904541\n",
            "Train Epoch: 244 [48640/60000 (81%)]\tLoss: 735.895691\n",
            "Train Epoch: 244 [49920/60000 (83%)]\tLoss: 728.235229\n",
            "Train Epoch: 244 [51200/60000 (85%)]\tLoss: 734.959717\n",
            "Train Epoch: 244 [52480/60000 (87%)]\tLoss: 747.779907\n",
            "Train Epoch: 244 [53760/60000 (90%)]\tLoss: 734.369019\n",
            "Train Epoch: 244 [55040/60000 (92%)]\tLoss: 728.194641\n",
            "Train Epoch: 244 [56320/60000 (94%)]\tLoss: 733.824097\n",
            "Train Epoch: 244 [57600/60000 (96%)]\tLoss: 746.204224\n",
            "Train Epoch: 244 [58880/60000 (98%)]\tLoss: 738.491211\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978302001953125\n",
            "\n",
            "Train Epoch: 245 [0/60000 (0%)]\tLoss: 743.390442\n",
            "Train Epoch: 245 [1280/60000 (2%)]\tLoss: 713.670044\n",
            "Train Epoch: 245 [2560/60000 (4%)]\tLoss: 726.891602\n",
            "Train Epoch: 245 [3840/60000 (6%)]\tLoss: 725.296753\n",
            "Train Epoch: 245 [5120/60000 (9%)]\tLoss: 728.229736\n",
            "Train Epoch: 245 [6400/60000 (11%)]\tLoss: 747.882263\n",
            "Train Epoch: 245 [7680/60000 (13%)]\tLoss: 719.846313\n",
            "Train Epoch: 245 [8960/60000 (15%)]\tLoss: 749.796692\n",
            "Train Epoch: 245 [10240/60000 (17%)]\tLoss: 747.517273\n",
            "Train Epoch: 245 [11520/60000 (19%)]\tLoss: 719.679260\n",
            "Train Epoch: 245 [12800/60000 (21%)]\tLoss: 749.078064\n",
            "Train Epoch: 245 [14080/60000 (23%)]\tLoss: 761.592163\n",
            "Train Epoch: 245 [15360/60000 (26%)]\tLoss: 724.880249\n",
            "Train Epoch: 245 [16640/60000 (28%)]\tLoss: 730.119934\n",
            "Train Epoch: 245 [17920/60000 (30%)]\tLoss: 755.286194\n",
            "Train Epoch: 245 [19200/60000 (32%)]\tLoss: 704.750122\n",
            "Train Epoch: 245 [20480/60000 (34%)]\tLoss: 727.244934\n",
            "Train Epoch: 245 [21760/60000 (36%)]\tLoss: 740.542786\n",
            "Train Epoch: 245 [23040/60000 (38%)]\tLoss: 747.773560\n",
            "Train Epoch: 245 [24320/60000 (41%)]\tLoss: 722.701111\n",
            "Train Epoch: 245 [25600/60000 (43%)]\tLoss: 748.184204\n",
            "Train Epoch: 245 [26880/60000 (45%)]\tLoss: 731.553650\n",
            "Train Epoch: 245 [28160/60000 (47%)]\tLoss: 735.789307\n",
            "Train Epoch: 245 [29440/60000 (49%)]\tLoss: 737.186157\n",
            "Train Epoch: 245 [30720/60000 (51%)]\tLoss: 728.088623\n",
            "Train Epoch: 245 [32000/60000 (53%)]\tLoss: 729.231201\n",
            "Train Epoch: 245 [33280/60000 (55%)]\tLoss: 738.164001\n",
            "Train Epoch: 245 [34560/60000 (58%)]\tLoss: 723.464294\n",
            "Train Epoch: 245 [35840/60000 (60%)]\tLoss: 733.807129\n",
            "Train Epoch: 245 [37120/60000 (62%)]\tLoss: 716.450562\n",
            "Train Epoch: 245 [38400/60000 (64%)]\tLoss: 740.886597\n",
            "Train Epoch: 245 [39680/60000 (66%)]\tLoss: 731.460999\n",
            "Train Epoch: 245 [40960/60000 (68%)]\tLoss: 736.918457\n",
            "Train Epoch: 245 [42240/60000 (70%)]\tLoss: 744.211365\n",
            "Train Epoch: 245 [43520/60000 (72%)]\tLoss: 714.027344\n",
            "Train Epoch: 245 [44800/60000 (75%)]\tLoss: 738.250671\n",
            "Train Epoch: 245 [46080/60000 (77%)]\tLoss: 752.208740\n",
            "Train Epoch: 245 [47360/60000 (79%)]\tLoss: 731.139343\n",
            "Train Epoch: 245 [48640/60000 (81%)]\tLoss: 733.009521\n",
            "Train Epoch: 245 [49920/60000 (83%)]\tLoss: 744.410034\n",
            "Train Epoch: 245 [51200/60000 (85%)]\tLoss: 722.446228\n",
            "Train Epoch: 245 [52480/60000 (87%)]\tLoss: 765.293030\n",
            "Train Epoch: 245 [53760/60000 (90%)]\tLoss: 722.685364\n",
            "Train Epoch: 245 [55040/60000 (92%)]\tLoss: 742.620972\n",
            "Train Epoch: 245 [56320/60000 (94%)]\tLoss: 741.340088\n",
            "Train Epoch: 245 [57600/60000 (96%)]\tLoss: 747.248352\n",
            "Train Epoch: 245 [58880/60000 (98%)]\tLoss: 738.027710\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978282630443573\n",
            "\n",
            "Train Epoch: 246 [0/60000 (0%)]\tLoss: 723.473999\n",
            "Train Epoch: 246 [1280/60000 (2%)]\tLoss: 757.528870\n",
            "Train Epoch: 246 [2560/60000 (4%)]\tLoss: 719.058594\n",
            "Train Epoch: 246 [3840/60000 (6%)]\tLoss: 748.249146\n",
            "Train Epoch: 246 [5120/60000 (9%)]\tLoss: 739.010925\n",
            "Train Epoch: 246 [6400/60000 (11%)]\tLoss: 756.147400\n",
            "Train Epoch: 246 [7680/60000 (13%)]\tLoss: 747.491760\n",
            "Train Epoch: 246 [8960/60000 (15%)]\tLoss: 728.410095\n",
            "Train Epoch: 246 [10240/60000 (17%)]\tLoss: 747.889160\n",
            "Train Epoch: 246 [11520/60000 (19%)]\tLoss: 730.323792\n",
            "Train Epoch: 246 [12800/60000 (21%)]\tLoss: 743.297668\n",
            "Train Epoch: 246 [14080/60000 (23%)]\tLoss: 736.002441\n",
            "Train Epoch: 246 [15360/60000 (26%)]\tLoss: 731.871643\n",
            "Train Epoch: 246 [16640/60000 (28%)]\tLoss: 745.861572\n",
            "Train Epoch: 246 [17920/60000 (30%)]\tLoss: 748.272400\n",
            "Train Epoch: 246 [19200/60000 (32%)]\tLoss: 750.664856\n",
            "Train Epoch: 246 [20480/60000 (34%)]\tLoss: 728.053467\n",
            "Train Epoch: 246 [21760/60000 (36%)]\tLoss: 742.403015\n",
            "Train Epoch: 246 [23040/60000 (38%)]\tLoss: 731.984009\n",
            "Train Epoch: 246 [24320/60000 (41%)]\tLoss: 729.439148\n",
            "Train Epoch: 246 [25600/60000 (43%)]\tLoss: 707.537659\n",
            "Train Epoch: 246 [26880/60000 (45%)]\tLoss: 730.444458\n",
            "Train Epoch: 246 [28160/60000 (47%)]\tLoss: 730.255554\n",
            "Train Epoch: 246 [29440/60000 (49%)]\tLoss: 736.524170\n",
            "Train Epoch: 246 [30720/60000 (51%)]\tLoss: 735.962524\n",
            "Train Epoch: 246 [32000/60000 (53%)]\tLoss: 755.824219\n",
            "Train Epoch: 246 [33280/60000 (55%)]\tLoss: 748.208435\n",
            "Train Epoch: 246 [34560/60000 (58%)]\tLoss: 745.646423\n",
            "Train Epoch: 246 [35840/60000 (60%)]\tLoss: 736.895203\n",
            "Train Epoch: 246 [37120/60000 (62%)]\tLoss: 769.658508\n",
            "Train Epoch: 246 [38400/60000 (64%)]\tLoss: 745.649780\n",
            "Train Epoch: 246 [39680/60000 (66%)]\tLoss: 757.535278\n",
            "Train Epoch: 246 [40960/60000 (68%)]\tLoss: 732.020386\n",
            "Train Epoch: 246 [42240/60000 (70%)]\tLoss: 730.964905\n",
            "Train Epoch: 246 [43520/60000 (72%)]\tLoss: 725.122620\n",
            "Train Epoch: 246 [44800/60000 (75%)]\tLoss: 730.430420\n",
            "Train Epoch: 246 [46080/60000 (77%)]\tLoss: 728.065247\n",
            "Train Epoch: 246 [47360/60000 (79%)]\tLoss: 724.108337\n",
            "Train Epoch: 246 [48640/60000 (81%)]\tLoss: 712.462585\n",
            "Train Epoch: 246 [49920/60000 (83%)]\tLoss: 734.659058\n",
            "Train Epoch: 246 [51200/60000 (85%)]\tLoss: 737.473328\n",
            "Train Epoch: 246 [52480/60000 (87%)]\tLoss: 736.927734\n",
            "Train Epoch: 246 [53760/60000 (90%)]\tLoss: 735.252319\n",
            "Train Epoch: 246 [55040/60000 (92%)]\tLoss: 733.580566\n",
            "Train Epoch: 246 [56320/60000 (94%)]\tLoss: 732.153137\n",
            "Train Epoch: 246 [57600/60000 (96%)]\tLoss: 728.488831\n",
            "Train Epoch: 246 [58880/60000 (98%)]\tLoss: 723.755554\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784823060035706\n",
            "\n",
            "Train Epoch: 247 [0/60000 (0%)]\tLoss: 747.123596\n",
            "Train Epoch: 247 [1280/60000 (2%)]\tLoss: 758.737671\n",
            "Train Epoch: 247 [2560/60000 (4%)]\tLoss: 733.972473\n",
            "Train Epoch: 247 [3840/60000 (6%)]\tLoss: 734.675354\n",
            "Train Epoch: 247 [5120/60000 (9%)]\tLoss: 715.648499\n",
            "Train Epoch: 247 [6400/60000 (11%)]\tLoss: 744.815063\n",
            "Train Epoch: 247 [7680/60000 (13%)]\tLoss: 739.379700\n",
            "Train Epoch: 247 [8960/60000 (15%)]\tLoss: 748.528198\n",
            "Train Epoch: 247 [10240/60000 (17%)]\tLoss: 751.022766\n",
            "Train Epoch: 247 [11520/60000 (19%)]\tLoss: 761.106812\n",
            "Train Epoch: 247 [12800/60000 (21%)]\tLoss: 727.430115\n",
            "Train Epoch: 247 [14080/60000 (23%)]\tLoss: 719.160278\n",
            "Train Epoch: 247 [15360/60000 (26%)]\tLoss: 716.735962\n",
            "Train Epoch: 247 [16640/60000 (28%)]\tLoss: 726.241699\n",
            "Train Epoch: 247 [17920/60000 (30%)]\tLoss: 724.851501\n",
            "Train Epoch: 247 [19200/60000 (32%)]\tLoss: 749.104858\n",
            "Train Epoch: 247 [20480/60000 (34%)]\tLoss: 745.151672\n",
            "Train Epoch: 247 [21760/60000 (36%)]\tLoss: 750.074585\n",
            "Train Epoch: 247 [23040/60000 (38%)]\tLoss: 734.611084\n",
            "Train Epoch: 247 [24320/60000 (41%)]\tLoss: 746.455811\n",
            "Train Epoch: 247 [25600/60000 (43%)]\tLoss: 745.649048\n",
            "Train Epoch: 247 [26880/60000 (45%)]\tLoss: 739.940796\n",
            "Train Epoch: 247 [28160/60000 (47%)]\tLoss: 737.735291\n",
            "Train Epoch: 247 [29440/60000 (49%)]\tLoss: 726.097046\n",
            "Train Epoch: 247 [30720/60000 (51%)]\tLoss: 750.602356\n",
            "Train Epoch: 247 [32000/60000 (53%)]\tLoss: 736.737549\n",
            "Train Epoch: 247 [33280/60000 (55%)]\tLoss: 719.468994\n",
            "Train Epoch: 247 [34560/60000 (58%)]\tLoss: 748.303467\n",
            "Train Epoch: 247 [35840/60000 (60%)]\tLoss: 746.800110\n",
            "Train Epoch: 247 [37120/60000 (62%)]\tLoss: 699.956360\n",
            "Train Epoch: 247 [38400/60000 (64%)]\tLoss: 713.394043\n",
            "Train Epoch: 247 [39680/60000 (66%)]\tLoss: 759.668091\n",
            "Train Epoch: 247 [40960/60000 (68%)]\tLoss: 724.893311\n",
            "Train Epoch: 247 [42240/60000 (70%)]\tLoss: 719.722900\n",
            "Train Epoch: 247 [43520/60000 (72%)]\tLoss: 721.095825\n",
            "Train Epoch: 247 [44800/60000 (75%)]\tLoss: 736.267090\n",
            "Train Epoch: 247 [46080/60000 (77%)]\tLoss: 756.475159\n",
            "Train Epoch: 247 [47360/60000 (79%)]\tLoss: 734.194580\n",
            "Train Epoch: 247 [48640/60000 (81%)]\tLoss: 721.734680\n",
            "Train Epoch: 247 [49920/60000 (83%)]\tLoss: 745.498474\n",
            "Train Epoch: 247 [51200/60000 (85%)]\tLoss: 744.298462\n",
            "Train Epoch: 247 [52480/60000 (87%)]\tLoss: 749.373474\n",
            "Train Epoch: 247 [53760/60000 (90%)]\tLoss: 756.193909\n",
            "Train Epoch: 247 [55040/60000 (92%)]\tLoss: 730.277710\n",
            "Train Epoch: 247 [56320/60000 (94%)]\tLoss: 723.537720\n",
            "Train Epoch: 247 [57600/60000 (96%)]\tLoss: 741.091736\n",
            "Train Epoch: 247 [58880/60000 (98%)]\tLoss: 726.086182\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781798124313354\n",
            "\n",
            "Train Epoch: 248 [0/60000 (0%)]\tLoss: 734.801208\n",
            "Train Epoch: 248 [1280/60000 (2%)]\tLoss: 744.073975\n",
            "Train Epoch: 248 [2560/60000 (4%)]\tLoss: 740.309021\n",
            "Train Epoch: 248 [3840/60000 (6%)]\tLoss: 711.674561\n",
            "Train Epoch: 248 [5120/60000 (9%)]\tLoss: 724.564880\n",
            "Train Epoch: 248 [6400/60000 (11%)]\tLoss: 729.595825\n",
            "Train Epoch: 248 [7680/60000 (13%)]\tLoss: 734.286499\n",
            "Train Epoch: 248 [8960/60000 (15%)]\tLoss: 740.370850\n",
            "Train Epoch: 248 [10240/60000 (17%)]\tLoss: 754.691223\n",
            "Train Epoch: 248 [11520/60000 (19%)]\tLoss: 762.251709\n",
            "Train Epoch: 248 [12800/60000 (21%)]\tLoss: 734.090515\n",
            "Train Epoch: 248 [14080/60000 (23%)]\tLoss: 702.489258\n",
            "Train Epoch: 248 [15360/60000 (26%)]\tLoss: 721.556335\n",
            "Train Epoch: 248 [16640/60000 (28%)]\tLoss: 726.814331\n",
            "Train Epoch: 248 [17920/60000 (30%)]\tLoss: 730.333679\n",
            "Train Epoch: 248 [19200/60000 (32%)]\tLoss: 755.670410\n",
            "Train Epoch: 248 [20480/60000 (34%)]\tLoss: 745.759033\n",
            "Train Epoch: 248 [21760/60000 (36%)]\tLoss: 721.455811\n",
            "Train Epoch: 248 [23040/60000 (38%)]\tLoss: 718.162476\n",
            "Train Epoch: 248 [24320/60000 (41%)]\tLoss: 734.362488\n",
            "Train Epoch: 248 [25600/60000 (43%)]\tLoss: 730.358704\n",
            "Train Epoch: 248 [26880/60000 (45%)]\tLoss: 746.734192\n",
            "Train Epoch: 248 [28160/60000 (47%)]\tLoss: 740.023743\n",
            "Train Epoch: 248 [29440/60000 (49%)]\tLoss: 734.314575\n",
            "Train Epoch: 248 [30720/60000 (51%)]\tLoss: 721.765381\n",
            "Train Epoch: 248 [32000/60000 (53%)]\tLoss: 738.311829\n",
            "Train Epoch: 248 [33280/60000 (55%)]\tLoss: 736.318726\n",
            "Train Epoch: 248 [34560/60000 (58%)]\tLoss: 764.906677\n",
            "Train Epoch: 248 [35840/60000 (60%)]\tLoss: 731.846375\n",
            "Train Epoch: 248 [37120/60000 (62%)]\tLoss: 720.988403\n",
            "Train Epoch: 248 [38400/60000 (64%)]\tLoss: 732.637817\n",
            "Train Epoch: 248 [39680/60000 (66%)]\tLoss: 752.689880\n",
            "Train Epoch: 248 [40960/60000 (68%)]\tLoss: 728.637146\n",
            "Train Epoch: 248 [42240/60000 (70%)]\tLoss: 739.599304\n",
            "Train Epoch: 248 [43520/60000 (72%)]\tLoss: 718.385254\n",
            "Train Epoch: 248 [44800/60000 (75%)]\tLoss: 728.640198\n",
            "Train Epoch: 248 [46080/60000 (77%)]\tLoss: 729.236633\n",
            "Train Epoch: 248 [47360/60000 (79%)]\tLoss: 729.563171\n",
            "Train Epoch: 248 [48640/60000 (81%)]\tLoss: 709.763611\n",
            "Train Epoch: 248 [49920/60000 (83%)]\tLoss: 722.321838\n",
            "Train Epoch: 248 [51200/60000 (85%)]\tLoss: 742.102600\n",
            "Train Epoch: 248 [52480/60000 (87%)]\tLoss: 732.875122\n",
            "Train Epoch: 248 [53760/60000 (90%)]\tLoss: 743.102539\n",
            "Train Epoch: 248 [55040/60000 (92%)]\tLoss: 732.972595\n",
            "Train Epoch: 248 [56320/60000 (94%)]\tLoss: 744.343628\n",
            "Train Epoch: 248 [57600/60000 (96%)]\tLoss: 731.490662\n",
            "Train Epoch: 248 [58880/60000 (98%)]\tLoss: 744.181641\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978435069322586\n",
            "\n",
            "Train Epoch: 249 [0/60000 (0%)]\tLoss: 726.446350\n",
            "Train Epoch: 249 [1280/60000 (2%)]\tLoss: 743.868958\n",
            "Train Epoch: 249 [2560/60000 (4%)]\tLoss: 732.355042\n",
            "Train Epoch: 249 [3840/60000 (6%)]\tLoss: 713.479004\n",
            "Train Epoch: 249 [5120/60000 (9%)]\tLoss: 751.311523\n",
            "Train Epoch: 249 [6400/60000 (11%)]\tLoss: 751.785583\n",
            "Train Epoch: 249 [7680/60000 (13%)]\tLoss: 718.918091\n",
            "Train Epoch: 249 [8960/60000 (15%)]\tLoss: 720.123352\n",
            "Train Epoch: 249 [10240/60000 (17%)]\tLoss: 726.875854\n",
            "Train Epoch: 249 [11520/60000 (19%)]\tLoss: 731.133545\n",
            "Train Epoch: 249 [12800/60000 (21%)]\tLoss: 699.623474\n",
            "Train Epoch: 249 [14080/60000 (23%)]\tLoss: 720.299194\n",
            "Train Epoch: 249 [15360/60000 (26%)]\tLoss: 724.242065\n",
            "Train Epoch: 249 [16640/60000 (28%)]\tLoss: 718.729065\n",
            "Train Epoch: 249 [17920/60000 (30%)]\tLoss: 731.351196\n",
            "Train Epoch: 249 [19200/60000 (32%)]\tLoss: 741.147644\n",
            "Train Epoch: 249 [20480/60000 (34%)]\tLoss: 733.545532\n",
            "Train Epoch: 249 [21760/60000 (36%)]\tLoss: 740.952881\n",
            "Train Epoch: 249 [23040/60000 (38%)]\tLoss: 739.673523\n",
            "Train Epoch: 249 [24320/60000 (41%)]\tLoss: 745.374268\n",
            "Train Epoch: 249 [25600/60000 (43%)]\tLoss: 729.152710\n",
            "Train Epoch: 249 [26880/60000 (45%)]\tLoss: 725.018677\n",
            "Train Epoch: 249 [28160/60000 (47%)]\tLoss: 744.190125\n",
            "Train Epoch: 249 [29440/60000 (49%)]\tLoss: 715.856812\n",
            "Train Epoch: 249 [30720/60000 (51%)]\tLoss: 728.852234\n",
            "Train Epoch: 249 [32000/60000 (53%)]\tLoss: 701.859070\n",
            "Train Epoch: 249 [33280/60000 (55%)]\tLoss: 744.473572\n",
            "Train Epoch: 249 [34560/60000 (58%)]\tLoss: 753.352966\n",
            "Train Epoch: 249 [35840/60000 (60%)]\tLoss: 699.410706\n",
            "Train Epoch: 249 [37120/60000 (62%)]\tLoss: 717.988708\n",
            "Train Epoch: 249 [38400/60000 (64%)]\tLoss: 728.666992\n",
            "Train Epoch: 249 [39680/60000 (66%)]\tLoss: 736.048279\n",
            "Train Epoch: 249 [40960/60000 (68%)]\tLoss: 748.395325\n",
            "Train Epoch: 249 [42240/60000 (70%)]\tLoss: 740.266052\n",
            "Train Epoch: 249 [43520/60000 (72%)]\tLoss: 738.726013\n",
            "Train Epoch: 249 [44800/60000 (75%)]\tLoss: 739.090088\n",
            "Train Epoch: 249 [46080/60000 (77%)]\tLoss: 729.111206\n",
            "Train Epoch: 249 [47360/60000 (79%)]\tLoss: 739.791748\n",
            "Train Epoch: 249 [48640/60000 (81%)]\tLoss: 761.937012\n",
            "Train Epoch: 249 [49920/60000 (83%)]\tLoss: 746.372131\n",
            "Train Epoch: 249 [51200/60000 (85%)]\tLoss: 739.660339\n",
            "Train Epoch: 249 [52480/60000 (87%)]\tLoss: 741.484558\n",
            "Train Epoch: 249 [53760/60000 (90%)]\tLoss: 748.679504\n",
            "Train Epoch: 249 [55040/60000 (92%)]\tLoss: 746.099060\n",
            "Train Epoch: 249 [56320/60000 (94%)]\tLoss: 741.681091\n",
            "Train Epoch: 249 [57600/60000 (96%)]\tLoss: 733.835449\n",
            "Train Epoch: 249 [58880/60000 (98%)]\tLoss: 755.205933\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783248007297516\n",
            "\n",
            "Train Epoch: 250 [0/60000 (0%)]\tLoss: 726.208862\n",
            "Train Epoch: 250 [1280/60000 (2%)]\tLoss: 719.762817\n",
            "Train Epoch: 250 [2560/60000 (4%)]\tLoss: 733.567627\n",
            "Train Epoch: 250 [3840/60000 (6%)]\tLoss: 723.274719\n",
            "Train Epoch: 250 [5120/60000 (9%)]\tLoss: 727.995117\n",
            "Train Epoch: 250 [6400/60000 (11%)]\tLoss: 759.684570\n",
            "Train Epoch: 250 [7680/60000 (13%)]\tLoss: 757.228699\n",
            "Train Epoch: 250 [8960/60000 (15%)]\tLoss: 742.942444\n",
            "Train Epoch: 250 [10240/60000 (17%)]\tLoss: 721.948547\n",
            "Train Epoch: 250 [11520/60000 (19%)]\tLoss: 723.178101\n",
            "Train Epoch: 250 [12800/60000 (21%)]\tLoss: 736.268250\n",
            "Train Epoch: 250 [14080/60000 (23%)]\tLoss: 737.036865\n",
            "Train Epoch: 250 [15360/60000 (26%)]\tLoss: 713.655029\n",
            "Train Epoch: 250 [16640/60000 (28%)]\tLoss: 722.470886\n",
            "Train Epoch: 250 [17920/60000 (30%)]\tLoss: 752.980164\n",
            "Train Epoch: 250 [19200/60000 (32%)]\tLoss: 742.697571\n",
            "Train Epoch: 250 [20480/60000 (34%)]\tLoss: 721.141785\n",
            "Train Epoch: 250 [21760/60000 (36%)]\tLoss: 767.298035\n",
            "Train Epoch: 250 [23040/60000 (38%)]\tLoss: 754.615356\n",
            "Train Epoch: 250 [24320/60000 (41%)]\tLoss: 749.347290\n",
            "Train Epoch: 250 [25600/60000 (43%)]\tLoss: 730.859009\n",
            "Train Epoch: 250 [26880/60000 (45%)]\tLoss: 741.674988\n",
            "Train Epoch: 250 [28160/60000 (47%)]\tLoss: 742.368958\n",
            "Train Epoch: 250 [29440/60000 (49%)]\tLoss: 737.715088\n",
            "Train Epoch: 250 [30720/60000 (51%)]\tLoss: 759.779175\n",
            "Train Epoch: 250 [32000/60000 (53%)]\tLoss: 736.671326\n",
            "Train Epoch: 250 [33280/60000 (55%)]\tLoss: 720.487366\n",
            "Train Epoch: 250 [34560/60000 (58%)]\tLoss: 721.008423\n",
            "Train Epoch: 250 [35840/60000 (60%)]\tLoss: 747.477234\n",
            "Train Epoch: 250 [37120/60000 (62%)]\tLoss: 744.681335\n",
            "Train Epoch: 250 [38400/60000 (64%)]\tLoss: 734.339600\n",
            "Train Epoch: 250 [39680/60000 (66%)]\tLoss: 736.692200\n",
            "Train Epoch: 250 [40960/60000 (68%)]\tLoss: 757.749878\n",
            "Train Epoch: 250 [42240/60000 (70%)]\tLoss: 728.708801\n",
            "Train Epoch: 250 [43520/60000 (72%)]\tLoss: 733.073425\n",
            "Train Epoch: 250 [44800/60000 (75%)]\tLoss: 709.380859\n",
            "Train Epoch: 250 [46080/60000 (77%)]\tLoss: 728.880676\n",
            "Train Epoch: 250 [47360/60000 (79%)]\tLoss: 747.462830\n",
            "Train Epoch: 250 [48640/60000 (81%)]\tLoss: 748.804810\n",
            "Train Epoch: 250 [49920/60000 (83%)]\tLoss: 738.982971\n",
            "Train Epoch: 250 [51200/60000 (85%)]\tLoss: 729.592896\n",
            "Train Epoch: 250 [52480/60000 (87%)]\tLoss: 729.234009\n",
            "Train Epoch: 250 [53760/60000 (90%)]\tLoss: 745.960083\n",
            "Train Epoch: 250 [55040/60000 (92%)]\tLoss: 720.886047\n",
            "Train Epoch: 250 [56320/60000 (94%)]\tLoss: 763.820862\n",
            "Train Epoch: 250 [57600/60000 (96%)]\tLoss: 726.657654\n",
            "Train Epoch: 250 [58880/60000 (98%)]\tLoss: 763.211426\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978720873594284\n",
            "\n",
            "Train Epoch: 251 [0/60000 (0%)]\tLoss: 733.592407\n",
            "Train Epoch: 251 [1280/60000 (2%)]\tLoss: 711.745544\n",
            "Train Epoch: 251 [2560/60000 (4%)]\tLoss: 743.136108\n",
            "Train Epoch: 251 [3840/60000 (6%)]\tLoss: 736.321777\n",
            "Train Epoch: 251 [5120/60000 (9%)]\tLoss: 743.267090\n",
            "Train Epoch: 251 [6400/60000 (11%)]\tLoss: 742.334167\n",
            "Train Epoch: 251 [7680/60000 (13%)]\tLoss: 721.945190\n",
            "Train Epoch: 251 [8960/60000 (15%)]\tLoss: 720.409302\n",
            "Train Epoch: 251 [10240/60000 (17%)]\tLoss: 723.897888\n",
            "Train Epoch: 251 [11520/60000 (19%)]\tLoss: 746.898865\n",
            "Train Epoch: 251 [12800/60000 (21%)]\tLoss: 751.832153\n",
            "Train Epoch: 251 [14080/60000 (23%)]\tLoss: 715.385071\n",
            "Train Epoch: 251 [15360/60000 (26%)]\tLoss: 737.259827\n",
            "Train Epoch: 251 [16640/60000 (28%)]\tLoss: 731.710815\n",
            "Train Epoch: 251 [17920/60000 (30%)]\tLoss: 754.793640\n",
            "Train Epoch: 251 [19200/60000 (32%)]\tLoss: 714.966431\n",
            "Train Epoch: 251 [20480/60000 (34%)]\tLoss: 725.655884\n",
            "Train Epoch: 251 [21760/60000 (36%)]\tLoss: 741.531433\n",
            "Train Epoch: 251 [23040/60000 (38%)]\tLoss: 729.291565\n",
            "Train Epoch: 251 [24320/60000 (41%)]\tLoss: 704.081238\n",
            "Train Epoch: 251 [25600/60000 (43%)]\tLoss: 738.471069\n",
            "Train Epoch: 251 [26880/60000 (45%)]\tLoss: 737.533936\n",
            "Train Epoch: 251 [28160/60000 (47%)]\tLoss: 742.069397\n",
            "Train Epoch: 251 [29440/60000 (49%)]\tLoss: 749.902832\n",
            "Train Epoch: 251 [30720/60000 (51%)]\tLoss: 735.157410\n",
            "Train Epoch: 251 [32000/60000 (53%)]\tLoss: 745.226318\n",
            "Train Epoch: 251 [33280/60000 (55%)]\tLoss: 718.160950\n",
            "Train Epoch: 251 [34560/60000 (58%)]\tLoss: 725.882080\n",
            "Train Epoch: 251 [35840/60000 (60%)]\tLoss: 762.116516\n",
            "Train Epoch: 251 [37120/60000 (62%)]\tLoss: 736.231812\n",
            "Train Epoch: 251 [38400/60000 (64%)]\tLoss: 743.069702\n",
            "Train Epoch: 251 [39680/60000 (66%)]\tLoss: 773.971313\n",
            "Train Epoch: 251 [40960/60000 (68%)]\tLoss: 754.864319\n",
            "Train Epoch: 251 [42240/60000 (70%)]\tLoss: 728.729736\n",
            "Train Epoch: 251 [43520/60000 (72%)]\tLoss: 728.228088\n",
            "Train Epoch: 251 [44800/60000 (75%)]\tLoss: 714.837341\n",
            "Train Epoch: 251 [46080/60000 (77%)]\tLoss: 732.923401\n",
            "Train Epoch: 251 [47360/60000 (79%)]\tLoss: 732.885986\n",
            "Train Epoch: 251 [48640/60000 (81%)]\tLoss: 728.406311\n",
            "Train Epoch: 251 [49920/60000 (83%)]\tLoss: 718.937439\n",
            "Train Epoch: 251 [51200/60000 (85%)]\tLoss: 728.087830\n",
            "Train Epoch: 251 [52480/60000 (87%)]\tLoss: 725.237732\n",
            "Train Epoch: 251 [53760/60000 (90%)]\tLoss: 732.773132\n",
            "Train Epoch: 251 [55040/60000 (92%)]\tLoss: 748.128967\n",
            "Train Epoch: 251 [56320/60000 (94%)]\tLoss: 723.979431\n",
            "Train Epoch: 251 [57600/60000 (96%)]\tLoss: 728.032471\n",
            "Train Epoch: 251 [58880/60000 (98%)]\tLoss: 740.752136\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783520698547363\n",
            "\n",
            "Train Epoch: 252 [0/60000 (0%)]\tLoss: 740.041382\n",
            "Train Epoch: 252 [1280/60000 (2%)]\tLoss: 741.465820\n",
            "Train Epoch: 252 [2560/60000 (4%)]\tLoss: 724.275146\n",
            "Train Epoch: 252 [3840/60000 (6%)]\tLoss: 731.817017\n",
            "Train Epoch: 252 [5120/60000 (9%)]\tLoss: 729.259827\n",
            "Train Epoch: 252 [6400/60000 (11%)]\tLoss: 743.835327\n",
            "Train Epoch: 252 [7680/60000 (13%)]\tLoss: 723.580200\n",
            "Train Epoch: 252 [8960/60000 (15%)]\tLoss: 737.926331\n",
            "Train Epoch: 252 [10240/60000 (17%)]\tLoss: 737.246277\n",
            "Train Epoch: 252 [11520/60000 (19%)]\tLoss: 761.183350\n",
            "Train Epoch: 252 [12800/60000 (21%)]\tLoss: 743.604553\n",
            "Train Epoch: 252 [14080/60000 (23%)]\tLoss: 743.207458\n",
            "Train Epoch: 252 [15360/60000 (26%)]\tLoss: 754.124817\n",
            "Train Epoch: 252 [16640/60000 (28%)]\tLoss: 721.641479\n",
            "Train Epoch: 252 [17920/60000 (30%)]\tLoss: 725.708374\n",
            "Train Epoch: 252 [19200/60000 (32%)]\tLoss: 740.420105\n",
            "Train Epoch: 252 [20480/60000 (34%)]\tLoss: 723.145569\n",
            "Train Epoch: 252 [21760/60000 (36%)]\tLoss: 736.577515\n",
            "Train Epoch: 252 [23040/60000 (38%)]\tLoss: 729.754700\n",
            "Train Epoch: 252 [24320/60000 (41%)]\tLoss: 735.611511\n",
            "Train Epoch: 252 [25600/60000 (43%)]\tLoss: 725.033264\n",
            "Train Epoch: 252 [26880/60000 (45%)]\tLoss: 737.657654\n",
            "Train Epoch: 252 [28160/60000 (47%)]\tLoss: 753.347290\n",
            "Train Epoch: 252 [29440/60000 (49%)]\tLoss: 724.632751\n",
            "Train Epoch: 252 [30720/60000 (51%)]\tLoss: 750.529785\n",
            "Train Epoch: 252 [32000/60000 (53%)]\tLoss: 720.317566\n",
            "Train Epoch: 252 [33280/60000 (55%)]\tLoss: 749.700073\n",
            "Train Epoch: 252 [34560/60000 (58%)]\tLoss: 753.420959\n",
            "Train Epoch: 252 [35840/60000 (60%)]\tLoss: 722.161804\n",
            "Train Epoch: 252 [37120/60000 (62%)]\tLoss: 742.696350\n",
            "Train Epoch: 252 [38400/60000 (64%)]\tLoss: 737.850159\n",
            "Train Epoch: 252 [39680/60000 (66%)]\tLoss: 732.822998\n",
            "Train Epoch: 252 [40960/60000 (68%)]\tLoss: 745.584717\n",
            "Train Epoch: 252 [42240/60000 (70%)]\tLoss: 743.883728\n",
            "Train Epoch: 252 [43520/60000 (72%)]\tLoss: 731.706116\n",
            "Train Epoch: 252 [44800/60000 (75%)]\tLoss: 732.841003\n",
            "Train Epoch: 252 [46080/60000 (77%)]\tLoss: 716.123291\n",
            "Train Epoch: 252 [47360/60000 (79%)]\tLoss: 706.204895\n",
            "Train Epoch: 252 [48640/60000 (81%)]\tLoss: 742.138733\n",
            "Train Epoch: 252 [49920/60000 (83%)]\tLoss: 728.632935\n",
            "Train Epoch: 252 [51200/60000 (85%)]\tLoss: 747.228394\n",
            "Train Epoch: 252 [52480/60000 (87%)]\tLoss: 747.279419\n",
            "Train Epoch: 252 [53760/60000 (90%)]\tLoss: 750.547424\n",
            "Train Epoch: 252 [55040/60000 (92%)]\tLoss: 762.213806\n",
            "Train Epoch: 252 [56320/60000 (94%)]\tLoss: 739.496216\n",
            "Train Epoch: 252 [57600/60000 (96%)]\tLoss: 724.052246\n",
            "Train Epoch: 252 [58880/60000 (98%)]\tLoss: 733.702820\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780711829662323\n",
            "\n",
            "Train Epoch: 253 [0/60000 (0%)]\tLoss: 712.564331\n",
            "Train Epoch: 253 [1280/60000 (2%)]\tLoss: 730.172424\n",
            "Train Epoch: 253 [2560/60000 (4%)]\tLoss: 733.411011\n",
            "Train Epoch: 253 [3840/60000 (6%)]\tLoss: 764.164246\n",
            "Train Epoch: 253 [5120/60000 (9%)]\tLoss: 730.793579\n",
            "Train Epoch: 253 [6400/60000 (11%)]\tLoss: 718.083008\n",
            "Train Epoch: 253 [7680/60000 (13%)]\tLoss: 726.711182\n",
            "Train Epoch: 253 [8960/60000 (15%)]\tLoss: 756.596863\n",
            "Train Epoch: 253 [10240/60000 (17%)]\tLoss: 704.105225\n",
            "Train Epoch: 253 [11520/60000 (19%)]\tLoss: 748.773193\n",
            "Train Epoch: 253 [12800/60000 (21%)]\tLoss: 733.818970\n",
            "Train Epoch: 253 [14080/60000 (23%)]\tLoss: 761.526855\n",
            "Train Epoch: 253 [15360/60000 (26%)]\tLoss: 719.578125\n",
            "Train Epoch: 253 [16640/60000 (28%)]\tLoss: 716.593933\n",
            "Train Epoch: 253 [17920/60000 (30%)]\tLoss: 729.388123\n",
            "Train Epoch: 253 [19200/60000 (32%)]\tLoss: 738.384644\n",
            "Train Epoch: 253 [20480/60000 (34%)]\tLoss: 720.579773\n",
            "Train Epoch: 253 [21760/60000 (36%)]\tLoss: 753.499023\n",
            "Train Epoch: 253 [23040/60000 (38%)]\tLoss: 737.089661\n",
            "Train Epoch: 253 [24320/60000 (41%)]\tLoss: 722.461792\n",
            "Train Epoch: 253 [25600/60000 (43%)]\tLoss: 718.846619\n",
            "Train Epoch: 253 [26880/60000 (45%)]\tLoss: 760.775696\n",
            "Train Epoch: 253 [28160/60000 (47%)]\tLoss: 749.484375\n",
            "Train Epoch: 253 [29440/60000 (49%)]\tLoss: 727.144104\n",
            "Train Epoch: 253 [30720/60000 (51%)]\tLoss: 720.236633\n",
            "Train Epoch: 253 [32000/60000 (53%)]\tLoss: 743.808472\n",
            "Train Epoch: 253 [33280/60000 (55%)]\tLoss: 717.781555\n",
            "Train Epoch: 253 [34560/60000 (58%)]\tLoss: 752.491211\n",
            "Train Epoch: 253 [35840/60000 (60%)]\tLoss: 697.905579\n",
            "Train Epoch: 253 [37120/60000 (62%)]\tLoss: 752.238586\n",
            "Train Epoch: 253 [38400/60000 (64%)]\tLoss: 752.063782\n",
            "Train Epoch: 253 [39680/60000 (66%)]\tLoss: 737.465454\n",
            "Train Epoch: 253 [40960/60000 (68%)]\tLoss: 721.870850\n",
            "Train Epoch: 253 [42240/60000 (70%)]\tLoss: 737.243103\n",
            "Train Epoch: 253 [43520/60000 (72%)]\tLoss: 757.748413\n",
            "Train Epoch: 253 [44800/60000 (75%)]\tLoss: 745.352722\n",
            "Train Epoch: 253 [46080/60000 (77%)]\tLoss: 751.519165\n",
            "Train Epoch: 253 [47360/60000 (79%)]\tLoss: 721.907898\n",
            "Train Epoch: 253 [48640/60000 (81%)]\tLoss: 730.727783\n",
            "Train Epoch: 253 [49920/60000 (83%)]\tLoss: 734.568481\n",
            "Train Epoch: 253 [51200/60000 (85%)]\tLoss: 715.947388\n",
            "Train Epoch: 253 [52480/60000 (87%)]\tLoss: 768.623962\n",
            "Train Epoch: 253 [53760/60000 (90%)]\tLoss: 768.767090\n",
            "Train Epoch: 253 [55040/60000 (92%)]\tLoss: 721.671082\n",
            "Train Epoch: 253 [56320/60000 (94%)]\tLoss: 739.948425\n",
            "Train Epoch: 253 [57600/60000 (96%)]\tLoss: 743.537720\n",
            "Train Epoch: 253 [58880/60000 (98%)]\tLoss: 726.192993\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785556197166443\n",
            "\n",
            "Train Epoch: 254 [0/60000 (0%)]\tLoss: 723.361694\n",
            "Train Epoch: 254 [1280/60000 (2%)]\tLoss: 723.034851\n",
            "Train Epoch: 254 [2560/60000 (4%)]\tLoss: 765.536926\n",
            "Train Epoch: 254 [3840/60000 (6%)]\tLoss: 737.179810\n",
            "Train Epoch: 254 [5120/60000 (9%)]\tLoss: 731.158813\n",
            "Train Epoch: 254 [6400/60000 (11%)]\tLoss: 731.208374\n",
            "Train Epoch: 254 [7680/60000 (13%)]\tLoss: 729.730896\n",
            "Train Epoch: 254 [8960/60000 (15%)]\tLoss: 750.003418\n",
            "Train Epoch: 254 [10240/60000 (17%)]\tLoss: 739.466919\n",
            "Train Epoch: 254 [11520/60000 (19%)]\tLoss: 756.042175\n",
            "Train Epoch: 254 [12800/60000 (21%)]\tLoss: 732.006775\n",
            "Train Epoch: 254 [14080/60000 (23%)]\tLoss: 753.367737\n",
            "Train Epoch: 254 [15360/60000 (26%)]\tLoss: 736.031982\n",
            "Train Epoch: 254 [16640/60000 (28%)]\tLoss: 761.748657\n",
            "Train Epoch: 254 [17920/60000 (30%)]\tLoss: 744.634583\n",
            "Train Epoch: 254 [19200/60000 (32%)]\tLoss: 730.340027\n",
            "Train Epoch: 254 [20480/60000 (34%)]\tLoss: 725.168396\n",
            "Train Epoch: 254 [21760/60000 (36%)]\tLoss: 730.697571\n",
            "Train Epoch: 254 [23040/60000 (38%)]\tLoss: 739.772339\n",
            "Train Epoch: 254 [24320/60000 (41%)]\tLoss: 709.332397\n",
            "Train Epoch: 254 [25600/60000 (43%)]\tLoss: 735.485413\n",
            "Train Epoch: 254 [26880/60000 (45%)]\tLoss: 730.202515\n",
            "Train Epoch: 254 [28160/60000 (47%)]\tLoss: 713.070557\n",
            "Train Epoch: 254 [29440/60000 (49%)]\tLoss: 755.728455\n",
            "Train Epoch: 254 [30720/60000 (51%)]\tLoss: 748.372009\n",
            "Train Epoch: 254 [32000/60000 (53%)]\tLoss: 742.120911\n",
            "Train Epoch: 254 [33280/60000 (55%)]\tLoss: 715.003418\n",
            "Train Epoch: 254 [34560/60000 (58%)]\tLoss: 731.316589\n",
            "Train Epoch: 254 [35840/60000 (60%)]\tLoss: 748.002319\n",
            "Train Epoch: 254 [37120/60000 (62%)]\tLoss: 741.052979\n",
            "Train Epoch: 254 [38400/60000 (64%)]\tLoss: 702.167603\n",
            "Train Epoch: 254 [39680/60000 (66%)]\tLoss: 727.287964\n",
            "Train Epoch: 254 [40960/60000 (68%)]\tLoss: 715.535461\n",
            "Train Epoch: 254 [42240/60000 (70%)]\tLoss: 761.173340\n",
            "Train Epoch: 254 [43520/60000 (72%)]\tLoss: 764.544800\n",
            "Train Epoch: 254 [44800/60000 (75%)]\tLoss: 742.047729\n",
            "Train Epoch: 254 [46080/60000 (77%)]\tLoss: 738.334045\n",
            "Train Epoch: 254 [47360/60000 (79%)]\tLoss: 745.222595\n",
            "Train Epoch: 254 [48640/60000 (81%)]\tLoss: 740.755310\n",
            "Train Epoch: 254 [49920/60000 (83%)]\tLoss: 743.948242\n",
            "Train Epoch: 254 [51200/60000 (85%)]\tLoss: 736.946655\n",
            "Train Epoch: 254 [52480/60000 (87%)]\tLoss: 775.617432\n",
            "Train Epoch: 254 [53760/60000 (90%)]\tLoss: 732.697327\n",
            "Train Epoch: 254 [55040/60000 (92%)]\tLoss: 722.813232\n",
            "Train Epoch: 254 [56320/60000 (94%)]\tLoss: 712.720215\n",
            "Train Epoch: 254 [57600/60000 (96%)]\tLoss: 740.291138\n",
            "Train Epoch: 254 [58880/60000 (98%)]\tLoss: 718.240234\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784699380397797\n",
            "\n",
            "Train Epoch: 255 [0/60000 (0%)]\tLoss: 739.170837\n",
            "Train Epoch: 255 [1280/60000 (2%)]\tLoss: 748.510376\n",
            "Train Epoch: 255 [2560/60000 (4%)]\tLoss: 716.775635\n",
            "Train Epoch: 255 [3840/60000 (6%)]\tLoss: 748.174438\n",
            "Train Epoch: 255 [5120/60000 (9%)]\tLoss: 732.071899\n",
            "Train Epoch: 255 [6400/60000 (11%)]\tLoss: 751.749207\n",
            "Train Epoch: 255 [7680/60000 (13%)]\tLoss: 734.994629\n",
            "Train Epoch: 255 [8960/60000 (15%)]\tLoss: 722.511963\n",
            "Train Epoch: 255 [10240/60000 (17%)]\tLoss: 740.722839\n",
            "Train Epoch: 255 [11520/60000 (19%)]\tLoss: 763.887817\n",
            "Train Epoch: 255 [12800/60000 (21%)]\tLoss: 729.533691\n",
            "Train Epoch: 255 [14080/60000 (23%)]\tLoss: 738.978149\n",
            "Train Epoch: 255 [15360/60000 (26%)]\tLoss: 729.650146\n",
            "Train Epoch: 255 [16640/60000 (28%)]\tLoss: 733.614624\n",
            "Train Epoch: 255 [17920/60000 (30%)]\tLoss: 752.169922\n",
            "Train Epoch: 255 [19200/60000 (32%)]\tLoss: 731.256714\n",
            "Train Epoch: 255 [20480/60000 (34%)]\tLoss: 728.200867\n",
            "Train Epoch: 255 [21760/60000 (36%)]\tLoss: 724.251221\n",
            "Train Epoch: 255 [23040/60000 (38%)]\tLoss: 746.557251\n",
            "Train Epoch: 255 [24320/60000 (41%)]\tLoss: 762.438721\n",
            "Train Epoch: 255 [25600/60000 (43%)]\tLoss: 743.737610\n",
            "Train Epoch: 255 [26880/60000 (45%)]\tLoss: 740.185120\n",
            "Train Epoch: 255 [28160/60000 (47%)]\tLoss: 757.128235\n",
            "Train Epoch: 255 [29440/60000 (49%)]\tLoss: 748.360962\n",
            "Train Epoch: 255 [30720/60000 (51%)]\tLoss: 737.888916\n",
            "Train Epoch: 255 [32000/60000 (53%)]\tLoss: 753.044800\n",
            "Train Epoch: 255 [33280/60000 (55%)]\tLoss: 702.063843\n",
            "Train Epoch: 255 [34560/60000 (58%)]\tLoss: 760.692993\n",
            "Train Epoch: 255 [35840/60000 (60%)]\tLoss: 759.206726\n",
            "Train Epoch: 255 [37120/60000 (62%)]\tLoss: 735.165405\n",
            "Train Epoch: 255 [38400/60000 (64%)]\tLoss: 710.184082\n",
            "Train Epoch: 255 [39680/60000 (66%)]\tLoss: 749.722900\n",
            "Train Epoch: 255 [40960/60000 (68%)]\tLoss: 747.785461\n",
            "Train Epoch: 255 [42240/60000 (70%)]\tLoss: 715.992920\n",
            "Train Epoch: 255 [43520/60000 (72%)]\tLoss: 720.020264\n",
            "Train Epoch: 255 [44800/60000 (75%)]\tLoss: 734.957031\n",
            "Train Epoch: 255 [46080/60000 (77%)]\tLoss: 763.068298\n",
            "Train Epoch: 255 [47360/60000 (79%)]\tLoss: 735.415222\n",
            "Train Epoch: 255 [48640/60000 (81%)]\tLoss: 744.113953\n",
            "Train Epoch: 255 [49920/60000 (83%)]\tLoss: 746.975769\n",
            "Train Epoch: 255 [51200/60000 (85%)]\tLoss: 745.640381\n",
            "Train Epoch: 255 [52480/60000 (87%)]\tLoss: 727.149780\n",
            "Train Epoch: 255 [53760/60000 (90%)]\tLoss: 722.325500\n",
            "Train Epoch: 255 [55040/60000 (92%)]\tLoss: 771.901489\n",
            "Train Epoch: 255 [56320/60000 (94%)]\tLoss: 724.460693\n",
            "Train Epoch: 255 [57600/60000 (96%)]\tLoss: 724.438293\n",
            "Train Epoch: 255 [58880/60000 (98%)]\tLoss: 750.195068\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782669842243195\n",
            "\n",
            "Train Epoch: 256 [0/60000 (0%)]\tLoss: 737.265564\n",
            "Train Epoch: 256 [1280/60000 (2%)]\tLoss: 711.278625\n",
            "Train Epoch: 256 [2560/60000 (4%)]\tLoss: 740.028259\n",
            "Train Epoch: 256 [3840/60000 (6%)]\tLoss: 729.523926\n",
            "Train Epoch: 256 [5120/60000 (9%)]\tLoss: 724.880371\n",
            "Train Epoch: 256 [6400/60000 (11%)]\tLoss: 729.831177\n",
            "Train Epoch: 256 [7680/60000 (13%)]\tLoss: 712.059448\n",
            "Train Epoch: 256 [8960/60000 (15%)]\tLoss: 746.053101\n",
            "Train Epoch: 256 [10240/60000 (17%)]\tLoss: 728.344849\n",
            "Train Epoch: 256 [11520/60000 (19%)]\tLoss: 765.138855\n",
            "Train Epoch: 256 [12800/60000 (21%)]\tLoss: 732.404968\n",
            "Train Epoch: 256 [14080/60000 (23%)]\tLoss: 718.712646\n",
            "Train Epoch: 256 [15360/60000 (26%)]\tLoss: 727.786377\n",
            "Train Epoch: 256 [16640/60000 (28%)]\tLoss: 747.951599\n",
            "Train Epoch: 256 [17920/60000 (30%)]\tLoss: 732.772034\n",
            "Train Epoch: 256 [19200/60000 (32%)]\tLoss: 731.154419\n",
            "Train Epoch: 256 [20480/60000 (34%)]\tLoss: 726.460205\n",
            "Train Epoch: 256 [21760/60000 (36%)]\tLoss: 739.947937\n",
            "Train Epoch: 256 [23040/60000 (38%)]\tLoss: 760.229797\n",
            "Train Epoch: 256 [24320/60000 (41%)]\tLoss: 748.486084\n",
            "Train Epoch: 256 [25600/60000 (43%)]\tLoss: 722.392517\n",
            "Train Epoch: 256 [26880/60000 (45%)]\tLoss: 748.954163\n",
            "Train Epoch: 256 [28160/60000 (47%)]\tLoss: 727.146667\n",
            "Train Epoch: 256 [29440/60000 (49%)]\tLoss: 746.563416\n",
            "Train Epoch: 256 [30720/60000 (51%)]\tLoss: 754.661438\n",
            "Train Epoch: 256 [32000/60000 (53%)]\tLoss: 719.587280\n",
            "Train Epoch: 256 [33280/60000 (55%)]\tLoss: 748.206543\n",
            "Train Epoch: 256 [34560/60000 (58%)]\tLoss: 743.518311\n",
            "Train Epoch: 256 [35840/60000 (60%)]\tLoss: 722.222290\n",
            "Train Epoch: 256 [37120/60000 (62%)]\tLoss: 739.927368\n",
            "Train Epoch: 256 [38400/60000 (64%)]\tLoss: 739.682678\n",
            "Train Epoch: 256 [39680/60000 (66%)]\tLoss: 727.079041\n",
            "Train Epoch: 256 [40960/60000 (68%)]\tLoss: 765.052429\n",
            "Train Epoch: 256 [42240/60000 (70%)]\tLoss: 752.702209\n",
            "Train Epoch: 256 [43520/60000 (72%)]\tLoss: 743.044556\n",
            "Train Epoch: 256 [44800/60000 (75%)]\tLoss: 732.605957\n",
            "Train Epoch: 256 [46080/60000 (77%)]\tLoss: 725.039124\n",
            "Train Epoch: 256 [47360/60000 (79%)]\tLoss: 715.177979\n",
            "Train Epoch: 256 [48640/60000 (81%)]\tLoss: 734.372559\n",
            "Train Epoch: 256 [49920/60000 (83%)]\tLoss: 727.822754\n",
            "Train Epoch: 256 [51200/60000 (85%)]\tLoss: 741.692688\n",
            "Train Epoch: 256 [52480/60000 (87%)]\tLoss: 740.164307\n",
            "Train Epoch: 256 [53760/60000 (90%)]\tLoss: 732.503662\n",
            "Train Epoch: 256 [55040/60000 (92%)]\tLoss: 727.307068\n",
            "Train Epoch: 256 [56320/60000 (94%)]\tLoss: 736.481262\n",
            "Train Epoch: 256 [57600/60000 (96%)]\tLoss: 722.098145\n",
            "Train Epoch: 256 [58880/60000 (98%)]\tLoss: 715.002869\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786356389522552\n",
            "\n",
            "Train Epoch: 257 [0/60000 (0%)]\tLoss: 744.535889\n",
            "Train Epoch: 257 [1280/60000 (2%)]\tLoss: 725.938904\n",
            "Train Epoch: 257 [2560/60000 (4%)]\tLoss: 726.606384\n",
            "Train Epoch: 257 [3840/60000 (6%)]\tLoss: 729.937439\n",
            "Train Epoch: 257 [5120/60000 (9%)]\tLoss: 738.525513\n",
            "Train Epoch: 257 [6400/60000 (11%)]\tLoss: 719.026001\n",
            "Train Epoch: 257 [7680/60000 (13%)]\tLoss: 730.029541\n",
            "Train Epoch: 257 [8960/60000 (15%)]\tLoss: 743.225037\n",
            "Train Epoch: 257 [10240/60000 (17%)]\tLoss: 732.919495\n",
            "Train Epoch: 257 [11520/60000 (19%)]\tLoss: 742.137512\n",
            "Train Epoch: 257 [12800/60000 (21%)]\tLoss: 718.057373\n",
            "Train Epoch: 257 [14080/60000 (23%)]\tLoss: 748.506958\n",
            "Train Epoch: 257 [15360/60000 (26%)]\tLoss: 724.549011\n",
            "Train Epoch: 257 [16640/60000 (28%)]\tLoss: 754.643433\n",
            "Train Epoch: 257 [17920/60000 (30%)]\tLoss: 755.891235\n",
            "Train Epoch: 257 [19200/60000 (32%)]\tLoss: 737.867615\n",
            "Train Epoch: 257 [20480/60000 (34%)]\tLoss: 729.269958\n",
            "Train Epoch: 257 [21760/60000 (36%)]\tLoss: 740.486694\n",
            "Train Epoch: 257 [23040/60000 (38%)]\tLoss: 757.512817\n",
            "Train Epoch: 257 [24320/60000 (41%)]\tLoss: 742.064148\n",
            "Train Epoch: 257 [25600/60000 (43%)]\tLoss: 750.332458\n",
            "Train Epoch: 257 [26880/60000 (45%)]\tLoss: 726.924255\n",
            "Train Epoch: 257 [28160/60000 (47%)]\tLoss: 750.337097\n",
            "Train Epoch: 257 [29440/60000 (49%)]\tLoss: 750.589294\n",
            "Train Epoch: 257 [30720/60000 (51%)]\tLoss: 737.783447\n",
            "Train Epoch: 257 [32000/60000 (53%)]\tLoss: 748.140991\n",
            "Train Epoch: 257 [33280/60000 (55%)]\tLoss: 726.263062\n",
            "Train Epoch: 257 [34560/60000 (58%)]\tLoss: 732.028137\n",
            "Train Epoch: 257 [35840/60000 (60%)]\tLoss: 764.367432\n",
            "Train Epoch: 257 [37120/60000 (62%)]\tLoss: 704.572021\n",
            "Train Epoch: 257 [38400/60000 (64%)]\tLoss: 717.943481\n",
            "Train Epoch: 257 [39680/60000 (66%)]\tLoss: 777.078796\n",
            "Train Epoch: 257 [40960/60000 (68%)]\tLoss: 723.769165\n",
            "Train Epoch: 257 [42240/60000 (70%)]\tLoss: 740.295959\n",
            "Train Epoch: 257 [43520/60000 (72%)]\tLoss: 753.641235\n",
            "Train Epoch: 257 [44800/60000 (75%)]\tLoss: 739.225403\n",
            "Train Epoch: 257 [46080/60000 (77%)]\tLoss: 748.046814\n",
            "Train Epoch: 257 [47360/60000 (79%)]\tLoss: 742.361572\n",
            "Train Epoch: 257 [48640/60000 (81%)]\tLoss: 729.222656\n",
            "Train Epoch: 257 [49920/60000 (83%)]\tLoss: 728.320557\n",
            "Train Epoch: 257 [51200/60000 (85%)]\tLoss: 754.518982\n",
            "Train Epoch: 257 [52480/60000 (87%)]\tLoss: 741.440491\n",
            "Train Epoch: 257 [53760/60000 (90%)]\tLoss: 741.727539\n",
            "Train Epoch: 257 [55040/60000 (92%)]\tLoss: 732.370911\n",
            "Train Epoch: 257 [56320/60000 (94%)]\tLoss: 739.623047\n",
            "Train Epoch: 257 [57600/60000 (96%)]\tLoss: 726.805969\n",
            "Train Epoch: 257 [58880/60000 (98%)]\tLoss: 735.773254\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978098601102829\n",
            "\n",
            "Train Epoch: 258 [0/60000 (0%)]\tLoss: 758.473938\n",
            "Train Epoch: 258 [1280/60000 (2%)]\tLoss: 718.068787\n",
            "Train Epoch: 258 [2560/60000 (4%)]\tLoss: 723.910522\n",
            "Train Epoch: 258 [3840/60000 (6%)]\tLoss: 721.008484\n",
            "Train Epoch: 258 [5120/60000 (9%)]\tLoss: 761.086853\n",
            "Train Epoch: 258 [6400/60000 (11%)]\tLoss: 770.727173\n",
            "Train Epoch: 258 [7680/60000 (13%)]\tLoss: 731.899536\n",
            "Train Epoch: 258 [8960/60000 (15%)]\tLoss: 724.121582\n",
            "Train Epoch: 258 [10240/60000 (17%)]\tLoss: 731.208008\n",
            "Train Epoch: 258 [11520/60000 (19%)]\tLoss: 729.162659\n",
            "Train Epoch: 258 [12800/60000 (21%)]\tLoss: 734.415649\n",
            "Train Epoch: 258 [14080/60000 (23%)]\tLoss: 762.595276\n",
            "Train Epoch: 258 [15360/60000 (26%)]\tLoss: 729.948853\n",
            "Train Epoch: 258 [16640/60000 (28%)]\tLoss: 752.923584\n",
            "Train Epoch: 258 [17920/60000 (30%)]\tLoss: 750.983398\n",
            "Train Epoch: 258 [19200/60000 (32%)]\tLoss: 734.856567\n",
            "Train Epoch: 258 [20480/60000 (34%)]\tLoss: 725.361694\n",
            "Train Epoch: 258 [21760/60000 (36%)]\tLoss: 757.083130\n",
            "Train Epoch: 258 [23040/60000 (38%)]\tLoss: 724.136108\n",
            "Train Epoch: 258 [24320/60000 (41%)]\tLoss: 708.717285\n",
            "Train Epoch: 258 [25600/60000 (43%)]\tLoss: 729.296814\n",
            "Train Epoch: 258 [26880/60000 (45%)]\tLoss: 723.216003\n",
            "Train Epoch: 258 [28160/60000 (47%)]\tLoss: 740.921753\n",
            "Train Epoch: 258 [29440/60000 (49%)]\tLoss: 720.601257\n",
            "Train Epoch: 258 [30720/60000 (51%)]\tLoss: 765.823792\n",
            "Train Epoch: 258 [32000/60000 (53%)]\tLoss: 707.592651\n",
            "Train Epoch: 258 [33280/60000 (55%)]\tLoss: 710.584473\n",
            "Train Epoch: 258 [34560/60000 (58%)]\tLoss: 745.566406\n",
            "Train Epoch: 258 [35840/60000 (60%)]\tLoss: 732.141663\n",
            "Train Epoch: 258 [37120/60000 (62%)]\tLoss: 731.907898\n",
            "Train Epoch: 258 [38400/60000 (64%)]\tLoss: 756.040833\n",
            "Train Epoch: 258 [39680/60000 (66%)]\tLoss: 732.154236\n",
            "Train Epoch: 258 [40960/60000 (68%)]\tLoss: 740.331482\n",
            "Train Epoch: 258 [42240/60000 (70%)]\tLoss: 741.246033\n",
            "Train Epoch: 258 [43520/60000 (72%)]\tLoss: 761.198486\n",
            "Train Epoch: 258 [44800/60000 (75%)]\tLoss: 740.875732\n",
            "Train Epoch: 258 [46080/60000 (77%)]\tLoss: 734.317322\n",
            "Train Epoch: 258 [47360/60000 (79%)]\tLoss: 736.405762\n",
            "Train Epoch: 258 [48640/60000 (81%)]\tLoss: 734.666443\n",
            "Train Epoch: 258 [49920/60000 (83%)]\tLoss: 748.787476\n",
            "Train Epoch: 258 [51200/60000 (85%)]\tLoss: 759.485291\n",
            "Train Epoch: 258 [52480/60000 (87%)]\tLoss: 728.471252\n",
            "Train Epoch: 258 [53760/60000 (90%)]\tLoss: 715.316772\n",
            "Train Epoch: 258 [55040/60000 (92%)]\tLoss: 739.683350\n",
            "Train Epoch: 258 [56320/60000 (94%)]\tLoss: 734.768677\n",
            "Train Epoch: 258 [57600/60000 (96%)]\tLoss: 727.497009\n",
            "Train Epoch: 258 [58880/60000 (98%)]\tLoss: 740.987854\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783525168895721\n",
            "\n",
            "Train Epoch: 259 [0/60000 (0%)]\tLoss: 748.252625\n",
            "Train Epoch: 259 [1280/60000 (2%)]\tLoss: 732.971252\n",
            "Train Epoch: 259 [2560/60000 (4%)]\tLoss: 745.151978\n",
            "Train Epoch: 259 [3840/60000 (6%)]\tLoss: 748.329163\n",
            "Train Epoch: 259 [5120/60000 (9%)]\tLoss: 723.406555\n",
            "Train Epoch: 259 [6400/60000 (11%)]\tLoss: 725.347717\n",
            "Train Epoch: 259 [7680/60000 (13%)]\tLoss: 752.639465\n",
            "Train Epoch: 259 [8960/60000 (15%)]\tLoss: 746.949280\n",
            "Train Epoch: 259 [10240/60000 (17%)]\tLoss: 757.513489\n",
            "Train Epoch: 259 [11520/60000 (19%)]\tLoss: 743.014038\n",
            "Train Epoch: 259 [12800/60000 (21%)]\tLoss: 736.824524\n",
            "Train Epoch: 259 [14080/60000 (23%)]\tLoss: 763.858154\n",
            "Train Epoch: 259 [15360/60000 (26%)]\tLoss: 736.644836\n",
            "Train Epoch: 259 [16640/60000 (28%)]\tLoss: 747.210571\n",
            "Train Epoch: 259 [17920/60000 (30%)]\tLoss: 750.055725\n",
            "Train Epoch: 259 [19200/60000 (32%)]\tLoss: 745.392761\n",
            "Train Epoch: 259 [20480/60000 (34%)]\tLoss: 727.942261\n",
            "Train Epoch: 259 [21760/60000 (36%)]\tLoss: 718.221924\n",
            "Train Epoch: 259 [23040/60000 (38%)]\tLoss: 710.764954\n",
            "Train Epoch: 259 [24320/60000 (41%)]\tLoss: 736.839294\n",
            "Train Epoch: 259 [25600/60000 (43%)]\tLoss: 744.141113\n",
            "Train Epoch: 259 [26880/60000 (45%)]\tLoss: 756.419373\n",
            "Train Epoch: 259 [28160/60000 (47%)]\tLoss: 725.995239\n",
            "Train Epoch: 259 [29440/60000 (49%)]\tLoss: 713.249146\n",
            "Train Epoch: 259 [30720/60000 (51%)]\tLoss: 719.340637\n",
            "Train Epoch: 259 [32000/60000 (53%)]\tLoss: 716.468445\n",
            "Train Epoch: 259 [33280/60000 (55%)]\tLoss: 739.313171\n",
            "Train Epoch: 259 [34560/60000 (58%)]\tLoss: 712.423462\n",
            "Train Epoch: 259 [35840/60000 (60%)]\tLoss: 748.066528\n",
            "Train Epoch: 259 [37120/60000 (62%)]\tLoss: 724.923462\n",
            "Train Epoch: 259 [38400/60000 (64%)]\tLoss: 754.602966\n",
            "Train Epoch: 259 [39680/60000 (66%)]\tLoss: 737.261536\n",
            "Train Epoch: 259 [40960/60000 (68%)]\tLoss: 713.246582\n",
            "Train Epoch: 259 [42240/60000 (70%)]\tLoss: 703.493652\n",
            "Train Epoch: 259 [43520/60000 (72%)]\tLoss: 724.900452\n",
            "Train Epoch: 259 [44800/60000 (75%)]\tLoss: 743.533020\n",
            "Train Epoch: 259 [46080/60000 (77%)]\tLoss: 740.055969\n",
            "Train Epoch: 259 [47360/60000 (79%)]\tLoss: 729.143311\n",
            "Train Epoch: 259 [48640/60000 (81%)]\tLoss: 741.296936\n",
            "Train Epoch: 259 [49920/60000 (83%)]\tLoss: 735.513672\n",
            "Train Epoch: 259 [51200/60000 (85%)]\tLoss: 740.906921\n",
            "Train Epoch: 259 [52480/60000 (87%)]\tLoss: 726.860413\n",
            "Train Epoch: 259 [53760/60000 (90%)]\tLoss: 746.523499\n",
            "Train Epoch: 259 [55040/60000 (92%)]\tLoss: 723.895142\n",
            "Train Epoch: 259 [56320/60000 (94%)]\tLoss: 720.312805\n",
            "Train Epoch: 259 [57600/60000 (96%)]\tLoss: 754.234985\n",
            "Train Epoch: 259 [58880/60000 (98%)]\tLoss: 735.541992\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.197846919298172\n",
            "\n",
            "Train Epoch: 260 [0/60000 (0%)]\tLoss: 704.890564\n",
            "Train Epoch: 260 [1280/60000 (2%)]\tLoss: 732.587952\n",
            "Train Epoch: 260 [2560/60000 (4%)]\tLoss: 743.134644\n",
            "Train Epoch: 260 [3840/60000 (6%)]\tLoss: 750.992493\n",
            "Train Epoch: 260 [5120/60000 (9%)]\tLoss: 745.521301\n",
            "Train Epoch: 260 [6400/60000 (11%)]\tLoss: 754.925659\n",
            "Train Epoch: 260 [7680/60000 (13%)]\tLoss: 730.825378\n",
            "Train Epoch: 260 [8960/60000 (15%)]\tLoss: 745.910156\n",
            "Train Epoch: 260 [10240/60000 (17%)]\tLoss: 749.087524\n",
            "Train Epoch: 260 [11520/60000 (19%)]\tLoss: 731.411194\n",
            "Train Epoch: 260 [12800/60000 (21%)]\tLoss: 742.815186\n",
            "Train Epoch: 260 [14080/60000 (23%)]\tLoss: 753.638428\n",
            "Train Epoch: 260 [15360/60000 (26%)]\tLoss: 740.957947\n",
            "Train Epoch: 260 [16640/60000 (28%)]\tLoss: 725.604736\n",
            "Train Epoch: 260 [17920/60000 (30%)]\tLoss: 732.151672\n",
            "Train Epoch: 260 [19200/60000 (32%)]\tLoss: 744.287659\n",
            "Train Epoch: 260 [20480/60000 (34%)]\tLoss: 722.766724\n",
            "Train Epoch: 260 [21760/60000 (36%)]\tLoss: 736.640808\n",
            "Train Epoch: 260 [23040/60000 (38%)]\tLoss: 736.901672\n",
            "Train Epoch: 260 [24320/60000 (41%)]\tLoss: 719.407471\n",
            "Train Epoch: 260 [25600/60000 (43%)]\tLoss: 742.001770\n",
            "Train Epoch: 260 [26880/60000 (45%)]\tLoss: 734.232666\n",
            "Train Epoch: 260 [28160/60000 (47%)]\tLoss: 723.123108\n",
            "Train Epoch: 260 [29440/60000 (49%)]\tLoss: 761.333557\n",
            "Train Epoch: 260 [30720/60000 (51%)]\tLoss: 753.808960\n",
            "Train Epoch: 260 [32000/60000 (53%)]\tLoss: 742.544495\n",
            "Train Epoch: 260 [33280/60000 (55%)]\tLoss: 742.662659\n",
            "Train Epoch: 260 [34560/60000 (58%)]\tLoss: 721.074707\n",
            "Train Epoch: 260 [35840/60000 (60%)]\tLoss: 725.112610\n",
            "Train Epoch: 260 [37120/60000 (62%)]\tLoss: 740.128662\n",
            "Train Epoch: 260 [38400/60000 (64%)]\tLoss: 732.247131\n",
            "Train Epoch: 260 [39680/60000 (66%)]\tLoss: 751.740967\n",
            "Train Epoch: 260 [40960/60000 (68%)]\tLoss: 744.380737\n",
            "Train Epoch: 260 [42240/60000 (70%)]\tLoss: 712.399414\n",
            "Train Epoch: 260 [43520/60000 (72%)]\tLoss: 757.118652\n",
            "Train Epoch: 260 [44800/60000 (75%)]\tLoss: 725.439453\n",
            "Train Epoch: 260 [46080/60000 (77%)]\tLoss: 747.337036\n",
            "Train Epoch: 260 [47360/60000 (79%)]\tLoss: 705.295044\n",
            "Train Epoch: 260 [48640/60000 (81%)]\tLoss: 758.359985\n",
            "Train Epoch: 260 [49920/60000 (83%)]\tLoss: 727.970032\n",
            "Train Epoch: 260 [51200/60000 (85%)]\tLoss: 719.911560\n",
            "Train Epoch: 260 [52480/60000 (87%)]\tLoss: 740.478455\n",
            "Train Epoch: 260 [53760/60000 (90%)]\tLoss: 728.590759\n",
            "Train Epoch: 260 [55040/60000 (92%)]\tLoss: 739.234436\n",
            "Train Epoch: 260 [56320/60000 (94%)]\tLoss: 744.608093\n",
            "Train Epoch: 260 [57600/60000 (96%)]\tLoss: 755.943970\n",
            "Train Epoch: 260 [58880/60000 (98%)]\tLoss: 743.979248\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781950116157532\n",
            "\n",
            "Train Epoch: 261 [0/60000 (0%)]\tLoss: 733.953308\n",
            "Train Epoch: 261 [1280/60000 (2%)]\tLoss: 714.885742\n",
            "Train Epoch: 261 [2560/60000 (4%)]\tLoss: 742.364014\n",
            "Train Epoch: 261 [3840/60000 (6%)]\tLoss: 724.409058\n",
            "Train Epoch: 261 [5120/60000 (9%)]\tLoss: 729.070862\n",
            "Train Epoch: 261 [6400/60000 (11%)]\tLoss: 751.591553\n",
            "Train Epoch: 261 [7680/60000 (13%)]\tLoss: 727.687195\n",
            "Train Epoch: 261 [8960/60000 (15%)]\tLoss: 732.211060\n",
            "Train Epoch: 261 [10240/60000 (17%)]\tLoss: 721.900513\n",
            "Train Epoch: 261 [11520/60000 (19%)]\tLoss: 725.146667\n",
            "Train Epoch: 261 [12800/60000 (21%)]\tLoss: 745.274658\n",
            "Train Epoch: 261 [14080/60000 (23%)]\tLoss: 727.944702\n",
            "Train Epoch: 261 [15360/60000 (26%)]\tLoss: 739.595520\n",
            "Train Epoch: 261 [16640/60000 (28%)]\tLoss: 743.319702\n",
            "Train Epoch: 261 [17920/60000 (30%)]\tLoss: 751.681274\n",
            "Train Epoch: 261 [19200/60000 (32%)]\tLoss: 716.566772\n",
            "Train Epoch: 261 [20480/60000 (34%)]\tLoss: 746.098083\n",
            "Train Epoch: 261 [21760/60000 (36%)]\tLoss: 761.531006\n",
            "Train Epoch: 261 [23040/60000 (38%)]\tLoss: 734.230774\n",
            "Train Epoch: 261 [24320/60000 (41%)]\tLoss: 733.404114\n",
            "Train Epoch: 261 [25600/60000 (43%)]\tLoss: 722.015015\n",
            "Train Epoch: 261 [26880/60000 (45%)]\tLoss: 721.224854\n",
            "Train Epoch: 261 [28160/60000 (47%)]\tLoss: 739.161438\n",
            "Train Epoch: 261 [29440/60000 (49%)]\tLoss: 743.397766\n",
            "Train Epoch: 261 [30720/60000 (51%)]\tLoss: 726.332947\n",
            "Train Epoch: 261 [32000/60000 (53%)]\tLoss: 753.136902\n",
            "Train Epoch: 261 [33280/60000 (55%)]\tLoss: 733.218384\n",
            "Train Epoch: 261 [34560/60000 (58%)]\tLoss: 730.970276\n",
            "Train Epoch: 261 [35840/60000 (60%)]\tLoss: 743.176819\n",
            "Train Epoch: 261 [37120/60000 (62%)]\tLoss: 742.795776\n",
            "Train Epoch: 261 [38400/60000 (64%)]\tLoss: 734.434509\n",
            "Train Epoch: 261 [39680/60000 (66%)]\tLoss: 732.395020\n",
            "Train Epoch: 261 [40960/60000 (68%)]\tLoss: 730.031555\n",
            "Train Epoch: 261 [42240/60000 (70%)]\tLoss: 744.783386\n",
            "Train Epoch: 261 [43520/60000 (72%)]\tLoss: 719.169800\n",
            "Train Epoch: 261 [44800/60000 (75%)]\tLoss: 751.040649\n",
            "Train Epoch: 261 [46080/60000 (77%)]\tLoss: 731.065552\n",
            "Train Epoch: 261 [47360/60000 (79%)]\tLoss: 746.039246\n",
            "Train Epoch: 261 [48640/60000 (81%)]\tLoss: 729.062805\n",
            "Train Epoch: 261 [49920/60000 (83%)]\tLoss: 734.379272\n",
            "Train Epoch: 261 [51200/60000 (85%)]\tLoss: 729.361328\n",
            "Train Epoch: 261 [52480/60000 (87%)]\tLoss: 746.769531\n",
            "Train Epoch: 261 [53760/60000 (90%)]\tLoss: 746.487427\n",
            "Train Epoch: 261 [55040/60000 (92%)]\tLoss: 769.661316\n",
            "Train Epoch: 261 [56320/60000 (94%)]\tLoss: 750.559875\n",
            "Train Epoch: 261 [57600/60000 (96%)]\tLoss: 758.198303\n",
            "Train Epoch: 261 [58880/60000 (98%)]\tLoss: 727.242615\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786372780799866\n",
            "\n",
            "Train Epoch: 262 [0/60000 (0%)]\tLoss: 728.038757\n",
            "Train Epoch: 262 [1280/60000 (2%)]\tLoss: 749.211304\n",
            "Train Epoch: 262 [2560/60000 (4%)]\tLoss: 731.901611\n",
            "Train Epoch: 262 [3840/60000 (6%)]\tLoss: 735.773804\n",
            "Train Epoch: 262 [5120/60000 (9%)]\tLoss: 757.456055\n",
            "Train Epoch: 262 [6400/60000 (11%)]\tLoss: 757.854004\n",
            "Train Epoch: 262 [7680/60000 (13%)]\tLoss: 718.440613\n",
            "Train Epoch: 262 [8960/60000 (15%)]\tLoss: 734.206970\n",
            "Train Epoch: 262 [10240/60000 (17%)]\tLoss: 738.506409\n",
            "Train Epoch: 262 [11520/60000 (19%)]\tLoss: 734.709412\n",
            "Train Epoch: 262 [12800/60000 (21%)]\tLoss: 744.027771\n",
            "Train Epoch: 262 [14080/60000 (23%)]\tLoss: 749.647705\n",
            "Train Epoch: 262 [15360/60000 (26%)]\tLoss: 768.896912\n",
            "Train Epoch: 262 [16640/60000 (28%)]\tLoss: 735.985596\n",
            "Train Epoch: 262 [17920/60000 (30%)]\tLoss: 721.262329\n",
            "Train Epoch: 262 [19200/60000 (32%)]\tLoss: 727.068298\n",
            "Train Epoch: 262 [20480/60000 (34%)]\tLoss: 700.959473\n",
            "Train Epoch: 262 [21760/60000 (36%)]\tLoss: 745.041748\n",
            "Train Epoch: 262 [23040/60000 (38%)]\tLoss: 717.713318\n",
            "Train Epoch: 262 [24320/60000 (41%)]\tLoss: 711.331299\n",
            "Train Epoch: 262 [25600/60000 (43%)]\tLoss: 737.467041\n",
            "Train Epoch: 262 [26880/60000 (45%)]\tLoss: 732.391296\n",
            "Train Epoch: 262 [28160/60000 (47%)]\tLoss: 760.476440\n",
            "Train Epoch: 262 [29440/60000 (49%)]\tLoss: 737.808655\n",
            "Train Epoch: 262 [30720/60000 (51%)]\tLoss: 744.631409\n",
            "Train Epoch: 262 [32000/60000 (53%)]\tLoss: 760.607849\n",
            "Train Epoch: 262 [33280/60000 (55%)]\tLoss: 727.576599\n",
            "Train Epoch: 262 [34560/60000 (58%)]\tLoss: 738.193054\n",
            "Train Epoch: 262 [35840/60000 (60%)]\tLoss: 745.108521\n",
            "Train Epoch: 262 [37120/60000 (62%)]\tLoss: 729.622314\n",
            "Train Epoch: 262 [38400/60000 (64%)]\tLoss: 751.256775\n",
            "Train Epoch: 262 [39680/60000 (66%)]\tLoss: 730.164185\n",
            "Train Epoch: 262 [40960/60000 (68%)]\tLoss: 746.986694\n",
            "Train Epoch: 262 [42240/60000 (70%)]\tLoss: 753.107300\n",
            "Train Epoch: 262 [43520/60000 (72%)]\tLoss: 701.820374\n",
            "Train Epoch: 262 [44800/60000 (75%)]\tLoss: 741.124878\n",
            "Train Epoch: 262 [46080/60000 (77%)]\tLoss: 728.985657\n",
            "Train Epoch: 262 [47360/60000 (79%)]\tLoss: 733.779114\n",
            "Train Epoch: 262 [48640/60000 (81%)]\tLoss: 719.991272\n",
            "Train Epoch: 262 [49920/60000 (83%)]\tLoss: 741.985291\n",
            "Train Epoch: 262 [51200/60000 (85%)]\tLoss: 735.775269\n",
            "Train Epoch: 262 [52480/60000 (87%)]\tLoss: 737.080017\n",
            "Train Epoch: 262 [53760/60000 (90%)]\tLoss: 712.468079\n",
            "Train Epoch: 262 [55040/60000 (92%)]\tLoss: 738.585205\n",
            "Train Epoch: 262 [56320/60000 (94%)]\tLoss: 718.864746\n",
            "Train Epoch: 262 [57600/60000 (96%)]\tLoss: 739.223450\n",
            "Train Epoch: 262 [58880/60000 (98%)]\tLoss: 737.261169\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785161316394806\n",
            "\n",
            "Train Epoch: 263 [0/60000 (0%)]\tLoss: 725.448120\n",
            "Train Epoch: 263 [1280/60000 (2%)]\tLoss: 738.656250\n",
            "Train Epoch: 263 [2560/60000 (4%)]\tLoss: 720.511292\n",
            "Train Epoch: 263 [3840/60000 (6%)]\tLoss: 751.101135\n",
            "Train Epoch: 263 [5120/60000 (9%)]\tLoss: 736.705933\n",
            "Train Epoch: 263 [6400/60000 (11%)]\tLoss: 755.223328\n",
            "Train Epoch: 263 [7680/60000 (13%)]\tLoss: 767.005981\n",
            "Train Epoch: 263 [8960/60000 (15%)]\tLoss: 729.996338\n",
            "Train Epoch: 263 [10240/60000 (17%)]\tLoss: 727.960815\n",
            "Train Epoch: 263 [11520/60000 (19%)]\tLoss: 727.681152\n",
            "Train Epoch: 263 [12800/60000 (21%)]\tLoss: 748.915466\n",
            "Train Epoch: 263 [14080/60000 (23%)]\tLoss: 734.256531\n",
            "Train Epoch: 263 [15360/60000 (26%)]\tLoss: 725.465454\n",
            "Train Epoch: 263 [16640/60000 (28%)]\tLoss: 720.503113\n",
            "Train Epoch: 263 [17920/60000 (30%)]\tLoss: 747.927246\n",
            "Train Epoch: 263 [19200/60000 (32%)]\tLoss: 743.652588\n",
            "Train Epoch: 263 [20480/60000 (34%)]\tLoss: 714.617310\n",
            "Train Epoch: 263 [21760/60000 (36%)]\tLoss: 723.714172\n",
            "Train Epoch: 263 [23040/60000 (38%)]\tLoss: 774.767822\n",
            "Train Epoch: 263 [24320/60000 (41%)]\tLoss: 708.251709\n",
            "Train Epoch: 263 [25600/60000 (43%)]\tLoss: 736.165405\n",
            "Train Epoch: 263 [26880/60000 (45%)]\tLoss: 719.406921\n",
            "Train Epoch: 263 [28160/60000 (47%)]\tLoss: 744.358643\n",
            "Train Epoch: 263 [29440/60000 (49%)]\tLoss: 734.372498\n",
            "Train Epoch: 263 [30720/60000 (51%)]\tLoss: 723.453674\n",
            "Train Epoch: 263 [32000/60000 (53%)]\tLoss: 756.377869\n",
            "Train Epoch: 263 [33280/60000 (55%)]\tLoss: 736.784119\n",
            "Train Epoch: 263 [34560/60000 (58%)]\tLoss: 727.989075\n",
            "Train Epoch: 263 [35840/60000 (60%)]\tLoss: 699.273621\n",
            "Train Epoch: 263 [37120/60000 (62%)]\tLoss: 747.808716\n",
            "Train Epoch: 263 [38400/60000 (64%)]\tLoss: 730.612305\n",
            "Train Epoch: 263 [39680/60000 (66%)]\tLoss: 743.629639\n",
            "Train Epoch: 263 [40960/60000 (68%)]\tLoss: 745.013672\n",
            "Train Epoch: 263 [42240/60000 (70%)]\tLoss: 739.563660\n",
            "Train Epoch: 263 [43520/60000 (72%)]\tLoss: 749.923340\n",
            "Train Epoch: 263 [44800/60000 (75%)]\tLoss: 731.296936\n",
            "Train Epoch: 263 [46080/60000 (77%)]\tLoss: 742.672913\n",
            "Train Epoch: 263 [47360/60000 (79%)]\tLoss: 732.192261\n",
            "Train Epoch: 263 [48640/60000 (81%)]\tLoss: 734.378601\n",
            "Train Epoch: 263 [49920/60000 (83%)]\tLoss: 732.755554\n",
            "Train Epoch: 263 [51200/60000 (85%)]\tLoss: 741.391541\n",
            "Train Epoch: 263 [52480/60000 (87%)]\tLoss: 733.713196\n",
            "Train Epoch: 263 [53760/60000 (90%)]\tLoss: 726.413879\n",
            "Train Epoch: 263 [55040/60000 (92%)]\tLoss: 720.791382\n",
            "Train Epoch: 263 [56320/60000 (94%)]\tLoss: 722.299438\n",
            "Train Epoch: 263 [57600/60000 (96%)]\tLoss: 727.226868\n",
            "Train Epoch: 263 [58880/60000 (98%)]\tLoss: 725.339844\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782859086990356\n",
            "\n",
            "Train Epoch: 264 [0/60000 (0%)]\tLoss: 723.082458\n",
            "Train Epoch: 264 [1280/60000 (2%)]\tLoss: 740.916504\n",
            "Train Epoch: 264 [2560/60000 (4%)]\tLoss: 739.588135\n",
            "Train Epoch: 264 [3840/60000 (6%)]\tLoss: 747.496704\n",
            "Train Epoch: 264 [5120/60000 (9%)]\tLoss: 726.665466\n",
            "Train Epoch: 264 [6400/60000 (11%)]\tLoss: 714.897278\n",
            "Train Epoch: 264 [7680/60000 (13%)]\tLoss: 745.175049\n",
            "Train Epoch: 264 [8960/60000 (15%)]\tLoss: 742.215881\n",
            "Train Epoch: 264 [10240/60000 (17%)]\tLoss: 741.825073\n",
            "Train Epoch: 264 [11520/60000 (19%)]\tLoss: 732.490417\n",
            "Train Epoch: 264 [12800/60000 (21%)]\tLoss: 726.858154\n",
            "Train Epoch: 264 [14080/60000 (23%)]\tLoss: 726.655823\n",
            "Train Epoch: 264 [15360/60000 (26%)]\tLoss: 738.706543\n",
            "Train Epoch: 264 [16640/60000 (28%)]\tLoss: 752.069641\n",
            "Train Epoch: 264 [17920/60000 (30%)]\tLoss: 735.238281\n",
            "Train Epoch: 264 [19200/60000 (32%)]\tLoss: 736.776367\n",
            "Train Epoch: 264 [20480/60000 (34%)]\tLoss: 731.110046\n",
            "Train Epoch: 264 [21760/60000 (36%)]\tLoss: 744.145020\n",
            "Train Epoch: 264 [23040/60000 (38%)]\tLoss: 722.933533\n",
            "Train Epoch: 264 [24320/60000 (41%)]\tLoss: 724.657837\n",
            "Train Epoch: 264 [25600/60000 (43%)]\tLoss: 735.972961\n",
            "Train Epoch: 264 [26880/60000 (45%)]\tLoss: 733.536987\n",
            "Train Epoch: 264 [28160/60000 (47%)]\tLoss: 732.366211\n",
            "Train Epoch: 264 [29440/60000 (49%)]\tLoss: 742.919739\n",
            "Train Epoch: 264 [30720/60000 (51%)]\tLoss: 749.463928\n",
            "Train Epoch: 264 [32000/60000 (53%)]\tLoss: 721.669983\n",
            "Train Epoch: 264 [33280/60000 (55%)]\tLoss: 735.046631\n",
            "Train Epoch: 264 [34560/60000 (58%)]\tLoss: 753.110901\n",
            "Train Epoch: 264 [35840/60000 (60%)]\tLoss: 734.296997\n",
            "Train Epoch: 264 [37120/60000 (62%)]\tLoss: 749.445801\n",
            "Train Epoch: 264 [38400/60000 (64%)]\tLoss: 740.993713\n",
            "Train Epoch: 264 [39680/60000 (66%)]\tLoss: 737.598206\n",
            "Train Epoch: 264 [40960/60000 (68%)]\tLoss: 735.527771\n",
            "Train Epoch: 264 [42240/60000 (70%)]\tLoss: 730.081421\n",
            "Train Epoch: 264 [43520/60000 (72%)]\tLoss: 740.651062\n",
            "Train Epoch: 264 [44800/60000 (75%)]\tLoss: 725.862671\n",
            "Train Epoch: 264 [46080/60000 (77%)]\tLoss: 722.441406\n",
            "Train Epoch: 264 [47360/60000 (79%)]\tLoss: 746.692505\n",
            "Train Epoch: 264 [48640/60000 (81%)]\tLoss: 752.690674\n",
            "Train Epoch: 264 [49920/60000 (83%)]\tLoss: 751.619202\n",
            "Train Epoch: 264 [51200/60000 (85%)]\tLoss: 759.268738\n",
            "Train Epoch: 264 [52480/60000 (87%)]\tLoss: 736.363525\n",
            "Train Epoch: 264 [53760/60000 (90%)]\tLoss: 732.916931\n",
            "Train Epoch: 264 [55040/60000 (92%)]\tLoss: 715.562622\n",
            "Train Epoch: 264 [56320/60000 (94%)]\tLoss: 735.906738\n",
            "Train Epoch: 264 [57600/60000 (96%)]\tLoss: 730.739380\n",
            "Train Epoch: 264 [58880/60000 (98%)]\tLoss: 734.253418\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786255061626434\n",
            "\n",
            "Train Epoch: 265 [0/60000 (0%)]\tLoss: 719.966125\n",
            "Train Epoch: 265 [1280/60000 (2%)]\tLoss: 754.212708\n",
            "Train Epoch: 265 [2560/60000 (4%)]\tLoss: 738.291931\n",
            "Train Epoch: 265 [3840/60000 (6%)]\tLoss: 744.775940\n",
            "Train Epoch: 265 [5120/60000 (9%)]\tLoss: 735.994934\n",
            "Train Epoch: 265 [6400/60000 (11%)]\tLoss: 707.573730\n",
            "Train Epoch: 265 [7680/60000 (13%)]\tLoss: 731.411743\n",
            "Train Epoch: 265 [8960/60000 (15%)]\tLoss: 705.528870\n",
            "Train Epoch: 265 [10240/60000 (17%)]\tLoss: 738.907959\n",
            "Train Epoch: 265 [11520/60000 (19%)]\tLoss: 727.118103\n",
            "Train Epoch: 265 [12800/60000 (21%)]\tLoss: 749.150818\n",
            "Train Epoch: 265 [14080/60000 (23%)]\tLoss: 727.875854\n",
            "Train Epoch: 265 [15360/60000 (26%)]\tLoss: 724.894897\n",
            "Train Epoch: 265 [16640/60000 (28%)]\tLoss: 736.215271\n",
            "Train Epoch: 265 [17920/60000 (30%)]\tLoss: 740.899414\n",
            "Train Epoch: 265 [19200/60000 (32%)]\tLoss: 734.100159\n",
            "Train Epoch: 265 [20480/60000 (34%)]\tLoss: 747.312195\n",
            "Train Epoch: 265 [21760/60000 (36%)]\tLoss: 713.779480\n",
            "Train Epoch: 265 [23040/60000 (38%)]\tLoss: 702.491394\n",
            "Train Epoch: 265 [24320/60000 (41%)]\tLoss: 734.518982\n",
            "Train Epoch: 265 [25600/60000 (43%)]\tLoss: 742.971252\n",
            "Train Epoch: 265 [26880/60000 (45%)]\tLoss: 730.193481\n",
            "Train Epoch: 265 [28160/60000 (47%)]\tLoss: 752.182190\n",
            "Train Epoch: 265 [29440/60000 (49%)]\tLoss: 708.400879\n",
            "Train Epoch: 265 [30720/60000 (51%)]\tLoss: 735.841858\n",
            "Train Epoch: 265 [32000/60000 (53%)]\tLoss: 733.660278\n",
            "Train Epoch: 265 [33280/60000 (55%)]\tLoss: 744.483582\n",
            "Train Epoch: 265 [34560/60000 (58%)]\tLoss: 741.830811\n",
            "Train Epoch: 265 [35840/60000 (60%)]\tLoss: 750.440796\n",
            "Train Epoch: 265 [37120/60000 (62%)]\tLoss: 715.397888\n",
            "Train Epoch: 265 [38400/60000 (64%)]\tLoss: 738.073669\n",
            "Train Epoch: 265 [39680/60000 (66%)]\tLoss: 730.595703\n",
            "Train Epoch: 265 [40960/60000 (68%)]\tLoss: 751.370117\n",
            "Train Epoch: 265 [42240/60000 (70%)]\tLoss: 737.261292\n",
            "Train Epoch: 265 [43520/60000 (72%)]\tLoss: 737.294189\n",
            "Train Epoch: 265 [44800/60000 (75%)]\tLoss: 726.978149\n",
            "Train Epoch: 265 [46080/60000 (77%)]\tLoss: 737.273010\n",
            "Train Epoch: 265 [47360/60000 (79%)]\tLoss: 745.866272\n",
            "Train Epoch: 265 [48640/60000 (81%)]\tLoss: 733.796082\n",
            "Train Epoch: 265 [49920/60000 (83%)]\tLoss: 731.861206\n",
            "Train Epoch: 265 [51200/60000 (85%)]\tLoss: 732.191895\n",
            "Train Epoch: 265 [52480/60000 (87%)]\tLoss: 762.294800\n",
            "Train Epoch: 265 [53760/60000 (90%)]\tLoss: 767.056274\n",
            "Train Epoch: 265 [55040/60000 (92%)]\tLoss: 718.515076\n",
            "Train Epoch: 265 [56320/60000 (94%)]\tLoss: 729.139465\n",
            "Train Epoch: 265 [57600/60000 (96%)]\tLoss: 740.685852\n",
            "Train Epoch: 265 [58880/60000 (98%)]\tLoss: 727.018799\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978396624326706\n",
            "\n",
            "Train Epoch: 266 [0/60000 (0%)]\tLoss: 740.599060\n",
            "Train Epoch: 266 [1280/60000 (2%)]\tLoss: 723.763855\n",
            "Train Epoch: 266 [2560/60000 (4%)]\tLoss: 748.807434\n",
            "Train Epoch: 266 [3840/60000 (6%)]\tLoss: 710.931519\n",
            "Train Epoch: 266 [5120/60000 (9%)]\tLoss: 725.885986\n",
            "Train Epoch: 266 [6400/60000 (11%)]\tLoss: 726.052612\n",
            "Train Epoch: 266 [7680/60000 (13%)]\tLoss: 736.409851\n",
            "Train Epoch: 266 [8960/60000 (15%)]\tLoss: 751.375732\n",
            "Train Epoch: 266 [10240/60000 (17%)]\tLoss: 714.492065\n",
            "Train Epoch: 266 [11520/60000 (19%)]\tLoss: 734.657776\n",
            "Train Epoch: 266 [12800/60000 (21%)]\tLoss: 742.337830\n",
            "Train Epoch: 266 [14080/60000 (23%)]\tLoss: 727.347290\n",
            "Train Epoch: 266 [15360/60000 (26%)]\tLoss: 726.213135\n",
            "Train Epoch: 266 [16640/60000 (28%)]\tLoss: 738.845520\n",
            "Train Epoch: 266 [17920/60000 (30%)]\tLoss: 729.455444\n",
            "Train Epoch: 266 [19200/60000 (32%)]\tLoss: 717.685059\n",
            "Train Epoch: 266 [20480/60000 (34%)]\tLoss: 762.099548\n",
            "Train Epoch: 266 [21760/60000 (36%)]\tLoss: 729.767456\n",
            "Train Epoch: 266 [23040/60000 (38%)]\tLoss: 750.983459\n",
            "Train Epoch: 266 [24320/60000 (41%)]\tLoss: 748.404846\n",
            "Train Epoch: 266 [25600/60000 (43%)]\tLoss: 738.487732\n",
            "Train Epoch: 266 [26880/60000 (45%)]\tLoss: 715.892395\n",
            "Train Epoch: 266 [28160/60000 (47%)]\tLoss: 731.713074\n",
            "Train Epoch: 266 [29440/60000 (49%)]\tLoss: 733.682861\n",
            "Train Epoch: 266 [30720/60000 (51%)]\tLoss: 752.949219\n",
            "Train Epoch: 266 [32000/60000 (53%)]\tLoss: 771.995361\n",
            "Train Epoch: 266 [33280/60000 (55%)]\tLoss: 739.628601\n",
            "Train Epoch: 266 [34560/60000 (58%)]\tLoss: 730.887878\n",
            "Train Epoch: 266 [35840/60000 (60%)]\tLoss: 753.417908\n",
            "Train Epoch: 266 [37120/60000 (62%)]\tLoss: 738.297363\n",
            "Train Epoch: 266 [38400/60000 (64%)]\tLoss: 715.167480\n",
            "Train Epoch: 266 [39680/60000 (66%)]\tLoss: 748.131470\n",
            "Train Epoch: 266 [40960/60000 (68%)]\tLoss: 748.412598\n",
            "Train Epoch: 266 [42240/60000 (70%)]\tLoss: 729.778503\n",
            "Train Epoch: 266 [43520/60000 (72%)]\tLoss: 726.969543\n",
            "Train Epoch: 266 [44800/60000 (75%)]\tLoss: 746.994446\n",
            "Train Epoch: 266 [46080/60000 (77%)]\tLoss: 731.795044\n",
            "Train Epoch: 266 [47360/60000 (79%)]\tLoss: 716.242249\n",
            "Train Epoch: 266 [48640/60000 (81%)]\tLoss: 739.258789\n",
            "Train Epoch: 266 [49920/60000 (83%)]\tLoss: 708.067444\n",
            "Train Epoch: 266 [51200/60000 (85%)]\tLoss: 744.032104\n",
            "Train Epoch: 266 [52480/60000 (87%)]\tLoss: 729.402283\n",
            "Train Epoch: 266 [53760/60000 (90%)]\tLoss: 735.446594\n",
            "Train Epoch: 266 [55040/60000 (92%)]\tLoss: 726.469299\n",
            "Train Epoch: 266 [56320/60000 (94%)]\tLoss: 711.209900\n",
            "Train Epoch: 266 [57600/60000 (96%)]\tLoss: 727.042603\n",
            "Train Epoch: 266 [58880/60000 (98%)]\tLoss: 755.108093\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782131910324097\n",
            "\n",
            "Train Epoch: 267 [0/60000 (0%)]\tLoss: 743.472839\n",
            "Train Epoch: 267 [1280/60000 (2%)]\tLoss: 750.908142\n",
            "Train Epoch: 267 [2560/60000 (4%)]\tLoss: 742.023438\n",
            "Train Epoch: 267 [3840/60000 (6%)]\tLoss: 751.027588\n",
            "Train Epoch: 267 [5120/60000 (9%)]\tLoss: 747.684082\n",
            "Train Epoch: 267 [6400/60000 (11%)]\tLoss: 735.976196\n",
            "Train Epoch: 267 [7680/60000 (13%)]\tLoss: 749.509033\n",
            "Train Epoch: 267 [8960/60000 (15%)]\tLoss: 717.634155\n",
            "Train Epoch: 267 [10240/60000 (17%)]\tLoss: 724.992493\n",
            "Train Epoch: 267 [11520/60000 (19%)]\tLoss: 752.083374\n",
            "Train Epoch: 267 [12800/60000 (21%)]\tLoss: 728.081543\n",
            "Train Epoch: 267 [14080/60000 (23%)]\tLoss: 725.148621\n",
            "Train Epoch: 267 [15360/60000 (26%)]\tLoss: 733.951904\n",
            "Train Epoch: 267 [16640/60000 (28%)]\tLoss: 748.021301\n",
            "Train Epoch: 267 [17920/60000 (30%)]\tLoss: 711.782715\n",
            "Train Epoch: 267 [19200/60000 (32%)]\tLoss: 708.200378\n",
            "Train Epoch: 267 [20480/60000 (34%)]\tLoss: 746.132996\n",
            "Train Epoch: 267 [21760/60000 (36%)]\tLoss: 731.801575\n",
            "Train Epoch: 267 [23040/60000 (38%)]\tLoss: 712.388916\n",
            "Train Epoch: 267 [24320/60000 (41%)]\tLoss: 727.917664\n",
            "Train Epoch: 267 [25600/60000 (43%)]\tLoss: 736.339478\n",
            "Train Epoch: 267 [26880/60000 (45%)]\tLoss: 743.432800\n",
            "Train Epoch: 267 [28160/60000 (47%)]\tLoss: 735.097168\n",
            "Train Epoch: 267 [29440/60000 (49%)]\tLoss: 729.992126\n",
            "Train Epoch: 267 [30720/60000 (51%)]\tLoss: 716.632629\n",
            "Train Epoch: 267 [32000/60000 (53%)]\tLoss: 708.187622\n",
            "Train Epoch: 267 [33280/60000 (55%)]\tLoss: 732.846680\n",
            "Train Epoch: 267 [34560/60000 (58%)]\tLoss: 734.176453\n",
            "Train Epoch: 267 [35840/60000 (60%)]\tLoss: 719.564575\n",
            "Train Epoch: 267 [37120/60000 (62%)]\tLoss: 741.972473\n",
            "Train Epoch: 267 [38400/60000 (64%)]\tLoss: 730.212097\n",
            "Train Epoch: 267 [39680/60000 (66%)]\tLoss: 746.616455\n",
            "Train Epoch: 267 [40960/60000 (68%)]\tLoss: 733.677612\n",
            "Train Epoch: 267 [42240/60000 (70%)]\tLoss: 748.120605\n",
            "Train Epoch: 267 [43520/60000 (72%)]\tLoss: 717.417847\n",
            "Train Epoch: 267 [44800/60000 (75%)]\tLoss: 730.112061\n",
            "Train Epoch: 267 [46080/60000 (77%)]\tLoss: 726.617554\n",
            "Train Epoch: 267 [47360/60000 (79%)]\tLoss: 749.104858\n",
            "Train Epoch: 267 [48640/60000 (81%)]\tLoss: 762.655334\n",
            "Train Epoch: 267 [49920/60000 (83%)]\tLoss: 728.994690\n",
            "Train Epoch: 267 [51200/60000 (85%)]\tLoss: 762.883484\n",
            "Train Epoch: 267 [52480/60000 (87%)]\tLoss: 743.527954\n",
            "Train Epoch: 267 [53760/60000 (90%)]\tLoss: 739.725830\n",
            "Train Epoch: 267 [55040/60000 (92%)]\tLoss: 730.901978\n",
            "Train Epoch: 267 [56320/60000 (94%)]\tLoss: 791.583618\n",
            "Train Epoch: 267 [57600/60000 (96%)]\tLoss: 734.865723\n",
            "Train Epoch: 267 [58880/60000 (98%)]\tLoss: 714.002625\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784194231033325\n",
            "\n",
            "Train Epoch: 268 [0/60000 (0%)]\tLoss: 731.031921\n",
            "Train Epoch: 268 [1280/60000 (2%)]\tLoss: 706.208435\n",
            "Train Epoch: 268 [2560/60000 (4%)]\tLoss: 740.822021\n",
            "Train Epoch: 268 [3840/60000 (6%)]\tLoss: 720.022827\n",
            "Train Epoch: 268 [5120/60000 (9%)]\tLoss: 756.608093\n",
            "Train Epoch: 268 [6400/60000 (11%)]\tLoss: 728.871704\n",
            "Train Epoch: 268 [7680/60000 (13%)]\tLoss: 745.806702\n",
            "Train Epoch: 268 [8960/60000 (15%)]\tLoss: 732.646118\n",
            "Train Epoch: 268 [10240/60000 (17%)]\tLoss: 762.074707\n",
            "Train Epoch: 268 [11520/60000 (19%)]\tLoss: 723.132812\n",
            "Train Epoch: 268 [12800/60000 (21%)]\tLoss: 740.744324\n",
            "Train Epoch: 268 [14080/60000 (23%)]\tLoss: 743.853699\n",
            "Train Epoch: 268 [15360/60000 (26%)]\tLoss: 752.142456\n",
            "Train Epoch: 268 [16640/60000 (28%)]\tLoss: 742.377625\n",
            "Train Epoch: 268 [17920/60000 (30%)]\tLoss: 736.945435\n",
            "Train Epoch: 268 [19200/60000 (32%)]\tLoss: 745.335510\n",
            "Train Epoch: 268 [20480/60000 (34%)]\tLoss: 726.481201\n",
            "Train Epoch: 268 [21760/60000 (36%)]\tLoss: 734.545349\n",
            "Train Epoch: 268 [23040/60000 (38%)]\tLoss: 724.241455\n",
            "Train Epoch: 268 [24320/60000 (41%)]\tLoss: 747.343079\n",
            "Train Epoch: 268 [25600/60000 (43%)]\tLoss: 732.217896\n",
            "Train Epoch: 268 [26880/60000 (45%)]\tLoss: 729.097656\n",
            "Train Epoch: 268 [28160/60000 (47%)]\tLoss: 758.235229\n",
            "Train Epoch: 268 [29440/60000 (49%)]\tLoss: 749.007507\n",
            "Train Epoch: 268 [30720/60000 (51%)]\tLoss: 720.620850\n",
            "Train Epoch: 268 [32000/60000 (53%)]\tLoss: 719.304504\n",
            "Train Epoch: 268 [33280/60000 (55%)]\tLoss: 734.316711\n",
            "Train Epoch: 268 [34560/60000 (58%)]\tLoss: 752.288574\n",
            "Train Epoch: 268 [35840/60000 (60%)]\tLoss: 758.075745\n",
            "Train Epoch: 268 [37120/60000 (62%)]\tLoss: 745.377625\n",
            "Train Epoch: 268 [38400/60000 (64%)]\tLoss: 732.391907\n",
            "Train Epoch: 268 [39680/60000 (66%)]\tLoss: 746.375671\n",
            "Train Epoch: 268 [40960/60000 (68%)]\tLoss: 732.814148\n",
            "Train Epoch: 268 [42240/60000 (70%)]\tLoss: 753.632202\n",
            "Train Epoch: 268 [43520/60000 (72%)]\tLoss: 756.519043\n",
            "Train Epoch: 268 [44800/60000 (75%)]\tLoss: 741.930603\n",
            "Train Epoch: 268 [46080/60000 (77%)]\tLoss: 734.231201\n",
            "Train Epoch: 268 [47360/60000 (79%)]\tLoss: 703.799133\n",
            "Train Epoch: 268 [48640/60000 (81%)]\tLoss: 732.367737\n",
            "Train Epoch: 268 [49920/60000 (83%)]\tLoss: 734.785767\n",
            "Train Epoch: 268 [51200/60000 (85%)]\tLoss: 725.794739\n",
            "Train Epoch: 268 [52480/60000 (87%)]\tLoss: 740.634277\n",
            "Train Epoch: 268 [53760/60000 (90%)]\tLoss: 716.462341\n",
            "Train Epoch: 268 [55040/60000 (92%)]\tLoss: 694.356079\n",
            "Train Epoch: 268 [56320/60000 (94%)]\tLoss: 744.858337\n",
            "Train Epoch: 268 [57600/60000 (96%)]\tLoss: 754.239136\n",
            "Train Epoch: 268 [58880/60000 (98%)]\tLoss: 715.914185\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784678518772125\n",
            "\n",
            "Train Epoch: 269 [0/60000 (0%)]\tLoss: 743.054016\n",
            "Train Epoch: 269 [1280/60000 (2%)]\tLoss: 740.297852\n",
            "Train Epoch: 269 [2560/60000 (4%)]\tLoss: 733.199524\n",
            "Train Epoch: 269 [3840/60000 (6%)]\tLoss: 736.585754\n",
            "Train Epoch: 269 [5120/60000 (9%)]\tLoss: 749.884827\n",
            "Train Epoch: 269 [6400/60000 (11%)]\tLoss: 721.049683\n",
            "Train Epoch: 269 [7680/60000 (13%)]\tLoss: 729.389099\n",
            "Train Epoch: 269 [8960/60000 (15%)]\tLoss: 751.263672\n",
            "Train Epoch: 269 [10240/60000 (17%)]\tLoss: 751.083618\n",
            "Train Epoch: 269 [11520/60000 (19%)]\tLoss: 743.506348\n",
            "Train Epoch: 269 [12800/60000 (21%)]\tLoss: 731.035583\n",
            "Train Epoch: 269 [14080/60000 (23%)]\tLoss: 729.875732\n",
            "Train Epoch: 269 [15360/60000 (26%)]\tLoss: 750.045593\n",
            "Train Epoch: 269 [16640/60000 (28%)]\tLoss: 714.604797\n",
            "Train Epoch: 269 [17920/60000 (30%)]\tLoss: 718.998779\n",
            "Train Epoch: 269 [19200/60000 (32%)]\tLoss: 758.141541\n",
            "Train Epoch: 269 [20480/60000 (34%)]\tLoss: 745.141785\n",
            "Train Epoch: 269 [21760/60000 (36%)]\tLoss: 727.305542\n",
            "Train Epoch: 269 [23040/60000 (38%)]\tLoss: 752.342712\n",
            "Train Epoch: 269 [24320/60000 (41%)]\tLoss: 731.883972\n",
            "Train Epoch: 269 [25600/60000 (43%)]\tLoss: 767.671936\n",
            "Train Epoch: 269 [26880/60000 (45%)]\tLoss: 756.449036\n",
            "Train Epoch: 269 [28160/60000 (47%)]\tLoss: 735.685120\n",
            "Train Epoch: 269 [29440/60000 (49%)]\tLoss: 723.467712\n",
            "Train Epoch: 269 [30720/60000 (51%)]\tLoss: 761.929871\n",
            "Train Epoch: 269 [32000/60000 (53%)]\tLoss: 749.940186\n",
            "Train Epoch: 269 [33280/60000 (55%)]\tLoss: 763.545349\n",
            "Train Epoch: 269 [34560/60000 (58%)]\tLoss: 714.488586\n",
            "Train Epoch: 269 [35840/60000 (60%)]\tLoss: 737.723755\n",
            "Train Epoch: 269 [37120/60000 (62%)]\tLoss: 736.889404\n",
            "Train Epoch: 269 [38400/60000 (64%)]\tLoss: 745.408630\n",
            "Train Epoch: 269 [39680/60000 (66%)]\tLoss: 737.998962\n",
            "Train Epoch: 269 [40960/60000 (68%)]\tLoss: 743.372192\n",
            "Train Epoch: 269 [42240/60000 (70%)]\tLoss: 756.922852\n",
            "Train Epoch: 269 [43520/60000 (72%)]\tLoss: 732.271667\n",
            "Train Epoch: 269 [44800/60000 (75%)]\tLoss: 770.269836\n",
            "Train Epoch: 269 [46080/60000 (77%)]\tLoss: 743.302307\n",
            "Train Epoch: 269 [47360/60000 (79%)]\tLoss: 758.460693\n",
            "Train Epoch: 269 [48640/60000 (81%)]\tLoss: 712.910522\n",
            "Train Epoch: 269 [49920/60000 (83%)]\tLoss: 748.417297\n",
            "Train Epoch: 269 [51200/60000 (85%)]\tLoss: 755.345215\n",
            "Train Epoch: 269 [52480/60000 (87%)]\tLoss: 727.871704\n",
            "Train Epoch: 269 [53760/60000 (90%)]\tLoss: 726.471619\n",
            "Train Epoch: 269 [55040/60000 (92%)]\tLoss: 741.188660\n",
            "Train Epoch: 269 [56320/60000 (94%)]\tLoss: 725.517273\n",
            "Train Epoch: 269 [57600/60000 (96%)]\tLoss: 727.017395\n",
            "Train Epoch: 269 [58880/60000 (98%)]\tLoss: 738.324158\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978190392255783\n",
            "\n",
            "Train Epoch: 270 [0/60000 (0%)]\tLoss: 736.749817\n",
            "Train Epoch: 270 [1280/60000 (2%)]\tLoss: 760.360962\n",
            "Train Epoch: 270 [2560/60000 (4%)]\tLoss: 712.254150\n",
            "Train Epoch: 270 [3840/60000 (6%)]\tLoss: 744.484680\n",
            "Train Epoch: 270 [5120/60000 (9%)]\tLoss: 722.788940\n",
            "Train Epoch: 270 [6400/60000 (11%)]\tLoss: 744.630371\n",
            "Train Epoch: 270 [7680/60000 (13%)]\tLoss: 724.992371\n",
            "Train Epoch: 270 [8960/60000 (15%)]\tLoss: 744.612854\n",
            "Train Epoch: 270 [10240/60000 (17%)]\tLoss: 729.472229\n",
            "Train Epoch: 270 [11520/60000 (19%)]\tLoss: 723.210938\n",
            "Train Epoch: 270 [12800/60000 (21%)]\tLoss: 713.013367\n",
            "Train Epoch: 270 [14080/60000 (23%)]\tLoss: 734.303040\n",
            "Train Epoch: 270 [15360/60000 (26%)]\tLoss: 755.713989\n",
            "Train Epoch: 270 [16640/60000 (28%)]\tLoss: 722.886292\n",
            "Train Epoch: 270 [17920/60000 (30%)]\tLoss: 714.389404\n",
            "Train Epoch: 270 [19200/60000 (32%)]\tLoss: 720.801514\n",
            "Train Epoch: 270 [20480/60000 (34%)]\tLoss: 751.748169\n",
            "Train Epoch: 270 [21760/60000 (36%)]\tLoss: 735.819153\n",
            "Train Epoch: 270 [23040/60000 (38%)]\tLoss: 758.504761\n",
            "Train Epoch: 270 [24320/60000 (41%)]\tLoss: 746.874146\n",
            "Train Epoch: 270 [25600/60000 (43%)]\tLoss: 710.139343\n",
            "Train Epoch: 270 [26880/60000 (45%)]\tLoss: 725.370911\n",
            "Train Epoch: 270 [28160/60000 (47%)]\tLoss: 697.449402\n",
            "Train Epoch: 270 [29440/60000 (49%)]\tLoss: 750.406128\n",
            "Train Epoch: 270 [30720/60000 (51%)]\tLoss: 716.931763\n",
            "Train Epoch: 270 [32000/60000 (53%)]\tLoss: 753.732117\n",
            "Train Epoch: 270 [33280/60000 (55%)]\tLoss: 736.124695\n",
            "Train Epoch: 270 [34560/60000 (58%)]\tLoss: 749.728149\n",
            "Train Epoch: 270 [35840/60000 (60%)]\tLoss: 734.776245\n",
            "Train Epoch: 270 [37120/60000 (62%)]\tLoss: 722.579468\n",
            "Train Epoch: 270 [38400/60000 (64%)]\tLoss: 722.208740\n",
            "Train Epoch: 270 [39680/60000 (66%)]\tLoss: 731.578003\n",
            "Train Epoch: 270 [40960/60000 (68%)]\tLoss: 749.539734\n",
            "Train Epoch: 270 [42240/60000 (70%)]\tLoss: 706.020020\n",
            "Train Epoch: 270 [43520/60000 (72%)]\tLoss: 712.443359\n",
            "Train Epoch: 270 [44800/60000 (75%)]\tLoss: 729.409363\n",
            "Train Epoch: 270 [46080/60000 (77%)]\tLoss: 722.770142\n",
            "Train Epoch: 270 [47360/60000 (79%)]\tLoss: 747.588318\n",
            "Train Epoch: 270 [48640/60000 (81%)]\tLoss: 748.793152\n",
            "Train Epoch: 270 [49920/60000 (83%)]\tLoss: 739.451965\n",
            "Train Epoch: 270 [51200/60000 (85%)]\tLoss: 726.322876\n",
            "Train Epoch: 270 [52480/60000 (87%)]\tLoss: 728.998169\n",
            "Train Epoch: 270 [53760/60000 (90%)]\tLoss: 735.005066\n",
            "Train Epoch: 270 [55040/60000 (92%)]\tLoss: 742.938965\n",
            "Train Epoch: 270 [56320/60000 (94%)]\tLoss: 754.367432\n",
            "Train Epoch: 270 [57600/60000 (96%)]\tLoss: 727.781250\n",
            "Train Epoch: 270 [58880/60000 (98%)]\tLoss: 744.205688\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783614575862885\n",
            "\n",
            "Train Epoch: 271 [0/60000 (0%)]\tLoss: 726.665833\n",
            "Train Epoch: 271 [1280/60000 (2%)]\tLoss: 723.716980\n",
            "Train Epoch: 271 [2560/60000 (4%)]\tLoss: 747.070557\n",
            "Train Epoch: 271 [3840/60000 (6%)]\tLoss: 749.706482\n",
            "Train Epoch: 271 [5120/60000 (9%)]\tLoss: 732.808167\n",
            "Train Epoch: 271 [6400/60000 (11%)]\tLoss: 761.371948\n",
            "Train Epoch: 271 [7680/60000 (13%)]\tLoss: 752.024536\n",
            "Train Epoch: 271 [8960/60000 (15%)]\tLoss: 753.735718\n",
            "Train Epoch: 271 [10240/60000 (17%)]\tLoss: 735.615479\n",
            "Train Epoch: 271 [11520/60000 (19%)]\tLoss: 720.632324\n",
            "Train Epoch: 271 [12800/60000 (21%)]\tLoss: 728.792725\n",
            "Train Epoch: 271 [14080/60000 (23%)]\tLoss: 722.819641\n",
            "Train Epoch: 271 [15360/60000 (26%)]\tLoss: 734.490784\n",
            "Train Epoch: 271 [16640/60000 (28%)]\tLoss: 730.184387\n",
            "Train Epoch: 271 [17920/60000 (30%)]\tLoss: 696.967834\n",
            "Train Epoch: 271 [19200/60000 (32%)]\tLoss: 726.763855\n",
            "Train Epoch: 271 [20480/60000 (34%)]\tLoss: 741.549744\n",
            "Train Epoch: 271 [21760/60000 (36%)]\tLoss: 748.958252\n",
            "Train Epoch: 271 [23040/60000 (38%)]\tLoss: 723.991577\n",
            "Train Epoch: 271 [24320/60000 (41%)]\tLoss: 731.775635\n",
            "Train Epoch: 271 [25600/60000 (43%)]\tLoss: 728.463501\n",
            "Train Epoch: 271 [26880/60000 (45%)]\tLoss: 736.138916\n",
            "Train Epoch: 271 [28160/60000 (47%)]\tLoss: 725.899414\n",
            "Train Epoch: 271 [29440/60000 (49%)]\tLoss: 738.048279\n",
            "Train Epoch: 271 [30720/60000 (51%)]\tLoss: 737.750061\n",
            "Train Epoch: 271 [32000/60000 (53%)]\tLoss: 749.926636\n",
            "Train Epoch: 271 [33280/60000 (55%)]\tLoss: 730.571106\n",
            "Train Epoch: 271 [34560/60000 (58%)]\tLoss: 733.591980\n",
            "Train Epoch: 271 [35840/60000 (60%)]\tLoss: 713.976135\n",
            "Train Epoch: 271 [37120/60000 (62%)]\tLoss: 715.856812\n",
            "Train Epoch: 271 [38400/60000 (64%)]\tLoss: 699.923035\n",
            "Train Epoch: 271 [39680/60000 (66%)]\tLoss: 718.009949\n",
            "Train Epoch: 271 [40960/60000 (68%)]\tLoss: 742.326843\n",
            "Train Epoch: 271 [42240/60000 (70%)]\tLoss: 730.305969\n",
            "Train Epoch: 271 [43520/60000 (72%)]\tLoss: 737.597961\n",
            "Train Epoch: 271 [44800/60000 (75%)]\tLoss: 733.435303\n",
            "Train Epoch: 271 [46080/60000 (77%)]\tLoss: 735.600464\n",
            "Train Epoch: 271 [47360/60000 (79%)]\tLoss: 725.923889\n",
            "Train Epoch: 271 [48640/60000 (81%)]\tLoss: 740.097595\n",
            "Train Epoch: 271 [49920/60000 (83%)]\tLoss: 737.959351\n",
            "Train Epoch: 271 [51200/60000 (85%)]\tLoss: 740.350647\n",
            "Train Epoch: 271 [52480/60000 (87%)]\tLoss: 720.625427\n",
            "Train Epoch: 271 [53760/60000 (90%)]\tLoss: 728.564026\n",
            "Train Epoch: 271 [55040/60000 (92%)]\tLoss: 727.528259\n",
            "Train Epoch: 271 [56320/60000 (94%)]\tLoss: 737.552246\n",
            "Train Epoch: 271 [57600/60000 (96%)]\tLoss: 748.211975\n",
            "Train Epoch: 271 [58880/60000 (98%)]\tLoss: 744.399475\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784465432167053\n",
            "\n",
            "Train Epoch: 272 [0/60000 (0%)]\tLoss: 756.195984\n",
            "Train Epoch: 272 [1280/60000 (2%)]\tLoss: 717.340881\n",
            "Train Epoch: 272 [2560/60000 (4%)]\tLoss: 733.836853\n",
            "Train Epoch: 272 [3840/60000 (6%)]\tLoss: 739.580078\n",
            "Train Epoch: 272 [5120/60000 (9%)]\tLoss: 713.181702\n",
            "Train Epoch: 272 [6400/60000 (11%)]\tLoss: 743.756470\n",
            "Train Epoch: 272 [7680/60000 (13%)]\tLoss: 740.741882\n",
            "Train Epoch: 272 [8960/60000 (15%)]\tLoss: 711.631409\n",
            "Train Epoch: 272 [10240/60000 (17%)]\tLoss: 732.958313\n",
            "Train Epoch: 272 [11520/60000 (19%)]\tLoss: 729.710388\n",
            "Train Epoch: 272 [12800/60000 (21%)]\tLoss: 734.222778\n",
            "Train Epoch: 272 [14080/60000 (23%)]\tLoss: 723.901794\n",
            "Train Epoch: 272 [15360/60000 (26%)]\tLoss: 740.174500\n",
            "Train Epoch: 272 [16640/60000 (28%)]\tLoss: 745.728516\n",
            "Train Epoch: 272 [17920/60000 (30%)]\tLoss: 730.775696\n",
            "Train Epoch: 272 [19200/60000 (32%)]\tLoss: 718.459229\n",
            "Train Epoch: 272 [20480/60000 (34%)]\tLoss: 736.615967\n",
            "Train Epoch: 272 [21760/60000 (36%)]\tLoss: 733.873291\n",
            "Train Epoch: 272 [23040/60000 (38%)]\tLoss: 740.316528\n",
            "Train Epoch: 272 [24320/60000 (41%)]\tLoss: 726.525024\n",
            "Train Epoch: 272 [25600/60000 (43%)]\tLoss: 747.996521\n",
            "Train Epoch: 272 [26880/60000 (45%)]\tLoss: 740.974670\n",
            "Train Epoch: 272 [28160/60000 (47%)]\tLoss: 742.775879\n",
            "Train Epoch: 272 [29440/60000 (49%)]\tLoss: 712.820557\n",
            "Train Epoch: 272 [30720/60000 (51%)]\tLoss: 744.350342\n",
            "Train Epoch: 272 [32000/60000 (53%)]\tLoss: 739.348633\n",
            "Train Epoch: 272 [33280/60000 (55%)]\tLoss: 765.081848\n",
            "Train Epoch: 272 [34560/60000 (58%)]\tLoss: 725.414917\n",
            "Train Epoch: 272 [35840/60000 (60%)]\tLoss: 718.064697\n",
            "Train Epoch: 272 [37120/60000 (62%)]\tLoss: 753.092224\n",
            "Train Epoch: 272 [38400/60000 (64%)]\tLoss: 714.906433\n",
            "Train Epoch: 272 [39680/60000 (66%)]\tLoss: 724.621094\n",
            "Train Epoch: 272 [40960/60000 (68%)]\tLoss: 743.496033\n",
            "Train Epoch: 272 [42240/60000 (70%)]\tLoss: 753.376282\n",
            "Train Epoch: 272 [43520/60000 (72%)]\tLoss: 728.013123\n",
            "Train Epoch: 272 [44800/60000 (75%)]\tLoss: 736.253235\n",
            "Train Epoch: 272 [46080/60000 (77%)]\tLoss: 727.530334\n",
            "Train Epoch: 272 [47360/60000 (79%)]\tLoss: 719.714233\n",
            "Train Epoch: 272 [48640/60000 (81%)]\tLoss: 707.798950\n",
            "Train Epoch: 272 [49920/60000 (83%)]\tLoss: 752.841614\n",
            "Train Epoch: 272 [51200/60000 (85%)]\tLoss: 726.309509\n",
            "Train Epoch: 272 [52480/60000 (87%)]\tLoss: 719.612122\n",
            "Train Epoch: 272 [53760/60000 (90%)]\tLoss: 763.671753\n",
            "Train Epoch: 272 [55040/60000 (92%)]\tLoss: 724.743408\n",
            "Train Epoch: 272 [56320/60000 (94%)]\tLoss: 743.167175\n",
            "Train Epoch: 272 [57600/60000 (96%)]\tLoss: 723.664001\n",
            "Train Epoch: 272 [58880/60000 (98%)]\tLoss: 742.027954\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784903526306152\n",
            "\n",
            "Train Epoch: 273 [0/60000 (0%)]\tLoss: 746.649841\n",
            "Train Epoch: 273 [1280/60000 (2%)]\tLoss: 730.082458\n",
            "Train Epoch: 273 [2560/60000 (4%)]\tLoss: 743.442383\n",
            "Train Epoch: 273 [3840/60000 (6%)]\tLoss: 730.130737\n",
            "Train Epoch: 273 [5120/60000 (9%)]\tLoss: 732.897400\n",
            "Train Epoch: 273 [6400/60000 (11%)]\tLoss: 749.733826\n",
            "Train Epoch: 273 [7680/60000 (13%)]\tLoss: 734.003235\n",
            "Train Epoch: 273 [8960/60000 (15%)]\tLoss: 713.786499\n",
            "Train Epoch: 273 [10240/60000 (17%)]\tLoss: 720.833740\n",
            "Train Epoch: 273 [11520/60000 (19%)]\tLoss: 750.685669\n",
            "Train Epoch: 273 [12800/60000 (21%)]\tLoss: 724.372925\n",
            "Train Epoch: 273 [14080/60000 (23%)]\tLoss: 709.857483\n",
            "Train Epoch: 273 [15360/60000 (26%)]\tLoss: 720.434326\n",
            "Train Epoch: 273 [16640/60000 (28%)]\tLoss: 755.520203\n",
            "Train Epoch: 273 [17920/60000 (30%)]\tLoss: 725.864868\n",
            "Train Epoch: 273 [19200/60000 (32%)]\tLoss: 745.899475\n",
            "Train Epoch: 273 [20480/60000 (34%)]\tLoss: 750.589905\n",
            "Train Epoch: 273 [21760/60000 (36%)]\tLoss: 728.364014\n",
            "Train Epoch: 273 [23040/60000 (38%)]\tLoss: 728.565735\n",
            "Train Epoch: 273 [24320/60000 (41%)]\tLoss: 751.225281\n",
            "Train Epoch: 273 [25600/60000 (43%)]\tLoss: 744.811401\n",
            "Train Epoch: 273 [26880/60000 (45%)]\tLoss: 738.137024\n",
            "Train Epoch: 273 [28160/60000 (47%)]\tLoss: 749.398071\n",
            "Train Epoch: 273 [29440/60000 (49%)]\tLoss: 737.059692\n",
            "Train Epoch: 273 [30720/60000 (51%)]\tLoss: 737.078125\n",
            "Train Epoch: 273 [32000/60000 (53%)]\tLoss: 734.357483\n",
            "Train Epoch: 273 [33280/60000 (55%)]\tLoss: 736.239685\n",
            "Train Epoch: 273 [34560/60000 (58%)]\tLoss: 720.249573\n",
            "Train Epoch: 273 [35840/60000 (60%)]\tLoss: 741.455627\n",
            "Train Epoch: 273 [37120/60000 (62%)]\tLoss: 736.823975\n",
            "Train Epoch: 273 [38400/60000 (64%)]\tLoss: 739.431580\n",
            "Train Epoch: 273 [39680/60000 (66%)]\tLoss: 734.996094\n",
            "Train Epoch: 273 [40960/60000 (68%)]\tLoss: 751.834900\n",
            "Train Epoch: 273 [42240/60000 (70%)]\tLoss: 732.941772\n",
            "Train Epoch: 273 [43520/60000 (72%)]\tLoss: 728.196411\n",
            "Train Epoch: 273 [44800/60000 (75%)]\tLoss: 745.592468\n",
            "Train Epoch: 273 [46080/60000 (77%)]\tLoss: 727.332397\n",
            "Train Epoch: 273 [47360/60000 (79%)]\tLoss: 738.719727\n",
            "Train Epoch: 273 [48640/60000 (81%)]\tLoss: 740.419861\n",
            "Train Epoch: 273 [49920/60000 (83%)]\tLoss: 766.872131\n",
            "Train Epoch: 273 [51200/60000 (85%)]\tLoss: 735.845764\n",
            "Train Epoch: 273 [52480/60000 (87%)]\tLoss: 731.119324\n",
            "Train Epoch: 273 [53760/60000 (90%)]\tLoss: 723.830383\n",
            "Train Epoch: 273 [55040/60000 (92%)]\tLoss: 743.465637\n",
            "Train Epoch: 273 [56320/60000 (94%)]\tLoss: 755.741760\n",
            "Train Epoch: 273 [57600/60000 (96%)]\tLoss: 718.566284\n",
            "Train Epoch: 273 [58880/60000 (98%)]\tLoss: 741.920776\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978469341993332\n",
            "\n",
            "Train Epoch: 274 [0/60000 (0%)]\tLoss: 756.610107\n",
            "Train Epoch: 274 [1280/60000 (2%)]\tLoss: 753.686768\n",
            "Train Epoch: 274 [2560/60000 (4%)]\tLoss: 736.768677\n",
            "Train Epoch: 274 [3840/60000 (6%)]\tLoss: 764.838257\n",
            "Train Epoch: 274 [5120/60000 (9%)]\tLoss: 738.192139\n",
            "Train Epoch: 274 [6400/60000 (11%)]\tLoss: 715.029114\n",
            "Train Epoch: 274 [7680/60000 (13%)]\tLoss: 726.899170\n",
            "Train Epoch: 274 [8960/60000 (15%)]\tLoss: 761.341553\n",
            "Train Epoch: 274 [10240/60000 (17%)]\tLoss: 747.885254\n",
            "Train Epoch: 274 [11520/60000 (19%)]\tLoss: 724.241455\n",
            "Train Epoch: 274 [12800/60000 (21%)]\tLoss: 738.275940\n",
            "Train Epoch: 274 [14080/60000 (23%)]\tLoss: 723.958435\n",
            "Train Epoch: 274 [15360/60000 (26%)]\tLoss: 740.876343\n",
            "Train Epoch: 274 [16640/60000 (28%)]\tLoss: 744.572083\n",
            "Train Epoch: 274 [17920/60000 (30%)]\tLoss: 752.980408\n",
            "Train Epoch: 274 [19200/60000 (32%)]\tLoss: 738.885437\n",
            "Train Epoch: 274 [20480/60000 (34%)]\tLoss: 739.993469\n",
            "Train Epoch: 274 [21760/60000 (36%)]\tLoss: 710.486938\n",
            "Train Epoch: 274 [23040/60000 (38%)]\tLoss: 715.910400\n",
            "Train Epoch: 274 [24320/60000 (41%)]\tLoss: 743.438599\n",
            "Train Epoch: 274 [25600/60000 (43%)]\tLoss: 755.096924\n",
            "Train Epoch: 274 [26880/60000 (45%)]\tLoss: 731.167175\n",
            "Train Epoch: 274 [28160/60000 (47%)]\tLoss: 729.655090\n",
            "Train Epoch: 274 [29440/60000 (49%)]\tLoss: 733.827698\n",
            "Train Epoch: 274 [30720/60000 (51%)]\tLoss: 741.315552\n",
            "Train Epoch: 274 [32000/60000 (53%)]\tLoss: 731.104248\n",
            "Train Epoch: 274 [33280/60000 (55%)]\tLoss: 752.195862\n",
            "Train Epoch: 274 [34560/60000 (58%)]\tLoss: 706.691833\n",
            "Train Epoch: 274 [35840/60000 (60%)]\tLoss: 730.014709\n",
            "Train Epoch: 274 [37120/60000 (62%)]\tLoss: 719.682129\n",
            "Train Epoch: 274 [38400/60000 (64%)]\tLoss: 737.851624\n",
            "Train Epoch: 274 [39680/60000 (66%)]\tLoss: 745.366089\n",
            "Train Epoch: 274 [40960/60000 (68%)]\tLoss: 739.909058\n",
            "Train Epoch: 274 [42240/60000 (70%)]\tLoss: 738.414917\n",
            "Train Epoch: 274 [43520/60000 (72%)]\tLoss: 750.730530\n",
            "Train Epoch: 274 [44800/60000 (75%)]\tLoss: 730.302063\n",
            "Train Epoch: 274 [46080/60000 (77%)]\tLoss: 739.856689\n",
            "Train Epoch: 274 [47360/60000 (79%)]\tLoss: 750.868591\n",
            "Train Epoch: 274 [48640/60000 (81%)]\tLoss: 752.683350\n",
            "Train Epoch: 274 [49920/60000 (83%)]\tLoss: 726.093140\n",
            "Train Epoch: 274 [51200/60000 (85%)]\tLoss: 763.247070\n",
            "Train Epoch: 274 [52480/60000 (87%)]\tLoss: 725.624268\n",
            "Train Epoch: 274 [53760/60000 (90%)]\tLoss: 724.988708\n",
            "Train Epoch: 274 [55040/60000 (92%)]\tLoss: 728.221924\n",
            "Train Epoch: 274 [56320/60000 (94%)]\tLoss: 758.398376\n",
            "Train Epoch: 274 [57600/60000 (96%)]\tLoss: 734.410034\n",
            "Train Epoch: 274 [58880/60000 (98%)]\tLoss: 735.803955\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783556461334229\n",
            "\n",
            "Train Epoch: 275 [0/60000 (0%)]\tLoss: 748.125488\n",
            "Train Epoch: 275 [1280/60000 (2%)]\tLoss: 718.579773\n",
            "Train Epoch: 275 [2560/60000 (4%)]\tLoss: 748.636047\n",
            "Train Epoch: 275 [3840/60000 (6%)]\tLoss: 726.174072\n",
            "Train Epoch: 275 [5120/60000 (9%)]\tLoss: 740.497070\n",
            "Train Epoch: 275 [6400/60000 (11%)]\tLoss: 730.298706\n",
            "Train Epoch: 275 [7680/60000 (13%)]\tLoss: 765.655823\n",
            "Train Epoch: 275 [8960/60000 (15%)]\tLoss: 724.511047\n",
            "Train Epoch: 275 [10240/60000 (17%)]\tLoss: 715.837219\n",
            "Train Epoch: 275 [11520/60000 (19%)]\tLoss: 736.419556\n",
            "Train Epoch: 275 [12800/60000 (21%)]\tLoss: 738.762207\n",
            "Train Epoch: 275 [14080/60000 (23%)]\tLoss: 741.026428\n",
            "Train Epoch: 275 [15360/60000 (26%)]\tLoss: 735.648743\n",
            "Train Epoch: 275 [16640/60000 (28%)]\tLoss: 718.368286\n",
            "Train Epoch: 275 [17920/60000 (30%)]\tLoss: 714.006287\n",
            "Train Epoch: 275 [19200/60000 (32%)]\tLoss: 739.671631\n",
            "Train Epoch: 275 [20480/60000 (34%)]\tLoss: 747.592529\n",
            "Train Epoch: 275 [21760/60000 (36%)]\tLoss: 750.824280\n",
            "Train Epoch: 275 [23040/60000 (38%)]\tLoss: 739.355652\n",
            "Train Epoch: 275 [24320/60000 (41%)]\tLoss: 734.250916\n",
            "Train Epoch: 275 [25600/60000 (43%)]\tLoss: 731.292480\n",
            "Train Epoch: 275 [26880/60000 (45%)]\tLoss: 744.398071\n",
            "Train Epoch: 275 [28160/60000 (47%)]\tLoss: 733.293091\n",
            "Train Epoch: 275 [29440/60000 (49%)]\tLoss: 727.655273\n",
            "Train Epoch: 275 [30720/60000 (51%)]\tLoss: 711.684814\n",
            "Train Epoch: 275 [32000/60000 (53%)]\tLoss: 762.390137\n",
            "Train Epoch: 275 [33280/60000 (55%)]\tLoss: 746.708191\n",
            "Train Epoch: 275 [34560/60000 (58%)]\tLoss: 744.800903\n",
            "Train Epoch: 275 [35840/60000 (60%)]\tLoss: 749.075562\n",
            "Train Epoch: 275 [37120/60000 (62%)]\tLoss: 741.650391\n",
            "Train Epoch: 275 [38400/60000 (64%)]\tLoss: 752.456482\n",
            "Train Epoch: 275 [39680/60000 (66%)]\tLoss: 745.859863\n",
            "Train Epoch: 275 [40960/60000 (68%)]\tLoss: 737.007141\n",
            "Train Epoch: 275 [42240/60000 (70%)]\tLoss: 750.283203\n",
            "Train Epoch: 275 [43520/60000 (72%)]\tLoss: 736.483032\n",
            "Train Epoch: 275 [44800/60000 (75%)]\tLoss: 710.712646\n",
            "Train Epoch: 275 [46080/60000 (77%)]\tLoss: 727.165527\n",
            "Train Epoch: 275 [47360/60000 (79%)]\tLoss: 758.346130\n",
            "Train Epoch: 275 [48640/60000 (81%)]\tLoss: 751.220947\n",
            "Train Epoch: 275 [49920/60000 (83%)]\tLoss: 740.125000\n",
            "Train Epoch: 275 [51200/60000 (85%)]\tLoss: 723.703186\n",
            "Train Epoch: 275 [52480/60000 (87%)]\tLoss: 738.022339\n",
            "Train Epoch: 275 [53760/60000 (90%)]\tLoss: 735.719666\n",
            "Train Epoch: 275 [55040/60000 (92%)]\tLoss: 731.227722\n",
            "Train Epoch: 275 [56320/60000 (94%)]\tLoss: 726.457153\n",
            "Train Epoch: 275 [57600/60000 (96%)]\tLoss: 719.460632\n",
            "Train Epoch: 275 [58880/60000 (98%)]\tLoss: 730.141785\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788619875907898\n",
            "\n",
            "Train Epoch: 276 [0/60000 (0%)]\tLoss: 738.604126\n",
            "Train Epoch: 276 [1280/60000 (2%)]\tLoss: 750.028809\n",
            "Train Epoch: 276 [2560/60000 (4%)]\tLoss: 734.593201\n",
            "Train Epoch: 276 [3840/60000 (6%)]\tLoss: 759.090393\n",
            "Train Epoch: 276 [5120/60000 (9%)]\tLoss: 748.692993\n",
            "Train Epoch: 276 [6400/60000 (11%)]\tLoss: 732.978455\n",
            "Train Epoch: 276 [7680/60000 (13%)]\tLoss: 735.992737\n",
            "Train Epoch: 276 [8960/60000 (15%)]\tLoss: 754.031433\n",
            "Train Epoch: 276 [10240/60000 (17%)]\tLoss: 755.180054\n",
            "Train Epoch: 276 [11520/60000 (19%)]\tLoss: 758.262878\n",
            "Train Epoch: 276 [12800/60000 (21%)]\tLoss: 713.665161\n",
            "Train Epoch: 276 [14080/60000 (23%)]\tLoss: 728.157166\n",
            "Train Epoch: 276 [15360/60000 (26%)]\tLoss: 745.486633\n",
            "Train Epoch: 276 [16640/60000 (28%)]\tLoss: 756.556213\n",
            "Train Epoch: 276 [17920/60000 (30%)]\tLoss: 730.272522\n",
            "Train Epoch: 276 [19200/60000 (32%)]\tLoss: 757.909607\n",
            "Train Epoch: 276 [20480/60000 (34%)]\tLoss: 747.017212\n",
            "Train Epoch: 276 [21760/60000 (36%)]\tLoss: 753.620483\n",
            "Train Epoch: 276 [23040/60000 (38%)]\tLoss: 734.904907\n",
            "Train Epoch: 276 [24320/60000 (41%)]\tLoss: 746.857483\n",
            "Train Epoch: 276 [25600/60000 (43%)]\tLoss: 721.886963\n",
            "Train Epoch: 276 [26880/60000 (45%)]\tLoss: 751.241150\n",
            "Train Epoch: 276 [28160/60000 (47%)]\tLoss: 734.821106\n",
            "Train Epoch: 276 [29440/60000 (49%)]\tLoss: 752.878540\n",
            "Train Epoch: 276 [30720/60000 (51%)]\tLoss: 741.955200\n",
            "Train Epoch: 276 [32000/60000 (53%)]\tLoss: 743.917603\n",
            "Train Epoch: 276 [33280/60000 (55%)]\tLoss: 733.446289\n",
            "Train Epoch: 276 [34560/60000 (58%)]\tLoss: 741.561157\n",
            "Train Epoch: 276 [35840/60000 (60%)]\tLoss: 717.738403\n",
            "Train Epoch: 276 [37120/60000 (62%)]\tLoss: 738.839600\n",
            "Train Epoch: 276 [38400/60000 (64%)]\tLoss: 714.368164\n",
            "Train Epoch: 276 [39680/60000 (66%)]\tLoss: 749.056702\n",
            "Train Epoch: 276 [40960/60000 (68%)]\tLoss: 747.499207\n",
            "Train Epoch: 276 [42240/60000 (70%)]\tLoss: 736.065674\n",
            "Train Epoch: 276 [43520/60000 (72%)]\tLoss: 740.264832\n",
            "Train Epoch: 276 [44800/60000 (75%)]\tLoss: 733.485107\n",
            "Train Epoch: 276 [46080/60000 (77%)]\tLoss: 729.066711\n",
            "Train Epoch: 276 [47360/60000 (79%)]\tLoss: 729.312500\n",
            "Train Epoch: 276 [48640/60000 (81%)]\tLoss: 744.147278\n",
            "Train Epoch: 276 [49920/60000 (83%)]\tLoss: 712.085999\n",
            "Train Epoch: 276 [51200/60000 (85%)]\tLoss: 729.335083\n",
            "Train Epoch: 276 [52480/60000 (87%)]\tLoss: 766.234863\n",
            "Train Epoch: 276 [53760/60000 (90%)]\tLoss: 734.289062\n",
            "Train Epoch: 276 [55040/60000 (92%)]\tLoss: 732.752991\n",
            "Train Epoch: 276 [56320/60000 (94%)]\tLoss: 732.898376\n",
            "Train Epoch: 276 [57600/60000 (96%)]\tLoss: 725.492126\n",
            "Train Epoch: 276 [58880/60000 (98%)]\tLoss: 709.272278\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782871007919312\n",
            "\n",
            "Train Epoch: 277 [0/60000 (0%)]\tLoss: 752.503967\n",
            "Train Epoch: 277 [1280/60000 (2%)]\tLoss: 729.186096\n",
            "Train Epoch: 277 [2560/60000 (4%)]\tLoss: 745.380432\n",
            "Train Epoch: 277 [3840/60000 (6%)]\tLoss: 727.798584\n",
            "Train Epoch: 277 [5120/60000 (9%)]\tLoss: 762.541321\n",
            "Train Epoch: 277 [6400/60000 (11%)]\tLoss: 721.076599\n",
            "Train Epoch: 277 [7680/60000 (13%)]\tLoss: 749.735229\n",
            "Train Epoch: 277 [8960/60000 (15%)]\tLoss: 736.638123\n",
            "Train Epoch: 277 [10240/60000 (17%)]\tLoss: 738.901917\n",
            "Train Epoch: 277 [11520/60000 (19%)]\tLoss: 743.062744\n",
            "Train Epoch: 277 [12800/60000 (21%)]\tLoss: 759.908081\n",
            "Train Epoch: 277 [14080/60000 (23%)]\tLoss: 743.196411\n",
            "Train Epoch: 277 [15360/60000 (26%)]\tLoss: 745.230957\n",
            "Train Epoch: 277 [16640/60000 (28%)]\tLoss: 729.125549\n",
            "Train Epoch: 277 [17920/60000 (30%)]\tLoss: 749.035767\n",
            "Train Epoch: 277 [19200/60000 (32%)]\tLoss: 713.808655\n",
            "Train Epoch: 277 [20480/60000 (34%)]\tLoss: 722.886292\n",
            "Train Epoch: 277 [21760/60000 (36%)]\tLoss: 742.354309\n",
            "Train Epoch: 277 [23040/60000 (38%)]\tLoss: 726.134705\n",
            "Train Epoch: 277 [24320/60000 (41%)]\tLoss: 733.132019\n",
            "Train Epoch: 277 [25600/60000 (43%)]\tLoss: 752.583984\n",
            "Train Epoch: 277 [26880/60000 (45%)]\tLoss: 721.800415\n",
            "Train Epoch: 277 [28160/60000 (47%)]\tLoss: 736.976074\n",
            "Train Epoch: 277 [29440/60000 (49%)]\tLoss: 765.289917\n",
            "Train Epoch: 277 [30720/60000 (51%)]\tLoss: 725.084229\n",
            "Train Epoch: 277 [32000/60000 (53%)]\tLoss: 723.046875\n",
            "Train Epoch: 277 [33280/60000 (55%)]\tLoss: 736.527100\n",
            "Train Epoch: 277 [34560/60000 (58%)]\tLoss: 734.089294\n",
            "Train Epoch: 277 [35840/60000 (60%)]\tLoss: 707.345215\n",
            "Train Epoch: 277 [37120/60000 (62%)]\tLoss: 748.315002\n",
            "Train Epoch: 277 [38400/60000 (64%)]\tLoss: 733.397827\n",
            "Train Epoch: 277 [39680/60000 (66%)]\tLoss: 737.495056\n",
            "Train Epoch: 277 [40960/60000 (68%)]\tLoss: 747.869202\n",
            "Train Epoch: 277 [42240/60000 (70%)]\tLoss: 709.285828\n",
            "Train Epoch: 277 [43520/60000 (72%)]\tLoss: 740.915527\n",
            "Train Epoch: 277 [44800/60000 (75%)]\tLoss: 743.621338\n",
            "Train Epoch: 277 [46080/60000 (77%)]\tLoss: 734.748047\n",
            "Train Epoch: 277 [47360/60000 (79%)]\tLoss: 732.774475\n",
            "Train Epoch: 277 [48640/60000 (81%)]\tLoss: 742.178589\n",
            "Train Epoch: 277 [49920/60000 (83%)]\tLoss: 736.123779\n",
            "Train Epoch: 277 [51200/60000 (85%)]\tLoss: 754.001160\n",
            "Train Epoch: 277 [52480/60000 (87%)]\tLoss: 761.626587\n",
            "Train Epoch: 277 [53760/60000 (90%)]\tLoss: 745.252747\n",
            "Train Epoch: 277 [55040/60000 (92%)]\tLoss: 725.255737\n",
            "Train Epoch: 277 [56320/60000 (94%)]\tLoss: 747.933105\n",
            "Train Epoch: 277 [57600/60000 (96%)]\tLoss: 722.050293\n",
            "Train Epoch: 277 [58880/60000 (98%)]\tLoss: 736.709595\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19788561761379242\n",
            "\n",
            "Train Epoch: 278 [0/60000 (0%)]\tLoss: 727.365662\n",
            "Train Epoch: 278 [1280/60000 (2%)]\tLoss: 736.678589\n",
            "Train Epoch: 278 [2560/60000 (4%)]\tLoss: 715.251587\n",
            "Train Epoch: 278 [3840/60000 (6%)]\tLoss: 732.274536\n",
            "Train Epoch: 278 [5120/60000 (9%)]\tLoss: 727.572388\n",
            "Train Epoch: 278 [6400/60000 (11%)]\tLoss: 761.515137\n",
            "Train Epoch: 278 [7680/60000 (13%)]\tLoss: 717.973206\n",
            "Train Epoch: 278 [8960/60000 (15%)]\tLoss: 732.326416\n",
            "Train Epoch: 278 [10240/60000 (17%)]\tLoss: 749.932861\n",
            "Train Epoch: 278 [11520/60000 (19%)]\tLoss: 727.422852\n",
            "Train Epoch: 278 [12800/60000 (21%)]\tLoss: 754.254883\n",
            "Train Epoch: 278 [14080/60000 (23%)]\tLoss: 748.015503\n",
            "Train Epoch: 278 [15360/60000 (26%)]\tLoss: 711.419983\n",
            "Train Epoch: 278 [16640/60000 (28%)]\tLoss: 756.402832\n",
            "Train Epoch: 278 [17920/60000 (30%)]\tLoss: 744.292969\n",
            "Train Epoch: 278 [19200/60000 (32%)]\tLoss: 741.271423\n",
            "Train Epoch: 278 [20480/60000 (34%)]\tLoss: 761.855469\n",
            "Train Epoch: 278 [21760/60000 (36%)]\tLoss: 741.470581\n",
            "Train Epoch: 278 [23040/60000 (38%)]\tLoss: 722.016479\n",
            "Train Epoch: 278 [24320/60000 (41%)]\tLoss: 757.219666\n",
            "Train Epoch: 278 [25600/60000 (43%)]\tLoss: 723.282532\n",
            "Train Epoch: 278 [26880/60000 (45%)]\tLoss: 737.711426\n",
            "Train Epoch: 278 [28160/60000 (47%)]\tLoss: 746.084351\n",
            "Train Epoch: 278 [29440/60000 (49%)]\tLoss: 718.569336\n",
            "Train Epoch: 278 [30720/60000 (51%)]\tLoss: 752.294128\n",
            "Train Epoch: 278 [32000/60000 (53%)]\tLoss: 730.884399\n",
            "Train Epoch: 278 [33280/60000 (55%)]\tLoss: 714.473145\n",
            "Train Epoch: 278 [34560/60000 (58%)]\tLoss: 759.081055\n",
            "Train Epoch: 278 [35840/60000 (60%)]\tLoss: 725.125671\n",
            "Train Epoch: 278 [37120/60000 (62%)]\tLoss: 713.688782\n",
            "Train Epoch: 278 [38400/60000 (64%)]\tLoss: 713.985413\n",
            "Train Epoch: 278 [39680/60000 (66%)]\tLoss: 730.130859\n",
            "Train Epoch: 278 [40960/60000 (68%)]\tLoss: 718.940674\n",
            "Train Epoch: 278 [42240/60000 (70%)]\tLoss: 724.595703\n",
            "Train Epoch: 278 [43520/60000 (72%)]\tLoss: 739.220520\n",
            "Train Epoch: 278 [44800/60000 (75%)]\tLoss: 745.440002\n",
            "Train Epoch: 278 [46080/60000 (77%)]\tLoss: 730.734619\n",
            "Train Epoch: 278 [47360/60000 (79%)]\tLoss: 722.921936\n",
            "Train Epoch: 278 [48640/60000 (81%)]\tLoss: 748.435303\n",
            "Train Epoch: 278 [49920/60000 (83%)]\tLoss: 731.987976\n",
            "Train Epoch: 278 [51200/60000 (85%)]\tLoss: 749.934814\n",
            "Train Epoch: 278 [52480/60000 (87%)]\tLoss: 738.541077\n",
            "Train Epoch: 278 [53760/60000 (90%)]\tLoss: 743.552368\n",
            "Train Epoch: 278 [55040/60000 (92%)]\tLoss: 746.090576\n",
            "Train Epoch: 278 [56320/60000 (94%)]\tLoss: 700.506714\n",
            "Train Epoch: 278 [57600/60000 (96%)]\tLoss: 734.685242\n",
            "Train Epoch: 278 [58880/60000 (98%)]\tLoss: 750.807739\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785216450691223\n",
            "\n",
            "Train Epoch: 279 [0/60000 (0%)]\tLoss: 748.448242\n",
            "Train Epoch: 279 [1280/60000 (2%)]\tLoss: 731.613281\n",
            "Train Epoch: 279 [2560/60000 (4%)]\tLoss: 724.105103\n",
            "Train Epoch: 279 [3840/60000 (6%)]\tLoss: 738.287292\n",
            "Train Epoch: 279 [5120/60000 (9%)]\tLoss: 711.290100\n",
            "Train Epoch: 279 [6400/60000 (11%)]\tLoss: 733.587463\n",
            "Train Epoch: 279 [7680/60000 (13%)]\tLoss: 742.335144\n",
            "Train Epoch: 279 [8960/60000 (15%)]\tLoss: 735.991333\n",
            "Train Epoch: 279 [10240/60000 (17%)]\tLoss: 739.718262\n",
            "Train Epoch: 279 [11520/60000 (19%)]\tLoss: 745.638367\n",
            "Train Epoch: 279 [12800/60000 (21%)]\tLoss: 736.286560\n",
            "Train Epoch: 279 [14080/60000 (23%)]\tLoss: 734.967346\n",
            "Train Epoch: 279 [15360/60000 (26%)]\tLoss: 748.396179\n",
            "Train Epoch: 279 [16640/60000 (28%)]\tLoss: 742.885681\n",
            "Train Epoch: 279 [17920/60000 (30%)]\tLoss: 736.916016\n",
            "Train Epoch: 279 [19200/60000 (32%)]\tLoss: 751.113220\n",
            "Train Epoch: 279 [20480/60000 (34%)]\tLoss: 739.512207\n",
            "Train Epoch: 279 [21760/60000 (36%)]\tLoss: 740.289307\n",
            "Train Epoch: 279 [23040/60000 (38%)]\tLoss: 742.303955\n",
            "Train Epoch: 279 [24320/60000 (41%)]\tLoss: 703.799316\n",
            "Train Epoch: 279 [25600/60000 (43%)]\tLoss: 720.751526\n",
            "Train Epoch: 279 [26880/60000 (45%)]\tLoss: 740.348389\n",
            "Train Epoch: 279 [28160/60000 (47%)]\tLoss: 734.185425\n",
            "Train Epoch: 279 [29440/60000 (49%)]\tLoss: 707.152466\n",
            "Train Epoch: 279 [30720/60000 (51%)]\tLoss: 716.000732\n",
            "Train Epoch: 279 [32000/60000 (53%)]\tLoss: 752.390625\n",
            "Train Epoch: 279 [33280/60000 (55%)]\tLoss: 747.353271\n",
            "Train Epoch: 279 [34560/60000 (58%)]\tLoss: 726.130249\n",
            "Train Epoch: 279 [35840/60000 (60%)]\tLoss: 754.103149\n",
            "Train Epoch: 279 [37120/60000 (62%)]\tLoss: 755.519836\n",
            "Train Epoch: 279 [38400/60000 (64%)]\tLoss: 738.274170\n",
            "Train Epoch: 279 [39680/60000 (66%)]\tLoss: 738.666382\n",
            "Train Epoch: 279 [40960/60000 (68%)]\tLoss: 746.548279\n",
            "Train Epoch: 279 [42240/60000 (70%)]\tLoss: 752.255127\n",
            "Train Epoch: 279 [43520/60000 (72%)]\tLoss: 748.340759\n",
            "Train Epoch: 279 [44800/60000 (75%)]\tLoss: 723.128540\n",
            "Train Epoch: 279 [46080/60000 (77%)]\tLoss: 728.972900\n",
            "Train Epoch: 279 [47360/60000 (79%)]\tLoss: 723.647156\n",
            "Train Epoch: 279 [48640/60000 (81%)]\tLoss: 743.945923\n",
            "Train Epoch: 279 [49920/60000 (83%)]\tLoss: 723.505432\n",
            "Train Epoch: 279 [51200/60000 (85%)]\tLoss: 746.354919\n",
            "Train Epoch: 279 [52480/60000 (87%)]\tLoss: 751.755432\n",
            "Train Epoch: 279 [53760/60000 (90%)]\tLoss: 719.282043\n",
            "Train Epoch: 279 [55040/60000 (92%)]\tLoss: 731.650574\n",
            "Train Epoch: 279 [56320/60000 (94%)]\tLoss: 756.765869\n",
            "Train Epoch: 279 [57600/60000 (96%)]\tLoss: 725.470825\n",
            "Train Epoch: 279 [58880/60000 (98%)]\tLoss: 721.080994\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785043597221375\n",
            "\n",
            "Train Epoch: 280 [0/60000 (0%)]\tLoss: 720.021790\n",
            "Train Epoch: 280 [1280/60000 (2%)]\tLoss: 728.691650\n",
            "Train Epoch: 280 [2560/60000 (4%)]\tLoss: 739.177856\n",
            "Train Epoch: 280 [3840/60000 (6%)]\tLoss: 738.987793\n",
            "Train Epoch: 280 [5120/60000 (9%)]\tLoss: 719.235168\n",
            "Train Epoch: 280 [6400/60000 (11%)]\tLoss: 738.203064\n",
            "Train Epoch: 280 [7680/60000 (13%)]\tLoss: 746.376038\n",
            "Train Epoch: 280 [8960/60000 (15%)]\tLoss: 722.878723\n",
            "Train Epoch: 280 [10240/60000 (17%)]\tLoss: 739.965210\n",
            "Train Epoch: 280 [11520/60000 (19%)]\tLoss: 740.346619\n",
            "Train Epoch: 280 [12800/60000 (21%)]\tLoss: 736.574890\n",
            "Train Epoch: 280 [14080/60000 (23%)]\tLoss: 732.524658\n",
            "Train Epoch: 280 [15360/60000 (26%)]\tLoss: 717.630920\n",
            "Train Epoch: 280 [16640/60000 (28%)]\tLoss: 714.669739\n",
            "Train Epoch: 280 [17920/60000 (30%)]\tLoss: 748.667419\n",
            "Train Epoch: 280 [19200/60000 (32%)]\tLoss: 721.222839\n",
            "Train Epoch: 280 [20480/60000 (34%)]\tLoss: 766.046143\n",
            "Train Epoch: 280 [21760/60000 (36%)]\tLoss: 736.241760\n",
            "Train Epoch: 280 [23040/60000 (38%)]\tLoss: 750.682434\n",
            "Train Epoch: 280 [24320/60000 (41%)]\tLoss: 744.128540\n",
            "Train Epoch: 280 [25600/60000 (43%)]\tLoss: 725.389587\n",
            "Train Epoch: 280 [26880/60000 (45%)]\tLoss: 716.594238\n",
            "Train Epoch: 280 [28160/60000 (47%)]\tLoss: 744.833862\n",
            "Train Epoch: 280 [29440/60000 (49%)]\tLoss: 727.258545\n",
            "Train Epoch: 280 [30720/60000 (51%)]\tLoss: 738.253723\n",
            "Train Epoch: 280 [32000/60000 (53%)]\tLoss: 747.489807\n",
            "Train Epoch: 280 [33280/60000 (55%)]\tLoss: 736.027893\n",
            "Train Epoch: 280 [34560/60000 (58%)]\tLoss: 728.236023\n",
            "Train Epoch: 280 [35840/60000 (60%)]\tLoss: 724.462891\n",
            "Train Epoch: 280 [37120/60000 (62%)]\tLoss: 748.546326\n",
            "Train Epoch: 280 [38400/60000 (64%)]\tLoss: 732.576233\n",
            "Train Epoch: 280 [39680/60000 (66%)]\tLoss: 743.053467\n",
            "Train Epoch: 280 [40960/60000 (68%)]\tLoss: 732.476379\n",
            "Train Epoch: 280 [42240/60000 (70%)]\tLoss: 730.480774\n",
            "Train Epoch: 280 [43520/60000 (72%)]\tLoss: 755.884827\n",
            "Train Epoch: 280 [44800/60000 (75%)]\tLoss: 732.545532\n",
            "Train Epoch: 280 [46080/60000 (77%)]\tLoss: 739.946533\n",
            "Train Epoch: 280 [47360/60000 (79%)]\tLoss: 724.977844\n",
            "Train Epoch: 280 [48640/60000 (81%)]\tLoss: 739.693848\n",
            "Train Epoch: 280 [49920/60000 (83%)]\tLoss: 736.872620\n",
            "Train Epoch: 280 [51200/60000 (85%)]\tLoss: 716.079468\n",
            "Train Epoch: 280 [52480/60000 (87%)]\tLoss: 745.417603\n",
            "Train Epoch: 280 [53760/60000 (90%)]\tLoss: 730.507812\n",
            "Train Epoch: 280 [55040/60000 (92%)]\tLoss: 743.030823\n",
            "Train Epoch: 280 [56320/60000 (94%)]\tLoss: 731.275024\n",
            "Train Epoch: 280 [57600/60000 (96%)]\tLoss: 726.358704\n",
            "Train Epoch: 280 [58880/60000 (98%)]\tLoss: 747.694031\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978146731853485\n",
            "\n",
            "Train Epoch: 281 [0/60000 (0%)]\tLoss: 714.679688\n",
            "Train Epoch: 281 [1280/60000 (2%)]\tLoss: 749.078674\n",
            "Train Epoch: 281 [2560/60000 (4%)]\tLoss: 725.239868\n",
            "Train Epoch: 281 [3840/60000 (6%)]\tLoss: 747.526123\n",
            "Train Epoch: 281 [5120/60000 (9%)]\tLoss: 745.467285\n",
            "Train Epoch: 281 [6400/60000 (11%)]\tLoss: 740.707214\n",
            "Train Epoch: 281 [7680/60000 (13%)]\tLoss: 746.784790\n",
            "Train Epoch: 281 [8960/60000 (15%)]\tLoss: 714.368164\n",
            "Train Epoch: 281 [10240/60000 (17%)]\tLoss: 723.462708\n",
            "Train Epoch: 281 [11520/60000 (19%)]\tLoss: 722.798401\n",
            "Train Epoch: 281 [12800/60000 (21%)]\tLoss: 727.530212\n",
            "Train Epoch: 281 [14080/60000 (23%)]\tLoss: 739.187927\n",
            "Train Epoch: 281 [15360/60000 (26%)]\tLoss: 732.362305\n",
            "Train Epoch: 281 [16640/60000 (28%)]\tLoss: 739.817383\n",
            "Train Epoch: 281 [17920/60000 (30%)]\tLoss: 735.226685\n",
            "Train Epoch: 281 [19200/60000 (32%)]\tLoss: 717.836670\n",
            "Train Epoch: 281 [20480/60000 (34%)]\tLoss: 776.928894\n",
            "Train Epoch: 281 [21760/60000 (36%)]\tLoss: 730.241211\n",
            "Train Epoch: 281 [23040/60000 (38%)]\tLoss: 726.174072\n",
            "Train Epoch: 281 [24320/60000 (41%)]\tLoss: 746.244019\n",
            "Train Epoch: 281 [25600/60000 (43%)]\tLoss: 717.147034\n",
            "Train Epoch: 281 [26880/60000 (45%)]\tLoss: 712.139648\n",
            "Train Epoch: 281 [28160/60000 (47%)]\tLoss: 736.383484\n",
            "Train Epoch: 281 [29440/60000 (49%)]\tLoss: 729.544861\n",
            "Train Epoch: 281 [30720/60000 (51%)]\tLoss: 723.197449\n",
            "Train Epoch: 281 [32000/60000 (53%)]\tLoss: 748.701965\n",
            "Train Epoch: 281 [33280/60000 (55%)]\tLoss: 748.340454\n",
            "Train Epoch: 281 [34560/60000 (58%)]\tLoss: 725.849304\n",
            "Train Epoch: 281 [35840/60000 (60%)]\tLoss: 758.707642\n",
            "Train Epoch: 281 [37120/60000 (62%)]\tLoss: 740.111084\n",
            "Train Epoch: 281 [38400/60000 (64%)]\tLoss: 740.008667\n",
            "Train Epoch: 281 [39680/60000 (66%)]\tLoss: 714.951782\n",
            "Train Epoch: 281 [40960/60000 (68%)]\tLoss: 753.675232\n",
            "Train Epoch: 281 [42240/60000 (70%)]\tLoss: 732.553955\n",
            "Train Epoch: 281 [43520/60000 (72%)]\tLoss: 743.151306\n",
            "Train Epoch: 281 [44800/60000 (75%)]\tLoss: 733.014526\n",
            "Train Epoch: 281 [46080/60000 (77%)]\tLoss: 722.422974\n",
            "Train Epoch: 281 [47360/60000 (79%)]\tLoss: 724.678406\n",
            "Train Epoch: 281 [48640/60000 (81%)]\tLoss: 713.039917\n",
            "Train Epoch: 281 [49920/60000 (83%)]\tLoss: 752.540344\n",
            "Train Epoch: 281 [51200/60000 (85%)]\tLoss: 758.575684\n",
            "Train Epoch: 281 [52480/60000 (87%)]\tLoss: 760.746704\n",
            "Train Epoch: 281 [53760/60000 (90%)]\tLoss: 756.384033\n",
            "Train Epoch: 281 [55040/60000 (92%)]\tLoss: 733.083496\n",
            "Train Epoch: 281 [56320/60000 (94%)]\tLoss: 716.345581\n",
            "Train Epoch: 281 [57600/60000 (96%)]\tLoss: 739.016174\n",
            "Train Epoch: 281 [58880/60000 (98%)]\tLoss: 737.036499\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19779819250106812\n",
            "\n",
            "Train Epoch: 282 [0/60000 (0%)]\tLoss: 727.921753\n",
            "Train Epoch: 282 [1280/60000 (2%)]\tLoss: 783.262512\n",
            "Train Epoch: 282 [2560/60000 (4%)]\tLoss: 737.348877\n",
            "Train Epoch: 282 [3840/60000 (6%)]\tLoss: 738.434998\n",
            "Train Epoch: 282 [5120/60000 (9%)]\tLoss: 722.749268\n",
            "Train Epoch: 282 [6400/60000 (11%)]\tLoss: 739.072632\n",
            "Train Epoch: 282 [7680/60000 (13%)]\tLoss: 753.707642\n",
            "Train Epoch: 282 [8960/60000 (15%)]\tLoss: 737.699158\n",
            "Train Epoch: 282 [10240/60000 (17%)]\tLoss: 728.846924\n",
            "Train Epoch: 282 [11520/60000 (19%)]\tLoss: 732.793457\n",
            "Train Epoch: 282 [12800/60000 (21%)]\tLoss: 753.153137\n",
            "Train Epoch: 282 [14080/60000 (23%)]\tLoss: 730.280029\n",
            "Train Epoch: 282 [15360/60000 (26%)]\tLoss: 743.847534\n",
            "Train Epoch: 282 [16640/60000 (28%)]\tLoss: 752.901917\n",
            "Train Epoch: 282 [17920/60000 (30%)]\tLoss: 734.992676\n",
            "Train Epoch: 282 [19200/60000 (32%)]\tLoss: 759.177002\n",
            "Train Epoch: 282 [20480/60000 (34%)]\tLoss: 712.678467\n",
            "Train Epoch: 282 [21760/60000 (36%)]\tLoss: 734.951050\n",
            "Train Epoch: 282 [23040/60000 (38%)]\tLoss: 737.733093\n",
            "Train Epoch: 282 [24320/60000 (41%)]\tLoss: 748.316406\n",
            "Train Epoch: 282 [25600/60000 (43%)]\tLoss: 745.667664\n",
            "Train Epoch: 282 [26880/60000 (45%)]\tLoss: 750.267944\n",
            "Train Epoch: 282 [28160/60000 (47%)]\tLoss: 727.839233\n",
            "Train Epoch: 282 [29440/60000 (49%)]\tLoss: 714.590027\n",
            "Train Epoch: 282 [30720/60000 (51%)]\tLoss: 744.776489\n",
            "Train Epoch: 282 [32000/60000 (53%)]\tLoss: 747.088135\n",
            "Train Epoch: 282 [33280/60000 (55%)]\tLoss: 737.002991\n",
            "Train Epoch: 282 [34560/60000 (58%)]\tLoss: 754.127808\n",
            "Train Epoch: 282 [35840/60000 (60%)]\tLoss: 730.720398\n",
            "Train Epoch: 282 [37120/60000 (62%)]\tLoss: 747.406494\n",
            "Train Epoch: 282 [38400/60000 (64%)]\tLoss: 749.068115\n",
            "Train Epoch: 282 [39680/60000 (66%)]\tLoss: 756.594177\n",
            "Train Epoch: 282 [40960/60000 (68%)]\tLoss: 723.281433\n",
            "Train Epoch: 282 [42240/60000 (70%)]\tLoss: 746.950684\n",
            "Train Epoch: 282 [43520/60000 (72%)]\tLoss: 735.986511\n",
            "Train Epoch: 282 [44800/60000 (75%)]\tLoss: 744.587219\n",
            "Train Epoch: 282 [46080/60000 (77%)]\tLoss: 729.864746\n",
            "Train Epoch: 282 [47360/60000 (79%)]\tLoss: 755.830994\n",
            "Train Epoch: 282 [48640/60000 (81%)]\tLoss: 753.353760\n",
            "Train Epoch: 282 [49920/60000 (83%)]\tLoss: 710.177795\n",
            "Train Epoch: 282 [51200/60000 (85%)]\tLoss: 723.758484\n",
            "Train Epoch: 282 [52480/60000 (87%)]\tLoss: 756.622864\n",
            "Train Epoch: 282 [53760/60000 (90%)]\tLoss: 712.563110\n",
            "Train Epoch: 282 [55040/60000 (92%)]\tLoss: 727.601318\n",
            "Train Epoch: 282 [56320/60000 (94%)]\tLoss: 754.511719\n",
            "Train Epoch: 282 [57600/60000 (96%)]\tLoss: 752.180908\n",
            "Train Epoch: 282 [58880/60000 (98%)]\tLoss: 712.337097\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19789478182792664\n",
            "\n",
            "Train Epoch: 283 [0/60000 (0%)]\tLoss: 738.437866\n",
            "Train Epoch: 283 [1280/60000 (2%)]\tLoss: 726.527039\n",
            "Train Epoch: 283 [2560/60000 (4%)]\tLoss: 737.849854\n",
            "Train Epoch: 283 [3840/60000 (6%)]\tLoss: 722.560669\n",
            "Train Epoch: 283 [5120/60000 (9%)]\tLoss: 731.326660\n",
            "Train Epoch: 283 [6400/60000 (11%)]\tLoss: 735.229980\n",
            "Train Epoch: 283 [7680/60000 (13%)]\tLoss: 726.712280\n",
            "Train Epoch: 283 [8960/60000 (15%)]\tLoss: 748.030884\n",
            "Train Epoch: 283 [10240/60000 (17%)]\tLoss: 755.250427\n",
            "Train Epoch: 283 [11520/60000 (19%)]\tLoss: 745.327942\n",
            "Train Epoch: 283 [12800/60000 (21%)]\tLoss: 763.643311\n",
            "Train Epoch: 283 [14080/60000 (23%)]\tLoss: 769.109375\n",
            "Train Epoch: 283 [15360/60000 (26%)]\tLoss: 744.850281\n",
            "Train Epoch: 283 [16640/60000 (28%)]\tLoss: 748.294312\n",
            "Train Epoch: 283 [17920/60000 (30%)]\tLoss: 732.242493\n",
            "Train Epoch: 283 [19200/60000 (32%)]\tLoss: 746.338013\n",
            "Train Epoch: 283 [20480/60000 (34%)]\tLoss: 735.452454\n",
            "Train Epoch: 283 [21760/60000 (36%)]\tLoss: 712.941589\n",
            "Train Epoch: 283 [23040/60000 (38%)]\tLoss: 733.460083\n",
            "Train Epoch: 283 [24320/60000 (41%)]\tLoss: 725.591736\n",
            "Train Epoch: 283 [25600/60000 (43%)]\tLoss: 753.663452\n",
            "Train Epoch: 283 [26880/60000 (45%)]\tLoss: 733.249512\n",
            "Train Epoch: 283 [28160/60000 (47%)]\tLoss: 741.411255\n",
            "Train Epoch: 283 [29440/60000 (49%)]\tLoss: 760.039795\n",
            "Train Epoch: 283 [30720/60000 (51%)]\tLoss: 743.003479\n",
            "Train Epoch: 283 [32000/60000 (53%)]\tLoss: 737.000122\n",
            "Train Epoch: 283 [33280/60000 (55%)]\tLoss: 755.347046\n",
            "Train Epoch: 283 [34560/60000 (58%)]\tLoss: 718.405579\n",
            "Train Epoch: 283 [35840/60000 (60%)]\tLoss: 752.079346\n",
            "Train Epoch: 283 [37120/60000 (62%)]\tLoss: 721.224304\n",
            "Train Epoch: 283 [38400/60000 (64%)]\tLoss: 733.367126\n",
            "Train Epoch: 283 [39680/60000 (66%)]\tLoss: 742.099304\n",
            "Train Epoch: 283 [40960/60000 (68%)]\tLoss: 725.726379\n",
            "Train Epoch: 283 [42240/60000 (70%)]\tLoss: 740.922241\n",
            "Train Epoch: 283 [43520/60000 (72%)]\tLoss: 742.765869\n",
            "Train Epoch: 283 [44800/60000 (75%)]\tLoss: 733.901733\n",
            "Train Epoch: 283 [46080/60000 (77%)]\tLoss: 736.495667\n",
            "Train Epoch: 283 [47360/60000 (79%)]\tLoss: 727.455750\n",
            "Train Epoch: 283 [48640/60000 (81%)]\tLoss: 745.778503\n",
            "Train Epoch: 283 [49920/60000 (83%)]\tLoss: 729.708313\n",
            "Train Epoch: 283 [51200/60000 (85%)]\tLoss: 742.371704\n",
            "Train Epoch: 283 [52480/60000 (87%)]\tLoss: 745.420105\n",
            "Train Epoch: 283 [53760/60000 (90%)]\tLoss: 724.542297\n",
            "Train Epoch: 283 [55040/60000 (92%)]\tLoss: 725.456726\n",
            "Train Epoch: 283 [56320/60000 (94%)]\tLoss: 709.134766\n",
            "Train Epoch: 283 [57600/60000 (96%)]\tLoss: 732.793030\n",
            "Train Epoch: 283 [58880/60000 (98%)]\tLoss: 741.375183\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786061346530914\n",
            "\n",
            "Train Epoch: 284 [0/60000 (0%)]\tLoss: 744.992676\n",
            "Train Epoch: 284 [1280/60000 (2%)]\tLoss: 735.108826\n",
            "Train Epoch: 284 [2560/60000 (4%)]\tLoss: 732.964294\n",
            "Train Epoch: 284 [3840/60000 (6%)]\tLoss: 741.296692\n",
            "Train Epoch: 284 [5120/60000 (9%)]\tLoss: 738.372070\n",
            "Train Epoch: 284 [6400/60000 (11%)]\tLoss: 716.263367\n",
            "Train Epoch: 284 [7680/60000 (13%)]\tLoss: 726.244812\n",
            "Train Epoch: 284 [8960/60000 (15%)]\tLoss: 747.365540\n",
            "Train Epoch: 284 [10240/60000 (17%)]\tLoss: 739.562073\n",
            "Train Epoch: 284 [11520/60000 (19%)]\tLoss: 721.829712\n",
            "Train Epoch: 284 [12800/60000 (21%)]\tLoss: 728.974121\n",
            "Train Epoch: 284 [14080/60000 (23%)]\tLoss: 744.483398\n",
            "Train Epoch: 284 [15360/60000 (26%)]\tLoss: 725.390991\n",
            "Train Epoch: 284 [16640/60000 (28%)]\tLoss: 726.699951\n",
            "Train Epoch: 284 [17920/60000 (30%)]\tLoss: 720.944641\n",
            "Train Epoch: 284 [19200/60000 (32%)]\tLoss: 765.718994\n",
            "Train Epoch: 284 [20480/60000 (34%)]\tLoss: 744.848206\n",
            "Train Epoch: 284 [21760/60000 (36%)]\tLoss: 745.512024\n",
            "Train Epoch: 284 [23040/60000 (38%)]\tLoss: 728.501465\n",
            "Train Epoch: 284 [24320/60000 (41%)]\tLoss: 748.791138\n",
            "Train Epoch: 284 [25600/60000 (43%)]\tLoss: 748.888428\n",
            "Train Epoch: 284 [26880/60000 (45%)]\tLoss: 726.877502\n",
            "Train Epoch: 284 [28160/60000 (47%)]\tLoss: 744.933411\n",
            "Train Epoch: 284 [29440/60000 (49%)]\tLoss: 761.156982\n",
            "Train Epoch: 284 [30720/60000 (51%)]\tLoss: 746.731506\n",
            "Train Epoch: 284 [32000/60000 (53%)]\tLoss: 749.486938\n",
            "Train Epoch: 284 [33280/60000 (55%)]\tLoss: 748.726501\n",
            "Train Epoch: 284 [34560/60000 (58%)]\tLoss: 732.063293\n",
            "Train Epoch: 284 [35840/60000 (60%)]\tLoss: 728.517029\n",
            "Train Epoch: 284 [37120/60000 (62%)]\tLoss: 741.960999\n",
            "Train Epoch: 284 [38400/60000 (64%)]\tLoss: 739.289001\n",
            "Train Epoch: 284 [39680/60000 (66%)]\tLoss: 733.463501\n",
            "Train Epoch: 284 [40960/60000 (68%)]\tLoss: 712.499695\n",
            "Train Epoch: 284 [42240/60000 (70%)]\tLoss: 735.172424\n",
            "Train Epoch: 284 [43520/60000 (72%)]\tLoss: 730.412109\n",
            "Train Epoch: 284 [44800/60000 (75%)]\tLoss: 717.783813\n",
            "Train Epoch: 284 [46080/60000 (77%)]\tLoss: 741.542664\n",
            "Train Epoch: 284 [47360/60000 (79%)]\tLoss: 743.118286\n",
            "Train Epoch: 284 [48640/60000 (81%)]\tLoss: 741.278381\n",
            "Train Epoch: 284 [49920/60000 (83%)]\tLoss: 731.539795\n",
            "Train Epoch: 284 [51200/60000 (85%)]\tLoss: 730.495667\n",
            "Train Epoch: 284 [52480/60000 (87%)]\tLoss: 715.311340\n",
            "Train Epoch: 284 [53760/60000 (90%)]\tLoss: 721.230835\n",
            "Train Epoch: 284 [55040/60000 (92%)]\tLoss: 736.517151\n",
            "Train Epoch: 284 [56320/60000 (94%)]\tLoss: 748.753479\n",
            "Train Epoch: 284 [57600/60000 (96%)]\tLoss: 733.965881\n",
            "Train Epoch: 284 [58880/60000 (98%)]\tLoss: 752.276062\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781284034252167\n",
            "\n",
            "Train Epoch: 285 [0/60000 (0%)]\tLoss: 720.269897\n",
            "Train Epoch: 285 [1280/60000 (2%)]\tLoss: 743.836304\n",
            "Train Epoch: 285 [2560/60000 (4%)]\tLoss: 734.073608\n",
            "Train Epoch: 285 [3840/60000 (6%)]\tLoss: 739.332520\n",
            "Train Epoch: 285 [5120/60000 (9%)]\tLoss: 717.309814\n",
            "Train Epoch: 285 [6400/60000 (11%)]\tLoss: 741.664246\n",
            "Train Epoch: 285 [7680/60000 (13%)]\tLoss: 746.559204\n",
            "Train Epoch: 285 [8960/60000 (15%)]\tLoss: 748.088074\n",
            "Train Epoch: 285 [10240/60000 (17%)]\tLoss: 741.892456\n",
            "Train Epoch: 285 [11520/60000 (19%)]\tLoss: 726.864136\n",
            "Train Epoch: 285 [12800/60000 (21%)]\tLoss: 722.737000\n",
            "Train Epoch: 285 [14080/60000 (23%)]\tLoss: 742.721130\n",
            "Train Epoch: 285 [15360/60000 (26%)]\tLoss: 740.871887\n",
            "Train Epoch: 285 [16640/60000 (28%)]\tLoss: 741.036804\n",
            "Train Epoch: 285 [17920/60000 (30%)]\tLoss: 730.353149\n",
            "Train Epoch: 285 [19200/60000 (32%)]\tLoss: 755.616150\n",
            "Train Epoch: 285 [20480/60000 (34%)]\tLoss: 706.005737\n",
            "Train Epoch: 285 [21760/60000 (36%)]\tLoss: 737.660156\n",
            "Train Epoch: 285 [23040/60000 (38%)]\tLoss: 751.470642\n",
            "Train Epoch: 285 [24320/60000 (41%)]\tLoss: 737.823669\n",
            "Train Epoch: 285 [25600/60000 (43%)]\tLoss: 758.682922\n",
            "Train Epoch: 285 [26880/60000 (45%)]\tLoss: 725.175476\n",
            "Train Epoch: 285 [28160/60000 (47%)]\tLoss: 726.411133\n",
            "Train Epoch: 285 [29440/60000 (49%)]\tLoss: 730.606873\n",
            "Train Epoch: 285 [30720/60000 (51%)]\tLoss: 726.120178\n",
            "Train Epoch: 285 [32000/60000 (53%)]\tLoss: 754.502441\n",
            "Train Epoch: 285 [33280/60000 (55%)]\tLoss: 720.976685\n",
            "Train Epoch: 285 [34560/60000 (58%)]\tLoss: 732.831482\n",
            "Train Epoch: 285 [35840/60000 (60%)]\tLoss: 764.962524\n",
            "Train Epoch: 285 [37120/60000 (62%)]\tLoss: 743.597595\n",
            "Train Epoch: 285 [38400/60000 (64%)]\tLoss: 745.697449\n",
            "Train Epoch: 285 [39680/60000 (66%)]\tLoss: 728.400574\n",
            "Train Epoch: 285 [40960/60000 (68%)]\tLoss: 738.200745\n",
            "Train Epoch: 285 [42240/60000 (70%)]\tLoss: 725.003662\n",
            "Train Epoch: 285 [43520/60000 (72%)]\tLoss: 729.386902\n",
            "Train Epoch: 285 [44800/60000 (75%)]\tLoss: 733.488403\n",
            "Train Epoch: 285 [46080/60000 (77%)]\tLoss: 755.961365\n",
            "Train Epoch: 285 [47360/60000 (79%)]\tLoss: 756.445618\n",
            "Train Epoch: 285 [48640/60000 (81%)]\tLoss: 743.673401\n",
            "Train Epoch: 285 [49920/60000 (83%)]\tLoss: 700.786926\n",
            "Train Epoch: 285 [51200/60000 (85%)]\tLoss: 719.764221\n",
            "Train Epoch: 285 [52480/60000 (87%)]\tLoss: 747.171814\n",
            "Train Epoch: 285 [53760/60000 (90%)]\tLoss: 738.263489\n",
            "Train Epoch: 285 [55040/60000 (92%)]\tLoss: 716.743958\n",
            "Train Epoch: 285 [56320/60000 (94%)]\tLoss: 741.054932\n",
            "Train Epoch: 285 [57600/60000 (96%)]\tLoss: 720.025574\n",
            "Train Epoch: 285 [58880/60000 (98%)]\tLoss: 754.910278\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786903262138367\n",
            "\n",
            "Train Epoch: 286 [0/60000 (0%)]\tLoss: 747.152405\n",
            "Train Epoch: 286 [1280/60000 (2%)]\tLoss: 732.682678\n",
            "Train Epoch: 286 [2560/60000 (4%)]\tLoss: 748.538940\n",
            "Train Epoch: 286 [3840/60000 (6%)]\tLoss: 739.233643\n",
            "Train Epoch: 286 [5120/60000 (9%)]\tLoss: 732.241882\n",
            "Train Epoch: 286 [6400/60000 (11%)]\tLoss: 742.909912\n",
            "Train Epoch: 286 [7680/60000 (13%)]\tLoss: 716.811829\n",
            "Train Epoch: 286 [8960/60000 (15%)]\tLoss: 728.128296\n",
            "Train Epoch: 286 [10240/60000 (17%)]\tLoss: 718.174805\n",
            "Train Epoch: 286 [11520/60000 (19%)]\tLoss: 755.257141\n",
            "Train Epoch: 286 [12800/60000 (21%)]\tLoss: 771.938965\n",
            "Train Epoch: 286 [14080/60000 (23%)]\tLoss: 746.588257\n",
            "Train Epoch: 286 [15360/60000 (26%)]\tLoss: 710.515991\n",
            "Train Epoch: 286 [16640/60000 (28%)]\tLoss: 711.011536\n",
            "Train Epoch: 286 [17920/60000 (30%)]\tLoss: 743.988831\n",
            "Train Epoch: 286 [19200/60000 (32%)]\tLoss: 737.025574\n",
            "Train Epoch: 286 [20480/60000 (34%)]\tLoss: 753.547546\n",
            "Train Epoch: 286 [21760/60000 (36%)]\tLoss: 761.954041\n",
            "Train Epoch: 286 [23040/60000 (38%)]\tLoss: 749.659363\n",
            "Train Epoch: 286 [24320/60000 (41%)]\tLoss: 771.004578\n",
            "Train Epoch: 286 [25600/60000 (43%)]\tLoss: 740.816650\n",
            "Train Epoch: 286 [26880/60000 (45%)]\tLoss: 703.536499\n",
            "Train Epoch: 286 [28160/60000 (47%)]\tLoss: 753.242249\n",
            "Train Epoch: 286 [29440/60000 (49%)]\tLoss: 749.077026\n",
            "Train Epoch: 286 [30720/60000 (51%)]\tLoss: 741.227478\n",
            "Train Epoch: 286 [32000/60000 (53%)]\tLoss: 741.701843\n",
            "Train Epoch: 286 [33280/60000 (55%)]\tLoss: 728.309509\n",
            "Train Epoch: 286 [34560/60000 (58%)]\tLoss: 727.231812\n",
            "Train Epoch: 286 [35840/60000 (60%)]\tLoss: 745.079712\n",
            "Train Epoch: 286 [37120/60000 (62%)]\tLoss: 732.279907\n",
            "Train Epoch: 286 [38400/60000 (64%)]\tLoss: 760.929138\n",
            "Train Epoch: 286 [39680/60000 (66%)]\tLoss: 737.976379\n",
            "Train Epoch: 286 [40960/60000 (68%)]\tLoss: 713.821594\n",
            "Train Epoch: 286 [42240/60000 (70%)]\tLoss: 712.213196\n",
            "Train Epoch: 286 [43520/60000 (72%)]\tLoss: 726.201904\n",
            "Train Epoch: 286 [44800/60000 (75%)]\tLoss: 748.769409\n",
            "Train Epoch: 286 [46080/60000 (77%)]\tLoss: 728.680237\n",
            "Train Epoch: 286 [47360/60000 (79%)]\tLoss: 714.094543\n",
            "Train Epoch: 286 [48640/60000 (81%)]\tLoss: 701.468567\n",
            "Train Epoch: 286 [49920/60000 (83%)]\tLoss: 736.680481\n",
            "Train Epoch: 286 [51200/60000 (85%)]\tLoss: 758.283813\n",
            "Train Epoch: 286 [52480/60000 (87%)]\tLoss: 728.168518\n",
            "Train Epoch: 286 [53760/60000 (90%)]\tLoss: 737.229004\n",
            "Train Epoch: 286 [55040/60000 (92%)]\tLoss: 755.729004\n",
            "Train Epoch: 286 [56320/60000 (94%)]\tLoss: 714.666199\n",
            "Train Epoch: 286 [57600/60000 (96%)]\tLoss: 727.186096\n",
            "Train Epoch: 286 [58880/60000 (98%)]\tLoss: 744.214233\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784075021743774\n",
            "\n",
            "Train Epoch: 287 [0/60000 (0%)]\tLoss: 728.555115\n",
            "Train Epoch: 287 [1280/60000 (2%)]\tLoss: 720.701721\n",
            "Train Epoch: 287 [2560/60000 (4%)]\tLoss: 746.427429\n",
            "Train Epoch: 287 [3840/60000 (6%)]\tLoss: 735.947998\n",
            "Train Epoch: 287 [5120/60000 (9%)]\tLoss: 772.305725\n",
            "Train Epoch: 287 [6400/60000 (11%)]\tLoss: 735.507751\n",
            "Train Epoch: 287 [7680/60000 (13%)]\tLoss: 739.212463\n",
            "Train Epoch: 287 [8960/60000 (15%)]\tLoss: 737.493164\n",
            "Train Epoch: 287 [10240/60000 (17%)]\tLoss: 729.694275\n",
            "Train Epoch: 287 [11520/60000 (19%)]\tLoss: 750.463135\n",
            "Train Epoch: 287 [12800/60000 (21%)]\tLoss: 730.342957\n",
            "Train Epoch: 287 [14080/60000 (23%)]\tLoss: 737.972900\n",
            "Train Epoch: 287 [15360/60000 (26%)]\tLoss: 716.483826\n",
            "Train Epoch: 287 [16640/60000 (28%)]\tLoss: 753.524902\n",
            "Train Epoch: 287 [17920/60000 (30%)]\tLoss: 763.743225\n",
            "Train Epoch: 287 [19200/60000 (32%)]\tLoss: 722.391846\n",
            "Train Epoch: 287 [20480/60000 (34%)]\tLoss: 722.910156\n",
            "Train Epoch: 287 [21760/60000 (36%)]\tLoss: 734.166138\n",
            "Train Epoch: 287 [23040/60000 (38%)]\tLoss: 715.808716\n",
            "Train Epoch: 287 [24320/60000 (41%)]\tLoss: 710.956421\n",
            "Train Epoch: 287 [25600/60000 (43%)]\tLoss: 761.233459\n",
            "Train Epoch: 287 [26880/60000 (45%)]\tLoss: 725.732300\n",
            "Train Epoch: 287 [28160/60000 (47%)]\tLoss: 713.615173\n",
            "Train Epoch: 287 [29440/60000 (49%)]\tLoss: 715.301514\n",
            "Train Epoch: 287 [30720/60000 (51%)]\tLoss: 758.175476\n",
            "Train Epoch: 287 [32000/60000 (53%)]\tLoss: 732.820801\n",
            "Train Epoch: 287 [33280/60000 (55%)]\tLoss: 738.405029\n",
            "Train Epoch: 287 [34560/60000 (58%)]\tLoss: 712.466064\n",
            "Train Epoch: 287 [35840/60000 (60%)]\tLoss: 731.958130\n",
            "Train Epoch: 287 [37120/60000 (62%)]\tLoss: 752.694214\n",
            "Train Epoch: 287 [38400/60000 (64%)]\tLoss: 739.667847\n",
            "Train Epoch: 287 [39680/60000 (66%)]\tLoss: 737.206787\n",
            "Train Epoch: 287 [40960/60000 (68%)]\tLoss: 727.175415\n",
            "Train Epoch: 287 [42240/60000 (70%)]\tLoss: 753.929138\n",
            "Train Epoch: 287 [43520/60000 (72%)]\tLoss: 720.479370\n",
            "Train Epoch: 287 [44800/60000 (75%)]\tLoss: 739.227173\n",
            "Train Epoch: 287 [46080/60000 (77%)]\tLoss: 737.616272\n",
            "Train Epoch: 287 [47360/60000 (79%)]\tLoss: 724.264709\n",
            "Train Epoch: 287 [48640/60000 (81%)]\tLoss: 750.919678\n",
            "Train Epoch: 287 [49920/60000 (83%)]\tLoss: 727.029480\n",
            "Train Epoch: 287 [51200/60000 (85%)]\tLoss: 720.237122\n",
            "Train Epoch: 287 [52480/60000 (87%)]\tLoss: 737.444336\n",
            "Train Epoch: 287 [53760/60000 (90%)]\tLoss: 731.876770\n",
            "Train Epoch: 287 [55040/60000 (92%)]\tLoss: 738.558655\n",
            "Train Epoch: 287 [56320/60000 (94%)]\tLoss: 751.271606\n",
            "Train Epoch: 287 [57600/60000 (96%)]\tLoss: 733.616638\n",
            "Train Epoch: 287 [58880/60000 (98%)]\tLoss: 740.399597\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784514605998993\n",
            "\n",
            "Train Epoch: 288 [0/60000 (0%)]\tLoss: 726.612915\n",
            "Train Epoch: 288 [1280/60000 (2%)]\tLoss: 715.241699\n",
            "Train Epoch: 288 [2560/60000 (4%)]\tLoss: 729.825195\n",
            "Train Epoch: 288 [3840/60000 (6%)]\tLoss: 738.301270\n",
            "Train Epoch: 288 [5120/60000 (9%)]\tLoss: 712.941956\n",
            "Train Epoch: 288 [6400/60000 (11%)]\tLoss: 741.367493\n",
            "Train Epoch: 288 [7680/60000 (13%)]\tLoss: 734.474426\n",
            "Train Epoch: 288 [8960/60000 (15%)]\tLoss: 738.120300\n",
            "Train Epoch: 288 [10240/60000 (17%)]\tLoss: 700.827515\n",
            "Train Epoch: 288 [11520/60000 (19%)]\tLoss: 706.994446\n",
            "Train Epoch: 288 [12800/60000 (21%)]\tLoss: 739.007019\n",
            "Train Epoch: 288 [14080/60000 (23%)]\tLoss: 755.789246\n",
            "Train Epoch: 288 [15360/60000 (26%)]\tLoss: 713.348633\n",
            "Train Epoch: 288 [16640/60000 (28%)]\tLoss: 740.298462\n",
            "Train Epoch: 288 [17920/60000 (30%)]\tLoss: 738.622498\n",
            "Train Epoch: 288 [19200/60000 (32%)]\tLoss: 735.279175\n",
            "Train Epoch: 288 [20480/60000 (34%)]\tLoss: 753.950500\n",
            "Train Epoch: 288 [21760/60000 (36%)]\tLoss: 753.225525\n",
            "Train Epoch: 288 [23040/60000 (38%)]\tLoss: 713.608826\n",
            "Train Epoch: 288 [24320/60000 (41%)]\tLoss: 742.405518\n",
            "Train Epoch: 288 [25600/60000 (43%)]\tLoss: 735.023376\n",
            "Train Epoch: 288 [26880/60000 (45%)]\tLoss: 714.433411\n",
            "Train Epoch: 288 [28160/60000 (47%)]\tLoss: 737.024109\n",
            "Train Epoch: 288 [29440/60000 (49%)]\tLoss: 758.843811\n",
            "Train Epoch: 288 [30720/60000 (51%)]\tLoss: 735.257751\n",
            "Train Epoch: 288 [32000/60000 (53%)]\tLoss: 748.844971\n",
            "Train Epoch: 288 [33280/60000 (55%)]\tLoss: 739.386719\n",
            "Train Epoch: 288 [34560/60000 (58%)]\tLoss: 706.024536\n",
            "Train Epoch: 288 [35840/60000 (60%)]\tLoss: 753.515991\n",
            "Train Epoch: 288 [37120/60000 (62%)]\tLoss: 731.541077\n",
            "Train Epoch: 288 [38400/60000 (64%)]\tLoss: 747.509033\n",
            "Train Epoch: 288 [39680/60000 (66%)]\tLoss: 742.835083\n",
            "Train Epoch: 288 [40960/60000 (68%)]\tLoss: 727.025452\n",
            "Train Epoch: 288 [42240/60000 (70%)]\tLoss: 728.278381\n",
            "Train Epoch: 288 [43520/60000 (72%)]\tLoss: 729.638123\n",
            "Train Epoch: 288 [44800/60000 (75%)]\tLoss: 732.813721\n",
            "Train Epoch: 288 [46080/60000 (77%)]\tLoss: 768.035095\n",
            "Train Epoch: 288 [47360/60000 (79%)]\tLoss: 724.828430\n",
            "Train Epoch: 288 [48640/60000 (81%)]\tLoss: 751.177551\n",
            "Train Epoch: 288 [49920/60000 (83%)]\tLoss: 718.958984\n",
            "Train Epoch: 288 [51200/60000 (85%)]\tLoss: 730.346497\n",
            "Train Epoch: 288 [52480/60000 (87%)]\tLoss: 728.774536\n",
            "Train Epoch: 288 [53760/60000 (90%)]\tLoss: 761.123901\n",
            "Train Epoch: 288 [55040/60000 (92%)]\tLoss: 743.983032\n",
            "Train Epoch: 288 [56320/60000 (94%)]\tLoss: 751.823792\n",
            "Train Epoch: 288 [57600/60000 (96%)]\tLoss: 738.753845\n",
            "Train Epoch: 288 [58880/60000 (98%)]\tLoss: 735.616028\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978800892829895\n",
            "\n",
            "Train Epoch: 289 [0/60000 (0%)]\tLoss: 723.724609\n",
            "Train Epoch: 289 [1280/60000 (2%)]\tLoss: 729.203247\n",
            "Train Epoch: 289 [2560/60000 (4%)]\tLoss: 736.406677\n",
            "Train Epoch: 289 [3840/60000 (6%)]\tLoss: 728.007568\n",
            "Train Epoch: 289 [5120/60000 (9%)]\tLoss: 754.793640\n",
            "Train Epoch: 289 [6400/60000 (11%)]\tLoss: 730.914429\n",
            "Train Epoch: 289 [7680/60000 (13%)]\tLoss: 707.615051\n",
            "Train Epoch: 289 [8960/60000 (15%)]\tLoss: 768.605286\n",
            "Train Epoch: 289 [10240/60000 (17%)]\tLoss: 734.842285\n",
            "Train Epoch: 289 [11520/60000 (19%)]\tLoss: 736.259216\n",
            "Train Epoch: 289 [12800/60000 (21%)]\tLoss: 715.360657\n",
            "Train Epoch: 289 [14080/60000 (23%)]\tLoss: 727.789795\n",
            "Train Epoch: 289 [15360/60000 (26%)]\tLoss: 741.870483\n",
            "Train Epoch: 289 [16640/60000 (28%)]\tLoss: 719.840881\n",
            "Train Epoch: 289 [17920/60000 (30%)]\tLoss: 743.038940\n",
            "Train Epoch: 289 [19200/60000 (32%)]\tLoss: 718.073425\n",
            "Train Epoch: 289 [20480/60000 (34%)]\tLoss: 741.609009\n",
            "Train Epoch: 289 [21760/60000 (36%)]\tLoss: 747.493591\n",
            "Train Epoch: 289 [23040/60000 (38%)]\tLoss: 721.265015\n",
            "Train Epoch: 289 [24320/60000 (41%)]\tLoss: 740.572815\n",
            "Train Epoch: 289 [25600/60000 (43%)]\tLoss: 742.405396\n",
            "Train Epoch: 289 [26880/60000 (45%)]\tLoss: 722.813965\n",
            "Train Epoch: 289 [28160/60000 (47%)]\tLoss: 742.796326\n",
            "Train Epoch: 289 [29440/60000 (49%)]\tLoss: 740.981750\n",
            "Train Epoch: 289 [30720/60000 (51%)]\tLoss: 744.338867\n",
            "Train Epoch: 289 [32000/60000 (53%)]\tLoss: 733.126099\n",
            "Train Epoch: 289 [33280/60000 (55%)]\tLoss: 725.066345\n",
            "Train Epoch: 289 [34560/60000 (58%)]\tLoss: 736.766418\n",
            "Train Epoch: 289 [35840/60000 (60%)]\tLoss: 743.906311\n",
            "Train Epoch: 289 [37120/60000 (62%)]\tLoss: 734.938599\n",
            "Train Epoch: 289 [38400/60000 (64%)]\tLoss: 707.270386\n",
            "Train Epoch: 289 [39680/60000 (66%)]\tLoss: 736.980591\n",
            "Train Epoch: 289 [40960/60000 (68%)]\tLoss: 748.535645\n",
            "Train Epoch: 289 [42240/60000 (70%)]\tLoss: 739.638794\n",
            "Train Epoch: 289 [43520/60000 (72%)]\tLoss: 741.307495\n",
            "Train Epoch: 289 [44800/60000 (75%)]\tLoss: 740.843079\n",
            "Train Epoch: 289 [46080/60000 (77%)]\tLoss: 734.476196\n",
            "Train Epoch: 289 [47360/60000 (79%)]\tLoss: 746.840515\n",
            "Train Epoch: 289 [48640/60000 (81%)]\tLoss: 732.795532\n",
            "Train Epoch: 289 [49920/60000 (83%)]\tLoss: 774.244080\n",
            "Train Epoch: 289 [51200/60000 (85%)]\tLoss: 741.203735\n",
            "Train Epoch: 289 [52480/60000 (87%)]\tLoss: 728.889893\n",
            "Train Epoch: 289 [53760/60000 (90%)]\tLoss: 726.459290\n",
            "Train Epoch: 289 [55040/60000 (92%)]\tLoss: 740.496033\n",
            "Train Epoch: 289 [56320/60000 (94%)]\tLoss: 695.654602\n",
            "Train Epoch: 289 [57600/60000 (96%)]\tLoss: 709.614014\n",
            "Train Epoch: 289 [58880/60000 (98%)]\tLoss: 743.093872\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978665143251419\n",
            "\n",
            "Train Epoch: 290 [0/60000 (0%)]\tLoss: 735.499634\n",
            "Train Epoch: 290 [1280/60000 (2%)]\tLoss: 711.731689\n",
            "Train Epoch: 290 [2560/60000 (4%)]\tLoss: 752.956543\n",
            "Train Epoch: 290 [3840/60000 (6%)]\tLoss: 735.408264\n",
            "Train Epoch: 290 [5120/60000 (9%)]\tLoss: 726.660095\n",
            "Train Epoch: 290 [6400/60000 (11%)]\tLoss: 740.428589\n",
            "Train Epoch: 290 [7680/60000 (13%)]\tLoss: 740.053162\n",
            "Train Epoch: 290 [8960/60000 (15%)]\tLoss: 722.317810\n",
            "Train Epoch: 290 [10240/60000 (17%)]\tLoss: 732.718811\n",
            "Train Epoch: 290 [11520/60000 (19%)]\tLoss: 714.264404\n",
            "Train Epoch: 290 [12800/60000 (21%)]\tLoss: 731.610596\n",
            "Train Epoch: 290 [14080/60000 (23%)]\tLoss: 735.453003\n",
            "Train Epoch: 290 [15360/60000 (26%)]\tLoss: 735.648743\n",
            "Train Epoch: 290 [16640/60000 (28%)]\tLoss: 728.884155\n",
            "Train Epoch: 290 [17920/60000 (30%)]\tLoss: 727.791504\n",
            "Train Epoch: 290 [19200/60000 (32%)]\tLoss: 749.165039\n",
            "Train Epoch: 290 [20480/60000 (34%)]\tLoss: 741.338684\n",
            "Train Epoch: 290 [21760/60000 (36%)]\tLoss: 742.163635\n",
            "Train Epoch: 290 [23040/60000 (38%)]\tLoss: 742.656311\n",
            "Train Epoch: 290 [24320/60000 (41%)]\tLoss: 730.625305\n",
            "Train Epoch: 290 [25600/60000 (43%)]\tLoss: 745.921204\n",
            "Train Epoch: 290 [26880/60000 (45%)]\tLoss: 719.877869\n",
            "Train Epoch: 290 [28160/60000 (47%)]\tLoss: 723.772644\n",
            "Train Epoch: 290 [29440/60000 (49%)]\tLoss: 733.885132\n",
            "Train Epoch: 290 [30720/60000 (51%)]\tLoss: 718.122925\n",
            "Train Epoch: 290 [32000/60000 (53%)]\tLoss: 732.567505\n",
            "Train Epoch: 290 [33280/60000 (55%)]\tLoss: 729.738586\n",
            "Train Epoch: 290 [34560/60000 (58%)]\tLoss: 738.508972\n",
            "Train Epoch: 290 [35840/60000 (60%)]\tLoss: 752.790283\n",
            "Train Epoch: 290 [37120/60000 (62%)]\tLoss: 718.191895\n",
            "Train Epoch: 290 [38400/60000 (64%)]\tLoss: 754.079773\n",
            "Train Epoch: 290 [39680/60000 (66%)]\tLoss: 756.879089\n",
            "Train Epoch: 290 [40960/60000 (68%)]\tLoss: 734.038452\n",
            "Train Epoch: 290 [42240/60000 (70%)]\tLoss: 749.240417\n",
            "Train Epoch: 290 [43520/60000 (72%)]\tLoss: 729.843262\n",
            "Train Epoch: 290 [44800/60000 (75%)]\tLoss: 752.324341\n",
            "Train Epoch: 290 [46080/60000 (77%)]\tLoss: 751.207703\n",
            "Train Epoch: 290 [47360/60000 (79%)]\tLoss: 742.295715\n",
            "Train Epoch: 290 [48640/60000 (81%)]\tLoss: 716.752197\n",
            "Train Epoch: 290 [49920/60000 (83%)]\tLoss: 730.614258\n",
            "Train Epoch: 290 [51200/60000 (85%)]\tLoss: 746.421387\n",
            "Train Epoch: 290 [52480/60000 (87%)]\tLoss: 739.931396\n",
            "Train Epoch: 290 [53760/60000 (90%)]\tLoss: 717.983643\n",
            "Train Epoch: 290 [55040/60000 (92%)]\tLoss: 738.041992\n",
            "Train Epoch: 290 [56320/60000 (94%)]\tLoss: 726.811218\n",
            "Train Epoch: 290 [57600/60000 (96%)]\tLoss: 719.590881\n",
            "Train Epoch: 290 [58880/60000 (98%)]\tLoss: 730.773743\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786256551742554\n",
            "\n",
            "Train Epoch: 291 [0/60000 (0%)]\tLoss: 757.654602\n",
            "Train Epoch: 291 [1280/60000 (2%)]\tLoss: 741.249023\n",
            "Train Epoch: 291 [2560/60000 (4%)]\tLoss: 747.499817\n",
            "Train Epoch: 291 [3840/60000 (6%)]\tLoss: 736.810242\n",
            "Train Epoch: 291 [5120/60000 (9%)]\tLoss: 722.746155\n",
            "Train Epoch: 291 [6400/60000 (11%)]\tLoss: 739.038574\n",
            "Train Epoch: 291 [7680/60000 (13%)]\tLoss: 736.601013\n",
            "Train Epoch: 291 [8960/60000 (15%)]\tLoss: 745.431885\n",
            "Train Epoch: 291 [10240/60000 (17%)]\tLoss: 762.756042\n",
            "Train Epoch: 291 [11520/60000 (19%)]\tLoss: 752.152039\n",
            "Train Epoch: 291 [12800/60000 (21%)]\tLoss: 723.946899\n",
            "Train Epoch: 291 [14080/60000 (23%)]\tLoss: 765.855591\n",
            "Train Epoch: 291 [15360/60000 (26%)]\tLoss: 718.591125\n",
            "Train Epoch: 291 [16640/60000 (28%)]\tLoss: 734.891174\n",
            "Train Epoch: 291 [17920/60000 (30%)]\tLoss: 730.072144\n",
            "Train Epoch: 291 [19200/60000 (32%)]\tLoss: 740.211304\n",
            "Train Epoch: 291 [20480/60000 (34%)]\tLoss: 723.909729\n",
            "Train Epoch: 291 [21760/60000 (36%)]\tLoss: 721.489868\n",
            "Train Epoch: 291 [23040/60000 (38%)]\tLoss: 745.014343\n",
            "Train Epoch: 291 [24320/60000 (41%)]\tLoss: 727.982117\n",
            "Train Epoch: 291 [25600/60000 (43%)]\tLoss: 761.753235\n",
            "Train Epoch: 291 [26880/60000 (45%)]\tLoss: 730.413025\n",
            "Train Epoch: 291 [28160/60000 (47%)]\tLoss: 738.315735\n",
            "Train Epoch: 291 [29440/60000 (49%)]\tLoss: 755.451782\n",
            "Train Epoch: 291 [30720/60000 (51%)]\tLoss: 749.340210\n",
            "Train Epoch: 291 [32000/60000 (53%)]\tLoss: 721.997192\n",
            "Train Epoch: 291 [33280/60000 (55%)]\tLoss: 754.885803\n",
            "Train Epoch: 291 [34560/60000 (58%)]\tLoss: 757.988281\n",
            "Train Epoch: 291 [35840/60000 (60%)]\tLoss: 737.007874\n",
            "Train Epoch: 291 [37120/60000 (62%)]\tLoss: 721.038879\n",
            "Train Epoch: 291 [38400/60000 (64%)]\tLoss: 708.566284\n",
            "Train Epoch: 291 [39680/60000 (66%)]\tLoss: 740.873230\n",
            "Train Epoch: 291 [40960/60000 (68%)]\tLoss: 740.485046\n",
            "Train Epoch: 291 [42240/60000 (70%)]\tLoss: 743.518005\n",
            "Train Epoch: 291 [43520/60000 (72%)]\tLoss: 717.271851\n",
            "Train Epoch: 291 [44800/60000 (75%)]\tLoss: 739.450378\n",
            "Train Epoch: 291 [46080/60000 (77%)]\tLoss: 731.277771\n",
            "Train Epoch: 291 [47360/60000 (79%)]\tLoss: 733.632568\n",
            "Train Epoch: 291 [48640/60000 (81%)]\tLoss: 746.469727\n",
            "Train Epoch: 291 [49920/60000 (83%)]\tLoss: 731.289001\n",
            "Train Epoch: 291 [51200/60000 (85%)]\tLoss: 736.176331\n",
            "Train Epoch: 291 [52480/60000 (87%)]\tLoss: 698.862122\n",
            "Train Epoch: 291 [53760/60000 (90%)]\tLoss: 740.172729\n",
            "Train Epoch: 291 [55040/60000 (92%)]\tLoss: 739.719727\n",
            "Train Epoch: 291 [56320/60000 (94%)]\tLoss: 730.027344\n",
            "Train Epoch: 291 [57600/60000 (96%)]\tLoss: 732.730286\n",
            "Train Epoch: 291 [58880/60000 (98%)]\tLoss: 729.743774\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783653318881989\n",
            "\n",
            "Train Epoch: 292 [0/60000 (0%)]\tLoss: 718.107971\n",
            "Train Epoch: 292 [1280/60000 (2%)]\tLoss: 729.026306\n",
            "Train Epoch: 292 [2560/60000 (4%)]\tLoss: 741.937317\n",
            "Train Epoch: 292 [3840/60000 (6%)]\tLoss: 757.262268\n",
            "Train Epoch: 292 [5120/60000 (9%)]\tLoss: 751.471924\n",
            "Train Epoch: 292 [6400/60000 (11%)]\tLoss: 724.431030\n",
            "Train Epoch: 292 [7680/60000 (13%)]\tLoss: 738.400269\n",
            "Train Epoch: 292 [8960/60000 (15%)]\tLoss: 741.830261\n",
            "Train Epoch: 292 [10240/60000 (17%)]\tLoss: 746.106995\n",
            "Train Epoch: 292 [11520/60000 (19%)]\tLoss: 740.423645\n",
            "Train Epoch: 292 [12800/60000 (21%)]\tLoss: 740.338562\n",
            "Train Epoch: 292 [14080/60000 (23%)]\tLoss: 776.859863\n",
            "Train Epoch: 292 [15360/60000 (26%)]\tLoss: 741.898621\n",
            "Train Epoch: 292 [16640/60000 (28%)]\tLoss: 724.113586\n",
            "Train Epoch: 292 [17920/60000 (30%)]\tLoss: 762.253479\n",
            "Train Epoch: 292 [19200/60000 (32%)]\tLoss: 725.846558\n",
            "Train Epoch: 292 [20480/60000 (34%)]\tLoss: 737.749451\n",
            "Train Epoch: 292 [21760/60000 (36%)]\tLoss: 732.932129\n",
            "Train Epoch: 292 [23040/60000 (38%)]\tLoss: 724.073242\n",
            "Train Epoch: 292 [24320/60000 (41%)]\tLoss: 733.169983\n",
            "Train Epoch: 292 [25600/60000 (43%)]\tLoss: 732.974792\n",
            "Train Epoch: 292 [26880/60000 (45%)]\tLoss: 758.141785\n",
            "Train Epoch: 292 [28160/60000 (47%)]\tLoss: 748.320679\n",
            "Train Epoch: 292 [29440/60000 (49%)]\tLoss: 738.762451\n",
            "Train Epoch: 292 [30720/60000 (51%)]\tLoss: 758.413330\n",
            "Train Epoch: 292 [32000/60000 (53%)]\tLoss: 737.699280\n",
            "Train Epoch: 292 [33280/60000 (55%)]\tLoss: 709.666565\n",
            "Train Epoch: 292 [34560/60000 (58%)]\tLoss: 761.234253\n",
            "Train Epoch: 292 [35840/60000 (60%)]\tLoss: 713.070618\n",
            "Train Epoch: 292 [37120/60000 (62%)]\tLoss: 722.597839\n",
            "Train Epoch: 292 [38400/60000 (64%)]\tLoss: 764.925903\n",
            "Train Epoch: 292 [39680/60000 (66%)]\tLoss: 738.985291\n",
            "Train Epoch: 292 [40960/60000 (68%)]\tLoss: 732.201416\n",
            "Train Epoch: 292 [42240/60000 (70%)]\tLoss: 773.794128\n",
            "Train Epoch: 292 [43520/60000 (72%)]\tLoss: 725.549438\n",
            "Train Epoch: 292 [44800/60000 (75%)]\tLoss: 758.277527\n",
            "Train Epoch: 292 [46080/60000 (77%)]\tLoss: 733.149292\n",
            "Train Epoch: 292 [47360/60000 (79%)]\tLoss: 745.750305\n",
            "Train Epoch: 292 [48640/60000 (81%)]\tLoss: 730.691589\n",
            "Train Epoch: 292 [49920/60000 (83%)]\tLoss: 727.083984\n",
            "Train Epoch: 292 [51200/60000 (85%)]\tLoss: 738.056213\n",
            "Train Epoch: 292 [52480/60000 (87%)]\tLoss: 739.852051\n",
            "Train Epoch: 292 [53760/60000 (90%)]\tLoss: 739.854126\n",
            "Train Epoch: 292 [55040/60000 (92%)]\tLoss: 736.594666\n",
            "Train Epoch: 292 [56320/60000 (94%)]\tLoss: 705.086853\n",
            "Train Epoch: 292 [57600/60000 (96%)]\tLoss: 745.652588\n",
            "Train Epoch: 292 [58880/60000 (98%)]\tLoss: 743.314331\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786521792411804\n",
            "\n",
            "Train Epoch: 293 [0/60000 (0%)]\tLoss: 732.228821\n",
            "Train Epoch: 293 [1280/60000 (2%)]\tLoss: 753.488220\n",
            "Train Epoch: 293 [2560/60000 (4%)]\tLoss: 742.659790\n",
            "Train Epoch: 293 [3840/60000 (6%)]\tLoss: 756.571350\n",
            "Train Epoch: 293 [5120/60000 (9%)]\tLoss: 726.203552\n",
            "Train Epoch: 293 [6400/60000 (11%)]\tLoss: 725.398438\n",
            "Train Epoch: 293 [7680/60000 (13%)]\tLoss: 741.492493\n",
            "Train Epoch: 293 [8960/60000 (15%)]\tLoss: 733.126831\n",
            "Train Epoch: 293 [10240/60000 (17%)]\tLoss: 760.158691\n",
            "Train Epoch: 293 [11520/60000 (19%)]\tLoss: 736.059509\n",
            "Train Epoch: 293 [12800/60000 (21%)]\tLoss: 729.852356\n",
            "Train Epoch: 293 [14080/60000 (23%)]\tLoss: 705.139465\n",
            "Train Epoch: 293 [15360/60000 (26%)]\tLoss: 699.627441\n",
            "Train Epoch: 293 [16640/60000 (28%)]\tLoss: 742.554382\n",
            "Train Epoch: 293 [17920/60000 (30%)]\tLoss: 754.395874\n",
            "Train Epoch: 293 [19200/60000 (32%)]\tLoss: 752.248657\n",
            "Train Epoch: 293 [20480/60000 (34%)]\tLoss: 738.249756\n",
            "Train Epoch: 293 [21760/60000 (36%)]\tLoss: 729.597717\n",
            "Train Epoch: 293 [23040/60000 (38%)]\tLoss: 727.157898\n",
            "Train Epoch: 293 [24320/60000 (41%)]\tLoss: 757.196411\n",
            "Train Epoch: 293 [25600/60000 (43%)]\tLoss: 743.190735\n",
            "Train Epoch: 293 [26880/60000 (45%)]\tLoss: 745.591980\n",
            "Train Epoch: 293 [28160/60000 (47%)]\tLoss: 722.985046\n",
            "Train Epoch: 293 [29440/60000 (49%)]\tLoss: 743.863525\n",
            "Train Epoch: 293 [30720/60000 (51%)]\tLoss: 746.011658\n",
            "Train Epoch: 293 [32000/60000 (53%)]\tLoss: 730.148438\n",
            "Train Epoch: 293 [33280/60000 (55%)]\tLoss: 748.947632\n",
            "Train Epoch: 293 [34560/60000 (58%)]\tLoss: 720.407043\n",
            "Train Epoch: 293 [35840/60000 (60%)]\tLoss: 737.694275\n",
            "Train Epoch: 293 [37120/60000 (62%)]\tLoss: 744.568726\n",
            "Train Epoch: 293 [38400/60000 (64%)]\tLoss: 711.148193\n",
            "Train Epoch: 293 [39680/60000 (66%)]\tLoss: 726.418396\n",
            "Train Epoch: 293 [40960/60000 (68%)]\tLoss: 721.627197\n",
            "Train Epoch: 293 [42240/60000 (70%)]\tLoss: 749.428955\n",
            "Train Epoch: 293 [43520/60000 (72%)]\tLoss: 731.398254\n",
            "Train Epoch: 293 [44800/60000 (75%)]\tLoss: 704.024231\n",
            "Train Epoch: 293 [46080/60000 (77%)]\tLoss: 760.483398\n",
            "Train Epoch: 293 [47360/60000 (79%)]\tLoss: 743.638245\n",
            "Train Epoch: 293 [48640/60000 (81%)]\tLoss: 758.898376\n",
            "Train Epoch: 293 [49920/60000 (83%)]\tLoss: 705.718018\n",
            "Train Epoch: 293 [51200/60000 (85%)]\tLoss: 743.820740\n",
            "Train Epoch: 293 [52480/60000 (87%)]\tLoss: 733.021057\n",
            "Train Epoch: 293 [53760/60000 (90%)]\tLoss: 753.115906\n",
            "Train Epoch: 293 [55040/60000 (92%)]\tLoss: 712.269470\n",
            "Train Epoch: 293 [56320/60000 (94%)]\tLoss: 725.863098\n",
            "Train Epoch: 293 [57600/60000 (96%)]\tLoss: 726.338196\n",
            "Train Epoch: 293 [58880/60000 (98%)]\tLoss: 750.789612\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784341752529144\n",
            "\n",
            "Train Epoch: 294 [0/60000 (0%)]\tLoss: 726.844116\n",
            "Train Epoch: 294 [1280/60000 (2%)]\tLoss: 760.756165\n",
            "Train Epoch: 294 [2560/60000 (4%)]\tLoss: 739.967957\n",
            "Train Epoch: 294 [3840/60000 (6%)]\tLoss: 743.638123\n",
            "Train Epoch: 294 [5120/60000 (9%)]\tLoss: 722.818054\n",
            "Train Epoch: 294 [6400/60000 (11%)]\tLoss: 748.677734\n",
            "Train Epoch: 294 [7680/60000 (13%)]\tLoss: 718.397461\n",
            "Train Epoch: 294 [8960/60000 (15%)]\tLoss: 742.558594\n",
            "Train Epoch: 294 [10240/60000 (17%)]\tLoss: 733.904236\n",
            "Train Epoch: 294 [11520/60000 (19%)]\tLoss: 726.386902\n",
            "Train Epoch: 294 [12800/60000 (21%)]\tLoss: 718.922119\n",
            "Train Epoch: 294 [14080/60000 (23%)]\tLoss: 736.470581\n",
            "Train Epoch: 294 [15360/60000 (26%)]\tLoss: 754.859253\n",
            "Train Epoch: 294 [16640/60000 (28%)]\tLoss: 726.516907\n",
            "Train Epoch: 294 [17920/60000 (30%)]\tLoss: 726.122498\n",
            "Train Epoch: 294 [19200/60000 (32%)]\tLoss: 743.362061\n",
            "Train Epoch: 294 [20480/60000 (34%)]\tLoss: 753.049377\n",
            "Train Epoch: 294 [21760/60000 (36%)]\tLoss: 725.989563\n",
            "Train Epoch: 294 [23040/60000 (38%)]\tLoss: 762.004883\n",
            "Train Epoch: 294 [24320/60000 (41%)]\tLoss: 733.919312\n",
            "Train Epoch: 294 [25600/60000 (43%)]\tLoss: 757.276978\n",
            "Train Epoch: 294 [26880/60000 (45%)]\tLoss: 748.057312\n",
            "Train Epoch: 294 [28160/60000 (47%)]\tLoss: 746.074402\n",
            "Train Epoch: 294 [29440/60000 (49%)]\tLoss: 761.227783\n",
            "Train Epoch: 294 [30720/60000 (51%)]\tLoss: 728.709229\n",
            "Train Epoch: 294 [32000/60000 (53%)]\tLoss: 732.033997\n",
            "Train Epoch: 294 [33280/60000 (55%)]\tLoss: 716.648621\n",
            "Train Epoch: 294 [34560/60000 (58%)]\tLoss: 753.506714\n",
            "Train Epoch: 294 [35840/60000 (60%)]\tLoss: 723.308594\n",
            "Train Epoch: 294 [37120/60000 (62%)]\tLoss: 749.574829\n",
            "Train Epoch: 294 [38400/60000 (64%)]\tLoss: 715.705994\n",
            "Train Epoch: 294 [39680/60000 (66%)]\tLoss: 718.865540\n",
            "Train Epoch: 294 [40960/60000 (68%)]\tLoss: 735.314514\n",
            "Train Epoch: 294 [42240/60000 (70%)]\tLoss: 757.504883\n",
            "Train Epoch: 294 [43520/60000 (72%)]\tLoss: 747.399353\n",
            "Train Epoch: 294 [44800/60000 (75%)]\tLoss: 736.347107\n",
            "Train Epoch: 294 [46080/60000 (77%)]\tLoss: 760.696716\n",
            "Train Epoch: 294 [47360/60000 (79%)]\tLoss: 721.910095\n",
            "Train Epoch: 294 [48640/60000 (81%)]\tLoss: 744.882385\n",
            "Train Epoch: 294 [49920/60000 (83%)]\tLoss: 723.349548\n",
            "Train Epoch: 294 [51200/60000 (85%)]\tLoss: 746.861206\n",
            "Train Epoch: 294 [52480/60000 (87%)]\tLoss: 744.204712\n",
            "Train Epoch: 294 [53760/60000 (90%)]\tLoss: 728.990906\n",
            "Train Epoch: 294 [55040/60000 (92%)]\tLoss: 716.413086\n",
            "Train Epoch: 294 [56320/60000 (94%)]\tLoss: 731.710876\n",
            "Train Epoch: 294 [57600/60000 (96%)]\tLoss: 732.479126\n",
            "Train Epoch: 294 [58880/60000 (98%)]\tLoss: 725.398193\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781294465065002\n",
            "\n",
            "Train Epoch: 295 [0/60000 (0%)]\tLoss: 733.013123\n",
            "Train Epoch: 295 [1280/60000 (2%)]\tLoss: 720.417480\n",
            "Train Epoch: 295 [2560/60000 (4%)]\tLoss: 738.124756\n",
            "Train Epoch: 295 [3840/60000 (6%)]\tLoss: 722.133362\n",
            "Train Epoch: 295 [5120/60000 (9%)]\tLoss: 741.157776\n",
            "Train Epoch: 295 [6400/60000 (11%)]\tLoss: 741.062195\n",
            "Train Epoch: 295 [7680/60000 (13%)]\tLoss: 745.592651\n",
            "Train Epoch: 295 [8960/60000 (15%)]\tLoss: 752.015686\n",
            "Train Epoch: 295 [10240/60000 (17%)]\tLoss: 753.228638\n",
            "Train Epoch: 295 [11520/60000 (19%)]\tLoss: 727.083130\n",
            "Train Epoch: 295 [12800/60000 (21%)]\tLoss: 755.713623\n",
            "Train Epoch: 295 [14080/60000 (23%)]\tLoss: 727.307739\n",
            "Train Epoch: 295 [15360/60000 (26%)]\tLoss: 754.547302\n",
            "Train Epoch: 295 [16640/60000 (28%)]\tLoss: 744.411011\n",
            "Train Epoch: 295 [17920/60000 (30%)]\tLoss: 744.644653\n",
            "Train Epoch: 295 [19200/60000 (32%)]\tLoss: 707.816101\n",
            "Train Epoch: 295 [20480/60000 (34%)]\tLoss: 744.725525\n",
            "Train Epoch: 295 [21760/60000 (36%)]\tLoss: 768.237854\n",
            "Train Epoch: 295 [23040/60000 (38%)]\tLoss: 738.986633\n",
            "Train Epoch: 295 [24320/60000 (41%)]\tLoss: 742.607361\n",
            "Train Epoch: 295 [25600/60000 (43%)]\tLoss: 738.099792\n",
            "Train Epoch: 295 [26880/60000 (45%)]\tLoss: 748.558594\n",
            "Train Epoch: 295 [28160/60000 (47%)]\tLoss: 745.794800\n",
            "Train Epoch: 295 [29440/60000 (49%)]\tLoss: 737.716675\n",
            "Train Epoch: 295 [30720/60000 (51%)]\tLoss: 732.556519\n",
            "Train Epoch: 295 [32000/60000 (53%)]\tLoss: 734.115845\n",
            "Train Epoch: 295 [33280/60000 (55%)]\tLoss: 741.561707\n",
            "Train Epoch: 295 [34560/60000 (58%)]\tLoss: 734.593994\n",
            "Train Epoch: 295 [35840/60000 (60%)]\tLoss: 755.374756\n",
            "Train Epoch: 295 [37120/60000 (62%)]\tLoss: 743.799988\n",
            "Train Epoch: 295 [38400/60000 (64%)]\tLoss: 716.898071\n",
            "Train Epoch: 295 [39680/60000 (66%)]\tLoss: 746.300110\n",
            "Train Epoch: 295 [40960/60000 (68%)]\tLoss: 748.961853\n",
            "Train Epoch: 295 [42240/60000 (70%)]\tLoss: 747.790955\n",
            "Train Epoch: 295 [43520/60000 (72%)]\tLoss: 723.289368\n",
            "Train Epoch: 295 [44800/60000 (75%)]\tLoss: 728.611572\n",
            "Train Epoch: 295 [46080/60000 (77%)]\tLoss: 720.364563\n",
            "Train Epoch: 295 [47360/60000 (79%)]\tLoss: 741.077637\n",
            "Train Epoch: 295 [48640/60000 (81%)]\tLoss: 757.294983\n",
            "Train Epoch: 295 [49920/60000 (83%)]\tLoss: 718.501282\n",
            "Train Epoch: 295 [51200/60000 (85%)]\tLoss: 733.715454\n",
            "Train Epoch: 295 [52480/60000 (87%)]\tLoss: 740.891052\n",
            "Train Epoch: 295 [53760/60000 (90%)]\tLoss: 733.800842\n",
            "Train Epoch: 295 [55040/60000 (92%)]\tLoss: 737.894348\n",
            "Train Epoch: 295 [56320/60000 (94%)]\tLoss: 751.615784\n",
            "Train Epoch: 295 [57600/60000 (96%)]\tLoss: 731.546814\n",
            "Train Epoch: 295 [58880/60000 (98%)]\tLoss: 729.356934\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19789038598537445\n",
            "\n",
            "Train Epoch: 296 [0/60000 (0%)]\tLoss: 749.462219\n",
            "Train Epoch: 296 [1280/60000 (2%)]\tLoss: 720.697021\n",
            "Train Epoch: 296 [2560/60000 (4%)]\tLoss: 740.179565\n",
            "Train Epoch: 296 [3840/60000 (6%)]\tLoss: 732.893005\n",
            "Train Epoch: 296 [5120/60000 (9%)]\tLoss: 740.794434\n",
            "Train Epoch: 296 [6400/60000 (11%)]\tLoss: 744.975403\n",
            "Train Epoch: 296 [7680/60000 (13%)]\tLoss: 737.573486\n",
            "Train Epoch: 296 [8960/60000 (15%)]\tLoss: 730.206604\n",
            "Train Epoch: 296 [10240/60000 (17%)]\tLoss: 732.945801\n",
            "Train Epoch: 296 [11520/60000 (19%)]\tLoss: 728.806763\n",
            "Train Epoch: 296 [12800/60000 (21%)]\tLoss: 737.554871\n",
            "Train Epoch: 296 [14080/60000 (23%)]\tLoss: 733.175903\n",
            "Train Epoch: 296 [15360/60000 (26%)]\tLoss: 752.391663\n",
            "Train Epoch: 296 [16640/60000 (28%)]\tLoss: 745.845581\n",
            "Train Epoch: 296 [17920/60000 (30%)]\tLoss: 737.273804\n",
            "Train Epoch: 296 [19200/60000 (32%)]\tLoss: 766.571899\n",
            "Train Epoch: 296 [20480/60000 (34%)]\tLoss: 731.223145\n",
            "Train Epoch: 296 [21760/60000 (36%)]\tLoss: 755.956482\n",
            "Train Epoch: 296 [23040/60000 (38%)]\tLoss: 728.511902\n",
            "Train Epoch: 296 [24320/60000 (41%)]\tLoss: 711.846375\n",
            "Train Epoch: 296 [25600/60000 (43%)]\tLoss: 724.656555\n",
            "Train Epoch: 296 [26880/60000 (45%)]\tLoss: 714.475952\n",
            "Train Epoch: 296 [28160/60000 (47%)]\tLoss: 754.233459\n",
            "Train Epoch: 296 [29440/60000 (49%)]\tLoss: 738.083496\n",
            "Train Epoch: 296 [30720/60000 (51%)]\tLoss: 730.783630\n",
            "Train Epoch: 296 [32000/60000 (53%)]\tLoss: 737.934021\n",
            "Train Epoch: 296 [33280/60000 (55%)]\tLoss: 719.899414\n",
            "Train Epoch: 296 [34560/60000 (58%)]\tLoss: 707.228699\n",
            "Train Epoch: 296 [35840/60000 (60%)]\tLoss: 745.400452\n",
            "Train Epoch: 296 [37120/60000 (62%)]\tLoss: 742.931702\n",
            "Train Epoch: 296 [38400/60000 (64%)]\tLoss: 733.065430\n",
            "Train Epoch: 296 [39680/60000 (66%)]\tLoss: 731.835632\n",
            "Train Epoch: 296 [40960/60000 (68%)]\tLoss: 711.426819\n",
            "Train Epoch: 296 [42240/60000 (70%)]\tLoss: 739.603088\n",
            "Train Epoch: 296 [43520/60000 (72%)]\tLoss: 722.748840\n",
            "Train Epoch: 296 [44800/60000 (75%)]\tLoss: 745.922058\n",
            "Train Epoch: 296 [46080/60000 (77%)]\tLoss: 732.545837\n",
            "Train Epoch: 296 [47360/60000 (79%)]\tLoss: 721.680786\n",
            "Train Epoch: 296 [48640/60000 (81%)]\tLoss: 742.113647\n",
            "Train Epoch: 296 [49920/60000 (83%)]\tLoss: 764.448486\n",
            "Train Epoch: 296 [51200/60000 (85%)]\tLoss: 730.308105\n",
            "Train Epoch: 296 [52480/60000 (87%)]\tLoss: 710.809692\n",
            "Train Epoch: 296 [53760/60000 (90%)]\tLoss: 733.628906\n",
            "Train Epoch: 296 [55040/60000 (92%)]\tLoss: 740.576111\n",
            "Train Epoch: 296 [56320/60000 (94%)]\tLoss: 712.385986\n",
            "Train Epoch: 296 [57600/60000 (96%)]\tLoss: 743.258789\n",
            "Train Epoch: 296 [58880/60000 (98%)]\tLoss: 746.841187\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781151413917542\n",
            "\n",
            "Train Epoch: 297 [0/60000 (0%)]\tLoss: 752.133972\n",
            "Train Epoch: 297 [1280/60000 (2%)]\tLoss: 759.166260\n",
            "Train Epoch: 297 [2560/60000 (4%)]\tLoss: 714.218628\n",
            "Train Epoch: 297 [3840/60000 (6%)]\tLoss: 708.985535\n",
            "Train Epoch: 297 [5120/60000 (9%)]\tLoss: 745.524170\n",
            "Train Epoch: 297 [6400/60000 (11%)]\tLoss: 719.502686\n",
            "Train Epoch: 297 [7680/60000 (13%)]\tLoss: 730.532776\n",
            "Train Epoch: 297 [8960/60000 (15%)]\tLoss: 762.095703\n",
            "Train Epoch: 297 [10240/60000 (17%)]\tLoss: 733.252502\n",
            "Train Epoch: 297 [11520/60000 (19%)]\tLoss: 758.771545\n",
            "Train Epoch: 297 [12800/60000 (21%)]\tLoss: 754.898071\n",
            "Train Epoch: 297 [14080/60000 (23%)]\tLoss: 743.478638\n",
            "Train Epoch: 297 [15360/60000 (26%)]\tLoss: 743.080750\n",
            "Train Epoch: 297 [16640/60000 (28%)]\tLoss: 721.425293\n",
            "Train Epoch: 297 [17920/60000 (30%)]\tLoss: 737.686218\n",
            "Train Epoch: 297 [19200/60000 (32%)]\tLoss: 757.565125\n",
            "Train Epoch: 297 [20480/60000 (34%)]\tLoss: 715.994324\n",
            "Train Epoch: 297 [21760/60000 (36%)]\tLoss: 723.447510\n",
            "Train Epoch: 297 [23040/60000 (38%)]\tLoss: 741.797974\n",
            "Train Epoch: 297 [24320/60000 (41%)]\tLoss: 732.494019\n",
            "Train Epoch: 297 [25600/60000 (43%)]\tLoss: 742.116089\n",
            "Train Epoch: 297 [26880/60000 (45%)]\tLoss: 727.251770\n",
            "Train Epoch: 297 [28160/60000 (47%)]\tLoss: 757.251282\n",
            "Train Epoch: 297 [29440/60000 (49%)]\tLoss: 745.453552\n",
            "Train Epoch: 297 [30720/60000 (51%)]\tLoss: 698.297485\n",
            "Train Epoch: 297 [32000/60000 (53%)]\tLoss: 737.490295\n",
            "Train Epoch: 297 [33280/60000 (55%)]\tLoss: 762.120422\n",
            "Train Epoch: 297 [34560/60000 (58%)]\tLoss: 707.694153\n",
            "Train Epoch: 297 [35840/60000 (60%)]\tLoss: 736.380493\n",
            "Train Epoch: 297 [37120/60000 (62%)]\tLoss: 715.475342\n",
            "Train Epoch: 297 [38400/60000 (64%)]\tLoss: 743.924316\n",
            "Train Epoch: 297 [39680/60000 (66%)]\tLoss: 720.864990\n",
            "Train Epoch: 297 [40960/60000 (68%)]\tLoss: 751.187073\n",
            "Train Epoch: 297 [42240/60000 (70%)]\tLoss: 741.213989\n",
            "Train Epoch: 297 [43520/60000 (72%)]\tLoss: 761.288635\n",
            "Train Epoch: 297 [44800/60000 (75%)]\tLoss: 738.126526\n",
            "Train Epoch: 297 [46080/60000 (77%)]\tLoss: 760.087341\n",
            "Train Epoch: 297 [47360/60000 (79%)]\tLoss: 721.399231\n",
            "Train Epoch: 297 [48640/60000 (81%)]\tLoss: 732.027344\n",
            "Train Epoch: 297 [49920/60000 (83%)]\tLoss: 730.450867\n",
            "Train Epoch: 297 [51200/60000 (85%)]\tLoss: 738.747070\n",
            "Train Epoch: 297 [52480/60000 (87%)]\tLoss: 718.044678\n",
            "Train Epoch: 297 [53760/60000 (90%)]\tLoss: 725.954773\n",
            "Train Epoch: 297 [55040/60000 (92%)]\tLoss: 734.941956\n",
            "Train Epoch: 297 [56320/60000 (94%)]\tLoss: 741.451904\n",
            "Train Epoch: 297 [57600/60000 (96%)]\tLoss: 711.848572\n",
            "Train Epoch: 297 [58880/60000 (98%)]\tLoss: 731.357544\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978340446949005\n",
            "\n",
            "Train Epoch: 298 [0/60000 (0%)]\tLoss: 735.798157\n",
            "Train Epoch: 298 [1280/60000 (2%)]\tLoss: 751.526611\n",
            "Train Epoch: 298 [2560/60000 (4%)]\tLoss: 721.413635\n",
            "Train Epoch: 298 [3840/60000 (6%)]\tLoss: 739.048035\n",
            "Train Epoch: 298 [5120/60000 (9%)]\tLoss: 735.548889\n",
            "Train Epoch: 298 [6400/60000 (11%)]\tLoss: 717.400696\n",
            "Train Epoch: 298 [7680/60000 (13%)]\tLoss: 737.776123\n",
            "Train Epoch: 298 [8960/60000 (15%)]\tLoss: 740.545044\n",
            "Train Epoch: 298 [10240/60000 (17%)]\tLoss: 750.209778\n",
            "Train Epoch: 298 [11520/60000 (19%)]\tLoss: 723.904968\n",
            "Train Epoch: 298 [12800/60000 (21%)]\tLoss: 734.164917\n",
            "Train Epoch: 298 [14080/60000 (23%)]\tLoss: 731.423706\n",
            "Train Epoch: 298 [15360/60000 (26%)]\tLoss: 729.783203\n",
            "Train Epoch: 298 [16640/60000 (28%)]\tLoss: 701.226746\n",
            "Train Epoch: 298 [17920/60000 (30%)]\tLoss: 724.922729\n",
            "Train Epoch: 298 [19200/60000 (32%)]\tLoss: 733.627686\n",
            "Train Epoch: 298 [20480/60000 (34%)]\tLoss: 735.465820\n",
            "Train Epoch: 298 [21760/60000 (36%)]\tLoss: 736.466309\n",
            "Train Epoch: 298 [23040/60000 (38%)]\tLoss: 726.330627\n",
            "Train Epoch: 298 [24320/60000 (41%)]\tLoss: 731.403137\n",
            "Train Epoch: 298 [25600/60000 (43%)]\tLoss: 722.674255\n",
            "Train Epoch: 298 [26880/60000 (45%)]\tLoss: 713.101746\n",
            "Train Epoch: 298 [28160/60000 (47%)]\tLoss: 734.227295\n",
            "Train Epoch: 298 [29440/60000 (49%)]\tLoss: 723.707275\n",
            "Train Epoch: 298 [30720/60000 (51%)]\tLoss: 738.124878\n",
            "Train Epoch: 298 [32000/60000 (53%)]\tLoss: 722.916931\n",
            "Train Epoch: 298 [33280/60000 (55%)]\tLoss: 761.913940\n",
            "Train Epoch: 298 [34560/60000 (58%)]\tLoss: 729.572876\n",
            "Train Epoch: 298 [35840/60000 (60%)]\tLoss: 757.343872\n",
            "Train Epoch: 298 [37120/60000 (62%)]\tLoss: 738.725647\n",
            "Train Epoch: 298 [38400/60000 (64%)]\tLoss: 698.800476\n",
            "Train Epoch: 298 [39680/60000 (66%)]\tLoss: 733.060486\n",
            "Train Epoch: 298 [40960/60000 (68%)]\tLoss: 729.869995\n",
            "Train Epoch: 298 [42240/60000 (70%)]\tLoss: 756.142517\n",
            "Train Epoch: 298 [43520/60000 (72%)]\tLoss: 762.050110\n",
            "Train Epoch: 298 [44800/60000 (75%)]\tLoss: 766.369080\n",
            "Train Epoch: 298 [46080/60000 (77%)]\tLoss: 750.794434\n",
            "Train Epoch: 298 [47360/60000 (79%)]\tLoss: 761.127319\n",
            "Train Epoch: 298 [48640/60000 (81%)]\tLoss: 732.518921\n",
            "Train Epoch: 298 [49920/60000 (83%)]\tLoss: 730.088928\n",
            "Train Epoch: 298 [51200/60000 (85%)]\tLoss: 757.308777\n",
            "Train Epoch: 298 [52480/60000 (87%)]\tLoss: 719.622314\n",
            "Train Epoch: 298 [53760/60000 (90%)]\tLoss: 730.852722\n",
            "Train Epoch: 298 [55040/60000 (92%)]\tLoss: 735.294556\n",
            "Train Epoch: 298 [56320/60000 (94%)]\tLoss: 734.556091\n",
            "Train Epoch: 298 [57600/60000 (96%)]\tLoss: 745.276428\n",
            "Train Epoch: 298 [58880/60000 (98%)]\tLoss: 724.726196\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783881306648254\n",
            "\n",
            "Train Epoch: 299 [0/60000 (0%)]\tLoss: 726.229797\n",
            "Train Epoch: 299 [1280/60000 (2%)]\tLoss: 729.915405\n",
            "Train Epoch: 299 [2560/60000 (4%)]\tLoss: 738.847412\n",
            "Train Epoch: 299 [3840/60000 (6%)]\tLoss: 747.778931\n",
            "Train Epoch: 299 [5120/60000 (9%)]\tLoss: 733.550842\n",
            "Train Epoch: 299 [6400/60000 (11%)]\tLoss: 713.303772\n",
            "Train Epoch: 299 [7680/60000 (13%)]\tLoss: 711.312439\n",
            "Train Epoch: 299 [8960/60000 (15%)]\tLoss: 765.038025\n",
            "Train Epoch: 299 [10240/60000 (17%)]\tLoss: 755.345520\n",
            "Train Epoch: 299 [11520/60000 (19%)]\tLoss: 739.115479\n",
            "Train Epoch: 299 [12800/60000 (21%)]\tLoss: 733.354431\n",
            "Train Epoch: 299 [14080/60000 (23%)]\tLoss: 717.380981\n",
            "Train Epoch: 299 [15360/60000 (26%)]\tLoss: 729.455811\n",
            "Train Epoch: 299 [16640/60000 (28%)]\tLoss: 734.877808\n",
            "Train Epoch: 299 [17920/60000 (30%)]\tLoss: 698.559143\n",
            "Train Epoch: 299 [19200/60000 (32%)]\tLoss: 754.823547\n",
            "Train Epoch: 299 [20480/60000 (34%)]\tLoss: 734.719360\n",
            "Train Epoch: 299 [21760/60000 (36%)]\tLoss: 728.298096\n",
            "Train Epoch: 299 [23040/60000 (38%)]\tLoss: 754.975647\n",
            "Train Epoch: 299 [24320/60000 (41%)]\tLoss: 745.117065\n",
            "Train Epoch: 299 [25600/60000 (43%)]\tLoss: 763.411377\n",
            "Train Epoch: 299 [26880/60000 (45%)]\tLoss: 738.125854\n",
            "Train Epoch: 299 [28160/60000 (47%)]\tLoss: 731.485413\n",
            "Train Epoch: 299 [29440/60000 (49%)]\tLoss: 722.383118\n",
            "Train Epoch: 299 [30720/60000 (51%)]\tLoss: 741.650940\n",
            "Train Epoch: 299 [32000/60000 (53%)]\tLoss: 752.517578\n",
            "Train Epoch: 299 [33280/60000 (55%)]\tLoss: 724.212646\n",
            "Train Epoch: 299 [34560/60000 (58%)]\tLoss: 742.486206\n",
            "Train Epoch: 299 [35840/60000 (60%)]\tLoss: 745.543030\n",
            "Train Epoch: 299 [37120/60000 (62%)]\tLoss: 741.101868\n",
            "Train Epoch: 299 [38400/60000 (64%)]\tLoss: 720.875793\n",
            "Train Epoch: 299 [39680/60000 (66%)]\tLoss: 749.494446\n",
            "Train Epoch: 299 [40960/60000 (68%)]\tLoss: 732.019348\n",
            "Train Epoch: 299 [42240/60000 (70%)]\tLoss: 739.311462\n",
            "Train Epoch: 299 [43520/60000 (72%)]\tLoss: 706.505859\n",
            "Train Epoch: 299 [44800/60000 (75%)]\tLoss: 734.999268\n",
            "Train Epoch: 299 [46080/60000 (77%)]\tLoss: 719.840759\n",
            "Train Epoch: 299 [47360/60000 (79%)]\tLoss: 710.314514\n",
            "Train Epoch: 299 [48640/60000 (81%)]\tLoss: 748.014282\n",
            "Train Epoch: 299 [49920/60000 (83%)]\tLoss: 741.366333\n",
            "Train Epoch: 299 [51200/60000 (85%)]\tLoss: 748.762817\n",
            "Train Epoch: 299 [52480/60000 (87%)]\tLoss: 747.336975\n",
            "Train Epoch: 299 [53760/60000 (90%)]\tLoss: 726.644165\n",
            "Train Epoch: 299 [55040/60000 (92%)]\tLoss: 743.069397\n",
            "Train Epoch: 299 [56320/60000 (94%)]\tLoss: 741.909058\n",
            "Train Epoch: 299 [57600/60000 (96%)]\tLoss: 729.919556\n",
            "Train Epoch: 299 [58880/60000 (98%)]\tLoss: 768.055969\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978481262922287\n",
            "\n",
            "Train Epoch: 300 [0/60000 (0%)]\tLoss: 725.833252\n",
            "Train Epoch: 300 [1280/60000 (2%)]\tLoss: 730.816589\n",
            "Train Epoch: 300 [2560/60000 (4%)]\tLoss: 740.978027\n",
            "Train Epoch: 300 [3840/60000 (6%)]\tLoss: 730.710632\n",
            "Train Epoch: 300 [5120/60000 (9%)]\tLoss: 751.768188\n",
            "Train Epoch: 300 [6400/60000 (11%)]\tLoss: 740.418152\n",
            "Train Epoch: 300 [7680/60000 (13%)]\tLoss: 730.370300\n",
            "Train Epoch: 300 [8960/60000 (15%)]\tLoss: 743.997253\n",
            "Train Epoch: 300 [10240/60000 (17%)]\tLoss: 740.557495\n",
            "Train Epoch: 300 [11520/60000 (19%)]\tLoss: 729.039429\n",
            "Train Epoch: 300 [12800/60000 (21%)]\tLoss: 724.839539\n",
            "Train Epoch: 300 [14080/60000 (23%)]\tLoss: 733.490906\n",
            "Train Epoch: 300 [15360/60000 (26%)]\tLoss: 725.415466\n",
            "Train Epoch: 300 [16640/60000 (28%)]\tLoss: 717.986450\n",
            "Train Epoch: 300 [17920/60000 (30%)]\tLoss: 737.240417\n",
            "Train Epoch: 300 [19200/60000 (32%)]\tLoss: 737.881531\n",
            "Train Epoch: 300 [20480/60000 (34%)]\tLoss: 722.264038\n",
            "Train Epoch: 300 [21760/60000 (36%)]\tLoss: 758.296692\n",
            "Train Epoch: 300 [23040/60000 (38%)]\tLoss: 746.452515\n",
            "Train Epoch: 300 [24320/60000 (41%)]\tLoss: 728.738403\n",
            "Train Epoch: 300 [25600/60000 (43%)]\tLoss: 732.672668\n",
            "Train Epoch: 300 [26880/60000 (45%)]\tLoss: 732.061646\n",
            "Train Epoch: 300 [28160/60000 (47%)]\tLoss: 726.513977\n",
            "Train Epoch: 300 [29440/60000 (49%)]\tLoss: 767.640747\n",
            "Train Epoch: 300 [30720/60000 (51%)]\tLoss: 717.135010\n",
            "Train Epoch: 300 [32000/60000 (53%)]\tLoss: 725.435608\n",
            "Train Epoch: 300 [33280/60000 (55%)]\tLoss: 736.067505\n",
            "Train Epoch: 300 [34560/60000 (58%)]\tLoss: 734.319336\n",
            "Train Epoch: 300 [35840/60000 (60%)]\tLoss: 729.611145\n",
            "Train Epoch: 300 [37120/60000 (62%)]\tLoss: 740.948792\n",
            "Train Epoch: 300 [38400/60000 (64%)]\tLoss: 742.802856\n",
            "Train Epoch: 300 [39680/60000 (66%)]\tLoss: 723.785400\n",
            "Train Epoch: 300 [40960/60000 (68%)]\tLoss: 728.782776\n",
            "Train Epoch: 300 [42240/60000 (70%)]\tLoss: 732.242798\n",
            "Train Epoch: 300 [43520/60000 (72%)]\tLoss: 759.225220\n",
            "Train Epoch: 300 [44800/60000 (75%)]\tLoss: 742.735352\n",
            "Train Epoch: 300 [46080/60000 (77%)]\tLoss: 714.376465\n",
            "Train Epoch: 300 [47360/60000 (79%)]\tLoss: 712.046326\n",
            "Train Epoch: 300 [48640/60000 (81%)]\tLoss: 736.647095\n",
            "Train Epoch: 300 [49920/60000 (83%)]\tLoss: 723.075378\n",
            "Train Epoch: 300 [51200/60000 (85%)]\tLoss: 722.516968\n",
            "Train Epoch: 300 [52480/60000 (87%)]\tLoss: 717.598572\n",
            "Train Epoch: 300 [53760/60000 (90%)]\tLoss: 723.097961\n",
            "Train Epoch: 300 [55040/60000 (92%)]\tLoss: 716.136353\n",
            "Train Epoch: 300 [56320/60000 (94%)]\tLoss: 741.947632\n",
            "Train Epoch: 300 [57600/60000 (96%)]\tLoss: 730.453247\n",
            "Train Epoch: 300 [58880/60000 (98%)]\tLoss: 767.353821\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783176481723785\n",
            "\n",
            "Train Epoch: 301 [0/60000 (0%)]\tLoss: 734.794922\n",
            "Train Epoch: 301 [1280/60000 (2%)]\tLoss: 745.595764\n",
            "Train Epoch: 301 [2560/60000 (4%)]\tLoss: 741.336609\n",
            "Train Epoch: 301 [3840/60000 (6%)]\tLoss: 743.921448\n",
            "Train Epoch: 301 [5120/60000 (9%)]\tLoss: 760.679077\n",
            "Train Epoch: 301 [6400/60000 (11%)]\tLoss: 715.972229\n",
            "Train Epoch: 301 [7680/60000 (13%)]\tLoss: 740.047913\n",
            "Train Epoch: 301 [8960/60000 (15%)]\tLoss: 731.970520\n",
            "Train Epoch: 301 [10240/60000 (17%)]\tLoss: 754.248657\n",
            "Train Epoch: 301 [11520/60000 (19%)]\tLoss: 747.495789\n",
            "Train Epoch: 301 [12800/60000 (21%)]\tLoss: 726.480774\n",
            "Train Epoch: 301 [14080/60000 (23%)]\tLoss: 725.179688\n",
            "Train Epoch: 301 [15360/60000 (26%)]\tLoss: 735.334351\n",
            "Train Epoch: 301 [16640/60000 (28%)]\tLoss: 740.144958\n",
            "Train Epoch: 301 [17920/60000 (30%)]\tLoss: 721.665771\n",
            "Train Epoch: 301 [19200/60000 (32%)]\tLoss: 715.126770\n",
            "Train Epoch: 301 [20480/60000 (34%)]\tLoss: 736.599976\n",
            "Train Epoch: 301 [21760/60000 (36%)]\tLoss: 754.541321\n",
            "Train Epoch: 301 [23040/60000 (38%)]\tLoss: 732.547852\n",
            "Train Epoch: 301 [24320/60000 (41%)]\tLoss: 743.206970\n",
            "Train Epoch: 301 [25600/60000 (43%)]\tLoss: 745.398560\n",
            "Train Epoch: 301 [26880/60000 (45%)]\tLoss: 728.003235\n",
            "Train Epoch: 301 [28160/60000 (47%)]\tLoss: 711.302124\n",
            "Train Epoch: 301 [29440/60000 (49%)]\tLoss: 723.937256\n",
            "Train Epoch: 301 [30720/60000 (51%)]\tLoss: 747.804016\n",
            "Train Epoch: 301 [32000/60000 (53%)]\tLoss: 739.687622\n",
            "Train Epoch: 301 [33280/60000 (55%)]\tLoss: 730.308533\n",
            "Train Epoch: 301 [34560/60000 (58%)]\tLoss: 731.554138\n",
            "Train Epoch: 301 [35840/60000 (60%)]\tLoss: 736.594482\n",
            "Train Epoch: 301 [37120/60000 (62%)]\tLoss: 743.160461\n",
            "Train Epoch: 301 [38400/60000 (64%)]\tLoss: 735.407104\n",
            "Train Epoch: 301 [39680/60000 (66%)]\tLoss: 747.503418\n",
            "Train Epoch: 301 [40960/60000 (68%)]\tLoss: 726.115417\n",
            "Train Epoch: 301 [42240/60000 (70%)]\tLoss: 724.092041\n",
            "Train Epoch: 301 [43520/60000 (72%)]\tLoss: 730.850159\n",
            "Train Epoch: 301 [44800/60000 (75%)]\tLoss: 742.941711\n",
            "Train Epoch: 301 [46080/60000 (77%)]\tLoss: 732.570862\n",
            "Train Epoch: 301 [47360/60000 (79%)]\tLoss: 726.302429\n",
            "Train Epoch: 301 [48640/60000 (81%)]\tLoss: 743.065369\n",
            "Train Epoch: 301 [49920/60000 (83%)]\tLoss: 745.487793\n",
            "Train Epoch: 301 [51200/60000 (85%)]\tLoss: 733.609558\n",
            "Train Epoch: 301 [52480/60000 (87%)]\tLoss: 736.854065\n",
            "Train Epoch: 301 [53760/60000 (90%)]\tLoss: 742.390137\n",
            "Train Epoch: 301 [55040/60000 (92%)]\tLoss: 743.870972\n",
            "Train Epoch: 301 [56320/60000 (94%)]\tLoss: 744.664368\n",
            "Train Epoch: 301 [57600/60000 (96%)]\tLoss: 710.540649\n",
            "Train Epoch: 301 [58880/60000 (98%)]\tLoss: 731.808777\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978621780872345\n",
            "\n",
            "Train Epoch: 302 [0/60000 (0%)]\tLoss: 751.812683\n",
            "Train Epoch: 302 [1280/60000 (2%)]\tLoss: 747.543396\n",
            "Train Epoch: 302 [2560/60000 (4%)]\tLoss: 733.793152\n",
            "Train Epoch: 302 [3840/60000 (6%)]\tLoss: 725.374146\n",
            "Train Epoch: 302 [5120/60000 (9%)]\tLoss: 738.323486\n",
            "Train Epoch: 302 [6400/60000 (11%)]\tLoss: 754.518188\n",
            "Train Epoch: 302 [7680/60000 (13%)]\tLoss: 737.526001\n",
            "Train Epoch: 302 [8960/60000 (15%)]\tLoss: 737.767151\n",
            "Train Epoch: 302 [10240/60000 (17%)]\tLoss: 734.833435\n",
            "Train Epoch: 302 [11520/60000 (19%)]\tLoss: 742.735901\n",
            "Train Epoch: 302 [12800/60000 (21%)]\tLoss: 726.634216\n",
            "Train Epoch: 302 [14080/60000 (23%)]\tLoss: 707.208008\n",
            "Train Epoch: 302 [15360/60000 (26%)]\tLoss: 714.479309\n",
            "Train Epoch: 302 [16640/60000 (28%)]\tLoss: 715.839905\n",
            "Train Epoch: 302 [17920/60000 (30%)]\tLoss: 757.078308\n",
            "Train Epoch: 302 [19200/60000 (32%)]\tLoss: 747.795349\n",
            "Train Epoch: 302 [20480/60000 (34%)]\tLoss: 754.000366\n",
            "Train Epoch: 302 [21760/60000 (36%)]\tLoss: 745.638062\n",
            "Train Epoch: 302 [23040/60000 (38%)]\tLoss: 704.988770\n",
            "Train Epoch: 302 [24320/60000 (41%)]\tLoss: 741.629395\n",
            "Train Epoch: 302 [25600/60000 (43%)]\tLoss: 749.758667\n",
            "Train Epoch: 302 [26880/60000 (45%)]\tLoss: 733.812134\n",
            "Train Epoch: 302 [28160/60000 (47%)]\tLoss: 761.373596\n",
            "Train Epoch: 302 [29440/60000 (49%)]\tLoss: 736.505554\n",
            "Train Epoch: 302 [30720/60000 (51%)]\tLoss: 733.916077\n",
            "Train Epoch: 302 [32000/60000 (53%)]\tLoss: 753.028931\n",
            "Train Epoch: 302 [33280/60000 (55%)]\tLoss: 738.256348\n",
            "Train Epoch: 302 [34560/60000 (58%)]\tLoss: 734.689270\n",
            "Train Epoch: 302 [35840/60000 (60%)]\tLoss: 735.092651\n",
            "Train Epoch: 302 [37120/60000 (62%)]\tLoss: 749.840332\n",
            "Train Epoch: 302 [38400/60000 (64%)]\tLoss: 759.361206\n",
            "Train Epoch: 302 [39680/60000 (66%)]\tLoss: 743.612793\n",
            "Train Epoch: 302 [40960/60000 (68%)]\tLoss: 741.647095\n",
            "Train Epoch: 302 [42240/60000 (70%)]\tLoss: 732.760376\n",
            "Train Epoch: 302 [43520/60000 (72%)]\tLoss: 735.571716\n",
            "Train Epoch: 302 [44800/60000 (75%)]\tLoss: 735.871277\n",
            "Train Epoch: 302 [46080/60000 (77%)]\tLoss: 734.947998\n",
            "Train Epoch: 302 [47360/60000 (79%)]\tLoss: 719.538208\n",
            "Train Epoch: 302 [48640/60000 (81%)]\tLoss: 739.408813\n",
            "Train Epoch: 302 [49920/60000 (83%)]\tLoss: 734.140259\n",
            "Train Epoch: 302 [51200/60000 (85%)]\tLoss: 745.448486\n",
            "Train Epoch: 302 [52480/60000 (87%)]\tLoss: 725.339478\n",
            "Train Epoch: 302 [53760/60000 (90%)]\tLoss: 754.840271\n",
            "Train Epoch: 302 [55040/60000 (92%)]\tLoss: 766.218811\n",
            "Train Epoch: 302 [56320/60000 (94%)]\tLoss: 701.481445\n",
            "Train Epoch: 302 [57600/60000 (96%)]\tLoss: 750.418213\n",
            "Train Epoch: 302 [58880/60000 (98%)]\tLoss: 709.632874\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782985746860504\n",
            "\n",
            "Train Epoch: 303 [0/60000 (0%)]\tLoss: 739.784607\n",
            "Train Epoch: 303 [1280/60000 (2%)]\tLoss: 727.946838\n",
            "Train Epoch: 303 [2560/60000 (4%)]\tLoss: 732.661377\n",
            "Train Epoch: 303 [3840/60000 (6%)]\tLoss: 743.975647\n",
            "Train Epoch: 303 [5120/60000 (9%)]\tLoss: 758.651794\n",
            "Train Epoch: 303 [6400/60000 (11%)]\tLoss: 731.788208\n",
            "Train Epoch: 303 [7680/60000 (13%)]\tLoss: 716.612488\n",
            "Train Epoch: 303 [8960/60000 (15%)]\tLoss: 731.689209\n",
            "Train Epoch: 303 [10240/60000 (17%)]\tLoss: 735.847473\n",
            "Train Epoch: 303 [11520/60000 (19%)]\tLoss: 720.180237\n",
            "Train Epoch: 303 [12800/60000 (21%)]\tLoss: 711.688904\n",
            "Train Epoch: 303 [14080/60000 (23%)]\tLoss: 736.800476\n",
            "Train Epoch: 303 [15360/60000 (26%)]\tLoss: 722.830139\n",
            "Train Epoch: 303 [16640/60000 (28%)]\tLoss: 731.359863\n",
            "Train Epoch: 303 [17920/60000 (30%)]\tLoss: 697.572937\n",
            "Train Epoch: 303 [19200/60000 (32%)]\tLoss: 734.941406\n",
            "Train Epoch: 303 [20480/60000 (34%)]\tLoss: 725.380310\n",
            "Train Epoch: 303 [21760/60000 (36%)]\tLoss: 749.097839\n",
            "Train Epoch: 303 [23040/60000 (38%)]\tLoss: 754.040283\n",
            "Train Epoch: 303 [24320/60000 (41%)]\tLoss: 716.638000\n",
            "Train Epoch: 303 [25600/60000 (43%)]\tLoss: 776.816833\n",
            "Train Epoch: 303 [26880/60000 (45%)]\tLoss: 749.484985\n",
            "Train Epoch: 303 [28160/60000 (47%)]\tLoss: 742.336853\n",
            "Train Epoch: 303 [29440/60000 (49%)]\tLoss: 717.758057\n",
            "Train Epoch: 303 [30720/60000 (51%)]\tLoss: 749.487732\n",
            "Train Epoch: 303 [32000/60000 (53%)]\tLoss: 764.567444\n",
            "Train Epoch: 303 [33280/60000 (55%)]\tLoss: 742.671692\n",
            "Train Epoch: 303 [34560/60000 (58%)]\tLoss: 759.555664\n",
            "Train Epoch: 303 [35840/60000 (60%)]\tLoss: 742.270691\n",
            "Train Epoch: 303 [37120/60000 (62%)]\tLoss: 743.062561\n",
            "Train Epoch: 303 [38400/60000 (64%)]\tLoss: 729.752136\n",
            "Train Epoch: 303 [39680/60000 (66%)]\tLoss: 734.800415\n",
            "Train Epoch: 303 [40960/60000 (68%)]\tLoss: 722.931335\n",
            "Train Epoch: 303 [42240/60000 (70%)]\tLoss: 729.971558\n",
            "Train Epoch: 303 [43520/60000 (72%)]\tLoss: 728.362793\n",
            "Train Epoch: 303 [44800/60000 (75%)]\tLoss: 726.971558\n",
            "Train Epoch: 303 [46080/60000 (77%)]\tLoss: 704.203491\n",
            "Train Epoch: 303 [47360/60000 (79%)]\tLoss: 716.204163\n",
            "Train Epoch: 303 [48640/60000 (81%)]\tLoss: 737.061035\n",
            "Train Epoch: 303 [49920/60000 (83%)]\tLoss: 733.841675\n",
            "Train Epoch: 303 [51200/60000 (85%)]\tLoss: 736.443054\n",
            "Train Epoch: 303 [52480/60000 (87%)]\tLoss: 744.200317\n",
            "Train Epoch: 303 [53760/60000 (90%)]\tLoss: 752.264160\n",
            "Train Epoch: 303 [55040/60000 (92%)]\tLoss: 750.125122\n",
            "Train Epoch: 303 [56320/60000 (94%)]\tLoss: 718.010315\n",
            "Train Epoch: 303 [57600/60000 (96%)]\tLoss: 743.000549\n",
            "Train Epoch: 303 [58880/60000 (98%)]\tLoss: 718.021484\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19786442816257477\n",
            "\n",
            "Train Epoch: 304 [0/60000 (0%)]\tLoss: 753.858826\n",
            "Train Epoch: 304 [1280/60000 (2%)]\tLoss: 729.133240\n",
            "Train Epoch: 304 [2560/60000 (4%)]\tLoss: 701.723083\n",
            "Train Epoch: 304 [3840/60000 (6%)]\tLoss: 739.245178\n",
            "Train Epoch: 304 [5120/60000 (9%)]\tLoss: 710.585327\n",
            "Train Epoch: 304 [6400/60000 (11%)]\tLoss: 752.802124\n",
            "Train Epoch: 304 [7680/60000 (13%)]\tLoss: 710.405823\n",
            "Train Epoch: 304 [8960/60000 (15%)]\tLoss: 727.453369\n",
            "Train Epoch: 304 [10240/60000 (17%)]\tLoss: 733.879578\n",
            "Train Epoch: 304 [11520/60000 (19%)]\tLoss: 726.763367\n",
            "Train Epoch: 304 [12800/60000 (21%)]\tLoss: 742.296021\n",
            "Train Epoch: 304 [14080/60000 (23%)]\tLoss: 716.417725\n",
            "Train Epoch: 304 [15360/60000 (26%)]\tLoss: 739.015137\n",
            "Train Epoch: 304 [16640/60000 (28%)]\tLoss: 730.454224\n",
            "Train Epoch: 304 [17920/60000 (30%)]\tLoss: 735.175781\n",
            "Train Epoch: 304 [19200/60000 (32%)]\tLoss: 745.213684\n",
            "Train Epoch: 304 [20480/60000 (34%)]\tLoss: 730.068909\n",
            "Train Epoch: 304 [21760/60000 (36%)]\tLoss: 738.848083\n",
            "Train Epoch: 304 [23040/60000 (38%)]\tLoss: 741.303223\n",
            "Train Epoch: 304 [24320/60000 (41%)]\tLoss: 746.981873\n",
            "Train Epoch: 304 [25600/60000 (43%)]\tLoss: 742.383179\n",
            "Train Epoch: 304 [26880/60000 (45%)]\tLoss: 693.032288\n",
            "Train Epoch: 304 [28160/60000 (47%)]\tLoss: 717.241821\n",
            "Train Epoch: 304 [29440/60000 (49%)]\tLoss: 757.100464\n",
            "Train Epoch: 304 [30720/60000 (51%)]\tLoss: 718.319641\n",
            "Train Epoch: 304 [32000/60000 (53%)]\tLoss: 733.395752\n",
            "Train Epoch: 304 [33280/60000 (55%)]\tLoss: 747.614380\n",
            "Train Epoch: 304 [34560/60000 (58%)]\tLoss: 754.957825\n",
            "Train Epoch: 304 [35840/60000 (60%)]\tLoss: 745.960876\n",
            "Train Epoch: 304 [37120/60000 (62%)]\tLoss: 721.509094\n",
            "Train Epoch: 304 [38400/60000 (64%)]\tLoss: 720.205078\n",
            "Train Epoch: 304 [39680/60000 (66%)]\tLoss: 708.618042\n",
            "Train Epoch: 304 [40960/60000 (68%)]\tLoss: 749.065979\n",
            "Train Epoch: 304 [42240/60000 (70%)]\tLoss: 732.101624\n",
            "Train Epoch: 304 [43520/60000 (72%)]\tLoss: 723.787292\n",
            "Train Epoch: 304 [44800/60000 (75%)]\tLoss: 752.698608\n",
            "Train Epoch: 304 [46080/60000 (77%)]\tLoss: 730.449463\n",
            "Train Epoch: 304 [47360/60000 (79%)]\tLoss: 751.532715\n",
            "Train Epoch: 304 [48640/60000 (81%)]\tLoss: 717.722961\n",
            "Train Epoch: 304 [49920/60000 (83%)]\tLoss: 744.419800\n",
            "Train Epoch: 304 [51200/60000 (85%)]\tLoss: 739.910400\n",
            "Train Epoch: 304 [52480/60000 (87%)]\tLoss: 742.758301\n",
            "Train Epoch: 304 [53760/60000 (90%)]\tLoss: 739.579163\n",
            "Train Epoch: 304 [55040/60000 (92%)]\tLoss: 711.850098\n",
            "Train Epoch: 304 [56320/60000 (94%)]\tLoss: 740.495422\n",
            "Train Epoch: 304 [57600/60000 (96%)]\tLoss: 718.567871\n",
            "Train Epoch: 304 [58880/60000 (98%)]\tLoss: 718.218201\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19785121083259583\n",
            "\n",
            "Train Epoch: 305 [0/60000 (0%)]\tLoss: 740.738647\n",
            "Train Epoch: 305 [1280/60000 (2%)]\tLoss: 742.669983\n",
            "Train Epoch: 305 [2560/60000 (4%)]\tLoss: 745.621643\n",
            "Train Epoch: 305 [3840/60000 (6%)]\tLoss: 737.056946\n",
            "Train Epoch: 305 [5120/60000 (9%)]\tLoss: 741.393982\n",
            "Train Epoch: 305 [6400/60000 (11%)]\tLoss: 752.344055\n",
            "Train Epoch: 305 [7680/60000 (13%)]\tLoss: 722.138855\n",
            "Train Epoch: 305 [8960/60000 (15%)]\tLoss: 734.422852\n",
            "Train Epoch: 305 [10240/60000 (17%)]\tLoss: 748.317383\n",
            "Train Epoch: 305 [11520/60000 (19%)]\tLoss: 750.280396\n",
            "Train Epoch: 305 [12800/60000 (21%)]\tLoss: 756.854370\n",
            "Train Epoch: 305 [14080/60000 (23%)]\tLoss: 736.988831\n",
            "Train Epoch: 305 [15360/60000 (26%)]\tLoss: 733.536316\n",
            "Train Epoch: 305 [16640/60000 (28%)]\tLoss: 734.755249\n",
            "Train Epoch: 305 [17920/60000 (30%)]\tLoss: 727.551880\n",
            "Train Epoch: 305 [19200/60000 (32%)]\tLoss: 716.275574\n",
            "Train Epoch: 305 [20480/60000 (34%)]\tLoss: 753.758545\n",
            "Train Epoch: 305 [21760/60000 (36%)]\tLoss: 741.117798\n",
            "Train Epoch: 305 [23040/60000 (38%)]\tLoss: 736.220398\n",
            "Train Epoch: 305 [24320/60000 (41%)]\tLoss: 740.125977\n",
            "Train Epoch: 305 [25600/60000 (43%)]\tLoss: 726.707642\n",
            "Train Epoch: 305 [26880/60000 (45%)]\tLoss: 744.715637\n",
            "Train Epoch: 305 [28160/60000 (47%)]\tLoss: 716.668030\n",
            "Train Epoch: 305 [29440/60000 (49%)]\tLoss: 744.161560\n",
            "Train Epoch: 305 [30720/60000 (51%)]\tLoss: 726.464783\n",
            "Train Epoch: 305 [32000/60000 (53%)]\tLoss: 743.367493\n",
            "Train Epoch: 305 [33280/60000 (55%)]\tLoss: 741.408142\n",
            "Train Epoch: 305 [34560/60000 (58%)]\tLoss: 729.256348\n",
            "Train Epoch: 305 [35840/60000 (60%)]\tLoss: 737.112793\n",
            "Train Epoch: 305 [37120/60000 (62%)]\tLoss: 750.982422\n",
            "Train Epoch: 305 [38400/60000 (64%)]\tLoss: 774.710266\n",
            "Train Epoch: 305 [39680/60000 (66%)]\tLoss: 718.703796\n",
            "Train Epoch: 305 [40960/60000 (68%)]\tLoss: 740.687866\n",
            "Train Epoch: 305 [42240/60000 (70%)]\tLoss: 744.531982\n",
            "Train Epoch: 305 [43520/60000 (72%)]\tLoss: 741.984497\n",
            "Train Epoch: 305 [44800/60000 (75%)]\tLoss: 741.485229\n",
            "Train Epoch: 305 [46080/60000 (77%)]\tLoss: 725.640503\n",
            "Train Epoch: 305 [47360/60000 (79%)]\tLoss: 732.733643\n",
            "Train Epoch: 305 [48640/60000 (81%)]\tLoss: 730.303101\n",
            "Train Epoch: 305 [49920/60000 (83%)]\tLoss: 742.525513\n",
            "Train Epoch: 305 [51200/60000 (85%)]\tLoss: 742.622742\n",
            "Train Epoch: 305 [52480/60000 (87%)]\tLoss: 735.812317\n",
            "Train Epoch: 305 [53760/60000 (90%)]\tLoss: 720.569580\n",
            "Train Epoch: 305 [55040/60000 (92%)]\tLoss: 752.312805\n",
            "Train Epoch: 305 [56320/60000 (94%)]\tLoss: 753.354065\n",
            "Train Epoch: 305 [57600/60000 (96%)]\tLoss: 747.535095\n",
            "Train Epoch: 305 [58880/60000 (98%)]\tLoss: 717.671814\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783581793308258\n",
            "\n",
            "Train Epoch: 306 [0/60000 (0%)]\tLoss: 753.421509\n",
            "Train Epoch: 306 [1280/60000 (2%)]\tLoss: 746.675171\n",
            "Train Epoch: 306 [2560/60000 (4%)]\tLoss: 743.363953\n",
            "Train Epoch: 306 [3840/60000 (6%)]\tLoss: 726.902832\n",
            "Train Epoch: 306 [5120/60000 (9%)]\tLoss: 747.005920\n",
            "Train Epoch: 306 [6400/60000 (11%)]\tLoss: 765.097473\n",
            "Train Epoch: 306 [7680/60000 (13%)]\tLoss: 719.372253\n",
            "Train Epoch: 306 [8960/60000 (15%)]\tLoss: 730.963196\n",
            "Train Epoch: 306 [10240/60000 (17%)]\tLoss: 749.091003\n",
            "Train Epoch: 306 [11520/60000 (19%)]\tLoss: 761.169861\n",
            "Train Epoch: 306 [12800/60000 (21%)]\tLoss: 723.211914\n",
            "Train Epoch: 306 [14080/60000 (23%)]\tLoss: 733.405457\n",
            "Train Epoch: 306 [15360/60000 (26%)]\tLoss: 766.213196\n",
            "Train Epoch: 306 [16640/60000 (28%)]\tLoss: 748.689331\n",
            "Train Epoch: 306 [17920/60000 (30%)]\tLoss: 729.330688\n",
            "Train Epoch: 306 [19200/60000 (32%)]\tLoss: 748.027222\n",
            "Train Epoch: 306 [20480/60000 (34%)]\tLoss: 722.138916\n",
            "Train Epoch: 306 [21760/60000 (36%)]\tLoss: 711.894226\n",
            "Train Epoch: 306 [23040/60000 (38%)]\tLoss: 745.315979\n",
            "Train Epoch: 306 [24320/60000 (41%)]\tLoss: 726.174622\n",
            "Train Epoch: 306 [25600/60000 (43%)]\tLoss: 739.448547\n",
            "Train Epoch: 306 [26880/60000 (45%)]\tLoss: 760.881104\n",
            "Train Epoch: 306 [28160/60000 (47%)]\tLoss: 739.916931\n",
            "Train Epoch: 306 [29440/60000 (49%)]\tLoss: 785.065979\n",
            "Train Epoch: 306 [30720/60000 (51%)]\tLoss: 731.696533\n",
            "Train Epoch: 306 [32000/60000 (53%)]\tLoss: 738.747681\n",
            "Train Epoch: 306 [33280/60000 (55%)]\tLoss: 728.328918\n",
            "Train Epoch: 306 [34560/60000 (58%)]\tLoss: 739.916565\n",
            "Train Epoch: 306 [35840/60000 (60%)]\tLoss: 726.807129\n",
            "Train Epoch: 306 [37120/60000 (62%)]\tLoss: 740.139587\n",
            "Train Epoch: 306 [38400/60000 (64%)]\tLoss: 721.942017\n",
            "Train Epoch: 306 [39680/60000 (66%)]\tLoss: 737.497498\n",
            "Train Epoch: 306 [40960/60000 (68%)]\tLoss: 710.363770\n",
            "Train Epoch: 306 [42240/60000 (70%)]\tLoss: 726.400818\n",
            "Train Epoch: 306 [43520/60000 (72%)]\tLoss: 769.919434\n",
            "Train Epoch: 306 [44800/60000 (75%)]\tLoss: 765.955505\n",
            "Train Epoch: 306 [46080/60000 (77%)]\tLoss: 724.747742\n",
            "Train Epoch: 306 [47360/60000 (79%)]\tLoss: 769.670105\n",
            "Train Epoch: 306 [48640/60000 (81%)]\tLoss: 713.025452\n",
            "Train Epoch: 306 [49920/60000 (83%)]\tLoss: 717.985291\n",
            "Train Epoch: 306 [51200/60000 (85%)]\tLoss: 733.835876\n",
            "Train Epoch: 306 [52480/60000 (87%)]\tLoss: 722.647766\n",
            "Train Epoch: 306 [53760/60000 (90%)]\tLoss: 733.983276\n",
            "Train Epoch: 306 [55040/60000 (92%)]\tLoss: 748.449097\n",
            "Train Epoch: 306 [56320/60000 (94%)]\tLoss: 708.328735\n",
            "Train Epoch: 306 [57600/60000 (96%)]\tLoss: 747.291382\n",
            "Train Epoch: 306 [58880/60000 (98%)]\tLoss: 711.641296\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782395660877228\n",
            "\n",
            "Train Epoch: 307 [0/60000 (0%)]\tLoss: 769.854614\n",
            "Train Epoch: 307 [1280/60000 (2%)]\tLoss: 731.888733\n",
            "Train Epoch: 307 [2560/60000 (4%)]\tLoss: 748.384521\n",
            "Train Epoch: 307 [3840/60000 (6%)]\tLoss: 748.275269\n",
            "Train Epoch: 307 [5120/60000 (9%)]\tLoss: 717.244019\n",
            "Train Epoch: 307 [6400/60000 (11%)]\tLoss: 732.291199\n",
            "Train Epoch: 307 [7680/60000 (13%)]\tLoss: 743.410278\n",
            "Train Epoch: 307 [8960/60000 (15%)]\tLoss: 725.934509\n",
            "Train Epoch: 307 [10240/60000 (17%)]\tLoss: 742.709534\n",
            "Train Epoch: 307 [11520/60000 (19%)]\tLoss: 751.260071\n",
            "Train Epoch: 307 [12800/60000 (21%)]\tLoss: 741.746887\n",
            "Train Epoch: 307 [14080/60000 (23%)]\tLoss: 764.784363\n",
            "Train Epoch: 307 [15360/60000 (26%)]\tLoss: 757.594788\n",
            "Train Epoch: 307 [16640/60000 (28%)]\tLoss: 693.748657\n",
            "Train Epoch: 307 [17920/60000 (30%)]\tLoss: 734.627441\n",
            "Train Epoch: 307 [19200/60000 (32%)]\tLoss: 737.660034\n",
            "Train Epoch: 307 [20480/60000 (34%)]\tLoss: 718.637207\n",
            "Train Epoch: 307 [21760/60000 (36%)]\tLoss: 750.930176\n",
            "Train Epoch: 307 [23040/60000 (38%)]\tLoss: 732.414490\n",
            "Train Epoch: 307 [24320/60000 (41%)]\tLoss: 750.859070\n",
            "Train Epoch: 307 [25600/60000 (43%)]\tLoss: 711.746948\n",
            "Train Epoch: 307 [26880/60000 (45%)]\tLoss: 717.889771\n",
            "Train Epoch: 307 [28160/60000 (47%)]\tLoss: 752.832825\n",
            "Train Epoch: 307 [29440/60000 (49%)]\tLoss: 721.302490\n",
            "Train Epoch: 307 [30720/60000 (51%)]\tLoss: 756.310547\n",
            "Train Epoch: 307 [32000/60000 (53%)]\tLoss: 760.556946\n",
            "Train Epoch: 307 [33280/60000 (55%)]\tLoss: 732.995544\n",
            "Train Epoch: 307 [34560/60000 (58%)]\tLoss: 725.452148\n",
            "Train Epoch: 307 [35840/60000 (60%)]\tLoss: 719.430420\n",
            "Train Epoch: 307 [37120/60000 (62%)]\tLoss: 727.832336\n",
            "Train Epoch: 307 [38400/60000 (64%)]\tLoss: 761.011719\n",
            "Train Epoch: 307 [39680/60000 (66%)]\tLoss: 755.104065\n",
            "Train Epoch: 307 [40960/60000 (68%)]\tLoss: 720.151550\n",
            "Train Epoch: 307 [42240/60000 (70%)]\tLoss: 737.531006\n",
            "Train Epoch: 307 [43520/60000 (72%)]\tLoss: 719.435547\n",
            "Train Epoch: 307 [44800/60000 (75%)]\tLoss: 744.820557\n",
            "Train Epoch: 307 [46080/60000 (77%)]\tLoss: 731.420593\n",
            "Train Epoch: 307 [47360/60000 (79%)]\tLoss: 715.113403\n",
            "Train Epoch: 307 [48640/60000 (81%)]\tLoss: 720.507812\n",
            "Train Epoch: 307 [49920/60000 (83%)]\tLoss: 754.439148\n",
            "Train Epoch: 307 [51200/60000 (85%)]\tLoss: 714.832764\n",
            "Train Epoch: 307 [52480/60000 (87%)]\tLoss: 740.421082\n",
            "Train Epoch: 307 [53760/60000 (90%)]\tLoss: 747.269043\n",
            "Train Epoch: 307 [55040/60000 (92%)]\tLoss: 720.714417\n",
            "Train Epoch: 307 [56320/60000 (94%)]\tLoss: 735.256592\n",
            "Train Epoch: 307 [57600/60000 (96%)]\tLoss: 744.882385\n",
            "Train Epoch: 307 [58880/60000 (98%)]\tLoss: 732.741333\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781818985939026\n",
            "\n",
            "Train Epoch: 308 [0/60000 (0%)]\tLoss: 715.024109\n",
            "Train Epoch: 308 [1280/60000 (2%)]\tLoss: 714.650757\n",
            "Train Epoch: 308 [2560/60000 (4%)]\tLoss: 734.104797\n",
            "Train Epoch: 308 [3840/60000 (6%)]\tLoss: 726.408020\n",
            "Train Epoch: 308 [5120/60000 (9%)]\tLoss: 722.720215\n",
            "Train Epoch: 308 [6400/60000 (11%)]\tLoss: 738.295593\n",
            "Train Epoch: 308 [7680/60000 (13%)]\tLoss: 729.450012\n",
            "Train Epoch: 308 [8960/60000 (15%)]\tLoss: 748.771851\n",
            "Train Epoch: 308 [10240/60000 (17%)]\tLoss: 728.928589\n",
            "Train Epoch: 308 [11520/60000 (19%)]\tLoss: 743.636841\n",
            "Train Epoch: 308 [12800/60000 (21%)]\tLoss: 751.498230\n",
            "Train Epoch: 308 [14080/60000 (23%)]\tLoss: 732.925110\n",
            "Train Epoch: 308 [15360/60000 (26%)]\tLoss: 715.978943\n",
            "Train Epoch: 308 [16640/60000 (28%)]\tLoss: 743.907471\n",
            "Train Epoch: 308 [17920/60000 (30%)]\tLoss: 721.487061\n",
            "Train Epoch: 308 [19200/60000 (32%)]\tLoss: 749.393799\n",
            "Train Epoch: 308 [20480/60000 (34%)]\tLoss: 720.752991\n",
            "Train Epoch: 308 [21760/60000 (36%)]\tLoss: 737.964844\n",
            "Train Epoch: 308 [23040/60000 (38%)]\tLoss: 740.762451\n",
            "Train Epoch: 308 [24320/60000 (41%)]\tLoss: 743.932190\n",
            "Train Epoch: 308 [25600/60000 (43%)]\tLoss: 735.738281\n",
            "Train Epoch: 308 [26880/60000 (45%)]\tLoss: 724.264832\n",
            "Train Epoch: 308 [28160/60000 (47%)]\tLoss: 745.973938\n",
            "Train Epoch: 308 [29440/60000 (49%)]\tLoss: 735.539612\n",
            "Train Epoch: 308 [30720/60000 (51%)]\tLoss: 730.066772\n",
            "Train Epoch: 308 [32000/60000 (53%)]\tLoss: 739.238525\n",
            "Train Epoch: 308 [33280/60000 (55%)]\tLoss: 693.469177\n",
            "Train Epoch: 308 [34560/60000 (58%)]\tLoss: 715.574341\n",
            "Train Epoch: 308 [35840/60000 (60%)]\tLoss: 731.056519\n",
            "Train Epoch: 308 [37120/60000 (62%)]\tLoss: 729.403809\n",
            "Train Epoch: 308 [38400/60000 (64%)]\tLoss: 738.326538\n",
            "Train Epoch: 308 [39680/60000 (66%)]\tLoss: 706.644409\n",
            "Train Epoch: 308 [40960/60000 (68%)]\tLoss: 750.532104\n",
            "Train Epoch: 308 [42240/60000 (70%)]\tLoss: 743.310425\n",
            "Train Epoch: 308 [43520/60000 (72%)]\tLoss: 750.373230\n",
            "Train Epoch: 308 [44800/60000 (75%)]\tLoss: 713.683411\n",
            "Train Epoch: 308 [46080/60000 (77%)]\tLoss: 729.724670\n",
            "Train Epoch: 308 [47360/60000 (79%)]\tLoss: 732.276245\n",
            "Train Epoch: 308 [48640/60000 (81%)]\tLoss: 709.895203\n",
            "Train Epoch: 308 [49920/60000 (83%)]\tLoss: 749.669312\n",
            "Train Epoch: 308 [51200/60000 (85%)]\tLoss: 724.029968\n",
            "Train Epoch: 308 [52480/60000 (87%)]\tLoss: 746.608765\n",
            "Train Epoch: 308 [53760/60000 (90%)]\tLoss: 735.348755\n",
            "Train Epoch: 308 [55040/60000 (92%)]\tLoss: 712.066956\n",
            "Train Epoch: 308 [56320/60000 (94%)]\tLoss: 743.662354\n",
            "Train Epoch: 308 [57600/60000 (96%)]\tLoss: 756.537109\n",
            "Train Epoch: 308 [58880/60000 (98%)]\tLoss: 726.543152\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978348046541214\n",
            "\n",
            "Train Epoch: 309 [0/60000 (0%)]\tLoss: 747.179382\n",
            "Train Epoch: 309 [1280/60000 (2%)]\tLoss: 748.565796\n",
            "Train Epoch: 309 [2560/60000 (4%)]\tLoss: 727.438416\n",
            "Train Epoch: 309 [3840/60000 (6%)]\tLoss: 753.213379\n",
            "Train Epoch: 309 [5120/60000 (9%)]\tLoss: 740.853455\n",
            "Train Epoch: 309 [6400/60000 (11%)]\tLoss: 734.241211\n",
            "Train Epoch: 309 [7680/60000 (13%)]\tLoss: 734.720825\n",
            "Train Epoch: 309 [8960/60000 (15%)]\tLoss: 741.100586\n",
            "Train Epoch: 309 [10240/60000 (17%)]\tLoss: 723.644531\n",
            "Train Epoch: 309 [11520/60000 (19%)]\tLoss: 753.420288\n",
            "Train Epoch: 309 [12800/60000 (21%)]\tLoss: 740.174927\n",
            "Train Epoch: 309 [14080/60000 (23%)]\tLoss: 744.870422\n",
            "Train Epoch: 309 [15360/60000 (26%)]\tLoss: 759.136963\n",
            "Train Epoch: 309 [16640/60000 (28%)]\tLoss: 714.543762\n",
            "Train Epoch: 309 [17920/60000 (30%)]\tLoss: 726.925171\n",
            "Train Epoch: 309 [19200/60000 (32%)]\tLoss: 734.630310\n",
            "Train Epoch: 309 [20480/60000 (34%)]\tLoss: 712.988098\n",
            "Train Epoch: 309 [21760/60000 (36%)]\tLoss: 729.724304\n",
            "Train Epoch: 309 [23040/60000 (38%)]\tLoss: 734.685974\n",
            "Train Epoch: 309 [24320/60000 (41%)]\tLoss: 722.308533\n",
            "Train Epoch: 309 [25600/60000 (43%)]\tLoss: 744.913696\n",
            "Train Epoch: 309 [26880/60000 (45%)]\tLoss: 721.449707\n",
            "Train Epoch: 309 [28160/60000 (47%)]\tLoss: 757.015564\n",
            "Train Epoch: 309 [29440/60000 (49%)]\tLoss: 728.390991\n",
            "Train Epoch: 309 [30720/60000 (51%)]\tLoss: 720.208984\n",
            "Train Epoch: 309 [32000/60000 (53%)]\tLoss: 732.132751\n",
            "Train Epoch: 309 [33280/60000 (55%)]\tLoss: 747.044373\n",
            "Train Epoch: 309 [34560/60000 (58%)]\tLoss: 722.016113\n",
            "Train Epoch: 309 [35840/60000 (60%)]\tLoss: 740.035278\n",
            "Train Epoch: 309 [37120/60000 (62%)]\tLoss: 746.522827\n",
            "Train Epoch: 309 [38400/60000 (64%)]\tLoss: 767.818787\n",
            "Train Epoch: 309 [39680/60000 (66%)]\tLoss: 737.392578\n",
            "Train Epoch: 309 [40960/60000 (68%)]\tLoss: 727.562073\n",
            "Train Epoch: 309 [42240/60000 (70%)]\tLoss: 751.832397\n",
            "Train Epoch: 309 [43520/60000 (72%)]\tLoss: 738.491272\n",
            "Train Epoch: 309 [44800/60000 (75%)]\tLoss: 766.994812\n",
            "Train Epoch: 309 [46080/60000 (77%)]\tLoss: 744.388245\n",
            "Train Epoch: 309 [47360/60000 (79%)]\tLoss: 742.132874\n",
            "Train Epoch: 309 [48640/60000 (81%)]\tLoss: 748.586975\n",
            "Train Epoch: 309 [49920/60000 (83%)]\tLoss: 723.076721\n",
            "Train Epoch: 309 [51200/60000 (85%)]\tLoss: 747.088562\n",
            "Train Epoch: 309 [52480/60000 (87%)]\tLoss: 737.137878\n",
            "Train Epoch: 309 [53760/60000 (90%)]\tLoss: 724.639587\n",
            "Train Epoch: 309 [55040/60000 (92%)]\tLoss: 718.908203\n",
            "Train Epoch: 309 [56320/60000 (94%)]\tLoss: 741.840820\n",
            "Train Epoch: 309 [57600/60000 (96%)]\tLoss: 727.962952\n",
            "Train Epoch: 309 [58880/60000 (98%)]\tLoss: 746.270264\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783084094524384\n",
            "\n",
            "Train Epoch: 310 [0/60000 (0%)]\tLoss: 706.246338\n",
            "Train Epoch: 310 [1280/60000 (2%)]\tLoss: 741.267334\n",
            "Train Epoch: 310 [2560/60000 (4%)]\tLoss: 729.848389\n",
            "Train Epoch: 310 [3840/60000 (6%)]\tLoss: 735.800598\n",
            "Train Epoch: 310 [5120/60000 (9%)]\tLoss: 752.452515\n",
            "Train Epoch: 310 [6400/60000 (11%)]\tLoss: 749.162598\n",
            "Train Epoch: 310 [7680/60000 (13%)]\tLoss: 734.163025\n",
            "Train Epoch: 310 [8960/60000 (15%)]\tLoss: 751.006775\n",
            "Train Epoch: 310 [10240/60000 (17%)]\tLoss: 758.955078\n",
            "Train Epoch: 310 [11520/60000 (19%)]\tLoss: 737.030823\n",
            "Train Epoch: 310 [12800/60000 (21%)]\tLoss: 715.674744\n",
            "Train Epoch: 310 [14080/60000 (23%)]\tLoss: 770.683350\n",
            "Train Epoch: 310 [15360/60000 (26%)]\tLoss: 728.939758\n",
            "Train Epoch: 310 [16640/60000 (28%)]\tLoss: 733.757568\n",
            "Train Epoch: 310 [17920/60000 (30%)]\tLoss: 738.203735\n",
            "Train Epoch: 310 [19200/60000 (32%)]\tLoss: 722.577271\n",
            "Train Epoch: 310 [20480/60000 (34%)]\tLoss: 704.335266\n",
            "Train Epoch: 310 [21760/60000 (36%)]\tLoss: 728.148804\n",
            "Train Epoch: 310 [23040/60000 (38%)]\tLoss: 754.286743\n",
            "Train Epoch: 310 [24320/60000 (41%)]\tLoss: 744.060364\n",
            "Train Epoch: 310 [25600/60000 (43%)]\tLoss: 726.247742\n",
            "Train Epoch: 310 [26880/60000 (45%)]\tLoss: 736.870728\n",
            "Train Epoch: 310 [28160/60000 (47%)]\tLoss: 738.067932\n",
            "Train Epoch: 310 [29440/60000 (49%)]\tLoss: 740.720215\n",
            "Train Epoch: 310 [30720/60000 (51%)]\tLoss: 768.439819\n",
            "Train Epoch: 310 [32000/60000 (53%)]\tLoss: 741.672913\n",
            "Train Epoch: 310 [33280/60000 (55%)]\tLoss: 725.313477\n",
            "Train Epoch: 310 [34560/60000 (58%)]\tLoss: 727.123779\n",
            "Train Epoch: 310 [35840/60000 (60%)]\tLoss: 706.309448\n",
            "Train Epoch: 310 [37120/60000 (62%)]\tLoss: 734.038818\n",
            "Train Epoch: 310 [38400/60000 (64%)]\tLoss: 733.935852\n",
            "Train Epoch: 310 [39680/60000 (66%)]\tLoss: 733.431091\n",
            "Train Epoch: 310 [40960/60000 (68%)]\tLoss: 726.840210\n",
            "Train Epoch: 310 [42240/60000 (70%)]\tLoss: 750.492859\n",
            "Train Epoch: 310 [43520/60000 (72%)]\tLoss: 758.872681\n",
            "Train Epoch: 310 [44800/60000 (75%)]\tLoss: 731.683350\n",
            "Train Epoch: 310 [46080/60000 (77%)]\tLoss: 735.859497\n",
            "Train Epoch: 310 [47360/60000 (79%)]\tLoss: 736.221741\n",
            "Train Epoch: 310 [48640/60000 (81%)]\tLoss: 735.978210\n",
            "Train Epoch: 310 [49920/60000 (83%)]\tLoss: 746.137817\n",
            "Train Epoch: 310 [51200/60000 (85%)]\tLoss: 738.579407\n",
            "Train Epoch: 310 [52480/60000 (87%)]\tLoss: 711.840881\n",
            "Train Epoch: 310 [53760/60000 (90%)]\tLoss: 732.012024\n",
            "Train Epoch: 310 [55040/60000 (92%)]\tLoss: 754.500000\n",
            "Train Epoch: 310 [56320/60000 (94%)]\tLoss: 720.756348\n",
            "Train Epoch: 310 [57600/60000 (96%)]\tLoss: 746.324158\n",
            "Train Epoch: 310 [58880/60000 (98%)]\tLoss: 751.971558\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.1978389173746109\n",
            "\n",
            "Train Epoch: 311 [0/60000 (0%)]\tLoss: 704.901306\n",
            "Train Epoch: 311 [1280/60000 (2%)]\tLoss: 726.585632\n",
            "Train Epoch: 311 [2560/60000 (4%)]\tLoss: 707.489563\n",
            "Train Epoch: 311 [3840/60000 (6%)]\tLoss: 736.260315\n",
            "Train Epoch: 311 [5120/60000 (9%)]\tLoss: 750.686646\n",
            "Train Epoch: 311 [6400/60000 (11%)]\tLoss: 738.891479\n",
            "Train Epoch: 311 [7680/60000 (13%)]\tLoss: 740.252258\n",
            "Train Epoch: 311 [8960/60000 (15%)]\tLoss: 741.358215\n",
            "Train Epoch: 311 [10240/60000 (17%)]\tLoss: 727.148926\n",
            "Train Epoch: 311 [11520/60000 (19%)]\tLoss: 703.248840\n",
            "Train Epoch: 311 [12800/60000 (21%)]\tLoss: 743.613953\n",
            "Train Epoch: 311 [14080/60000 (23%)]\tLoss: 720.484314\n",
            "Train Epoch: 311 [15360/60000 (26%)]\tLoss: 770.112122\n",
            "Train Epoch: 311 [16640/60000 (28%)]\tLoss: 739.069458\n",
            "Train Epoch: 311 [17920/60000 (30%)]\tLoss: 710.610168\n",
            "Train Epoch: 311 [19200/60000 (32%)]\tLoss: 725.307800\n",
            "Train Epoch: 311 [20480/60000 (34%)]\tLoss: 746.584473\n",
            "Train Epoch: 311 [21760/60000 (36%)]\tLoss: 739.419250\n",
            "Train Epoch: 311 [23040/60000 (38%)]\tLoss: 730.783691\n",
            "Train Epoch: 311 [24320/60000 (41%)]\tLoss: 747.791809\n",
            "Train Epoch: 311 [25600/60000 (43%)]\tLoss: 725.678284\n",
            "Train Epoch: 311 [26880/60000 (45%)]\tLoss: 738.079346\n",
            "Train Epoch: 311 [28160/60000 (47%)]\tLoss: 730.709473\n",
            "Train Epoch: 311 [29440/60000 (49%)]\tLoss: 750.161987\n",
            "Train Epoch: 311 [30720/60000 (51%)]\tLoss: 736.549866\n",
            "Train Epoch: 311 [32000/60000 (53%)]\tLoss: 747.473145\n",
            "Train Epoch: 311 [33280/60000 (55%)]\tLoss: 733.263367\n",
            "Train Epoch: 311 [34560/60000 (58%)]\tLoss: 709.935608\n",
            "Train Epoch: 311 [35840/60000 (60%)]\tLoss: 728.948853\n",
            "Train Epoch: 311 [37120/60000 (62%)]\tLoss: 730.762146\n",
            "Train Epoch: 311 [38400/60000 (64%)]\tLoss: 746.848633\n",
            "Train Epoch: 311 [39680/60000 (66%)]\tLoss: 746.111511\n",
            "Train Epoch: 311 [40960/60000 (68%)]\tLoss: 759.552612\n",
            "Train Epoch: 311 [42240/60000 (70%)]\tLoss: 734.625000\n",
            "Train Epoch: 311 [43520/60000 (72%)]\tLoss: 737.189941\n",
            "Train Epoch: 311 [44800/60000 (75%)]\tLoss: 741.244629\n",
            "Train Epoch: 311 [46080/60000 (77%)]\tLoss: 728.366699\n",
            "Train Epoch: 311 [47360/60000 (79%)]\tLoss: 740.570312\n",
            "Train Epoch: 311 [48640/60000 (81%)]\tLoss: 722.589844\n",
            "Train Epoch: 311 [49920/60000 (83%)]\tLoss: 736.300659\n",
            "Train Epoch: 311 [51200/60000 (85%)]\tLoss: 728.075989\n",
            "Train Epoch: 311 [52480/60000 (87%)]\tLoss: 736.183105\n",
            "Train Epoch: 311 [53760/60000 (90%)]\tLoss: 755.020264\n",
            "Train Epoch: 311 [55040/60000 (92%)]\tLoss: 742.664429\n",
            "Train Epoch: 311 [56320/60000 (94%)]\tLoss: 742.652344\n",
            "Train Epoch: 311 [57600/60000 (96%)]\tLoss: 743.505432\n",
            "Train Epoch: 311 [58880/60000 (98%)]\tLoss: 740.523376\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.1978306919336319\n",
            "\n",
            "Train Epoch: 312 [0/60000 (0%)]\tLoss: 751.592163\n",
            "Train Epoch: 312 [1280/60000 (2%)]\tLoss: 738.247559\n",
            "Train Epoch: 312 [2560/60000 (4%)]\tLoss: 749.281311\n",
            "Train Epoch: 312 [3840/60000 (6%)]\tLoss: 725.776001\n",
            "Train Epoch: 312 [5120/60000 (9%)]\tLoss: 714.830566\n",
            "Train Epoch: 312 [6400/60000 (11%)]\tLoss: 711.972656\n",
            "Train Epoch: 312 [7680/60000 (13%)]\tLoss: 725.523438\n",
            "Train Epoch: 312 [8960/60000 (15%)]\tLoss: 735.291199\n",
            "Train Epoch: 312 [10240/60000 (17%)]\tLoss: 725.389526\n",
            "Train Epoch: 312 [11520/60000 (19%)]\tLoss: 737.796997\n",
            "Train Epoch: 312 [12800/60000 (21%)]\tLoss: 736.354553\n",
            "Train Epoch: 312 [14080/60000 (23%)]\tLoss: 727.837952\n",
            "Train Epoch: 312 [15360/60000 (26%)]\tLoss: 730.131897\n",
            "Train Epoch: 312 [16640/60000 (28%)]\tLoss: 716.506409\n",
            "Train Epoch: 312 [17920/60000 (30%)]\tLoss: 751.445435\n",
            "Train Epoch: 312 [19200/60000 (32%)]\tLoss: 740.574097\n",
            "Train Epoch: 312 [20480/60000 (34%)]\tLoss: 727.267212\n",
            "Train Epoch: 312 [21760/60000 (36%)]\tLoss: 745.086670\n",
            "Train Epoch: 312 [23040/60000 (38%)]\tLoss: 735.140991\n",
            "Train Epoch: 312 [24320/60000 (41%)]\tLoss: 741.154419\n",
            "Train Epoch: 312 [25600/60000 (43%)]\tLoss: 752.938110\n",
            "Train Epoch: 312 [26880/60000 (45%)]\tLoss: 732.732666\n",
            "Train Epoch: 312 [28160/60000 (47%)]\tLoss: 730.708191\n",
            "Train Epoch: 312 [29440/60000 (49%)]\tLoss: 728.675659\n",
            "Train Epoch: 312 [30720/60000 (51%)]\tLoss: 756.195251\n",
            "Train Epoch: 312 [32000/60000 (53%)]\tLoss: 733.506531\n",
            "Train Epoch: 312 [33280/60000 (55%)]\tLoss: 711.830933\n",
            "Train Epoch: 312 [34560/60000 (58%)]\tLoss: 739.739502\n",
            "Train Epoch: 312 [35840/60000 (60%)]\tLoss: 721.719116\n",
            "Train Epoch: 312 [37120/60000 (62%)]\tLoss: 750.471375\n",
            "Train Epoch: 312 [38400/60000 (64%)]\tLoss: 747.773071\n",
            "Train Epoch: 312 [39680/60000 (66%)]\tLoss: 755.628113\n",
            "Train Epoch: 312 [40960/60000 (68%)]\tLoss: 748.595642\n",
            "Train Epoch: 312 [42240/60000 (70%)]\tLoss: 731.352966\n",
            "Train Epoch: 312 [43520/60000 (72%)]\tLoss: 747.708557\n",
            "Train Epoch: 312 [44800/60000 (75%)]\tLoss: 749.134338\n",
            "Train Epoch: 312 [46080/60000 (77%)]\tLoss: 740.089050\n",
            "Train Epoch: 312 [47360/60000 (79%)]\tLoss: 721.238403\n",
            "Train Epoch: 312 [48640/60000 (81%)]\tLoss: 733.106384\n",
            "Train Epoch: 312 [49920/60000 (83%)]\tLoss: 745.214050\n",
            "Train Epoch: 312 [51200/60000 (85%)]\tLoss: 720.562134\n",
            "Train Epoch: 312 [52480/60000 (87%)]\tLoss: 729.129150\n",
            "Train Epoch: 312 [53760/60000 (90%)]\tLoss: 743.059814\n",
            "Train Epoch: 312 [55040/60000 (92%)]\tLoss: 724.584045\n",
            "Train Epoch: 312 [56320/60000 (94%)]\tLoss: 750.352661\n",
            "Train Epoch: 312 [57600/60000 (96%)]\tLoss: 745.129639\n",
            "Train Epoch: 312 [58880/60000 (98%)]\tLoss: 754.276672\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19780375063419342\n",
            "\n",
            "Train Epoch: 313 [0/60000 (0%)]\tLoss: 746.453979\n",
            "Train Epoch: 313 [1280/60000 (2%)]\tLoss: 723.322571\n",
            "Train Epoch: 313 [2560/60000 (4%)]\tLoss: 718.726257\n",
            "Train Epoch: 313 [3840/60000 (6%)]\tLoss: 764.824951\n",
            "Train Epoch: 313 [5120/60000 (9%)]\tLoss: 717.072754\n",
            "Train Epoch: 313 [6400/60000 (11%)]\tLoss: 748.681641\n",
            "Train Epoch: 313 [7680/60000 (13%)]\tLoss: 738.825500\n",
            "Train Epoch: 313 [8960/60000 (15%)]\tLoss: 732.452209\n",
            "Train Epoch: 313 [10240/60000 (17%)]\tLoss: 744.697754\n",
            "Train Epoch: 313 [11520/60000 (19%)]\tLoss: 735.510437\n",
            "Train Epoch: 313 [12800/60000 (21%)]\tLoss: 765.683472\n",
            "Train Epoch: 313 [14080/60000 (23%)]\tLoss: 738.842163\n",
            "Train Epoch: 313 [15360/60000 (26%)]\tLoss: 748.170715\n",
            "Train Epoch: 313 [16640/60000 (28%)]\tLoss: 749.036133\n",
            "Train Epoch: 313 [17920/60000 (30%)]\tLoss: 725.369934\n",
            "Train Epoch: 313 [19200/60000 (32%)]\tLoss: 734.986572\n",
            "Train Epoch: 313 [20480/60000 (34%)]\tLoss: 725.931335\n",
            "Train Epoch: 313 [21760/60000 (36%)]\tLoss: 731.099426\n",
            "Train Epoch: 313 [23040/60000 (38%)]\tLoss: 735.829712\n",
            "Train Epoch: 313 [24320/60000 (41%)]\tLoss: 725.364075\n",
            "Train Epoch: 313 [25600/60000 (43%)]\tLoss: 746.928284\n",
            "Train Epoch: 313 [26880/60000 (45%)]\tLoss: 741.574341\n",
            "Train Epoch: 313 [28160/60000 (47%)]\tLoss: 735.540771\n",
            "Train Epoch: 313 [29440/60000 (49%)]\tLoss: 738.473511\n",
            "Train Epoch: 313 [30720/60000 (51%)]\tLoss: 721.962463\n",
            "Train Epoch: 313 [32000/60000 (53%)]\tLoss: 735.677673\n",
            "Train Epoch: 313 [33280/60000 (55%)]\tLoss: 745.855957\n",
            "Train Epoch: 313 [34560/60000 (58%)]\tLoss: 723.895142\n",
            "Train Epoch: 313 [35840/60000 (60%)]\tLoss: 737.506958\n",
            "Train Epoch: 313 [37120/60000 (62%)]\tLoss: 719.856262\n",
            "Train Epoch: 313 [38400/60000 (64%)]\tLoss: 768.556091\n",
            "Train Epoch: 313 [39680/60000 (66%)]\tLoss: 722.964111\n",
            "Train Epoch: 313 [40960/60000 (68%)]\tLoss: 742.470398\n",
            "Train Epoch: 313 [42240/60000 (70%)]\tLoss: 726.709351\n",
            "Train Epoch: 313 [43520/60000 (72%)]\tLoss: 734.285583\n",
            "Train Epoch: 313 [44800/60000 (75%)]\tLoss: 768.019165\n",
            "Train Epoch: 313 [46080/60000 (77%)]\tLoss: 718.113770\n",
            "Train Epoch: 313 [47360/60000 (79%)]\tLoss: 739.236450\n",
            "Train Epoch: 313 [48640/60000 (81%)]\tLoss: 751.891602\n",
            "Train Epoch: 313 [49920/60000 (83%)]\tLoss: 741.444397\n",
            "Train Epoch: 313 [51200/60000 (85%)]\tLoss: 743.417053\n",
            "Train Epoch: 313 [52480/60000 (87%)]\tLoss: 722.993958\n",
            "Train Epoch: 313 [53760/60000 (90%)]\tLoss: 742.763672\n",
            "Train Epoch: 313 [55040/60000 (92%)]\tLoss: 733.900574\n",
            "Train Epoch: 313 [56320/60000 (94%)]\tLoss: 726.244446\n",
            "Train Epoch: 313 [57600/60000 (96%)]\tLoss: 747.727905\n",
            "Train Epoch: 313 [58880/60000 (98%)]\tLoss: 737.865234\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19781626760959625\n",
            "\n",
            "Train Epoch: 314 [0/60000 (0%)]\tLoss: 728.251038\n",
            "Train Epoch: 314 [1280/60000 (2%)]\tLoss: 738.444580\n",
            "Train Epoch: 314 [2560/60000 (4%)]\tLoss: 720.752258\n",
            "Train Epoch: 314 [3840/60000 (6%)]\tLoss: 730.518799\n",
            "Train Epoch: 314 [5120/60000 (9%)]\tLoss: 763.634888\n",
            "Train Epoch: 314 [6400/60000 (11%)]\tLoss: 742.223022\n",
            "Train Epoch: 314 [7680/60000 (13%)]\tLoss: 735.587524\n",
            "Train Epoch: 314 [8960/60000 (15%)]\tLoss: 722.948181\n",
            "Train Epoch: 314 [10240/60000 (17%)]\tLoss: 739.602417\n",
            "Train Epoch: 314 [11520/60000 (19%)]\tLoss: 738.625061\n",
            "Train Epoch: 314 [12800/60000 (21%)]\tLoss: 751.168701\n",
            "Train Epoch: 314 [14080/60000 (23%)]\tLoss: 735.121643\n",
            "Train Epoch: 314 [15360/60000 (26%)]\tLoss: 758.793213\n",
            "Train Epoch: 314 [16640/60000 (28%)]\tLoss: 710.183960\n",
            "Train Epoch: 314 [17920/60000 (30%)]\tLoss: 765.561218\n",
            "Train Epoch: 314 [19200/60000 (32%)]\tLoss: 728.598877\n",
            "Train Epoch: 314 [20480/60000 (34%)]\tLoss: 732.014282\n",
            "Train Epoch: 314 [21760/60000 (36%)]\tLoss: 731.727173\n",
            "Train Epoch: 314 [23040/60000 (38%)]\tLoss: 737.922119\n",
            "Train Epoch: 314 [24320/60000 (41%)]\tLoss: 736.332214\n",
            "Train Epoch: 314 [25600/60000 (43%)]\tLoss: 763.233887\n",
            "Train Epoch: 314 [26880/60000 (45%)]\tLoss: 732.856567\n",
            "Train Epoch: 314 [28160/60000 (47%)]\tLoss: 749.825684\n",
            "Train Epoch: 314 [29440/60000 (49%)]\tLoss: 750.011353\n",
            "Train Epoch: 314 [30720/60000 (51%)]\tLoss: 733.150513\n",
            "Train Epoch: 314 [32000/60000 (53%)]\tLoss: 743.514099\n",
            "Train Epoch: 314 [33280/60000 (55%)]\tLoss: 728.368103\n",
            "Train Epoch: 314 [34560/60000 (58%)]\tLoss: 734.674622\n",
            "Train Epoch: 314 [35840/60000 (60%)]\tLoss: 712.058594\n",
            "Train Epoch: 314 [37120/60000 (62%)]\tLoss: 720.820862\n",
            "Train Epoch: 314 [38400/60000 (64%)]\tLoss: 759.163391\n",
            "Train Epoch: 314 [39680/60000 (66%)]\tLoss: 743.500000\n",
            "Train Epoch: 314 [40960/60000 (68%)]\tLoss: 719.120361\n",
            "Train Epoch: 314 [42240/60000 (70%)]\tLoss: 727.610413\n",
            "Train Epoch: 314 [43520/60000 (72%)]\tLoss: 723.163818\n",
            "Train Epoch: 314 [44800/60000 (75%)]\tLoss: 719.776245\n",
            "Train Epoch: 314 [46080/60000 (77%)]\tLoss: 728.388184\n",
            "Train Epoch: 314 [47360/60000 (79%)]\tLoss: 736.804443\n",
            "Train Epoch: 314 [48640/60000 (81%)]\tLoss: 734.734558\n",
            "Train Epoch: 314 [49920/60000 (83%)]\tLoss: 736.601562\n",
            "Train Epoch: 314 [51200/60000 (85%)]\tLoss: 727.048279\n",
            "Train Epoch: 314 [52480/60000 (87%)]\tLoss: 712.294495\n",
            "Train Epoch: 314 [53760/60000 (90%)]\tLoss: 728.628052\n",
            "Train Epoch: 314 [55040/60000 (92%)]\tLoss: 713.686401\n",
            "Train Epoch: 314 [56320/60000 (94%)]\tLoss: 723.764404\n",
            "Train Epoch: 314 [57600/60000 (96%)]\tLoss: 721.582458\n",
            "Train Epoch: 314 [58880/60000 (98%)]\tLoss: 726.995483\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19784817099571228\n",
            "\n",
            "Train Epoch: 315 [0/60000 (0%)]\tLoss: 730.519104\n",
            "Train Epoch: 315 [1280/60000 (2%)]\tLoss: 736.624268\n",
            "Train Epoch: 315 [2560/60000 (4%)]\tLoss: 754.204590\n",
            "Train Epoch: 315 [3840/60000 (6%)]\tLoss: 746.625427\n",
            "Train Epoch: 315 [5120/60000 (9%)]\tLoss: 741.984009\n",
            "Train Epoch: 315 [6400/60000 (11%)]\tLoss: 738.667358\n",
            "Train Epoch: 315 [7680/60000 (13%)]\tLoss: 742.751221\n",
            "Train Epoch: 315 [8960/60000 (15%)]\tLoss: 745.305847\n",
            "Train Epoch: 315 [10240/60000 (17%)]\tLoss: 754.792297\n",
            "Train Epoch: 315 [11520/60000 (19%)]\tLoss: 748.758789\n",
            "Train Epoch: 315 [12800/60000 (21%)]\tLoss: 732.014709\n",
            "Train Epoch: 315 [14080/60000 (23%)]\tLoss: 720.056580\n",
            "Train Epoch: 315 [15360/60000 (26%)]\tLoss: 705.917175\n",
            "Train Epoch: 315 [16640/60000 (28%)]\tLoss: 723.798523\n",
            "Train Epoch: 315 [17920/60000 (30%)]\tLoss: 744.765320\n",
            "Train Epoch: 315 [19200/60000 (32%)]\tLoss: 714.076538\n",
            "Train Epoch: 315 [20480/60000 (34%)]\tLoss: 713.195740\n",
            "Train Epoch: 315 [21760/60000 (36%)]\tLoss: 741.976929\n",
            "Train Epoch: 315 [23040/60000 (38%)]\tLoss: 743.313904\n",
            "Train Epoch: 315 [24320/60000 (41%)]\tLoss: 741.572754\n",
            "Train Epoch: 315 [25600/60000 (43%)]\tLoss: 733.446716\n",
            "Train Epoch: 315 [26880/60000 (45%)]\tLoss: 755.199280\n",
            "Train Epoch: 315 [28160/60000 (47%)]\tLoss: 745.293640\n",
            "Train Epoch: 315 [29440/60000 (49%)]\tLoss: 745.412720\n",
            "Train Epoch: 315 [30720/60000 (51%)]\tLoss: 710.421997\n",
            "Train Epoch: 315 [32000/60000 (53%)]\tLoss: 759.409851\n",
            "Train Epoch: 315 [33280/60000 (55%)]\tLoss: 745.136780\n",
            "Train Epoch: 315 [34560/60000 (58%)]\tLoss: 738.266907\n",
            "Train Epoch: 315 [35840/60000 (60%)]\tLoss: 711.915771\n",
            "Train Epoch: 315 [37120/60000 (62%)]\tLoss: 748.952820\n",
            "Train Epoch: 315 [38400/60000 (64%)]\tLoss: 740.903809\n",
            "Train Epoch: 315 [39680/60000 (66%)]\tLoss: 726.196655\n",
            "Train Epoch: 315 [40960/60000 (68%)]\tLoss: 731.351624\n",
            "Train Epoch: 315 [42240/60000 (70%)]\tLoss: 702.503906\n",
            "Train Epoch: 315 [43520/60000 (72%)]\tLoss: 735.506897\n",
            "Train Epoch: 315 [44800/60000 (75%)]\tLoss: 727.089905\n",
            "Train Epoch: 315 [46080/60000 (77%)]\tLoss: 745.314880\n",
            "Train Epoch: 315 [47360/60000 (79%)]\tLoss: 728.446045\n",
            "Train Epoch: 315 [48640/60000 (81%)]\tLoss: 741.395020\n",
            "Train Epoch: 315 [49920/60000 (83%)]\tLoss: 724.292725\n",
            "Train Epoch: 315 [51200/60000 (85%)]\tLoss: 758.814514\n",
            "Train Epoch: 315 [52480/60000 (87%)]\tLoss: 742.599426\n",
            "Train Epoch: 315 [53760/60000 (90%)]\tLoss: 716.849915\n",
            "Train Epoch: 315 [55040/60000 (92%)]\tLoss: 736.125732\n",
            "Train Epoch: 315 [56320/60000 (94%)]\tLoss: 726.678162\n",
            "Train Epoch: 315 [57600/60000 (96%)]\tLoss: 728.026672\n",
            "Train Epoch: 315 [58880/60000 (98%)]\tLoss: 721.625549\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19782975316047668\n",
            "\n",
            "Train Epoch: 316 [0/60000 (0%)]\tLoss: 722.545471\n",
            "Train Epoch: 316 [1280/60000 (2%)]\tLoss: 743.395081\n",
            "Train Epoch: 316 [2560/60000 (4%)]\tLoss: 739.207703\n",
            "Train Epoch: 316 [3840/60000 (6%)]\tLoss: 721.184265\n",
            "Train Epoch: 316 [5120/60000 (9%)]\tLoss: 729.298462\n",
            "Train Epoch: 316 [6400/60000 (11%)]\tLoss: 764.961487\n",
            "Train Epoch: 316 [7680/60000 (13%)]\tLoss: 745.445984\n",
            "Train Epoch: 316 [8960/60000 (15%)]\tLoss: 726.619690\n",
            "Train Epoch: 316 [10240/60000 (17%)]\tLoss: 738.241699\n",
            "Train Epoch: 316 [11520/60000 (19%)]\tLoss: 766.157166\n",
            "Train Epoch: 316 [12800/60000 (21%)]\tLoss: 742.777893\n",
            "Train Epoch: 316 [14080/60000 (23%)]\tLoss: 748.803528\n",
            "Train Epoch: 316 [15360/60000 (26%)]\tLoss: 745.954407\n",
            "Train Epoch: 316 [16640/60000 (28%)]\tLoss: 730.155518\n",
            "Train Epoch: 316 [17920/60000 (30%)]\tLoss: 721.855957\n",
            "Train Epoch: 316 [19200/60000 (32%)]\tLoss: 764.709900\n",
            "Train Epoch: 316 [20480/60000 (34%)]\tLoss: 754.137024\n",
            "Train Epoch: 316 [21760/60000 (36%)]\tLoss: 714.990967\n",
            "Train Epoch: 316 [23040/60000 (38%)]\tLoss: 737.611267\n",
            "Train Epoch: 316 [24320/60000 (41%)]\tLoss: 714.853149\n",
            "Train Epoch: 316 [25600/60000 (43%)]\tLoss: 738.946045\n",
            "Train Epoch: 316 [26880/60000 (45%)]\tLoss: 767.378052\n",
            "Train Epoch: 316 [28160/60000 (47%)]\tLoss: 752.244751\n",
            "Train Epoch: 316 [29440/60000 (49%)]\tLoss: 713.114258\n",
            "Train Epoch: 316 [30720/60000 (51%)]\tLoss: 741.093689\n",
            "Train Epoch: 316 [32000/60000 (53%)]\tLoss: 742.241943\n",
            "Train Epoch: 316 [33280/60000 (55%)]\tLoss: 727.595154\n",
            "Train Epoch: 316 [34560/60000 (58%)]\tLoss: 706.586365\n",
            "Train Epoch: 316 [35840/60000 (60%)]\tLoss: 749.307617\n",
            "Train Epoch: 316 [37120/60000 (62%)]\tLoss: 725.005676\n",
            "Train Epoch: 316 [38400/60000 (64%)]\tLoss: 753.207947\n",
            "Train Epoch: 316 [39680/60000 (66%)]\tLoss: 757.313232\n",
            "Train Epoch: 316 [40960/60000 (68%)]\tLoss: 737.729187\n",
            "Train Epoch: 316 [42240/60000 (70%)]\tLoss: 752.767822\n",
            "Train Epoch: 316 [43520/60000 (72%)]\tLoss: 750.169678\n",
            "Train Epoch: 316 [44800/60000 (75%)]\tLoss: 730.609558\n",
            "Train Epoch: 316 [46080/60000 (77%)]\tLoss: 733.253357\n",
            "Train Epoch: 316 [47360/60000 (79%)]\tLoss: 731.590759\n",
            "Train Epoch: 316 [48640/60000 (81%)]\tLoss: 739.607178\n",
            "Train Epoch: 316 [49920/60000 (83%)]\tLoss: 737.536011\n",
            "Train Epoch: 316 [51200/60000 (85%)]\tLoss: 741.124512\n",
            "Train Epoch: 316 [52480/60000 (87%)]\tLoss: 766.882751\n",
            "Train Epoch: 316 [53760/60000 (90%)]\tLoss: 736.083130\n",
            "Train Epoch: 316 [55040/60000 (92%)]\tLoss: 747.191223\n",
            "Train Epoch: 316 [56320/60000 (94%)]\tLoss: 747.422485\n",
            "Train Epoch: 316 [57600/60000 (96%)]\tLoss: 767.772278\n",
            "Train Epoch: 316 [58880/60000 (98%)]\tLoss: 722.181458\n",
            "\n",
            "Test set: Average loss: 0.0940, Reconstruction error: 0.19783300161361694\n",
            "\n",
            "Train Epoch: 317 [0/60000 (0%)]\tLoss: 746.755676\n",
            "Train Epoch: 317 [1280/60000 (2%)]\tLoss: 730.678162\n",
            "Train Epoch: 317 [2560/60000 (4%)]\tLoss: 730.641541\n",
            "Train Epoch: 317 [3840/60000 (6%)]\tLoss: 740.043213\n",
            "Train Epoch: 317 [5120/60000 (9%)]\tLoss: 764.826111\n",
            "Train Epoch: 317 [6400/60000 (11%)]\tLoss: 743.158813\n",
            "Train Epoch: 317 [7680/60000 (13%)]\tLoss: 758.077454\n",
            "Train Epoch: 317 [8960/60000 (15%)]\tLoss: 746.722168\n",
            "Train Epoch: 317 [10240/60000 (17%)]\tLoss: 748.391235\n",
            "Train Epoch: 317 [11520/60000 (19%)]\tLoss: 732.386658\n",
            "Train Epoch: 317 [12800/60000 (21%)]\tLoss: 718.324524\n",
            "Train Epoch: 317 [14080/60000 (23%)]\tLoss: 695.164978\n",
            "Train Epoch: 317 [15360/60000 (26%)]\tLoss: 728.807129\n",
            "Train Epoch: 317 [16640/60000 (28%)]\tLoss: 741.052979\n",
            "Train Epoch: 317 [17920/60000 (30%)]\tLoss: 734.469666\n",
            "Train Epoch: 317 [19200/60000 (32%)]\tLoss: 696.284485\n",
            "Train Epoch: 317 [20480/60000 (34%)]\tLoss: 733.380554\n",
            "Train Epoch: 317 [21760/60000 (36%)]\tLoss: 740.291382\n",
            "Train Epoch: 317 [23040/60000 (38%)]\tLoss: 714.464233\n",
            "Train Epoch: 317 [24320/60000 (41%)]\tLoss: 748.066284\n",
            "Train Epoch: 317 [25600/60000 (43%)]\tLoss: 750.157288\n",
            "Train Epoch: 317 [26880/60000 (45%)]\tLoss: 736.521057\n",
            "Train Epoch: 317 [28160/60000 (47%)]\tLoss: 750.442383\n",
            "Train Epoch: 317 [29440/60000 (49%)]\tLoss: 723.087830\n",
            "Train Epoch: 317 [30720/60000 (51%)]\tLoss: 755.408386\n",
            "Train Epoch: 317 [32000/60000 (53%)]\tLoss: 709.115295\n",
            "Train Epoch: 317 [33280/60000 (55%)]\tLoss: 756.929382\n",
            "Train Epoch: 317 [34560/60000 (58%)]\tLoss: 722.542297\n",
            "Train Epoch: 317 [35840/60000 (60%)]\tLoss: 748.296936\n",
            "Train Epoch: 317 [37120/60000 (62%)]\tLoss: 772.974976\n",
            "Train Epoch: 317 [38400/60000 (64%)]\tLoss: 727.371338\n",
            "Train Epoch: 317 [39680/60000 (66%)]\tLoss: 738.758545\n",
            "Train Epoch: 317 [40960/60000 (68%)]\tLoss: 746.933044\n",
            "Train Epoch: 317 [42240/60000 (70%)]\tLoss: 752.539795\n",
            "Train Epoch: 317 [43520/60000 (72%)]\tLoss: 741.901306\n",
            "Train Epoch: 317 [44800/60000 (75%)]\tLoss: 740.292053\n",
            "Train Epoch: 317 [46080/60000 (77%)]\tLoss: 754.807617\n",
            "Train Epoch: 317 [47360/60000 (79%)]\tLoss: 738.783569\n",
            "Train Epoch: 317 [48640/60000 (81%)]\tLoss: 736.819946\n",
            "Train Epoch: 317 [49920/60000 (83%)]\tLoss: 741.952576\n",
            "Train Epoch: 317 [51200/60000 (85%)]\tLoss: 735.663635\n",
            "Train Epoch: 317 [52480/60000 (87%)]\tLoss: 770.367554\n",
            "Train Epoch: 317 [53760/60000 (90%)]\tLoss: 710.546143\n",
            "Train Epoch: 317 [55040/60000 (92%)]\tLoss: 739.183289\n",
            "Train Epoch: 317 [56320/60000 (94%)]\tLoss: 755.348999\n",
            "Train Epoch: 317 [57600/60000 (96%)]\tLoss: 725.425964\n",
            "Train Epoch: 317 [58880/60000 (98%)]\tLoss: 746.434875\n",
            "\n",
            "Test set: Average loss: 0.0941, Reconstruction error: 0.19783633947372437\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-040b9043c264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msbvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msbvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-d57ded6dc630>\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5aDfJvHXxkT",
        "colab_type": "code",
        "outputId": "92147d81-e26e-4d27-9cd4-44237663de26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "sbvae.visualize_embeddings(-1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvqSAEhERX1JAiYiIL/0NO+TYlzt0cgkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJstAFVO7Lls",
        "colab_type": "code",
        "outputId": "1072182f-fc68-47c1-f624-59e2ab6967a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sample = torch.randn(64, 50).to(device)\n",
        "sample = torch.sigmoid(sbvae.decode(sample)).reshape(64, 28, 28).cpu().detach().numpy()\n",
        "f, axarr = plt.subplots(8,8)\n",
        "for i in range(64):\n",
        "  axarr[i//8,i%8].imshow(sample[i])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAD8CAYAAABaZT40AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9S5V2UGXVVZZZb1LVXbQZZVVVlnvUv3/Wh3ENCDy3XYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 64 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}